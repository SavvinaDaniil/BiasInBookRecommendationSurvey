Index,State,Title,Dataset used,Dataset_used_clean,Problem,Algorithms,Type of feedback,Solution,Metrics,Result on book dataset,Type of prediction,Bias definition,Considers book characteristics,Dataset preprocessing,Bias perspective,Hyperparameter tuning,Code provided,Framework,Bias type,Action,Link,Venue,Venue_renamed,Publisher,Type,Year
1,Done,Flexibly manipulating popularity bias for tackling trade-offs in recommendation,Amazon-books,Amazon-books,Popularity bias is hard to deal with because sometimes popularity implies quality. So we don’t want to mitigate it for everyone.,"BPR, LightGCN, SGL, SmiGCL, DirectAU, MostPop, DICE, CPR, DirectMag",Implicit,Method DirectMag that allows platform/user to manupulate pop bias flexibly. (one parameter γ),"Novelty@20, Recall@20 per user group, NDCG@20 per user group","- Their method has high average novelty and accuracy (for different gammas)
- A trade off exists between novelty and accuracy but γ helps to deal with it, though not as well for amazon books as for yelp",Ranking,"we define it as the degree to which the model gives higher scores to more popular
items",No,No,Item,Yes,No,"CPR, DirectAU, SELFRec","Popularity, Statistical","Mitigating",https://www.sciencedirect.com/science/article/pii/S0306457323003436,Information Processing & Management,IPM,Elsevier,missing,2024
3,Done,Bias-Aware Hierarchical Clustering for detecting the discriminated groups of users in recommendation systems,Book-crossing,Book-crossing,"RS are optimized for the mainstream trends, minority preferences are discriminated against. Also black box, so hard to track hidden biases.","NMF, SVD, UserKNN, DeepFM, AFM, DCN, FiBiNET, WDL",Explicit,Bias-Aware Hierarchical Clustering algorithm that makes user clusters to find ones whose needs are not met by a black box RS. Then post-hoc explainer describes most important features of these users.,"NDCG histogram, clustering quality",discriminated user features not in the paper for BC! NDCG is lower for small groups of discriminated users than bigger groups.,"Both","If there exists a group of similar users 𝑈𝐵 ⊂ 𝑈 such that the average metric 𝑀(𝐴(𝑢𝑏)), 𝑢𝑏 ∈ 𝑈𝐵 is significantly lower
than the average metric for the rest of the users 𝑀(𝐴(𝑢)), 𝑢 ∈ 𝑈 ⧵ 𝑈𝐵 at a given confidence level 𝛼, we define the group 𝑈𝐵 as
discriminated by the algorithm 𝐴 in terms of metric 𝑀.",Yes,Yes,User,Yes,No,"DeepCTR, Surprise",Social,Measuring,https://www.sciencedirect.com/science/article/pii/S0306457321000285,Information Processing & Management,IPM,Elsevier,missing,2021
4,Done,Explaining recommender systems fairness and accuracy through the lens of data characteristics,Book-crossing,Book-crossing,DCs have impact on RS (CF) accuracy and fairness.,"UserKNN (various versions), ItemKNN (various versions), MF, SVD, BPR, PMF, NMF",Explicit,Regression based explanatory modelling. Experimental validation of a set of DCs with 23400 simulation with 3 datasets to derive their explanatory power over accuracy and fairness towards user gender and age.,"MAD (fairness) between NDCG between groups, and MAP between groups",the chosen DCs have tiny explanatory power of fairness on BC. also very few of them (popavg and spacesize the most impactful),Both,"1. However, these long-tail items have less chance to be recommended
since they have less historical feedback
2. The popularity profile of the user is measured as the average popularity of items consumed by a user.
Once averaged over users, the computed score provides an evaluation of the popularity bias",No,Yes,User,No,No,Cornac,"Age, Gender, Social",Measuring,https://www.sciencedirect.com/science/article/pii/S0306457321001503,Information Processing & Management,IPM,Elsevier,missing,2021
5,Done,Provider fairness across continents in collaborative recommender systems,Book-crossing,Book-crossing,"Items (movies, books) may be exposed differently by RS based on their continent of production — geographic imbalance. ","UserKNN, ItemKNN, BPR, BiasedMF, SVD++, MostPopular, Random",Explicit,"Enrich datasets with continent info. measure. Run RS and measure exposure per group. Mitigate with re-ranking approach that regulates visibility and exposure, comparison with state of the art.","Group representation, Disparate visibility, disparate exposure","90% produced in NA, BiasedMF has the best disparate visibility and exposure, both before and after the mitigation. The mitigation works. Other results!!!","Both","Popular items get over-recommended, to the detriment of long-tail ones.",Yes,No,Provider,No,No,LibRec,"Exposure, Popularity, Statistical, Visibility","Mitigating",https://www.sciencedirect.com/science/article/pii/S030645732100203X,Information Processing & Management,IPM,Elsevier,missing,2022
6,Done,Spiral of Silence and Its Application in Recommender Systems,Amazon-books,Amazon-books,"Spiral of silence means that missing ratings are biased because users are more likely to show ratings if they agree with the opinion climate. The majority opinion receives growing popularity, others are pushed back.","PMF, UserKNN, ItemKNN, BiasedMF, CPT-v, Logit-vd, RAPMF",Explicit,"Verify the existence of the issue. Study the characteristics of the issue (opinion climate, hardcore minority opinion users). Model missing ratings in 4 ways. Experimentally show that they all outperform state of the art.",,"For items with majority opinion, there were monotonic trends (section 2). Hardcore users feel more obligated to underrate a highly appreciated item than to save a criticized item (section 4). NO RS PROCESS ON THE BOOK DATASET",Ranking,,,,,,,,Statistical,Mitigating,10.1109/TKDE.2020.3013973,IEEE Transactions on Knowledge and Data Engineering,TKDE,IEEE,missing,2022
7,Done,Exploring author gender in book rating and recommendation,"Amazon-books, Book-crossing, GoodReads","Amazon-books, Book-crossing, GoodReads",Some of the patterns tracked by RS are irrelevant or discriminatory - position of women and minorities in the publishing world.,"UserKNN, ItemKNN, BiasedMF (ALS), BPR","Both",Examine the reponse of CF to the distribution of creator gender: compare profile with recommendation list. + simple re-ranking strategies to meet balance goals.,Representation in profile vs in recommendation,"Low representation of women (varies), On average, books by female authors are interacted with more frequently than books by male authors. representation in RS lists generally matches user profile gender balance, re-ranking has small effect on accuracy. in Amazon and and GoodReads, female author representation seems to be better among the most popular books than among the less-popular ones. In the
Amazon and BookCrossing data, we see high frequency of all-male and all-female profiles. We observe a population tendency to rate male authors more frequently than female authors in all data sets. Implicit-feedback algorithms tend to reflect a user’s profile gender balance in their recommendation lists. Explicit-feedback algorithms are much less responsive to their users’ input profiles, likely due to the fact that they rely on rating values, not the mere presence of a book.",Ranking,"al. 2016), interact with issues of bias, discrimination, and stereotyping.
Social impact is not a new concern in recommender systems. Balkanization (van
Alstyne and Brynjolfsson 2005) (popularized by Pariser (2011) as the notion of a filter
bubble), is one example of this concern: Do recommender systems enrich our lives
and participation in society or isolate us in echo chambers?",Yes,Yes,Author,Yes,Yes,Lenskit,"Gender, Social","Mitigating",http://link.springer.com/article/10.1007/s11257-020-09284-2,User Modeling and User-Adapted Interaction,UMUAI,Springer,Article,2021
9,Done,A bias detection tree approach for detecting disparities in a recommendation model’s errors,Book-crossing,Book-crossing,"RS algorithms are blackboxes so it’s hard to figure out whether combinations of attributes lead to more errors, which means there’s hidden bias.","DL two-tower CF RS (for bias detection only), SlopeOne, KNN, Co-Clustering, NMF, SVD (for BDT and minimax model selection)",Explicit,"Bias Detecrion Tree: model-agnostic technique to automatically detect combination of user-item attrivutes correlated with unequal treatment. Also, minimax model selection technique to improve performance for biased attributes.","Value error, Absolute error, Underestimate error, Overestimate error, total bias,","All error disparities in BC, especially high absolute error disparity. For BookCrossing, the most significant bias is associated with the activity and popularity features. Interestingly, we observe that these discrimination rules are differentfor the training and the test sets—for instance, the least active users have the smallest training error while they have the largest error on the test set. Clearly, these are the cases when a model overfits on some groups from the training set (cold-start users in this case), and the predictions on the test set are less accurate. SVD the winner for BC.",Rating,"applying a global objective results in optimizing
the mainstream trends while minority preference groups, aswell as those interested
in niche products, are not represented well (Beutel et al. 2017; Chen et al. 2020). Given
a lack of understanding of the dataset characteristics and insufficient diversity of represented
individuals, such approaches inevitably lead to amplifying hidden data biases
and existing disparities",Yes,No,"Item, User",Yes,Yes,Surprise,Social,"Mitigating",http://link.springer.com/article/10.1007/s11257-022-09334-x,User Modeling and User-Adapted Interaction,UMUAI,Springer,Article,2023
10,Done,Exploring potential biases towards blockbuster items in ranking-based recommendations,Goodbooks,Goodbooks,"Frequently consumed does not always mean well liked too, while literature usually only regards that as popularity when studying bias.","MostPop, Random, ItemAvg, UserKNN, ItemKNN, SlopeOne, SVD, SVD++, NMF, Co-Clustering",Explicit,"Consider blockbusters (=well liked+popular) and whether ranking-based RS is biased in favour of them. Practical formulation to measure blockbusterness. Then explore biases by 10 algorithms. ","Long-tail Coverafe (LTC), APLT, Novelty, Recommended Frequency (RF), Average popularity","GB imbalanced in terms of positive ratings. Also unbalanced towards a small set of items in terms of their blockbuster score. Low overlap between popular and liked items. Lower bias for GB (maybe because it’s sparse), more results per algorithm. ","Both","both popular and highly-liked, which we refer to as blockbuster
items, and to investigate whether the recommendation algorithms impose a consider
able
bias in favor of the blockbuster items",No,Yes,Item,No,Yes,Surprise,"Blockbuster, Statistical","Mitigating",http://link.springer.com/article/10.1007/s10618-022-00860-1,Data Mining and Knowledge Discovery,DMDK,Springer,Article,2022
11,Done,The Unfairness of Popularity Bias in Book Recommendation,Book-crossing,Book-crossing,Popularity bias.,"Random, MostPop, UserKNN, MF, PMF, NMF, WMF, BPR, PF, NeuMF, VAECF",Explicit,Divide in user groups. Evaluate RS on accuracy and popularity bias. Show tradeoff between personalization and unfairness for Diverse and Best seller groups.,"visual correlation, ΔGAP, correlation between NDCG and ΔGAP","83% of users have read at least 20% of unpopular books in their profile. users with larger profile sizes havediverse tastes and interact with a substantial amount of unpopular items. Some algorithms propagate bias (unfairly), some not. Most algorithms unfair towards users with niche or diverse tastes.","Both","one limitation of CF algorithms
is the problem of popularity bias which causes the popular (i.e., shorthead)
items to be over-emphasized in the recommendation list. In contrast, the
majority of less popular (i.e., long-tail) items do not get enough visibility in
the recommendation lists",Yes,Yes,"Item, User",No,Yes,Cornac,"Popularity, Statistical",Measuring,http://link.springer.com/chapter/10.1007/978-3-031-09316-6_7,Advances in Bias and Fairness in Information Retrieval,BIAS@ECIR,Springer,Chapter,2022
12,Done,Popularity Bias in Collaborative Filtering-Based Multimedia Recommender Systems,Book-crossing,Book-crossing,Popularity bias that leads to the underrepresentation of unpopular items in the recommendation lists.,"UserKNN, UserKNNAvg, NMF, CoClustering",Explicit,"Divide in user groups, divide items in groups, evaluate pop bias on item and user level.","visual correlation, MAE per user group.",positive relationship between an item’s popularity and how often this item gets recommended. lowest recommendation accuracy for LowPop users.,"Both","popularity bias, which leads
to the overrepresentation of popular items in the recommendation lists",No,Yes,"Item, User",No,Yes,Surprise,"Popularity, Statistical",Measuring,http://link.springer.com/chapter/10.1007/978-3-031-09316-6_1,Advances in Bias and Fairness in Information Retrieval,BIAS@ECIR,Springer,Chapter,2022
13,Done,Utilizing Implicit Feedback for User Mainstreaminess Evaluation and Bias Detection in Recommender Systems,Book-crossing,Book-crossing,"Mainstream bias: RS favor mainstream users, inferior results to non-mainstream users —> unfair. Profile size hasn’t been taken into account.",VAECF,Implicit,"Extend a previous paper to include profile size, then evaluate bias in an interpretable way. ","Recall of mainstream users, recommendation utility per user group",Their result are somewhat similar to other approaches when it comes to BookCrossing. Good performance for mainstream users,Ranking,"Mainstream bias refers to the phenomenon
that models favor mainstream users with desirable recommendations while nonmainstream
users receive low-quality results and could leave permanently",Mentions the fact that there are different domains,Yes,User,No,Yes,Unknown,"Mainstream, Statistical",Measuring,http://link.springer.com/chapter/10.1007/978-3-031-37249-0_4,Advances in Bias and Fairness in Information Retrieval,BIAS@ECIR,Springer,Chapter,2023
14,Done,An Offer You Cannot Refuse? Trends in the Coercive Impact of Amazon Book Recommendations,Amazon-books,Amazon-books,"Theory that companies have incentives to make users predictable (i.e., that their preferences are harder to change) via influencing their consumption.",Irrelevant,Explicit,"Test the theory using Barrier-to-exit metric on amazon book ratings 1998-2023, linear mixed-effects model with crossed random effects for user and categories to check the evolution. They also call for more/better research.",Barrier-to-exit,(With caveats and limitations) it has become more difficutl for these users to change preferences.,Irrelevant,,,,,,,,Statistical,Measuring,http://link.springer.com/chapter/10.1007/978-3-031-71975-2_1,Advances in Bias and Fairness in Information Retrieval,BIAS@ECIR,Springer,Chapter,2025
15,Done,Privacy-Preserving Fair Item Ranking,Book-crossing,Book-crossing,Computational methods for fair item ranking rely on disclosing user data to a centralized server → privacy concerns,SVD,Explicit,"DP and SMPC incorporation to advance item fairness post-processing but remain private. (extension of amortized attention ranking mechanism to be privacy-reserving). Evaluation on privacy, fairness, quality.",Unfairness measure,"Their privacy preserving method has similar results to the centralized version, but there is a trade off when it comes to the privacy budget.",Ranking,"Users are then susceptible to paying most of their
attention to the highest-ranked items in the ranked list, causing position bias",No,Unmentioned yes,"Are they the same?, Item, Provider",Unclear,No,Surprise,"Position, Statistical","Mitigating",http://link.springer.com/chapter/10.1007/978-3-031-28238-6_13,Advances in Information Retrieval,ECIR,Springer,Chapter,2023
16,Done,Towards Optimizing Ranking in Grid-Layout for Provider-Side Fairness,GoodReads,GoodReads,"Normally work on provider-side fairness is focused on linear layouts, not grid views common in streaming platforms. ","UserKNN, ItemKNN, WRLS, BPR",Implicit,Grid-aware re-ranking algorithm to optimize grid layouts for provider-side fairness by adapting existing techniques by taking into account grid features — starting point. (fair in terms of gender of aythors),AWRF,"Fairness is improved when re-ranking is grid aware, depending on the browsing model. Also depends on device size and column sizes.",Ranking,"provider-side fairness: whether exposure to users is fairly distributed
among items and the people who created them.",Yes,No,"Are they the same?, Author, Provider",Unclear,No,Lenskit,"Gender, Social","Mitigating",http://link.springer.com/chapter/10.1007/978-3-031-56069-9_7,Advances in Information Retrieval,ECIR,Springer,Chapter,2024
17.1,Done,On the instability of embeddings for recommender systems: the case of matrix factorization,Book-crossing,Book-crossing,"MF embeddings are unstable and are very different for even small differences of inital values, especially so for long-tail items!","BPR, FunkMF, PMF, UserKNN, ItemKNN, SLIM, PureSVD",Implicit,Adaptation (NN MF) which mitigate instability issues and achieve better accuracy in the long tail.,"Long-tail accuracy (MAP, Recall)","Dramatic instability for original algorithms. Quite low long-tail accuracy for most algorithms, improvement with NNMF compared to the original versions (but not all algos).",Ranking,"Unfortunately, most datasets exhibit strong
popularity biases [5]",No,Yes,Item,Yes,Yes,Unknown,"Popularity, Statistical","Mitigating",https://doi.org/10.1145/3412841.3442011,Proceedings of the 36th Annual ACM Symposium on Applied Computing,SAC,ACM,Research,2021
19,Done,Promoting Two-sided Fairness with Adaptive Weights for Providers and Customers in Recommendation,Book-crossing,Book-crossing,Studies often try to improve two-sided fairness (P and C) without thinking about the explicit goal of accuracy.,"BPR, LightGCN",Implicit,"Ada2Fair, a framework which extends the accuracy objective into a controllable loss over the interaction data, which boosts the utility of niche providers and inactive users.","Deviation between provider exposure scores (P-fair), deviation between NDCG@20 of users (C-fair), AF-score (trade off between fairness and bias)","(Publishers as providers) paretto optimality over the baselines (other fairness methods) for both algorithms, all added components contribute to that (ablation study).",Ranking,,Yes,Yes,"Provider, Publisher, User",Yes,Yes,RECBOLE,"Exposure, Statistical","Mitigating",https://doi.org/10.1145/3640457.3688169,Proceedings of the 18th ACM Conference on Recommender Systems,RecSys,ACM,Short,2024
20,Done,Reproducing Popularity Bias in Recommendation: The Effect of Evaluation Strategies,Book-crossing,Book-crossing,Different studies so different results when it comes to popularity bias and its unfairness.,"UserKNN, ItemKNN, UserKNNwmeans, UserItemAvg, SVD++, NMF, BMF, PMF, WMF, HPF, NeuMF, BPR, VAECF, MostPopular, Random",Explicit,Reproduce their work and repeat experiments for all combinations.,"Correlation, Coverage, ΔGAP","BC more prone to popularity bias according to pop corr, but also higher coverage - sparse dataset with scattered popularity.","Both","popularity bias is the algorithmic phenomenon
where items already popular in the users’ profiles tend to become even more popular due to being
disproportionally recommended.",Mentions the fact that there are different domains,Yes,"Item, User",No,Yes,Cornac,"Popularity, Statistical",Measuring,https://doi.org/10.1145/3637066,missing,TORS,ACM,Research,2024
21,Done,Toward Bias-Agnostic Recommender Systems: A Universal Generative Framework,Book-crossing,Book-crossing,"Debiasing methods are too ad hoc, bias-specific, lacking universality, not accounting for the co-existence of multiple biases.","MF, NGCF",Implicit,Generative framework for Bias Disentanglement (GBD) that constantly generates calibration pertubations during training to keep intermediate representations from being biased. Relies on bias-identifier introduced.,"NDCG, MRR, Recall@K, RR (recommendation rate) of items with different popularity levels.","ONLY POPULARITY BIAS TESTED ON BC. Improvement over NDCG, MRR, Recall with GDB, which is assumed to show that the impact of pop bias was reduced. RR not tested on the book data. Also other results, but not on BC.",Ranking,"Unfortunately, the generation of user behavior data is subject to various biases,
such as the Missing Not At Random (MNAR) problem [15, 51] caused by users’ selective behavior,
the position bias attributed to ranking place [6, 34], and the popularity bias due to the long-tail
phenomenon [1, 35] MORE for individual biases",No,Yes,Item,Yes,Yes,Unknown,"Bias-agnostic, Popularity, Statistical",Mitigating,https://doi.org/10.1145/3655617,missing,TOIS,ACM,Research,2024
22,Done,What We Evaluate When We Evaluate Recommender Systems: Understanding Recommender Systems’ Performance using Item Response Theory,Amazon-books,Amazon-books,"Offline evaluation neglects
how recommender systems more broadly model user preferences,
which is not captured by only considering the top-n recommenda
tions.",52 models lol,Implicit,"item response theory (IRT), a family
of latent variable models used in psychometric assessment, to gain
a comprehensive understanding of offline evaluation",precision etc…,"For amazon books, there wasnt any significant relationship between difficulty and popularity…only that when they rate many items, they will not necessarily get better recommendations indefinitely, only up to a point.",Ranking,,No,Yes,Item,Yes,Only results,RECBOLE,"Lower-Difficulty?, Statistical",Measuring,https://doi.org/10.1145/3604915.3608809,Proceedings of the 17th ACM Conference on Recommender Systems,RecSys,ACM,Research,2023
23,Done,A Personalized Framework for Consumer and Producer Group Fairness Optimization in Recommender Systems,Book-crossing,Book-crossing,"RS fairness work usually treats user and item fairness independently, even though it’s a two side marketplace.","PF, WMF, NeuMF, VAECF, Random, MostPop",Explicit,"CP-FairRank, a re-ranking algorithm that seamlessly integrates fairness constraints from both sides.",mCPF (joint C and P fairness),Not many results on the book set are included…but overall their method works to decrease mCFP with an ablation study for all datasets.,Ranking,"Exposure refers to how evenly items or
groups of items are exposed to users or groups of users. Relevance (effectiveness) determines to
what extent the items exposition is effective, i.e., matches with the user’s taste",No,Yes,"Provider, User",No,Yes,Cornac,"Popularity, Statistical, User activity",Mitigating,https://doi.org/10.1145/3651167,missing,TORS,ACM,Research,2024
24,Done,Biased User History Synthesis for Personalized Long-Tail Item Recommendation,Book-crossing,Book-crossing,Long-tail items are underrecommended.,"Two-tower NN, DeepFM, Wide and Deep (MORE)

NeuMF, NGCF, MGL… and other baselines",Unclear,Biased user history synthesis that via tail item biased sampling strategy and a synthesis model that produces augmented user profiles.,"HR@10 and NDCG@10 fore head, tail, overall","Overall improvement of tail recommendation, with exceptions.",Ranking,"in scenarios where recommendation models need
to handle a large number of items, a common issue arises when the
majority of items, known as tail items, receive very few interactions,
while a small subset of popular items, known as head items
dominate user engagement [9, 26]. This phenomenon, known as
the long-tail item problem, can result in model bias, with the model
overly focusing on head items and neglecting relevant tail items",No,Yes,Item,Yes,Yes,Unknown,"Popularity, Statistical",Mitigating,https://doi.org/10.1145/3640457.3688141,Proceedings of the 18th ACM Conference on Recommender Systems,RecSys,ACM,Research,2024
25,Done,Countering Popularity Bias by Regularizing Score Differences,GoodReads,GoodReads,The data is long tail and the RS could give unfairly high scores to popular items,"BPR, NeuCF, NGCF, LightGCN",Implicit,Method to reduce bias by regularizing the predicting scores to be equal across items a user preferred (extension of BPR loss with regularizer.),PopQ@1,"Best performance (good accuracy, high debias) for most algorithms compared to other debiasing methods.",Ranking,"popularity bias, which can come in
many forms [2, 8, 9, 29]. From the data side, the user-item feedback
data shows long tail distribution in item frequency with most interaction
focused on small number of popular items (data bias) [2, 25].
From the model side, the recommendation systems, trained on such
data, often give higher recommendation scores to more popular
items even among items equally liked by a user, resulting in overrecommending
popular items (model bias) [3, 34, 42]. Furthermore,
such biased recommendations to users could form a feedback loop
which may result in filter bubble or echo chamber",No,Yes,Item,Yes,Yes,Unknown,"Popularity, Statistical",Mitigating,https://doi.org/10.1145/3523227.3546757,Proceedings of the 16th ACM Conference on Recommender Systems,RecSys,ACM,Research,2022
26,Done,Comprehensive Fair Meta-learned Recommender System,Book-crossing,Book-crossing,"Cold start problem has issues of bias and unfairness, which are largely overlooked within metalearning techniques for cold start alleviation. RELEVANT: COUNTERFACTUAL, GROUP","PPR, Wide&Deep, DropoutNet, NLBA",Explicit,"CLOVER framework that ensures the fairness of meta-learned recommendation models (individual fairness, counterfactual fairness, group fairness) and try to satisfy all three bia a multi-task adversarial learning scheme.","CF, GF","Metalearning for cold start is more unfair than other cold start methods. However, with CLOVER it becomes more fair, while not sacrificing performance!","Both",Definitions of fairnesses…,No,No,User,Yes,"Yes, googling",Pytorch,"Age, Social","Mitigating",https://doi.org/10.1145/3534678.3539269,Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,SIGKDD,ACM,Research,2022
27,Done,Experiments on Generalizability of User-Oriented Fairness in Recommender Systems,Book-crossing,Book-crossing,A lot of work on fairness-aware RS (specifically user-oriented) but not sure if generalizable.,"MostPop, BPR, PF, WMF, NeuMF, VAECF","Both","Reproduce user-oriented fairness study, extensive experimentsto analyze dependence on various aspects (domain, model, user grouping).","difference of NDCG@10 between user groups (UGF), ΔGAP, ","different effect of the re-ranking method based on the user grouping (based on activity level vs based on affinity for popular items)the higher
number of interactions per user can lead to better performance of
fairness model (for all datasets) and same for the contribution of items in interactions, then other general results but not specifically mentioning bookcrossing. ",Ranking,"Fairness on one-sided markets [15, 23] aims at minimizing the dis
parity
between differen
groups and removing the algorithm’s
user
bias against the “protected” user group in the recommendation pro
cess.
In contrast, fairness on two-sided markets [39, 41, 42, 45] aims
to protect not only the protected users, but also some item groups,
leading to a fairer approach towards certain content providers (e.g.,
music and video recommendation) or vendors (e.g., eCommerce
recommendation)",Mentions the fact that there are different domains,Yes,User,No,Yes,Cornac,"Popularity, Statistical, User activity","Mitigating",https://doi.org/10.1145/3477495.3531718,Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval,SIGIR,ACM,Research,2022
28,Done,Measuring Commonality in Recommendation of Cultural Content to Strengthen Cultural Citizenship,LibraryThing,LibraryThing,RS create culture! but beyond-accuracy metrics such as fairness etc don’t really capture that.,Unknown (provided by previous work),Implicit,"Commonality = new measure of RS (the degree to which recs familiarize a given user population with specified categories of cultural content). Through discussions between compsci and socialsci, they find diversity for strengthening cultural citizenship as important goal of recsys that delivers cultural content. They compare commonality with novelty etc in 3 domains.",commonality (expresses the degree to which users become familiar with categories simultaneously),1. correlation with diversity and novelty metrics (i mean with commonality). 3. commonality performance degrades slightly with smaller samples,Ranking,"recommender systems can be developed explicitly to promote a value such as diversity
by counteracting racist and sexist biases and the neglect of non-Western content—and they can
advance these progressive changes as common experiences, thus enhancing cultural citizenship.",Yes,Yes,"Item, Topic",Unclear,Yes,Unknown,"Gender, Social",Measuring,https://doi.org/10.1145/3643138,missing,TORS,ACM,Research,2024
30,Done,Not All Embeddings are Created Equal: Towards Robust Cross-domain Recommendation via Contrastive Learning,Amazon-books,Amazon-books,"Cross domain recommendation (CDR) is great, but data imbalance across domains poses challenges (e.g., incosistency in user activity → user embeddings prioritize users that have more frequent interactions, and underserve the others).","BPRMF, NeuMF, LightGCN

HeroGraph, GA-MTDCR, CAT-ART",Implicit,"User Aware constrastive learning for robust cdr (UCLR) finetuned based on Low-Rank Adaptation. . ","MRR@10, HR@10, NDCG@10: all for users that only have one or two interactions in the Amazon dataset.",Significant performance improvement for less active users compared to the baselines.,Ranking,"Given the frequent issue of imbalanced user interactions in realworld
scenarios, existing CDR methods tend to overly focus on
users with higher interactions during the construction of user embeddings.
Consequently, this often results in the inability to provide
accurate recommendations for users with fewer interactions in the
target domain during the testing stage.",Mentions the fact that there are different domains,Yes,User,No,No,Pytorch,"Statistical, User activity","Mitigating",https://doi.org/10.1145/3589334.3645357,Proceedings of the ACM Web Conference 2024,WWW,ACM,Research,2024
32,Done,Improving the Estimation of Tail Ratings in Recommender System with Multi-Latent Representations,"Amazon-books, Amazon-kindle, GoodReads","Amazon-books, Amazon-kindle, GoodReads","Factor models and neural variants optimize for head ratings, therefore leading to large estimation errors for tail ratings. NOTICE: NOT ITEMS, RATINGS","MF, NCF",Explicit,"Show that the problem is a uni-modal assumption the models are underlied by. Also improve the estimation of tail ratings by extending single latent representation to multi, incorporate to an end-to-end neural prediction model.","rating prediction distribution, RMSE for tail ratings.","In the predictions, distributions of ratings are concentrated around the head - low tail ratings are most likely overestimated by current methods. Also, RMSE is extremely poor for tail ratings across datasets/algorithms. The polarized ratings are also unimodal!!!! (even though bi-modal in the training set)

For ratings far from the center, the overall improvement by MLR is substantial. In some cases, there are some decreases in the predicted tail rating
range near to the global mean. Improvement for polarizing items",Rating,"We say that the
are ratings from a user to a specifi
tail ratings
item that are significantly lower or significantly higher than an
item’s average rating, typically accounting for a smaller fraction
of all ratings on an item",Mentions the fact that there are different domains,Yes,Item,Yes,No,Unknown,"Low-rating, Statistical","Mitigating",https://doi.org/10.1145/3336191.3371810,Proceedings of the 13th International Conference on Web Search and Data Mining,WSDM,ACM,Research,2020
33,Done,Distributional Fairness-aware Recommendation,Book-crossing,Book-crossing,Measuring fairness as closeness of average performances between groups is not good enough — what if the variance is high?,"MF, NCF, LightGCN",Explicit,New type of fairness = the performance distributions across different user groups should be similar (group fairness ofc). How: generative adversarial training framework: DistFair. theoretically and experimentally show effectiveness,Recall@10 and NDCG@10 fairness.,"dist fairness is stricter as shown empirically on BC with LightGCN for US users vs rest. their framework achieves the best fairness performance in most cases (for active vs non active users)

some more results for ablation study etc…",Ranking,we require that the performance distributions of different user groups should be similar (also some related work),Mentions the fact that there are different domains,Unmentioned yes,User,Yes,No,Unknown,"Statistical, User activity","Mitigating",https://doi.org/10.1145/3652854,missing,TOIS,ACM,Research,2024
34,Done,Optimizing Neighborhoods for Fair Top-N Recommendation,GoodReads,GoodReads,Neighborhood-learning CF models have bias because they learn neighbourhoods that foster discriminatory patterns. There is some work (BNSLIM) but it’s inefficient and impacts accuracy.,,Implicit,"They propose two new algorithms: ADMM (better efficiency) and FSRL (better accuracy, compareable efficiency). Slso new metric for coverage disparities.

all of these are obviously for group fairness","BDV (difference between observed probability of recommending protected vs non-protected items), APCS (average provider coverage)","THEY ONLY MEASURE P-FAIRNESS FOR THIS. Their methods’ impact not as high as for the other dataset, but both increase the imbalance of EASE (more women-authored books). theirs scale better than other fairness aware methods, especially for goodreads (sparse). they consistently reduce unfairness",Ranking,"group fairness aims for different groups to be treated similarly.

also many definitions in introduction",Yes,Yes,"Author, Item, Provider",Yes,Yes,"OG_implementations, Pytorch, Reckpack","Gender, Social","Mitigating",https://doi.org/10.1145/3627043.3659539,"Adaptation and Personalization, Proceedings of the 32nd ACM Conference on User Modeling",UMAP,ACM,Research,2024
36,Done,Dual-Side Adversarial Learning Based Fair Recommendation for Sensitive Attribute Filtering,Book-crossing,Book-crossing,"A way to deal with discrimination in rec is to filter sensitive info so that they’re not learned when making user representations, however this ignores the latent relationship between user sensitive info and item attributes.","PPR, Wide&Deep, DropoutNet, NLBA, MELU",Explicit,"DALFRec, fairness-aware rec algorithm based on user and item-side adversarial learning to mitigate the effects of sensitive info on both sides. New evaluation strategy: asses the algorithm’s ability to reduce discrimination.","saAAC (sensitive attribute accuracy) = ability of algorithm to reduce discrimination.based on the items in the rec list and the latent releance between their content attributes and the user’s sensitive attributes. Also: CF, GF, AUC","the measure relation between user age and item publication year and author, but don’t comment on it (only ml1m). better fairness over traditional recs and other fairness methods.  

Other results, ablation…","Both","Discriminatory recommendation occurs when items
are recommended to users based more on their sensitive information than their preferences",Mentions the fact that there are different domains,No,User,Yes,No,Pytorch,"Age, Social","Mitigating",https://doi.org/10.1145/3648683,missing,TKDD,ACM,Research,2024
37,Done,Meta Graph Learning for Long-tail Recommendation,Book-crossing,Book-crossing,"Item distributions that are long-tail make it so that long-tail items have worse performance, especially in graph based recommendation.","BPR, NGCF, LightGCN, Over sampling, Down sampling,  GAT, EGLN, MELU, MIRec",Implicit,"Meta Graph Learning (MGL) framework for long-tail recommendation, also a popularity-aware constrastive learning strategy.

interesting framing: long-tail items only don’t get recommended accurately because they don’t have good enough representations (we don’t know enough about them)",NDCG@K and HR@K for tail items,"MGL outperforms
other methods in all evaluation metrics for both tail and head items, and the overall performance.

Some other results, not on BC",Ranking,"the models trained
on these uneven datasets would easily overfit a small fraction of
popular items, and lead to the popularity bias [1], which recommend
items simply from their popularity, rather than user-item matching.",No,Yes,Item,Yes,Yes,"OG_implementations, Pytorch","Popularity, Statistical",Mitigating,https://doi.org/10.1145/3580305.3599428,Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,SIGKDD,ACM,Research,2023
38,Done,FairSR: Fairness-aware Sequential Recommendation through Multi-Task Learning with Preference Graph Embeddings,Book-crossing,Book-crossing,Fairness issues also apply to sequential recommendation.,Many sequential rec ones…,Implicit,"They define a fainress-aware SR task and new metric - interaction fairness (estimates how rec items are fairly interacted with by users with different protected attribute groups). Also multi-task learning-based deep model FairSR: better performance, promising interaction fairness.","DIF@k (difference of interaction fairness, does the model improve interaction fairness)","FairSR consistently produces the highest DIF scores.

Ablation study, hyperparameter sensitivity.",Ranking,"Better IF means that recommended items tend to
be equally interacted by users of different protected attribute groups.",No,Yes,User,No,Yes,Pytorch,"Age, Gender, Social",Mitigating,https://doi.org/10.1145/3495163,missing,TIST,ACM,Research,2022
41,Done,CADPP: An Effective Approach to Recommend Attentive and Diverse Long-tail Items,Amazon-books,Amazon-books,The main difficulty with the long tail problem is to find long tail items that match users’ preferences but also are sufficiently diverse to avoid recommending always the same long-tail items.,"POP, SPOP, ItemKNN, FPMC, GRU4REC, NARM, STAMP, RepeatNet, SR-GNN",Implicit,"CADDP: a novel long-tail item rec approach (based on multi-pointer co-attention mechanism and the determinant point process). It extracts important feature embeddings to capture the common characteristics of multiple items clicked by users, and ensure that they are relevant and diverse.","Coverage@K, Tail-Coverage@K, Tail@K","CADPP achieves the best long-tail recommendation performance…

Ablation study and effect also…",Ranking,"It doesn’t specifically address popularity bias…but how to better recommend long-tail items, which is ofc related.",No,Yes,Item,No,No,Unknown,"Popularity, Statistical",Mitigating,https://doi.org/10.1145/3486622.3493961,IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology,WI-IAT,ACM,Research,2022
42,Done,Empowering Long-tail Item Recommendation through Cross Decoupling Network (CDN),Book-crossing,Book-crossing,"There’s a lot of academic work on improving tail item recommendation, it’s hard to transfer in industry because performance is worse, and also it’s complex and expensive. ",Two-tower model,Unclear,"Improve tail recommendation while maintaining performance, less training and service cost. How: they find that predictions of user preferences are biased under long-tail distributions (and most methods attempt to reduce bias only from an item distribution perspective). They design Cross Decoupling Network (CDN) that does some decoupling, basically to reduce the difference between the training and service data for both item distribution and user’s preference given an item.",NDCG@K and HR@K for tail items,"CDN achieves the best performance on long tails but also for all items, while the other tail-baselines significantly degrade the performance on head items. CDN more robust.

Ablation study etc…",Ranking,"That is, a small fraction
of items (head items) are extremely popular and receive most of
the user feedback, while rest of the items (tail items) have very little
if any user feedback. Recommender models that are trained based
on the long-tail data usually amplify head items, enable the “rich
get richer” effect while hurting long-term user satisfaction. Models
trained on highly skewed data distribution may lead to even worse
skewness in real-world applications.",No,No,Item,Unclear,No,Unknown,"Popularity, Statistical",Mitigating,https://doi.org/10.1145/3580305.3599814,Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,SIGKDD,ACM,Research,2023
44,Done,Reconsidering Learning Objectives in Unbiased Recommendation: A Distribution Shift Perspective,"GoodReads, Semi-synthetic",GoodReads,"Work in unbiased RS has emperical success but lacks theoretical guarantees (gap between recent algorithms and theory). ","MF, NCF

also various learning objectives for unbiasedness as baselines",Implicit,"Propose theoretical understanding of why existing unbiased learning objectives (e.g., re-weighting) work for unbiased recommendation → basically they implicitly align biased training and unbiased test distributions (distribution shift), they build bounds. Also AST (adversarial self training) framework for unbiased recommendations.","Unbiased ranking performance: NDCG@5, HR@5","AST significantly outperforms other methods (for all datasets). 

also ablation study. 

Other results unrelated to the book dataset.",Ranking,"However, in the real world,
exposures are affected by the past recommendation policy, which is
known as model selection bias.",No,Yes,"I guess, Item",Yes,No,Unknown,"Selection, Statistical","Mitigating",https://doi.org/10.1145/3580305.3599487,Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,SIGKDD,ACM,Research,2023
46,Done,Alleviating Cold-Start Problems in Recommendation through Pseudo-Labelling over Knowledge Graph,Book-crossing,Book-crossing,The cold-start problem is often solved by leveraging unobserved samples for extracting negative signals. but that can lead to popularity bias.,"RippleNet, MKR, KGAT, KGNN-LS, TopPopular",Unclear,Appropriately leverage unobserved samples: KG-aware (with side info about the items) recommender based on GNN which augments labelled samples through pseudo-sampling and aggressibely employs unobserved samples as positive instances and brings new items into the spotlight. KGPL!,"recall@10 for user group, some win system or soemthing, number of unique items recommended","KGPL performs better than other KG methods for non active users, but mildly so. Actually topPopular performs the best for non active users for the book dataset → so the other methods even kgpl struggle because of high sparsity. KGPL actually propagates popularity bias. 

Ablation analysis",Ranking,"However, as this strategy distils only
negative signals from unobserved samples, it may lead to biased
and sub-optimal results; recommender systems may underestimate
the chance of positive feedback of users or items rarely observed,
namely, cold-start users and items",Unknown,Unmentioned yes,"Item, User",Yes,No,Unknown,"Popularity, Statistical, User activity",Mitigating,https://doi.org/10.1145/3437963.3441773,Proceedings of the 14th ACM International Conference on Web Search and Data Mining,WSDM,ACM,Research,2021
47,Done,A Model of Two Tales: Dual Transfer Learning Framework for Improved Long-tail Item Recommendation,Book-crossing,Book-crossing,Longtail item distribution of item hurts model performance on tail items.,"Two-tower model as backbone, and various method specific baselines: Over-sampling, Under-sampling, ClassBalance, LogQ, Head2Tail, Tail2Head, MeLu",Implicit,Dual transfer learning framework that jointly learns knowledge transfer from both model-levev and item-level (tf from head to teal items).  MIRec,"HR@10, NDCG@10 - for tail items","MIRec achieves the best performance on tail items (and generally)

Ablation study etc but NO OTHER BOOK CROSSING RESULTS",Ranking,"As a result, recommendation
models trained on dataset with such long-tail item distribution
would easily overfit on a small fraction of popular items, and pro
duce
sub-optimal performance for the rest of the large chunk of
tail items. Deploying such models in real world applications would
also lead to the popularity bias [1] and “rich gets richer” feedback
loop [31]",Somewhat,Yes,Item,Yes,No,TensorFlow Recommenders,"Popularity, Statistical",Mitigating,https://doi.org/10.1145/3442381.3450086,Proceedings of the Web Conference 2021,WWW,ACM,Research,2021
48,Done,A Novel Classification Framework for Evaluating Individual and Aggregate Diversity in Top-N Recommendations,Book-crossing,Book-crossing,Traditional evaluation methods of recommendations don’t account for all aspects of user satisfaction.,"UserKNN (somewhat, MFR)",Explicit,"Novel user and item classification framework that can be used during user-centered evaluation of recommender systems.

User quadrants with 2 dimensions: NN similarity, sparsity of ratings

Same for item quadrants!",Recall and coverage (=did the user receive until one successful recommendation) for every user quadrant,"Worst performance for users who have rated many items but are dissimilar to other users, best for users who have rated few items but have high similarity.

No more results for books",Ranking,"Data sparsity [Adomavicius and
Tuzhilin 2005; Anand and Mobasher 2005] occurs as the size of the dataset increases
as even active users will only have provided ratings for a small percentage of the item
set. As a result of this, relationships between users and items can become difficult
to infer, in turn making the process of recommendation generation more challenging.",No,Yes,User,No,No,Unknown,"Agreement, Statistical",Measuring,https://doi.org/10.1145/2700491,missing,TIST,ACM,Research,2016
49,Done,Measuring Fairness in Ranked Results: An Analytical and Empirical Comparison,"Ekstrand data, GoodReads",GoodReads,"There’s been many metrics proposed that measure fairness in rankings, but so far no empirical and comparative analysis between them (and when it comes to applicability for different data)
(Generally about rankings, not only recommender systems)","UserKNN, ItemKNN, WRLS (MF), BPR",Implicit,"bridge the gap between theoretical and practical ap
plication: describe them and empirically compare them on the same experimental setup and datasets given three information access tasks — also senisitivity analysis to assess the impact of design vhoices and parameter settings.","These don’t account for actual item utility: Single rankings statistical parity (3), Multiple rankings statistical parity (2 - demographic parity, expected exposure disparity)


These do: Multiple Rankings Equal opportunity (4)","Generally metrics disagree on orderings and also they might agree on some experiments and not others.

Sensitivity analysis.

- for goodreads, ranked list size has impact on some metrics

- same for weighting strategy

- same for patience parameter",Ranking,"Through these ranked lists, the system exposes its items (and their
creators) to users, and this exposure affects what users discover,
consume, and purchase. Further, this exposure is not always evenly
or fairly distributed; different items or groups of items may receive
disparate exposure when exposure is not equitably distributed to
(relevant) items [11]. Disparate exposure can disadvantage content
creators on either an individual or group basis. Popularity bias
[1], for example, provides an advantage to creators based on their
prior popularity. The system may also, however, provide greater
or lesser exposure reflecting in ways that reproduce historical and
ongoing social discrimination, such as by disadvantaging creators
of a particular gender or race.",Somewhat,Yes,"Author, Provider",Used from other paper,Yes,Lenskit,"Gender, Social",Measuring,https://doi.org/10.1145/3477495.3532018,Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval,SIGIR,ACM,Research,2022
50,Done,Enhancing Fairness in Meta-learned User Modeling via Adaptive Sampling,Book-crossing,Book-crossing,"Meta-learning tackles cold start and fairness is an issue, there are promising methods that tackle unfairness. There is one unexplored question: what is the critical factor leading to unfairness in meta-learned user modelling?

GROUP FAIRNESS = a fair user modeling algorithm
should provide the same level of utility performance for various
user groups","Two-layer nework as user preference estimato. Meta-learning backcones: MELU, MetaCD

Reg, IPW, CLOVER, Wide&Deep, DroupoutNet, NLBA",Explicit,Theoretical analysis of combination between meta-learning and group fairness metrics to show that group proportion imbalance is the critical factor. Also novel Fairness aware Adaptive Sampling framework of meTa learning (FAST) which basically adaptively adjusts the sampling distribution for different user groups during the training process of meta-leanring - theoretical guarantees of convergence.,GF(MAE) and GF(MSE),"FAST demonstrates satisfactory fairness results
and comparable utility across various meta-learning paradigms. 

Ablation study",Rating,"the fairness problem has attracted significant attention
from a broad audience. It requires user groups divided by
sensitive attributes (e.g., gender, race) should be treated similarly.


*Doesn’t explicitly mention bias",No,Yes,User,No,Yes,"OG_implementations, Pytorch","Age, Social","Mitigating",https://doi.org/10.1145/3589334.3645369,Proceedings of the ACM Web Conference 2024,WWW,ACM,Research,2024
51,Done,Estimation of Fair Ranking Metrics with Incomplete Judgments,"Ekstrand data, GoodReads",GoodReads,"Fair ranking metrics normally require knowledge of membership of items in groups that relate to a protected attribute, however this info is rarely complete and available.

(Generally about rankings, not only recommender systems)","MF

For baselines: induced method baseline, Uniform sampling baseline",Implicit,"They propose a sampling strategy and estimation technique for four fair ranking metrics by formulating a robust and unbiased estimator that works well even with a limited number of labeled items.

(The assumption is that labelling is possible but comes at a cost so a strategically-selected sample can be labeled)","Kendall τ and RMSE between the fairness metrics with all judgements and with the sampled ones.

Fairness metrics: proportion based, exposure based (rank plays a part)","the proposed method, which uses a top
heavy sampling strategy, results in unbiased estimates of fair ranking metrics and outperforms naive baselines",Ranking,"In this paper, we study metrics for provider group fairness. This
means that the fairness goal is to ensure that the providers of items
or documents are treated fairly. One way to eval
uate
this is by measuring whether the exposure different providers
receive from the system is equitably distributed among providers
of documents with comparable relevance",Yes,Yes,"Author, Item, Provider",Unclear,No,Unknown,"Gender, Social",Measuring,https://doi.org/10.1145/3442381.3450080,Proceedings of the Web Conference 2021,WWW,ACM,Research,2021