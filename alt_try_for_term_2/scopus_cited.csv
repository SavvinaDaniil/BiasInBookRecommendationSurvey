Authors,Title,Year,Source title,Link,Abstract
"Chen T., Guestrin C.","XGBoost: A scalable tree boosting system",2016,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984950690&doi=10.1145%2f2939672.2939785&partnerID=40&md5=73effb39b7405c4cd7e8da0e496f6de7","Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable endto-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems. © 2016 ACM."
"He X., Liao L., Zhang H., Nie L., Hu X., Chua T.-S.","Neural collaborative filtering",2017,"26th International World Wide Web Conference, WWW 2017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031939960&doi=10.1145%2f3038912.3052569&partnerID=40&md5=90266dad26d67d8243243cda18e309a4","In recent years, deep neural networks have yielded immense success on speech recognition, computer vision and natural language processing. However, the exploration of deep neural networks on recommender systems has received relatively less scrutiny. In this work, we strive to develop techniques based on neural networks to tackle the key problem in recommendation — collaborative filtering — on the basis of implicit feedback. Although some recent work has employed deep learning for recommendation, they primarily used it to model auxiliary information, such as textual descriptions of items and acoustic features of musics. When it comes to model the key factor in collaborative filtering — the interaction between user and item features, they still resorted to matrix factorization and applied an inner product on the latent features of users and items. By replacing the inner product with a neural architecture that can learn an arbitrary function from data, we present a general framework named NCF, short for Neural network-based Collaborative Filtering. NCF is generic and can express and generalize matrix factorization under its framework. To supercharge NCF modelling with non-linearities, we propose to leverage a multi-layer perceptron to learn the user–item interaction function. Extensive experiments on two real-world datasets show significant improvements of our proposed NCF framework over the state-of-the-art methods. Empirical evidence shows that using deeper layers of neural networks offers better recommendation performance. © 2017 International World Wide Web Conference Committee (IW3C2)."
"Rendle S., Freudenthaler C., Gantner Z., Schmidt-Thieme L.","BPR: Bayesian personalized ranking from implicit feedback",2009,"Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence, UAI 2009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650134987&partnerID=40&md5=649613e4c1351694e19eec3a1a43c902","Item recommendation is the task of predicting a personalized ranking on a set of items (e.g. websites, movies, products). In this paper, we investigate the most common scenario with implicit feedback (e.g. clicks, purchases). There are many methods for item recommendation from implicit feedback like matrix factorization (MF) or adaptive knearest-neighbor (kNN). Even though these methods are designed for the item prediction task of personalized ranking, none of them is directly optimized for ranking. In this paper we present a generic optimization criterion BPR-Opt for personalized ranking that is the maximum posterior estimator derived from a Bayesian analysis of the problem. We also provide a generic learning algorithm for optimizing models with respect to BPR-Opt. The learning method is based on stochastic gradient descent with bootstrap sampling. We show how to apply our method to two state-of-the-art recommender models: matrix factorization and adaptive kNN. Our experiments indicate that for the task of personalized ranking our optimization method outperforms the standard learning techniques for MF and kNN. The results show the importance of optimizing models for the right criterion."
"Pearl J.","Causality",2009,"Causality",,[No abstract available]
"Hu Y., Volinsky C., Koren Y.","Collaborative filtering for implicit feedback datasets",2008,"Proceedings - IEEE International Conference on Data Mining, ICDM","https://www.scopus.com/inward/record.uri?eid=2-s2.0-67049164166&doi=10.1109%2fICDM.2008.22&partnerID=40&md5=ed42c02f8bff0d8db25ea2206828b79e","A common task of recommender systems is to improve customer experience through personalized recommendations based on prior implicit feedback. These systems passively track different sorts of user behavior, such as purchase history, watching habits and browsing activity, in order to model user preferences. Unlike the much more extensively esearched explicit feedback, we do not have any direct input from the users regarding their preferences. In particular, we lack substantial evidence on which products consumer dislike. In this work we identify unique properties of implicit feedback datasets. We propose treating the data as indication of positive and negative preference associated with vastly varying confidence levels. This leads to a factor model which is especially tailored for implicit feedback recommenders. We also suggest a scalable optimization procedure, which scales linearly with the data size. The algorithmis used successfully within a recommender system for television shows. It compares favorably with well tuned implementations of other known methods. In addition, we offer a novel way to give explanations to recommendations given by this factor model. ©2008 IEEE."
"He X., Deng K., Wang X., Li Y., Zhang Y., Wang M.","LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation",2020,"SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088628606&doi=10.1145%2f3397271.3401063&partnerID=40&md5=862daa5c5840d34ec4586bd72ae7cd2d","Graph Convolution Network (GCN) has become new state-of-the-art for collaborative filtering. Nevertheless, the reasons of its effectiveness for recommendation are not well understood. Existing work that adapts GCN to recommendation lacks thorough ablation analyses on GCN, which is originally designed for graph classification tasks and equipped with many neural network operations. However, we empirically find that the two most common designs in GCNs-feature transformation and nonlinear activation-contribute little to the performance of collaborative filtering. Even worse, including them adds to the difficulty of training and degrades recommendation performance. In this work, we aim to simplify the design of GCN to make it more concise and appropriate for recommendation. We propose a new model named LightGCN, including only the most essential component in GCN-neighborhood aggregation-for collaborative filtering. Specifically, LightGCN learns user and item embeddings by linearly propagating them on the user-item interaction graph, and uses the weighted sum of the embeddings learned at all layers as the final embedding. Such simple, linear, and neat model is much easier to implement and train, exhibiting substantial improvements (about 16.0% relative improvement on average) over Neural Graph Collaborative Filtering (NGCF)-a state-of-the-art GCN-based recommender model-under exactly the same experimental setting. Further analyses are provided towards the rationality of the simple LightGCN from both analytical and empirical perspectives. © 2020 ACM."
"Hardt M., Price E., Srebro N.","Equality of opportunity in supervised learning",2016,"Advances in Neural Information Processing Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018874612&partnerID=40&md5=ce6c2d44ec1f64083707a58f4df117a2","We propose a criterion for discrimination against a specified sensitive attribute in supervised learning, where the goal is to predict some target based on available features. Assuming data about the predictor, target, and membership in the protected group are available, we show how to optimally adjust any learned predictor so as to remove discrimination according to our definition. Our framework also improves incentives by shifting the cost of poor classification from disadvantaged groups to the decision maker, who can respond by improving the classification accuracy. We enourage readers to consult the more complete manuscript on the arXiv. © 2016 NIPS Foundation - All Rights Reserved."
"Dwork C., Hardt M., Pitassi T., Reingold O., Zemel R.","Fairness through awareness",2012,"ITCS 2012 - Innovations in Theoretical Computer Science Conference","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856446756&doi=10.1145%2f2090236.2090255&partnerID=40&md5=3dcbd1113e3dca15a06794233638dcf2","We study fairness in classification, where individuals are classified, e.g., admitted to a university, and the goal is to prevent discrimination against individuals based on their membership in some group, while maintaining utility for the classifier (the university). The main conceptual contribution of this paper is a framework for fair classification comprising (1) a (hypothetical) task-specific metric for determining the degree to which individuals are similar with respect to the classification task at hand; (2) an algorithm for maximizing utility subject to the fairness constraint, that similar individuals are treated similarly. We also present an adaptation of our approach to achieve the complementary goal of ""fair affirmative action,"" which guarantees statistical parity (i.e., the demographics of the set of individuals receiving any classification are the same as the demographics of the underlying population), while treating similar individuals as similarly as possible. Finally, we discuss the relationship of fairness to privacy: when fairness implies privacy, and how tools developed in the context of differential privacy may be applied to fairness. © 2012 ACM."
"Pearl J., Mackenzie D.","The Book of Why: the New Science of Cause and Effect",2018,"The Book of Why: The New Science of Cause and Effect",,[No abstract available]
"Li L., Chu W., Langford J., Schapire R.E.","A contextual-bandit approach to personalized news article recommendation",2010,"Proceedings of the 19th International Conference on World Wide Web, WWW '10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954641643&doi=10.1145%2f1772690.1772758&partnerID=40&md5=0deba3e304c09a3db001bfeeca14cd3f","Personalized web services strive to adapt their services (advertisements, news articles, etc.) to individual users by making use of both content and user information. Despite a few recent advances, this problem remains challenging for at least two reasons. First, web service is featured with dynamically changing pools of content, rendering traditional collaborative filtering methods inapplicable. Second, the scale of most web services of practical interest calls for solutions that are both fast in learning and computation. In this work, we model personalized recommendation of news articles as a contextual bandit problem, a principled approach in which a learning algorithm sequentially selects articles to serve users based on contextual information about the users and articles, while simultaneously adapting its article-selection strategy based on user-click feedback to maximize total user clicks. The contributions of this work are three-fold. First, we propose a new, general contextual bandit algorithm that is computationally efficient and well motivated from learning theory. Second, we argue that any bandit algorithm can be reliably evaluated offline using previously recorded random traffic. Finally, using this offline evaluation method, we successfully applied our new algorithm to a Yahoo Front Page Today Module dataset containing over 33 million events. Results showed a 12.5% click lift compared to a standard context-free bandit algorithm, and the advantage becomes even greater when data gets more scarce. © 2010 International World Wide Web Conference Committee (IW3C2)."
"Zhang S., Yao L., Sun A., Tay Y.","Deep learning based recommender system: A survey and new perspectives",2019,"ACM Computing Surveys","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062450758&doi=10.1145%2f3285029&partnerID=40&md5=c2c1fffe6540ec40178a1f8dd17b9676","With the growing volume of online information, recommender systems have been an effective strategy to overcome information overload. The utility of recommender systems cannot be overstated, given their widespread adoption in many web applications, along with their potential impact to ameliorate many problems related to over-choice. In recent years, deep learning has garnered considerable interest in many research fields such as computer vision and natural language processing, owing not only to stellar performance but also to the attractive property of learning feature representations from scratch. The influence of deep learning is also pervasive, recently demonstrating its effectiveness when applied to information retrieval and recommender systems research. The field of deep learning in recommender system is flourishing. This article aims to provide a comprehensive review of recent research efforts on deep learning-based recommender systems. More concretely, we provide and devise a taxonomy of deep learning-based recommendation models, along with a comprehensive summary of the state of the art. Finally, we expand on current trends and provide new perspectives pertaining to this new and exciting development of the field. © 2019 Association for Computing Machinery."
"Chouldechova A.","Fair Prediction with Disparate Impact: A Study of Bias in Recidivism Prediction Instruments",2017,"Big Data","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021102916&doi=10.1089%2fbig.2016.0047&partnerID=40&md5=1b979db8d74eaced7620bbdf004370dd","Recidivism prediction instruments (RPIs) provide decision-makers with an assessment of the likelihood that a criminal defendant will reoffend at a future point in time. Although such instruments are gaining increasing popularity across the country, their use is attracting tremendous controversy. Much of the controversy concerns potential discriminatory bias in the risk assessments that are produced. This article discusses several fairness criteria that have recently been applied to assess the fairness of RPIs. We demonstrate that the criteria cannot all be simultaneously satisfied when recidivism prevalence differs across groups. We then show how disparate impact can arise when an RPI fails to satisfy the criterion of error rate balance. © Copyright 2017, Mary Ann Liebert, Inc. 2017."
"Pan R., Zhou Y., Cao B., Liu N.N., Lukose R., Scholz M., Yang Q.","One-class collaborative filtering",2008,"Proceedings - IEEE International Conference on Data Mining, ICDM","https://www.scopus.com/inward/record.uri?eid=2-s2.0-67149083078&doi=10.1109%2fICDM.2008.16&partnerID=40&md5=771dca96e95aa63fbf5036dcae63b8b5","Many applications of collaborative filtering (CF), such as news item recommendation and bookmark rec- ommendation, are most naturally thought of as one- class collaborative filtering (OCCF) problems. In these problems, the training data usually consist simply of bi- nary data reflecting a user's action or inaction, such as page visitation in the case of news item recommenda- tion or webpage bookmarking in the bookmarking sce- nario. Usually this kind of data are extremely sparse (a small fraction are positive examples), therefore am- biguity arises in the interpretation of the non-positive examples. Negative examples and unlabeled positive ex- amples are mixed together and we are typically unable to distinguish them. For example, we cannot really at- tribute a user not bookmarking a page to a lack of inter- est or lack of awareness of the page. Previous research addressing this one-class problem only considered it as a classification task. In this paper, we consider the one- class problem under the CF setting. We propose two frameworks to tackle OCCF. One is based on weighted low rank approximation; the other is based on negative example sampling. The experimental results show that our approaches significantly outperform the baselines. © 2008 IEEE."
"He X., Zhang H., Kan M.-Y., Chua T.-S.","Fast matrix factorization for online recommendation with implicit feedback",2016,"SIGIR 2016 - Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980329382&doi=10.1145%2f2911451.2911489&partnerID=40&md5=e793c5dfbaa1a992f22320a2db81d74c","This paper contributes improvements on both the effectiveness and efficiency of Matrix Factorization (MF) methods for implicit feedback. We highlight two critical issues of existing works. First, due to the large space of unobserved feedback, most existing works resort to assign a uniform weight to the missing data to reduce computational complexity. However, such a uniform assumption is invalid in real-world settings. Second, most methods are also designed in an offline setting and fail to keep up with the dynamic nature of online data. We address the above two issues in learning MF models from implicit feedback. We first propose to weight the missing data based on item popularity, which is more effective and flexible than the uniform-weight assumption. However, such a non-uniform weighting poses efficiency challenge in learning the model. To address this, we specifically design a new learning algorithm based on the element-wise Alternating Least Squares (eALS) technique, for efficiently optimizing a MF model with variably-weighted missing data. We exploit this efficiency to then seamlessly devise an incremental update strategy that instantly refreshes a MF model given new feedback. Through comprehensive experiments on two public datasets in both offline and online protocols, we show that our eALS method consistently outperforms state-of-the-art implicit MF methods. Our implementation is available at https://github.com/hexiangnan/sigir16-eals. © 2016 ACM."
"Kusner M., Loftus J., Russell C., Silva R.","Counterfactual fairness",2017,"Advances in Neural Information Processing Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047021969&partnerID=40&md5=6984f80c004f463f37791b8a6c397ab8","Machine learning can impact people with legal or ethical consequences when it is used to automate decisions in areas such as insurance, lending, hiring, and predictive policing. In many of these scenarios, previous decisions have been made that are unfairly biased against certain subpopulations, for example those of a particular race, gender, or sexual orientation. Since this past data may be biased, machine learning predictors must account for this to avoid perpetuating or creating discriminatory practices. In this paper, we develop a framework for modeling fairness using tools from causal inference. Our definition of counterfactual fairness captures the intuition that a decision is fair towards an individual if it the same in (a) the actual world and (b) a counterfactual world where the individual belonged to a different demographic group. We demonstrate our framework on a real-world problem of fair prediction of success in law school. © 2017 Neural information processing systems foundation. All rights reserved."
"Wu Y., DuBois C., Zheng A.X., Ester M.","Collaborative denoising auto-encoders for top-N recommender systems",2016,"WSDM 2016 - Proceedings of the 9th ACM International Conference on Web Search and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964403193&doi=10.1145%2f2835776.2835837&partnerID=40&md5=ce0953349a442c99d62efbe8d5870218","Most real-world recommender services measure their performance based on the top-N results shown to the end users. Thus, advances in top-N recommendation have far-ranging consequences in practical applications. In this paper, we present a novel method, called Collaborative Denoising Auto-Encoder (CDAE), for top-N recommendation that utilizes the idea of Denoising Auto-Encoders. We demonstrate that the proposed model is a generalization of several well-known collaborative filtering models but with more flexible components. Thorough experiments are conducted to understand the performance of CDAE under various component settings. Furthermore, experimental results on several public datasets demonstrate that CDAE consistently outperforms state-of-the-art top-N recommendation methods on a variety of common evaluation metrics. © 2015 Copyright held by the owner/author(s)."
"Ma H., King I., Lyu M.R.","Learning to recommend with social trust ensemble",2009,"Proceedings - 32nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-72249094128&doi=10.1145%2f1571941.1571978&partnerID=40&md5=1506af24580e7d90dc1d3be81b013b11","As an indispensable technique in the field of Information Filtering, Recommender System has been well studied and developed both in academia and in industry recently. However, most of current recommender systems suffer the following problems: (1) The large-scale and sparse data of the user-item matrix seriously affect the recommendation quality. As a result, most of the recommender systems cannot easily deal with users who have made very few ratings. (2) The traditional recommender systems assume that all the users are independent and identically distributed; this assumption ignores the connections among users, which is not consistent with the real world recommendations. Aiming at modeling recommender systems more accurately and realistically, we propose a novel probabilistic factor analysis framework, which naturally fuses the users' tastes and their trusted friends' favors together. In this framework, we coin the term Social Trust Ensemble to represent the formulation of the social trust restrictions on the recommender systems. The complexity analysis indicates that our approach can be applied to very large datasets since it scales linearly with the number of observations, while the experimental results show that our method performs better than the state-of-the-art approaches. Copyright 2009 ACM."
"Friedman B., Nissenbaum H.","Bias in Computer Systems",1996,"ACM Transactions on Information Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030196306&doi=10.1145%2f230538.230561&partnerID=40&md5=7759e06c07c18aae348ee040f6b4cc15","From an analysis of actual cases, three categories of bias in computer systems have been developed: preexisting, technical, and emergent. Preexisting bias has its roots in social institutions, practices, and attitudes. Technical bias arises from technical constraints or considerations. Emergent bias arises in a context of use. Although others have pointed to bias in particular computer systems and have noted the general problem, we know of no comparable work that examines this phenomenon comprehensively and which offers a framework for understanding and remedying it. We conclude by suggesting that freedom from bias should be counted among the select set of criteria - including reliability, accuracy, and efficiency -according to which the quality of systems in use in society should be judged."
"Zafar M.B., Valera I., Rodriguez M.G., Gummadi K.P.","Fairness beyond disparate treatment & disparate impact: Learning classification without disparate mistreatment",2017,"26th International World Wide Web Conference, WWW 2017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048347682&doi=10.1145%2f3038912.3052660&partnerID=40&md5=e0ce633abceab72e3214b4c9965d03a8","Automated data-driven decision making systems are increasingly being used to assist, or even replace humans in many settings. These systems function by learning from historical decisions, often taken by humans. In order to maximize the utility of these systems (or, classifiers), their training involves minimizing the errors (or, misclassifications) over the given historical data. However, it is quite possible that the optimally trained classifier makes decisions for people belonging to different social groups with different misclassification rates (e.g., misclassification rates for females are higher than for males), thereby placing these groups at an unfair disadvantage. To account for and avoid such unfairness, in this paper, we introduce a new notion of unfairness, disparate mistreatment, which is defined in terms of misclassification rates. We then propose intuitive measures of disparate mistreatment for decision boundary-based classifiers, which can be easily incorporated into their formulation as convex-concave constraints. Experiments on synthetic as well as real world datasets show that our methodology is effective at avoiding disparate mistreatment, often at a small cost in terms of accuracy. © 2017 International World Wide Web Conference Committee (IW3C2)"
"Craswell N., Zoeter O., Taylor M., Ramsey B.","An experimental comparison of click position-bias models",2008,"WSDM'08 - Proceedings of the 2008 International Conference on Web Search and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-42549140738&doi=10.1145%2f1341531.1341545&partnerID=40&md5=7c68694d44b274257fd21b7ac741d35b","Search engine click logs provide an invaluable source of relevance information, but this information is biased. A key source of bias is presentation order: the probability of click is influenced by a document's position in the results page. This paper focuses on explaining that bias, modelling how probability of click depends on position. We propose four simple hypotheses about how position bias might arise. We carry out a large data-gathering effort, where we perturb the ranking of a major search engine, to see how clicks are affected. We then explore which of the four hypotheses best explains the real-world position effects, and compare these to a simple logistic regression model. The data are not well explained by simple position models, where some users click indiscriminately on rank 1 or there is a simple decay of attention over ranks. A ĝ€ cascade' model, where users view results from top to bottom and leave as soon as they see a worthwhile document, is our best explanation for position bias in early ranks. © 2008 ACM."
"Mehrabi N., Morstatter F., Saxena N., Lerman K., Galstyan A.","A survey on bias and fairness in machine learning",2019,"A survey on bias and fairness in machine learning",,[No abstract available]
"Zemel R., Wu Y., Swersky K., Pitassi T., Dwork C.","Learning fair representations",2013,"International Conference on Machine Learning",,[No abstract available]
"Vella F.","Estimating models with sample selection bias: A survey",1998,"Journal of Human Resources","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0001703017&doi=10.2307%2f146317&partnerID=40&md5=3ca33a85609d6fa65f0211f01f4e62bb","This paper surveys the available methods for estimating models with sample selection bias. I initially examine the fully parameterized model proposed by Heckman (1979) before investigating departures in two directions. First, I consider the relaxation of distributional assumptions. In doing so I present the available semi-parametric procedures. Second, I investigate the ability to tackle different selection rules generating the selection bias. Finally, I discuss how the estimation procedures applied in the cross-sectional case can be extended to panel data."
"Zafar M.B., Valera I., Rodriguez M.G., Gummadi K.P.","Fairness constraints: Mechanisms for fair classification",2017,"Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, AISTATS 2017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083938290&partnerID=40&md5=360b2b59ee31b327b6e813f39ab8a7a2","Algorithmic decision making systems are ubiquitous across a wide variety of online as well as offline services. These systems rely on complex learning methods and vast amounts of data to optimize the service functionality, satisfaction of the end user and profitability. However, there is a growing concern that these automated decisions can lead, even in the absence of intent, to a lack of fairness, i.e., their outcomes can disproportionately hurt (or, benefit) particular groups of people sharing one or more sensitive attributes (e.g., race, sex). In this paper, we introduce a flexible mechanism to design fair classifiers by leveraging a novel intuitive measure of decision boundary (un)fairness. We instantiate this mechanism with two well-known classifiers, logistic regression and support vector machines, and show on real-world data that our mechanism allows for a fine-grained control on the degree of fairness, often at a small cost in terms of accuracy. A Python implementation of our mechanism is available at fate-computing.mpi-sws.org Copyright 2017 by the author(s)."
"Blodgett S.L., Barocas S., Daumé H., Wallach H.","Language (Technology) is power: A critical survey of ⇜bias” in NLP",2020,"Proceedings of the Annual Meeting of the Association for Computational Linguistics","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115851015&partnerID=40&md5=25a07a7c117df0afd9f6f4bdef2e8edd","We survey 146 papers analyzing “bias” in NLP systems, fnding that their motivations are often vague, inconsistent, and lacking in normative reasoning, despite the fact that analyzing “bias” is an inherently normative process. We further fnd that these papers' proposed quantitative techniques for measuring or mitigating “bias” are poorly matched to their motivations and do not engage with the relevant literature outside of NLP. Based on these fndings, we describe the beginnings of a path forward by proposing three recommendations that should guide work analyzing “bias” in NLP systems. These recommendations rest on a greater recognition of the relationships between language and social hierarchies, encouraging researchers and practitioners to articulate their conceptualizations of “bias”-i.e., what kinds of system behaviors are harmful, in what ways, to whom, and why, as well as the normative reasoning underlying these statements-and to center work around the lived experiences of members of communities affected by NLP systems, while interrogating and reimagining the power relations between technologists and such communities. © 2020 Association for Computational Linguistics"
"Zheng G., Zhang F., Zheng Z., Xiang Y., Yuan N.J., Xie X., Li Z.","DRN: A deep reinforcement learning framework for news recommendation",2018,"The Web Conference 2018 - Proceedings of the World Wide Web Conference, WWW 2018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085176840&doi=10.1145%2f3178876.3185994&partnerID=40&md5=213dc0701c169f77a602f1fa919e5eee","In this paper, we propose a novel Deep Reinforcement Learning framework for news recommendation. Online personalized news recommendation is a highly challenging problem due to the dynamic nature of news features and user preferences. Although some online recommendation models have been proposed to address the dynamic nature of news recommendation, these methods have three major issues. First, they only try to model current reward (e.g., Click Through Rate). Second, very few studies consider to use user feedback other than click / no click labels (e.g., how frequent user returns) to help improve recommendation. Third, these methods tend to keep recommending similar news to users, which may cause users to get bored. Therefore, to address the aforementioned challenges, we propose a Deep Q-Learning based recommendation framework, which can model future reward explicitly. We further consider user return pattern as a supplement to click / no click label in order to capture more user feedback information. In addition, an effective exploration strategy is incorporated to find new attractive news for users. Extensive experiments are conducted on the offline dataset and online production environment of a commercial news recommendation application and have shown the superior performance of our methods. © 2018 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC BY 4.0 License."
"Wang J., Yu L., Zhang W., Gong Y., Xu Y., Wang B., Zhang P., Zhang D.","IRGAN: A minimax game for unifying generative and discriminative information retrieval models",2017,"SIGIR 2017 - Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029372592&doi=10.1145%2f3077136.3080786&partnerID=40&md5=c659c6d5de13eebaefdf9b25b0aad3d0","This paper provides a unified account of two schools of thinking in information retrieval modelling: The generative retrieval focusing on predicting relevant documents given a query, and the discriminative retrieval focusing on predicting relevancy given a querydocument pair. We propose a game theoretical minimax game to iteratively optimise both models. On one hand, the discriminative model, aiming to mine signals from labelled and unlabelled data, provides guidance to train the generative model towards fithing the underlying relevance distribution over documents given the query. On the other hand, the generative model, acting as an aftacker to the current discriminative model, generates difficult examples for the discriminative model in an adversarial way by minimising its discrimination objective. With the competition between these two models, we show that the unified framework takes advantage of both schools of thinking: (i) the generative model learns to fit the relevance distribution over documents via the signals from the discriminative model, and (ii) the discriminative model is able to exploit the unlabelled data selected by the generative model to achieve a beffer estimation for document ranking. Our experimental results have demonstrated significant performance gains as much as 23.96% on Precision@5 and 15.50% on MAP over strong baselines in a variety of applications including web search, item recommendation, and question answering. © 2017 Copyright held by the owner/author(s)."
"Datta A., Tschantz M.C., Datta A.","Automated experiments on ad privacy settings",2015,"Proceedings on Privacy Enhancing Technologies",,[No abstract available]
"Joachims T., Granka L., Pan B., Hembrooke H., Radlinski F., Gay G.","Evaluating the accuracy of implicit feedback from clicks and query reformulations in Web search",2007,"ACM Transactions on Information Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34247882698&doi=10.1145%2f1229179.1229181&partnerID=40&md5=daffc0932e92a3e1ed0574a91b4f6c9f","This article examines the reliability of implicit feedback generated from clickthrough data and query reformulations in World Wide Web (WWW) search. Analyzing the users' decision process using eyetracking and comparing implicit feedback against manual relevance judgments, we conclude that clicks are informative but biased. While this makes the interpretation of clicks as absolute relevance judgments difficult, we show that relative preferences derived from clicks are reasonably accurate on average. We find that such relative preferences are accurate not only between results from an individual query, but across multiple sets of results within chains of query reformulations. © 2007 ACM."
"Zhang Y., Chen X.","Explainable recommendation: A survey and new perspectives",2020,"Foundations and Trends in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082122478&doi=10.1561%2f1500000066&partnerID=40&md5=4c0476d20c3d6389f08dcbd34488a91c","Explainable recommendation attempts to develop models that generate not only high-quality recommendations but also intuitive explanations. The explanations may either be post-hoc or directly come from an explainable model (also called interpretable or transparent model in some contexts). Explainable recommendation tries to address the problem of why: by providing explanations to users or system designers, it helps humans to understand why certain items are recommended by the algorithm, where the human can either be users or system designers. Explainable recommendation helps to improve the transparency, persuasiveness, effectiveness, trustworthiness, and satisfaction of recommendation systems. It also facilitates system designers for better system debugging. In recent years, a large number of explainable recommendation approaches - especially model-based methods - have been proposed and applied in real-world systems. In this survey, we provide a comprehensive review for the explainable recommendation research. We first highlight the position of explainable recommendation in recommender system research by categorizing recommendation problems into the 5W, i.e., what, when, who, where, and why. We then conduct a comprehensive survey of explainable recommendation on three perspectives: 1) We provide a chronological research timeline of explainable recommendation, including user study approaches in the early years and more recent model-based approaches. 2) We provide a two-dimensional taxonomy to classify existing explainable recommendation research: one dimension is the information source (or display style) of the explanations, and the other dimension is the algorithmic mechanism to generate explainable recommendations. 3) We summarize how explainable recommendation applies to different recommendation tasks, such as product recommendation, social recommendation, and POI recommendation. We also devote a section to discuss the explanation perspectives in broader IR and AI/ML research. We end the survey by discussing potential future directions to promote the explainable recommendation research area and beyond. © 2019 Association for Computing Machinery. All rights reserved."
"Ntoutsi E., Fafalios P., Gadiraju U., Iosifidis V., Nejdl W., Vidal M.-E., Ruggieri S., Turini F., Papadopoulos S., Krasanakis E., Kompatsiaris I., Kinder-Kurlanda K., Wagner C., Karimi F., Fernandez M., Alani H., Berendt B., Kruegel T., Heinze C., Broelemann K., Kasneci G., Tiropanis T., Staab S.","Bias in data-driven artificial intelligence systems—An introductory survey",2020,"Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078894838&doi=10.1002%2fwidm.1356&partnerID=40&md5=f56beb887eea8a90beedb2f5aa428c10","Artificial Intelligence (AI)-based systems are widely employed nowadays to make decisions that have far-reaching impact on individuals and society. Their decisions might affect everyone, everywhere, and anytime, entailing concerns about potential human rights issues. Therefore, it is necessary to move beyond traditional AI algorithms optimized for predictive performance and embed ethical and legal principles in their design, training, and deployment to ensure social good while still benefiting from the huge potential of the AI technology. The goal of this survey is to provide a broad multidisciplinary overview of the area of bias in AI systems, focusing on technical challenges and solutions as well as to suggest new research directions towards approaches well-grounded in a legal frame. In this survey, we focus on data-driven AI, as a large part of AI is powered nowadays by (big) data and powerful machine learning algorithms. If otherwise not specified, we use the general term bias to describe problems related to the gathering or processing of data that might result in prejudiced decisions on the bases of demographic features such as race, sex, and so forth. This article is categorized under: Commercial, Legal, and Ethical Issues > Fairness in Data Mining Commercial, Legal, and Ethical Issues > Ethical Considerations Commercial, Legal, and Ethical Issues > Legal Issues. © 2020 The Authors. WIREs Data Mining and Knowledge Discovery published by Wiley Periodicals, Inc."
"Pedreshi D., Ruggieri S., Turini F.","Discrimination-aware data mining",2008,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-65449163899&doi=10.1145%2f1401890.1401959&partnerID=40&md5=e71f8ab35d1af22de066ea25d9d3b3b9","In the context of civil rights law, discrimination refers to unfair or unequal treatment of people based on membership to a category or a minority, without regard to individual merit. Rules extracted from databases by data mining techniques, such as classification or association rules, when used for decision tasks such as benefit or credit approval, can be discriminatory in the above sense. In this paper, the notion of discriminatory classification rules is introduced and studied. Providing a guarantee of non-discrimination is shown to be a non trivial task. A naive approach, like taking away all discriminatory attributes, is shown to be not enough when other background knowledge is available. Our approach leads to a precise formulation of the redlining problem along with a formal result relating discriminatory rules with apparently safe ones by means of background knowledge. An empirical assessment of the results on the German credit dataset is also provided. © 2008 ACM."
"Chapelle O., Zhang Y.","A Dynamic Bayesian Network click model for web search ranking",2009,"WWW'09 - Proceedings of the 18th International World Wide Web Conference","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865624822&doi=10.1145%2f1526709.1526711&partnerID=40&md5=1ad23f2c4cb79ed18d90abd9d5975460","As with any application of machine learning, web search ranking requires labeled data. The labels usually come in the form of relevance assessments made by editors. Click logs can also provide an important source of implicit feedback and can be used as a cheap proxy for editorial labels. The main difficulty however comes from the so called position bias - urls appearing in lower positions are less likely to be clicked even if they are relevant. In this paper, we propose a Dynamic Bayesian Network which aims at providing us with unbiased estimation of the relevance from the click logs. Experiments show that the proposed click model outperforms other existing click models in predicting both click-through rate and relevance. Copyright is held by the International World Wide Web Conference Committee (IW3C2)."
"Kleinberg J., Mullainathan S., Raghavan M.","Inherent trade-offs in the fair determination of risk scores",2017,"Leibniz International Proceedings in Informatics, LIPIcs","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021028155&doi=10.4230%2fLIPIcs.ITCS.2017.43&partnerID=40&md5=bd23f8dd252b45f3f48a469392a9f28f","Recent discussion in the public sphere about algorithmic classification has involved tension between competing notions of what it means for a probabilistic classification to be fair to different groups. We formalize three fairness conditions that lie at the heart of these debates, and we prove that except in highly constrained special cases, there is no method that can satisfy these three conditions simultaneously. Moreover, even satisfying all three conditions approximately requires that the data lie in an approximate version of one of the constrained special cases identified by our theorem. These results suggest some of the ways in which key notions of fairness are incompatible with each other, and hence provide a framework for thinking about the trade-offs between them."
"Lambrecht A., Tucker C.","Algorithmic bias? An empirical study of apparent gender-based discrimination in the display of stem career ads",2019,"Management Science","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069036783&doi=10.1287%2fmnsc.2018.3093&partnerID=40&md5=ae2d2362112da093cddffcf09230320e","We explore data from a field test of how an algorithm delivered ads promoting job opportunities in the science, technology, engineering and math fields. This ad was explicitly intended to be gender neutral in its delivery. Empirically, however, fewer women saw the ad than men. This happened because younger women are a prized demographic and are more expensive to show ads to. An algorithm that simply optimizes cost-effectiveness in ad delivery will deliver ads that were intended to be gender neutral in an apparently discriminatory way, because of crowding out. We show that this empirical regularity extends to other major digital platforms. Copyright: © 2019 INFORMS"
"Joachims T., Swaminathan A., Schnabel T.","Unbiased learning-to-rank with biased feedback",2017,"WSDM 2017 - Proceedings of the 10th ACM International Conference on Web Search and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015338094&doi=10.1145%2f3018661.3018699&partnerID=40&md5=68c2b2f1c007517af57518d663092cfb","Implicit feedback (e.g., clicks, dwell times, etc.) is an abundant source of data in human-interactive systems. While implicit feedback has many advantages (e.g., it is inexpensive to collect, user centric, and timely), its inherent biases are a key obstacle to its effective use. For example, position bias in search rankings strongly influences how many clicks a result receives, so that directly using click data as a training signal in Learning-to-Rank (LTR) methods yields sub-optimal results. To overcome this bias problem, we present a counterfactual inference framework that provides the theoretical basis for unbiased LTR via Empirical Risk Minimization despite biased data. Using this framework, we derive a Propensity-Weighted Ranking SVM for discriminative learning from implicit feedback, where click models take the role of the propensity estimator. In contrast to most conventional approaches to de-biasing the data using click models, this allows training of ranking functions even in settings where queries do not repeat. Beyond the theoretical support, we show empirically that the proposed learning method is highly effective in dealing with biases, that it is robust to noise and propensity model misspecification, and that it scales efficiently. We also demonstrate the real-world applicability of our approach on an operational search engine, where it substantially improves retrieval performance. © 2017 ACM."
"Singh A., Joachims T.","Fairness of exposure in rankings",2018,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051459091&doi=10.1145%2f3219819.3220088&partnerID=40&md5=412f7ad9f4ea17e1d70bb43160432461","Rankings are ubiquitous in the online world today. As we have transitioned from finding books in libraries to ranking products, jobs, job applicants, opinions and potential romantic partners, there is a substantial precedent that ranking systems have a responsibility not only to their users but also to the items being ranked. To address these often conflicting responsibilities, we propose a conceptual and computational framework that allows the formulation of fairness constraints on rankings in terms of exposure allocation. As part of this framework, we develop efficient algorithms for finding rankings that maximize the utility for the user while provably satisfying a specifiable notion of fairness. Since fairness goals can be application specific, we show how a broad range of fairness constraints can be implemented using our framework, including forms of demographic parity, disparate treatment, and disparate impact constraints. We illustrate the effect of these constraints by providing empirical results on two ranking problems. © 2018 Copyright held by the owner/author(s). Publication rights licensed to Association for Computing Machinery."
"Dupret G., Piwowarski B.","A user browsing model to predict search engine click data from past observations",2008,"ACM SIGIR 2008 - 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, Proceedings","https://www.scopus.com/inward/record.uri?eid=2-s2.0-57349140734&doi=10.1145%2f1390334.1390392&partnerID=40&md5=166616118ecccc69cd2d44d2cd659122","Search engine click logs provide an invaluable source of relevance information but this information is biased because we ignore which documents from the result list the users have actually seen before and after they clicked. Otherwise, we could estimate document relevance by simple counting. In this paper, we propose a set of assumptions on user browsing behavior that allows the estimation of the probability that a document is seen, thereby providing an unbiased estimate of document relevance. To train, test and compare our model to the best alternatives described in the Literature, we gather a large set of real data and proceed to an extensive cross-validation experiment. Our solution outperforms very significantly all previous models. As a side effect, we gain insight into the browsing behavior of users and we can compare it to the conclusions of an eye-tracking experiments by Joachims et al. [12]. In particular, our findings confirm that a user almost always see the document directly after a clicked document. They also explain why documents situated just after a very relevant document are clicked more often. Copyright 2008 ACM."
"Tarus J.K., Niu Z., Mustafa G.","Knowledge-based recommendation: a review of ontology-based recommender systems for e-learning",2018,"Artificial Intelligence Review","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010807186&doi=10.1007%2fs10462-017-9539-5&partnerID=40&md5=df09dd34c5230a6d7717ea3ff5deb817","Recommender systems in e-learning domain play an important role in assisting the learners to find useful and relevant learning materials that meet their learning needs. Personalized intelligent agents and recommender systems have been widely accepted as solutions towards overcoming information retrieval challenges by learners arising from information overload. Use of ontology for knowledge representation in knowledge-based recommender systems for e-learning has become an interesting research area. In knowledge-based recommendation for e-learning resources, ontology is used to represent knowledge about the learner and learning resources. Although a number of review studies have been carried out in the area of recommender systems, there are still gaps and deficiencies in the comprehensive literature review and survey in the specific area of ontology-based recommendation for e-learning. In this paper, we present a review of literature on ontology-based recommenders for e-learning. First, we analyze and classify the journal papers that were published from 2005 to 2014 in the field of ontology-based recommendation for e-learning. Secondly, we categorize the different recommendation techniques used by ontology-based e-learning recommenders. Thirdly, we categorize the knowledge representation technique, ontology type and ontology representation language used by ontology-based recommender systems, as well as types of learning resources recommended by e-learning recommenders. Lastly, we discuss the future trends of this recommendation approach in the context of e-learning. This study shows that use of ontology for knowledge representation in e-learning recommender systems can improve the quality of recommendations. It was also evident that hybridization of knowledge-based recommendation with other recommendation techniques can enhance the effectiveness of e-learning recommenders. © 2017, Springer Science+Business Media Dordrecht."
"Rendle S., Freudenthaler C.","Improving pairwise learning for item recommendation from implicit feedback",2014,"WSDM 2014 - Proceedings of the 7th ACM International Conference on Web Search and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906871528&doi=10.1145%2f2556195.2556248&partnerID=40&md5=1115085b1dacda60825d57f838ef26fd","Pairwise algorithms are popular for learning recommender systems from implicit feedback. For each user, or more generally context, they try to discriminate between a small set of selected items and the large set of remaining (irrelevant) items. Learning is typically based on stochastic gradient descent (SGD) with uniformly drawn pairs. In this work, we show that convergence of such SGD learning algorithms slows down considerably if the item popularity has a tailed distribution. We propose a non-uniform item sampler to overcome this problem. The proposed sampler is context-dependent and oversamples informative pairs to speed up convergence. An efficient implementation with constant amortized runtime costs is developed. Furthermore, it is shown how the proposed learning algorithm can be applied to a large class of recommender models. The properties of the new learning algorithm are studied empirically on two real-world recommender system problems. The experiments indicate that the proposed adaptive sampler improves the state-of-the art learning algorithm largely in convergence without negative effects on prediction quality or iteration runtime. © 2014 ACM."
"Zehlike M., Bonchi F., Castillo C., Hajian S., Megahed M., Baeza-Yates R.","FA∗IR: A fair top-k ranking algorithm",2017,"International Conference on Information and Knowledge Management, Proceedings","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037328865&doi=10.1145%2f3132847.3132938&partnerID=40&md5=269b036e841b9b7e7a121a926b6893db","In this work, we define and solve the Fair Top-k Ranking problem, in which we want to determine a subset of k candidates from a large pool of nk candidates, maximizing utility (i.e., select the ""best"" candidates) subject to group fairness criteria. Our ranked group fairness definition extends group fairness using the standard notion of protected groups and is based on ensuring that the proportion of protected candidates in every prefix of the top-k ranking remains statistically above or indistinguishable from a given minimum. Utility is operationalized in two ways: (i) every candidate included in the top-k should be more qualified than every candidate not included; and (ii) for every pair of candidates in the top-k, the more qualified candidate should be ranked above. An efficient algorithm is presented for producing the Fair Top-k Ranking, and tested experimentally on existing datasets as well as new datasets released with this paper, showing that our approach yields small distortions with respect to rankings that maximize utility without considering fairness criteria. To the best of our knowledge, this is the first algorithm grounded in statistical tests that can mitigate biases in the representation of an under-represented group along attranked list. © 2017 Copyright held by the owner/author(s). Publication rights licensed to ACM."
"Schnabel T., Swaminathan A., Singh A., Chandak N., Joachims T.","Recommendations as treatments: Debiasing learning and evaluation",2016,"Recommendations As Treatments: Debiasing Learning and Evaluation",,[No abstract available]
"Biega A.J., Gummadi K.P., Weikum G.","Equity of attention: Amortizing individual fairness in rankings",2018,"41st International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051552737&doi=10.1145%2f3209978.3210063&partnerID=40&md5=dc7ae83319d19725bcfbf2f9cea53035","Rankings of people and items are at the heart of selection-making, match-making, and recommender systems, ranging from employment sites to sharing economy platforms. As ranking positions influence the amount of attention the ranked subjects receive, biases in rankings can lead to unfair distribution of opportunities and resources such as jobs or income. This paper proposes new measures and mechanisms to quantify and mitigate unfairness from a bias inherent to all rankings, namely, the position bias which leads to disproportionately less attention being paid to low-ranked subjects. Our approach differs from recent fair ranking approaches in two important ways. First, existing works measure unfairness at the level of subject groups while our measures capture unfairness at the level of individual subjects, and as such subsume group unfairness. Second, as no single ranking can achieve individual attention fairness, we propose a novel mechanism that achieves amortized fairness, where attention accumulated across a series of rankings is proportional to accumulated relevance. We formulate the challenge of achieving amortized individual fairness subject to constraints on ranking quality as an online optimization problem and show that it can be solved as an integer linear program. Our experimental evaluation reveals that unfair attention distribution in rankings can be substantial, and demonstrates that our method can improve individual fairness while retaining high ranking quality. © 2018 ACM."
"Tang J., Gao H., Liu H.","MTrust: Discerning multi-faceted trust in a connected world",2012,"WSDM 2012 - Proceedings of the 5th ACM International Conference on Web Search and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863251494&doi=10.1145%2f2124295.2124309&partnerID=40&md5=d73f165d2482aa5c346c48ea084336fc","Traditionally, research about trust assumes a single type of trust between users. However, trust, as a social concept, inherently has many facets indicating multiple and heterogeneous trust relationships between users. Due to the presence of a large trust network for an online user, it is necessary to discern multi-faceted trust as there are naturally experts of different types. Our study in product review sites reveals that people place trust differently to different people. Since the widely used adjacency matrix cannot capture multi-faceted trust relationships between users, we propose a novel approach by incorporating these relationships into traditional rating prediction algorithms to reliably estimate their strengths. Our work results in interesting findings such as heterogeneous pairs of reciprocal links. Experimental results on real-world data from Epinions and Ciao show that our work of discerning multi-faceted trust can be applied to improve the performance of tasks such as rating prediction, facet-sensitive ranking, and status theory. Copyright 2012 ACM."
"Liang D., Charlin L., McInerney J., Blei D.M.","Modeling user exposure in recommendation",2016,"25th International World Wide Web Conference, WWW 2016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991238294&doi=10.1145%2f2872427.2883090&partnerID=40&md5=d27a751e30ad312f0be9da477d9c6fd7","Collaborative -ltering analyzes user preferences for items (e.g., books, movies, restaurants, academic papers) by exploiting the similarity patterns across users. In implicit feedback settings, all the items, including the ones that a user did not consume, are taken into consideration. But this assumption does not accord with the common sense understanding that users have a limited scope and awareness of items. For example, a user might not have heard of a certain paper, or might live too far away from a restaurant to experience it. In the language of causal analysis [9], the assignment mechanism (i.e., the items that a user is exposed to) is a latent variable that may change for various user/item combinations. In this paper, we propose a new probabilistic approach that directly incorporates user exposure to items into collaborative ffltering. The exposure is modeled as a latent variable and the model infers its value from data. In doing so, we recover one of the most successful state-of-Theart approaches as a special case of our model [8], and provide a plug-in method for conditioning exposure on various forms of exposure covariates (e.g., topics in text, venue locations). We show that our scalable inference algorithm outperforms existing benchmarks in four difierent domains both with and without exposure covariates."
"Ma X., Zhao L., Huang G., Wang Z., Hu Z., Zhu X., Gai K.","Entire space multi-task model: An effective approach for estimating post-click conversion rate",2018,"41st International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051518688&doi=10.1145%2f3209978.3210104&partnerID=40&md5=782618d3819e0c9c8ade27566794ed1b","Estimating post-click conversion rate (CVR) accurately is crucial for ranking systems in industrial applications such as recommendation and advertising. Conventional CVR modeling applies popular deep learning methods and achieves state-of-the-art performance. However it encounters several task-specific problems in practice, making CVR modeling challenging. For example, conventional CVR models are trained with samples of clicked impressions while utilized to make inference on the entire space with samples of all impressions. This causes a sample selection bias problem. Besides, there exists an extreme data sparsity problem, making the model fitting rather difficult. In this paper, we model CVR in a brand-new perspective by making good use of sequential pattern of user actions, i.e., impression -> click -> conversion. The proposed Entire Space Multi-task Model (ESMM) can eliminate the two problems simultaneously by i) modeling CVR directly over the entire space, ii) employing a feature representation transfer learning strategy. Experiments on dataset gathered from Taobao's recommender system demonstrate that ESMM significantly outperforms competitive methods. We also release a sampling version of this dataset to enable future research. To the best of our knowledge, this is the first public dataset which contains samples with sequential dependence of click and conversion labels for CVR modeling. © 2018 ACM."
"Abdollahpouri H., Burke R., Mobasher B.","Controlling popularity bias in learning-to-rank recommendation",2017,"RecSys 2017 - Proceedings of the 11th ACM Conference on Recommender Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029218088&doi=10.1145%2f3109859.3109912&partnerID=40&md5=71b0a4a2ae3cd7e0153706af58225909","Many recommendation algorithms su.er from popularity bias in their output: popular items are recommended frequently and less popular ones rarely, if at all. However, less popular, long-tail items are precisely those that are often desirable recommendations. In this paper, we introduce a flexible regularization-based framework to enhance the long-tail coverage of recommendation lists in a learning-to-rank algorithm. We show that regularization provides a tunable mechanism for controlling the trade-off between accuracy and coverage. Moreover, the experimental results using two data sets show that it is possible to improve coverage of long tail items without substantial loss of ranking performance. © 2017 ACM."
"Chen M., Beutel A., Covington P., Jain S., Belletti F., Chi E.H.","Top-k off-policy correction for a reinforce recommender system",2019,"WSDM 2019 - Proceedings of the 12th ACM International Conference on Web Search and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061700856&doi=10.1145%2f3289600.3290999&partnerID=40&md5=373a22b4cd93662e5877989c9f965e2a","Industrial recommender systems deal with extremely large action spaces - many millions of items to recommend. Moreover, they need to serve billions of users, who are unique at any point in time, making a complex user state space. Luckily, huge quantities of logged implicit feedback (e.g., user clicks, dwell time) are available for learning. Learning from the logged feedback is however subject to biases caused by only observing feedback on recommendations selected by the previous versions of the recommender. In this work, we present a general recipe of addressing such biases in a production top-K recommender system at YouTube, built with a policy-gradient-based algorithm, i.e. REINFORCE [48]. The contributions of the paper are: (1) scaling REINFORCE to a production recommender system with an action space on the orders of millions; (2) applying off-policy correction to address data biases in learning from logged feedback collected from multiple behavior policies; (3) proposing a novel top-K off-policy correction to account for our policy recommending multiple items at a time; (4) showcasing the value of exploration. We demonstrate the efficacy of our approaches through a series of simulations and multiple live experiments on YouTube. © 2019 held by the owner/author(s)."
"Steck H.","Training and testing of recommender systems on data missing not at random",2010,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956208065&doi=10.1145%2f1835804.1835895&partnerID=40&md5=837b937e97b53e986b855177b30bf914","Users typically rate only a small fraction of all available items. We show that the absence of ratings carries useful information for improving the top-k hit rate concerning all items, a natural accuracy measure for recommendations. As to test recommender systems, we present two performance measures that can be estimated, under mild assumptions, without bias from data even when ratings are missing not at random (MNAR). As to achieve optimal test results, we present appropriate surrogate objective functions for efficient training on MNAR data. Their main property is to account for all ratings-whether observed or missing in the data. Concerning the top-k hit rate on test data, our experiments indicate dramatic improvements over even sophisticated methods that are optimized on observed ratings only. © 2010 ACM."
"Shen Zheyan, Liu Jiashuo, He Yue, Zhang Xingxuan, Xu Renzhe, Yu Han, Cui Peng",[No title available],2021,"Towards out-of-distribution generalization: A survey",,[No abstract available]
"Zhang H., Shen F., Liu W., He X., Luan H., Chua T.-S.","Discrete collaborative filtering",2016,"SIGIR 2016 - Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980322368&doi=10.1145%2f2911451.2911502&partnerID=40&md5=2cfd00ae4a58b90a34618fb7616d2de3","We address the efficiency problem of Collaborative Filtering (CF) by hashing users and items as latent vectors in the form of binary codes, so that user-item affinity can be efficiently calculated in a Hamming space. However, existing hashing methods for CF employ binary code learning procedures that most suffer from the challenging discrete constraints. Hence, those methods generally adopt a two-stage learning scheme composed of relaxed optimization via discarding the discrete constraints, followed by binary quantization. We argue that such a scheme will result in a large quantization loss, which especially compromises the performance of large-scale CF that resorts to longer binary codes. In this paper, we propose a principled CF hashing framework called Discrete Collaborative Filtering (DCF), which directly tackles the challenging discrete optimization that should have been treated adequately in hashing. The formulation of DCF has two advantages: 1) the Hamming similarity induced loss that preserves the intrinsic user-item similarity, and 2) the balanced and uncorrelated code constraints that yield compact yet informative binary codes. We devise a computationally efficient algorithm with a rigorous convergence proof of DCF. Through extensive experiments on several real-world benchmarks, we show that DCF consistently outperforms state-of-the-art CF hashing techniques, e.g., though using only 8 bits, DCF is even significantly better than other methods using 128 bits. © 2016 ACM."
"Zhao X., Xia L., Zhang L., Ding Z., Yin D., Tang J.","Deep reinforcement learning for page-wise recommendations",2018,"RecSys 2018 - 12th ACM Conference on Recommender Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056760664&doi=10.1145%2f3240323.3240374&partnerID=40&md5=9b2ef631fd77ac16e60e80b40d816346","Recommender systems can mitigate the information overload problem by suggesting users' personalized items. In real-world recommendations such as e-commerce, a typical interaction between the system and its users is - users are recommended a page of items and provide feedback; and then the system recommends a new page of items. To effectively capture such interaction for recommendations, we need to solve two key problems - (1) how to update recommending strategy according to user's real-time feedback, and 2) how to generate a page of items with proper display, which pose tremendous challenges to traditional recommender systems. In this paper, we study the problem of page-wise recommendations aiming to address aforementioned two challenges simultaneously. In particular, we propose a principled approach to jointly generate a set of complementary items and the corresponding strategy to display them in a 2-D page; and propose a novel page-wise recommendation framework based on deep reinforcement learning, DeepPage, which can optimize a page of items with proper display based on real-time feedback from users. The experimental results based on a real-world e-commerce dataset demonstrate the effectiveness of the proposed framework. © 2018 Association for Computing Machinery."
"Beutel A., Chen J., Doshi T., Qian H., Wei L., Wu Y., Heldt L., Zhao Z., Hong L., Chi E.H., Goodrow C.","Fairness in recommendation ranking through pairwise comparisons",2019,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071197442&doi=10.1145%2f3292500.3330745&partnerID=40&md5=53cebcaf495da63170df316af98cf87b","Recommender systems are one of the most pervasive applications of machine learning in industry, with many services using them to match users to products or information. As such it is important to ask: what are the possible fairness risks, how can we quantify them, and how should we address them? In this paper we offer a set of novel metrics for evaluating algorithmic fairness concerns in recommender systems. In particular we show how measuring fairness based on pairwise comparisons from randomized experiments provides a tractable means to reason about fairness in rankings from recommender systems. Building on this metric, we offer a new regularizer to encourage improving this metric during model training and thus improve fairness in the resulting rankings. We apply this pairwise regularization to a large-scale, production recommender system and show that we are able to significantly improve the system's pairwise fairness. © 2019 Copyright held by the owner/author(s)."
"Zhao X., Xia L., Zhang L., Tang J., Ding Z., Yin D.","Recommendations with negative feedback via pairwise deep reinforcement learning",2018,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051481127&doi=10.1145%2f3219819.3219886&partnerID=40&md5=dbb3d134e549597db6f1575d747695fc","Recommender systems play a crucial role in mitigating the problem of information overload by suggesting users' personalized items or services. The vast majority of traditional recommender systems consider the recommendation procedure as a static process and make recommendations following a fixed strategy. In this paper, we propose a novel recommender system with the capability of continuously improving its strategies during the interactions with users. We model the sequential interactions between users and a recommender system as a Markov Decision Process (MDP) and leverage Reinforcement Learning (RL) to automatically learn the optimal strategies via recommending trial-and-error items and receiving reinforcements of these items from users' feedback. Users' feedback can be positive and negative and both types of feedback have great potentials to boost recommendations. However, the number of negative feedback is much larger than that of positive one; thus incorporating them simultaneously is challenging since positive feedback could be buried by negative one. In this paper, we develop a novel approach to incorporate them into the proposed deep recommender system (DEERS) framework. The experimental results based on real-world e-commerce data demonstrate the effectiveness of the proposed framework. Further experiments have been conducted to understand the importance of both positive and negative feedback in recommendations. © 2018 Association for Computing Machinery."
"Marlin B.M., Zemel R.S.","Collaborative prediction and ranking with non-random missing data",2009,"RecSys'09 - Proceedings of the 3rd ACM Conference on Recommender Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-72249101936&doi=10.1145%2f1639714.1639717&partnerID=40&md5=1b12941d8cc91ff6f4387a963939ffda","A fundamental aspect of rating-based recommender systems is the observation process, the process by which users choose the items they rate. Nearly all research on collaborative filtering and recommender systems is founded on the assumption that missing ratings are missing at random. The statistical theory of missing data shows that incorrect assumptions about missing data can lead to biased parameter estimation and prediction. In a recent study, we demonstrated strong evidence for violations of the missing at random condition in a real recommender system. In this paper we present the first study of the effect of non-random missing data on collaborative ranking, and extend our previous results regarding the impact of non-random missing data on collaborative prediction. Copyright 2009 ACM."
"Geyik S.C., Ambler S., Kenthapadi K.","Fairness-aware ranking in search & recommendation systems with application to linkedin talent search",2019,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071153136&doi=10.1145%2f3292500.3330691&partnerID=40&md5=050e9c6079ee06e2aae49d838e09bbe7","We present a framework for quantifying and mitigating algorithmic bias in mechanisms designed for ranking individuals, typically used as part of web-scale search and recommendation systems. We first propose complementary measures to quantify bias with respect to protected attributes such as gender and age. We then present algorithms for computing fairness-aware re-ranking of results. For a given search or recommendation task, our algorithms seek to achieve a desired distribution of top ranked results with respect to one or more protected attributes. We show that such a framework can be tailored to achieve fairness criteria such as equality of opportunity and demographic parity depending on the choice of the desired distribution. We evaluate the proposed algorithms via extensive simulations over different parameter choices, and study the effect of fairness-aware ranking on both bias and utility measures. We finally present the online A/B testing results from applying our framework towards representative ranking in LinkedIn Talent Search, and discuss the lessons learned in practice. Our approach resulted in tremendous improvement in the fairness metrics (nearly three fold increase in the number of search queries with representative results) without affecting the business metrics, which paved the way for deployment to 100% of LinkedIn Recruiter users worldwide. Ours is the first large-scale deployed framework for ensuring fairness in the hiring domain, with the potential positive impact for more than 630M LinkedIn members. © 2019 Association for Computing Machinery."
"Yao S., Huang B.","Beyond parity: Fairness objectives for collaborative filtering",2017,"Advances in Neural Information Processing Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046998283&partnerID=40&md5=73232f4f3a033b2bd5dbdd5241987c99","We study fairness in collaborative-filtering recommender systems, which are sensitive to discrimination that exists in historical data. Biased data can lead collaborative-filtering methods to make unfair predictions for users from minority groups. We identify the insufficiency of existing fairness metrics and propose four new metrics that address different forms of unfairness. These fairness metrics can be optimized by adding fairness terms to the learning objective. Experiments on synthetic and real data show that our new metrics can better measure fairness than the baseline, and that the fairness objectives effectively help reduce unfairness. © 2017 Neural information processing systems foundation. All rights reserved."
"Zhang Y., Feng F., He X., Wei T., Song C., Ling G., Zhang Y.","Causal Intervention for Leveraging Popularity Bias in Recommendation",2021,"SIGIR 2021 - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107977886&doi=10.1145%2f3404835.3462875&partnerID=40&md5=902b37537da2dbf3141616347dd77481","Recommender system usually faces popularity bias issues: from the data perspective, items exhibit uneven (usually long-tail) distribution on the interaction frequency; from the method perspective, collaborative filtering methods are prone to amplify the bias by over-recommending popular items. It is undoubtedly critical to consider popularity bias in recommender systems, and existing work mainly eliminates the bias effect with propensity-based unbiased learning or causal embeddings. However, we argue that not all biases in the data are bad, \ie some items demonstrate higher popularity because of their better intrinsic quality. Blindly pursuing unbiased learning may remove the beneficial patterns in the data, degrading the recommendation accuracy and user satisfaction. This work studies an unexplored problem in recommendation - - how to leverage popularity bias to improve the recommendation accuracy. The key lies in two aspects: how to remove the bad impact of popularity bias during training, and how to inject the desired popularity bias in the inference stage that generates top-K recommendations. This questions the causal mechanism of the recommendation generation process. Along this line, we find that item popularity plays the role ofconfounder between the exposed items and the observed interactions, causing the bad effect of bias amplification. To achieve our goal, we propose a new training and inference paradigm for recommendation named Popularity-bias Deconfounding and Adjusting (PDA). It removes the confounding popularity bias in model training and adjusts the recommendation score with desired popularity bias via causal intervention. We demonstrate the new paradigm on the latent factor model and perform extensive experiments on three real-world datasets from Kwai, Douban, and Tencent. Empirical studies validate that the deconfounded training is helpful to discover user real interests and the inference adjustment with popularity bias could further improve the recommendation accuracy. We release our code at https://github.com/zyang1580/PDA. © 2021 ACM."
"Swaminathan A., Joachims T.","Batch learning from logged bandit feedback through counterfactual risk minimization",2015,"Journal of Machine Learning Research","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962231719&partnerID=40&md5=17988650cdf319212a53c7cb436f4f2e","We develop a learning principle and an efficient algorithm for batch learning from logged bandit feedback. This learning setting is ubiquitous in online systems (e.g., ad placement, web search, recommendation), where an algorithm makes a prediction (e.g., ad ranking) for a given input (e.g., query) and observes bandit feedback (e.g., user clicks on presented ads). We first address the counterfactual nature of the learning problem (Bottou et al., 2013) through propensity scoring. Next, we prove generalization error bounds that account for the variance of the propensity-weighted empirical risk estimator. In analogy to the Structural Risk Minimization principle of Wapnik and Tscherwonenkis (1979), these constructive bounds give rise to the Counterfactual Risk Minimization (CRM) principle. We show how CRM can be used to derive a new learning method-called Policy Optimizer for Exponential Models (POEM)-for learning stochastic linear rules for structured output prediction. We present a decomposition of the POEM objective that enables efficient stochastic gradient optimization. The effectiveness and efficiency of POEM is evaluated on several simulated multi-label classification problems, as well as on a real-world information retrieval problem. The empirical results show that the CRM objective implemented in POEM provides improved robustness and generalization performance compared to the state-of-the-art. © 2015 Adith Swaminathan and Thorsten Joachims."
"Wang X., Bendersky M., Metzler D., Najork M.","Learning to rank with selection bias in personal search",2016,"SIGIR 2016 - Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980347492&doi=10.1145%2f2911451.2911537&partnerID=40&md5=abfb5835c3d4ef1c9f1eac21d61025f6","Click-through data has proven to be a critical resource for improving search ranking quality. Though a large amount of click data can be easily collected by search engines, various biases make it difficult to fully leverage this type of data. In the past, many click models have been proposed and successfully used to estimate the relevance for individual query-document pairs in the context of web search. These click models typically require a large quantity of clicks for each individual pair and this makes them difficult to apply in systems where click data is highly sparse due to personalized corpora and information needs, e.g., personal search. In this paper, we study the problem of how to leverage sparse click data in personal search and introduce a novel selection bias problem and address it in the learning-to-rank framework. This paper proposes a few bias estimation methods, including a novel query-dependent one that captures queries with similar results and can successfully deal with sparse data. We empirically demonstrate that learning-to-rank that accounts for query-dependent selection bias yields significant improvements in search effectiveness through online experiments with one of the world's largest personal search engines. © 2016 ACM."
"Zheng Y., Gao C., Li X., He X., Li Y., Jin D.","Disentangling user interest and conformity for recommendation with causal embedding",2021,"The Web Conference 2021 - Proceedings of the World Wide Web Conference, WWW 2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107966903&doi=10.1145%2f3442381.3449788&partnerID=40&md5=f1055cedba7d37e5536b5bd700f64740","Recommendation models are usually trained on observational interaction data. However, observational interaction data could result from users' conformity towards popular items, which entangles users' real interest. Existing methods tracks this problem as eliminating popularity bias, e.g., by re-weighting training samples or leveraging a small fraction of unbiased data. However, the variety of user conformity is ignored by these approaches, and different causes of an interaction are bundled together as unified representations, hence robustness and interpretability are not guaranteed when underlying causes are changing. In this paper, we present DICE, a general framework that learns representations where interest and conformity are structurally disentangled, and various backbone recommendation models could be smoothly integrated. We assign users and items with separate embeddings for interest and conformity, and make each embedding capture only one cause by training with cause-specific data which is obtained according to the colliding effect of causal inference. Our proposed methodology outperforms state-of-the-art baselines with remarkable improvements on two real-world datasets on top of various backbone models. We further demonstrate that the learned embeddings successfully capture the desired causes, and show that DICE guarantees the robustness and interpretability of recommendation. Â© 2021 ACM."
"Nabi R., Shpitser I.","Fair inference on outcomes",2018,"32nd AAAI Conference on Artificial Intelligence, AAAI 2018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051223554&partnerID=40&md5=8ad9c32a622c862a5a734792c9bbfc0b","In this paper, we consider the problem of fair statistical inference involving outcome variables. Examples include classification and regression problems, and estimating treatment effects in randomized trials or observational data. The issue of fairness arises in such problems where some covariates or treatments are “sensitive,” in the sense of having potential of creating discrimination. In this paper, we argue that the presence of discrimination can be formalized in a sensible way as the presence of an effect of a sensitive covariate on the outcome along certain causal pathways, a view which generalizes (Pearl 2009). A fair outcome model can then be learned by solving a constrained optimization problem. We discuss a number of complications that arise in classical statistical inference due to this view and provide workarounds based on recent work in causal and semi-parametric inference. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved."
"Wang X., Golbandi N., Bendersky M., Metzler D., Najork M.","Position bias estimation for unbiased learning to rank in personal search",2018,"WSDM 2018 - Proceedings of the 11th ACM International Conference on Web Search and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046969001&doi=10.1145%2f3159652.3159732&partnerID=40&md5=eb7975e8ce6db5134f59e42d70888b6c","A well-known challenge in learning from click data is its inherent bias and most notably position bias. Traditional click models aim to extract the (query, document) relevance and the estimated bias is usually discarded after relevance is extracted. In contrast, the most recent work on unbiased learning-to-rank can effectively leverage the bias and thus focuses on estimating bias rather than relevance [20, 31]. Existing approaches use search result randomization over a small percentage of production traffic to estimate the position bias. This is not desired because result randomization can negatively impact users' search experience. In this paper, we compare different schemes for result randomization (i.e., RandTopN and RandPair) and show their negative effect in personal search. Then we study how to infer such bias from regular click data without relying on randomization. We propose a regressionbased Expectation-Maximization (EM) algorithm that is based on a position bias click model and that can handle highly sparse clicks in personal search. We evaluate our EM algorithm and the extracted bias in the learning-to-rank setting. Our results show that it is promising to extract position bias from regular clicks without result randomization. The extracted bias can improve the learning-to-rank algorithms significantly. In addition, we compare the pointwise and pairwise learning-to-rank models. Our results show that pairwise models are more effective in leveraging the estimated bias. © 2018 Association for Computing Machinery."
"Mehrotra R., McInerney J., Bouchard H., Lalmas M., Diaz F.","Towards a fair marketplace: Counterfactual evaluation of the trade-off between relevance, fairness & satisfaction in recommendation systems",2018,"International Conference on Information and Knowledge Management, Proceedings","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058006573&doi=10.1145%2f3269206.3272027&partnerID=40&md5=011dcc299dd75a97fd8286f02e194bd3","Two-sided marketplaces are platforms that have customers not only on the demand side (e.g. users), but also on the supply side (e.g. retailer, artists). While traditional recommender systems focused specifically towards increasing consumer satisfaction by providing relevant content to consumers, two-sided marketplaces face the problem of additionally optimizing for supplier preferences, and visibility. Indeed, the suppliers would want a fair opportunity to be presented to users. Blindly optimizing for consumer relevance may have a detrimental impact on supplier fairness. Motivated by this problem, we focus on the trade-off between objectives of consumers and suppliers in the case of music streaming services, and consider the trade-off between relevance of recommendations to the consumer (i.e. user) and fairness of representation of suppliers (i.e. artists) and measure their impact on consumer satisfaction. We propose a conceptual and computational framework using counterfactual estimation techniques to understand, and evaluate different recommendation policies, specifically around the trade-off between relevance and fairness, without the need for running many costly A/B tests. We propose a number of recommendation policies which jointly optimize relevance and fairness, thereby achieving substantial improvement in supplier fairness without noticeable decline in user satisfaction. Additionally, we consider user disposition towards fair content, and propose a personalized recommendation policy which takes into account consumer's tolerance towards fair content. Our findings could guide the design of algorithms powering two-sided marketplaces, as well as guide future research on sophisticated algorithms for joint optimization of user relevance, satisfaction and fairness. © 2018 Association for Computing Machinery."
"Bonner S., Vasile F.","Causal embeddings for recommendation",2018,"RecSys 2018 - 12th ACM Conference on Recommender Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056763991&doi=10.1145%2f3240323.3240360&partnerID=40&md5=e96bc88d8c75b6259a238dcc6bc2fc04","Many current applications use recommendations in order to modify the natural user behavior, such as to increase the number of sales or the time spent on a website. This results in a gap between the final recommendation objective and the classical setup where recommendation candidates are evaluated by their coherence with past user behavior, by predicting either the missing entries in the user-item matrix, or the most likely next event. To bridge this gap, we optimize a recommendation policy for the task of increasing the desired outcome versus the organic user behavior. We show this is equivalent to learning to predict recommendation outcomes under a fully random recommendation policy. To this end, we propose a new domain adaptation algorithm that learns from logged data containing outcomes from a biased recommendation policy and predicts recommendation outcomes according to random exposure. We compare our method against state-of-the-art factorization methods, in addition to new approaches of causal recommendation and show significant improvements. © 2018 Copyright held by the owner/author(s)."
"Saito Y., Yaginuma S., Nishino Y., Sakata H., Nakata K.","Unbiased recommender learning from missing-not-at-random implicit feedback",2020,"WSDM 2020 - Proceedings of the 13th International Conference on Web Search and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079528003&doi=10.1145%2f3336191.3371783&partnerID=40&md5=2a5c785c46d4e480245a716ac2355bd7","Recommender systems widely use implicit feedback such as click data because of its general availability. Although the presence of clicks signals the users’ preference to some extent, the lack of such clicks does not necessarily indicate a negative response from the users, as it is possible that the users were not exposed to the items (positive-unlabeled problem). This leads to a difficulty in predicting the users’ preferences from implicit feedback. Previous studies addressed the positive-unlabeled problem by uniformly upweighting the loss for the positive feedback data or estimating the confidence of each data having relevance information via the EM-algorithm. However, these methods failed to address the missing-not-at-random problem in which popular or frequently recommended items are more likely to be clicked than other items even if a user does not have a considerable interest in them. To overcome these limitations, we first define an ideal loss function to be optimized to realize recommendations that maximize the relevance and propose an unbiased estimator for the ideal loss. Subsequently, we analyze the variance of the proposed unbiased estimator and further propose a clipped estimator that includes the unbiased estimator as a special case. We demonstrate that the clipped estimator is expected to improve the performance of the recommender system, by considering the bias-variance trade-off. We conduct semi-synthetic and real-world experiments and demonstrate that the proposed method largely outperforms the baselines. In particular, the proposed method works better for rare items that are less frequently observed in the training data. The findings indicate that the proposed method can better achieve the objective of recommending items with the highest relevance. © 2020 Association for Computing Machinery."
"Steck H.","Evaluation of recommendations: Rating-prediction and ranking",2013,"RecSys 2013 - Proceedings of the 7th ACM Conference on Recommender Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887575890&doi=10.1145%2f2507157.2507160&partnerID=40&md5=6195800d8a2d31bbf49830da5d8a12b7","The literature on recommender systems distinguishes typically between two broad categories of measuring recommendation accuracy: rating prediction, often quantified in terms of the root mean square error (RMSE), and ranking, measured in terms of metrics like precision and recall, among others. In this paper, we examine both approaches in detail, and find that the dominating difference lies instead in the training and test data considered: rating prediction is concerned with only the observed ratings, while ranking typically accounts for all items in the collection, whether the user has rated them or not. Furthermore, we show that predicting observed ratings, while popular in the literature, only solves a (small) part of the rating prediction task for any item in the collection, which is a common real-world problem. The reasons are selection bias in the data, combined with data sparsity. We show that the latter rating-prediction task involves the prediction task 'Who rated What' as a subproblem, which can be cast as a classification or ranking problem. This suggests that solving the ranking problem is not only valuable by itself, but also for predicting the rating value of any item. © 2013 ACM."
"Guo F., Liu C., Kannan A., Minka T., Taylor M., Wang Y.-M., Faloutsos C.","Click chain model in web search",2009,"WWW'09 - Proceedings of the 18th International World Wide Web Conference","https://www.scopus.com/inward/record.uri?eid=2-s2.0-74549137182&doi=10.1145%2f1526709.1526712&partnerID=40&md5=5c0f7343bad77e267239c7c8c1e90c6a","Given a terabyte click log, can we build an efficient and effective click model? It is commonly believed that web search click logs are a gold mine for search business, because they reflect users' preference over web documents presented by the search engine. Click models provide a principled approach to inferring user-perceived relevance of web documents, which can be leveraged in numerous applications in search businesses. Due to the huge volume of click data, scalability is a must. We present the click chain model (CCM), which is based on a solid, Bayesian framework. It is both scalable and incremental, perfectly meeting the computational challenges imposed by the voluminous click logs that constantly grow. We conduct an extensive experimental study on a data set containing 8.8 million query sessions obtained in July 2008 from a commercial search engine. CCM consistently outperforms two state-of-the-art competitors in a number of metrics, with over 9.7% better log-likelihood, over 6.2% better click perplexity and much more robust (up to 30%) prediction of the first and the last clicked position. Copyright is held by the International World Wide Web Conference Committee (IW3C2)."
"Wei T., Feng F., Chen J., Wu Z., Yi J., He X.","Model-Agnostic Counterfactual Reasoning for Eliminating Popularity Bias in Recommender System",2021,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114921261&doi=10.1145%2f3447548.3467289&partnerID=40&md5=09be884c5313a8ce64d1e39314de88d4","The general aim of the recommender system is to provide personalized suggestions to users, which is opposed to suggesting popular items. However, the normal training paradigm, i.e., fitting a recommender model to recover the user behavior data with pointwise or pairwise loss, makes the model biased towards popular items. This results in the terrible Matthew effect, making popular items be more frequently recommended and become even more popular. Existing work addresses this issue with Inverse Propensity Weighting (IPW), which decreases the impact of popular items on the training and increases the impact of long-tail items. Although theoretically sound, IPW methods are highly sensitive to the weighting strategy, which is notoriously difficult to tune. In this work, we explore the popularity bias issue from a novel and fundamental perspective - - cause-effect. We identify that popularity bias lies in the direct effect from the item node to the ranking score, such that an item's intrinsic property is the cause of mistakenly assigning it a higher ranking score. To eliminate popularity bias, it is essential to answer the counterfactual question that what the ranking score would be if the model only uses item property. To this end, we formulate a causal graph to describe the important cause-effect relations in the recommendation process. During training, we perform multi-task learning to achieve the contribution of each cause; during testing, we perform counterfactual inference to remove the effect of item popularity. Remarkably, our solution amends the learning process of recommendation which is agnostic to a wide range of models - - it can be easily implemented in existing methods. We demonstrate it on Matrix Factorization (MF) and LightGCN [20], which are representative of the conventional and SOTA model for collaborative filtering. Experiments on five real-world datasets demonstrate the effectiveness of our method. © 2021 ACM."
"Joachims T., Granka L., Pan B., Hembrooke H., Gay G.","Accurately interpreting clickthrough data as implicit feedback",2017,"ACM SIGIR Forum",,[No abstract available]
"Zhang J., Bareinboim E.","Fairness in decision-making the causal explanation formula",2018,"32nd AAAI Conference on Artificial Intelligence, AAAI 2018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059366419&partnerID=40&md5=c14c4e3190d9c1f191b049e0c6951c5b","AI plays an increasingly prominent role in society since decisions that were once made by humans are now delegated to automated systems. These systems are currently in charge of deciding bank loans, criminals' incarceration, and the hiring of new employees, and it's not difficult to envision that they will in the future underpin most of the decisions in society. Despite the high complexity entailed by this task, there is still not much understanding of basic properties of such systems. For instance, we currently cannot detect (neither explain nor correct) whether an AI system is operating fairly (i.e., is abiding by the decision-constraints agreed by society) or it is reinforcing biases and perpetuating a preceding prejudicial practice. Issues of discrimination have been discussed extensively in legal circles, but there exists still not much understanding of the formal conditions that a system must adhere to be deemed fair. In this paper, we use the language of structural causality (Pearl, 2000) to fill in this gap. We start by introducing three new fine-grained measures of transmission of change from stimulus to effect, which we called counterfactual direct (Ctf-DE), indirect (Ctf-IE), and spurious (Ctf-SE) effects. We then derive the causal explanation formula, which allows the AI designer to quantitatively evaluate fairness and explain the total observed disparity of decisions through different discriminatory mechanisms. We apply these results to various discrimination analysis tasks and run extensive simulations, including detection, evaluation, and optimization of decision-making under fairness constraints. We conclude studying the trade-off between different types of fairness criteria (outcome and procedural), and provide a quantitative approach to policy implementation and the design of fair decision-making systems. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved."
"Chaney A.J.B., Stewart B.M., Engelhardt B.E.","How algorithmic confounding in recommendation systems increases homogeneity and decreases utility",2018,"Proceedings of the 12th ACM Conference on Recommender Systems (RecSys’18)",,[No abstract available]
"Louizos C., Swersky K., Li Y., Welling M., Zemel R.","The variational fair autoencoder",2016,"4th International Conference on Learning Representations, ICLR 2016 - Conference Track Proceedings","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083951172&partnerID=40&md5=014ad546eba154510da23c4c71e70b89","We investigate the problem of learning representations that are invariant to certain nuisance or sensitive factors of variation in the data while retaining as much of the remaining information as possible. Our model is based on a variational autoencoding architecture (Kingma & Welling, 2014; Rezende et al., 2014) with priors that encourage independence between sensitive and latent factors of variation. Any subsequent processing, such as classification, can then be performed on this purged latent representation. To remove any remaining dependencies we incorporate an additional penalty term based on the “Maximum Mean Discrepancy” (MMD) (Gretton et al., 2006) measure. We discuss how these architectures can be efficiently trained on data and show in experiments that this method is more effective than previous work in removing unwanted sources of variation while maintaining informative latent representations. © ICLR 2016: San Juan, Puerto Rico. All Rights Reserved."
"Jannach D., Lerche L., Kamehkhosh I., Jugovac M.","What recommenders recommend: an analysis of recommendation biases and possible countermeasures",2015,"User Modeling and User-Adapted Interaction","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949112512&doi=10.1007%2fs11257-015-9165-3&partnerID=40&md5=92ca45d33f123d6d2bdd63c10c6a604e","Most real-world recommender systems are deployed in a commercial context or designed to represent a value-adding service, e.g., on shopping or Social Web platforms, and typical success indicators for such systems include conversion rates, customer loyalty or sales numbers. In academic research, in contrast, the evaluation and comparison of different recommendation algorithms is mostly based on offline experimental designs and accuracy or rank measures which are used as proxies to assess an algorithm’s recommendation quality. In this paper, we show that popular recommendation techniques—despite often being similar when compared with the help of accuracy measures—can be quite different with respect to which items they recommend. We report the results of an in-depth analysis in which we compare several recommendations strategies from different perspectives, including accuracy, catalog coverage and their bias to recommend popular items. Our analyses reveal that some recent techniques that perform well with respect to accuracy measures focus their recommendations on a tiny fraction of the item spectrum or recommend mostly top sellers. We analyze the reasons for some of these biases in terms of algorithmic design and parameterization and show how the characteristics of the recommendations can be altered by hyperparameter tuning. Finally, we propose two novel algorithmic schemes to counter these popularity biases. © 2015, Springer Science+Business Media Dordrecht."
"Marlin B.M., Zemel R.S., Sam R., Slaney M.","Collaborative filtering and the missing at random assumption",2007,"Proceedings of the 23rd Conference on Uncertainty in Artificial Intelligence, UAI 2007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-58149183811&partnerID=40&md5=afd31c6ca112ddd7db5c638734c3c4b0","Rating prediction is an important application, and a popular research topic in collaborative filtering. However, both the validity of learning algorithms, and the validity of standard testing procedures rest on the assumption that missing ratings are missing at random (MAR). In this paper we present the results of a user study in which we collect a random sample of ratings from current users of an online radio service. An analysis of the rating data collected in the study shows that the sample of random ratings has markedly different properties than ratings of user-selected songs. When asked to report on their own rating behaviour, a large number of users indicate they believe their opinion of a song does affect whether they choose to rate that song, a violation of the MAR condition. Finally, we present experimental results showing that incorporating an explicit model of the missing data mechanism can lead to significant improvements in prediction performance on the random sample of ratings."
"Johnson C.C.","Logistic matrix factorization for implicit feedback data",2014,"Advances in Neural Information Processing Systems",,[No abstract available]
"Chaney A.J.B., Blei D.M., Eliassi-Rad T.","A probabilistic model for using social networks in personalized item recommendation",2015,"RecSys 2015 - Proceedings of the 9th ACM Conference on Recommender Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962816279&doi=10.1145%2f2792838.2800193&partnerID=40&md5=915346c42f8e2b098d5789495f264226","Preference-based recommendation systems have transformed how we consume media. By analyzing usage data, these methods uncover our latent preferences for items (such as articles or movies) and form recommendations based on the behavior of others with similar tastes. But traditional preference-based recommendations do not account for the social aspect of consumption, where a trusted friend might point us to an interesting item that does not match our typical preferences. In this work, we aim to bridge the gap between preference-and social-based recommendations. We develop social Poisson factorization (SPF), a probabilistic model that incorporates social network information into a traditional factorization method; SPF introduces the social aspect to algorithmic recommendation. We develop a scalable algorithm for analyzing data with SPF, and demonstrate that it outperforms competing methods on six real-world datasets; data sources include a social reader and Etsy."
"Edwards H., Storkey A.","Censoring representations with an adversary",2016,"4th International Conference on Learning Representations, ICLR 2016 - Conference Track Proceedings","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083951030&partnerID=40&md5=5b4928ce909cceed161b854af7eefe9f","In practice, there are often explicit constraints on what representations or decisions are acceptable in an application of machine learning. For example it may be a legal requirement that a decision must not favour a particular group. Alternatively it can be that that representation of data must not have identifying information. We address these two related issues by learning flexible representations that minimize the capability of an adversarial critic. This adversary is trying to predict the relevant sensitive variable from the representation, and so minimizing the performance of the adversary ensures there is little or no information in the representation about the sensitive variable. We demonstrate this adversarial approach on two problems: making decisions free from discrimination and removing private information from images. We formulate the adversarial model as a minimax problem, and optimize that minimax objective using a stochastic gradient alternate min-max optimizer. We demonstrate the ability to provide discriminant free representations for standard test problems, and compare with previous state of the art methods for fairness, showing statistically significant improvement across most cases. The flexibility of this method is shown via a novel problem: removing annotations from images, from separate training examples of annotated and unannotated images, and with no a priori knowledge of the form of annotation provided to the model. © ICLR 2016: San Juan, Puerto Rico. All Rights Reserved."
"Morik M., Singh A., Hong J., Joachims T.","Controlling Fairness and Bias in Dynamic Learning-to-Rank",2020,"SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090145600&doi=10.1145%2f3397271.3401100&partnerID=40&md5=a3287f70e729b6064760e36001b2f473","Rankings are the primary interface through which many online platforms match users to items (e.g. news, products, music, video). In these two-sided markets, not only the users draw utility from the rankings, but the rankings also determine the utility (e.g. exposure, revenue) for the item providers (e.g. publishers, sellers, artists, studios). It has already been noted that myopically optimizing utility to the users-as done by virtually all learning-to-rank algorithms-can be unfair to the item providers. We, therefore, present a learning-to-rank approach for explicitly enforcing merit-based fairness guarantees to groups of items (e.g. articles by the same publisher, tracks by the same artist). In particular, we propose a learning algorithm that ensures notions of amortized group fairness, while simultaneously learning the ranking function from implicit feedback data. The algorithm takes the form of a controller that integrates unbiased estimators for both fairness and utility, dynamically adapting both as more data becomes available. In addition to its rigorous theoretical foundation and convergence guarantees, we find empirically that the algorithm is highly practical and robust. © 2020 ACM."
"Ai Q., Bi K., Luo C., Guo J., Croft W.B.","Unbiased learning to rank with unbiased propensity estimation",2018,"41st International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051531892&doi=10.1145%2f3209978.3209986&partnerID=40&md5=e6114a641f11bae56f002bd00f36b895","Learning to rank with biased click data is a well-known challenge. A variety of methods has been explored to debias click data for learning to rank such as click models, result interleaving and, more recently, the unbiased learning-to-rank framework based on inverse propensity weighting. Despite their differences, most existing studies separate the estimation of click bias (namely the propensity model ) from the learning of ranking algorithms. To estimate click propensities, they either conduct online result randomization, which can negatively affect the user experience, or offline parameter estimation, which has special requirements for click data and is optimized for objectives (e.g. click likelihood) that are not directly related to the ranking performance of the system. In this work, we address those problems by unifying the learning of propensity models and ranking models. We find that the problem of estimating a propensity model from click data is a dual problem of unbiased learning to rank. Based on this observation, we propose a Dual Learning Algorithm (DLA) that jointly learns an unbiased ranker and an unbiased propensity model. DLA is an automatic unbiased learning-to-rank framework as it directly learns unbiased ranking models from biased click data without any preprocessing. It can adapt to the change of bias distributions and is applicable to online learning. Our empirical experiments with synthetic and real-world data show that the models trained with DLA significantly outperformed the unbiased learning-to-rank algorithms based on result randomization and the models trained with relevance signals extracted by click models. © 2018 ACM."
"Patro G.K., Biswas A., Ganguly N., Gummadi K.P., Chakraborty A.","FairRec: Two-Sided Fairness for Personalized Recommendations in Two-Sided Platforms",2020,"The Web Conference 2020 - Proceedings of the World Wide Web Conference, WWW 2020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086566328&doi=10.1145%2f3366423.3380196&partnerID=40&md5=4bcb417981601f1bd404d62c323b0630","We investigate the problem of fair recommendation in the context of two-sided online platforms, comprising customers on one side and producers on the other. Traditionally, recommendation services in these platforms have focused on maximizing customer satisfaction by tailoring the results according to the personalized preferences of individual customers. However, our investigation reveals that such customer-centric design may lead to unfair distribution of exposure among the producers, which may adversely impact their well-being. On the other hand, a producer-centric design might become unfair to the customers. Thus, we consider fairness issues that span both customers and producers. Our approach involves a novel mapping of the fair recommendation problem to a constrained version of the problem of fairly allocating indivisible goods. Our proposed FairRec algorithm guarantees at least Maximin Share (MMS) of exposure for most of the producers and Envy-Free up to One Good (EF1) fairness for every customer. Extensive evaluations over multiple real-world datasets show the effectiveness of FairRec in ensuring two-sided fairness while incurring a marginal loss in the overall recommendation quality. © 2020 ACM."
"Burke R.","Multisided fairness for recommendation",2017,"Multisided Fairness for Recommendation",,[No abstract available]
"Zhao X., Zhang W., Wang J.","Interactive collaborative filtering",2013,"International Conference on Information and Knowledge Management, Proceedings","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889565597&doi=10.1145%2f2505515.2505690&partnerID=40&md5=5bcc589e360f60f96968d94f764ab8f9","In this paper, we study collaborative filtering (CF) in an interactive setting, in which a recommender system continuously recommends items to individual users and receives interactive feedback. Whilst users enjoy sequential recommendations, the recommendation predictions are constantly refined using up-to-date feedback on the recommended items. Bringing the interactive mechanism back to the CF process is fundamental because the ultimate goal for a rec-ommender system is about the discovery of interesting items for individual users and yet users' personal preferences and contexts evolve over time during the interactions with the system. This requires us not to distinguish between the stages of collecting information to construct the user profile and making recommendations, but to seamlessly integrate these stages together during the interactive process, with the goal of maximizing the overall recommendation accuracy throughout the interactions. This mechanism naturally addresses the cold-start problem as any user can immediately receive sequential recommendations without providing ratings beforehand. We formulate the interactive CF with the probabilistic matrix factorization (PMF) framework, and leverage several exploitation-exploration algorithms to select items, including the empirical Thompson sampling and upper confidence bound based algorithms. We conduct our experiment on cold-start users as well as warm-start users with drifting taste. Results show that the proposed methods have significant improvements over several strong baselines for the MovieLens, EachMovie and Netflix datasets. Copyright 2013 ACM."
"Li Y., Chen H., Fu Z., Ge Y., Zhang Y.","User-oriented fairness in recommendation",2021,"The Web Conference 2021 - Proceedings of the World Wide Web Conference, WWW 2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107988659&doi=10.1145%2f3442381.3449866&partnerID=40&md5=66c286eeff4e1cbc90cc4fb9e13dbb7e","As a highly data-driven application, recommender systems could be affected by data bias, resulting in unfair results for different data groups, which could be a reason that affects the system performance. Therefore, it is important to identify and solve the unfairness issues in recommendation scenarios. In this paper, we address the unfairness problem in recommender systems from the user perspective. We group users into advantaged and disadvantaged groups according to their level of activity, and conduct experiments to show that current recommender systems will behave unfairly between two groups of users. Specifically, the advantaged users (active) who only account for a small proportion in data enjoy much higher recommendation quality than those disadvantaged users (inactive). Such bias can also affect the overall performance since the disadvantaged users are the majority. To solve this problem, we provide a re-ranking approach to mitigate this unfairness problem by adding constraints over evaluation metrics. The experiments we conducted on several real-world datasets with various recommendation algorithms show that our approach can not only improve group fairness of users in recommender systems, but also achieve better overall recommendation performance. Â© 2021 ACM."
"Wang X., Xu Y., He X., Cao Y., Wang M., Chua T.-S.","Reinforced Negative Sampling over Knowledge Graph for Recommendation",2020,"The Web Conference 2020 - Proceedings of the World Wide Web Conference, WWW 2020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084497000&doi=10.1145%2f3366423.3380098&partnerID=40&md5=65eb46001481f27907921e81ecd683e8","Properly handling missing data is a fundamental challenge in recommendation. Most present works perform negative sampling from unobserved data to supply the training of recommender models with negative signals. Nevertheless, existing negative sampling strategies, either static or adaptive ones, are insufficient to yield high-quality negative samples - both informative to model training and reflective of user real needs. In this work, we hypothesize that item knowledge graph (KG), which provides rich relations among items and KG entities, could be useful to infer informative and factual negative samples. Towards this end, we develop a new negative sampling model, Knowledge Graph Policy Network (KGPolicy), which works as a reinforcement learning agent to explore high-quality negatives. Specifically, by conducting our designed exploration operations, it navigates from the target positive interaction, adaptively receives knowledge-aware negative signals, and ultimately yields a potential negative item to train the recommender. We tested on a matrix factorization (MF) model equipped with KGPolicy, and it achieves significant improvements over both state-of-the-art sampling methods like DNS [39] and IRGAN [30], and KG-enhanced recommender models like KGAT [32]. Further analyses from different angles provide insights of knowledge-aware sampling. We release the codes and datasets at https://github.com/xiangwang1223/kgpolicy. © 2020 ACM."
"Grgic-Hlaca N., Zafar M.B., Gummadi K.P., Weller A.","The case for process fairness in learning: Feature selection for fair decision making",2016,"NIPS Symposium on Machine Learning and the Law",,[No abstract available]
"Liu D., Cheng P., Dong Z., He X., Pan W., Ming Z.","A General Knowledge Distillation Framework for Counterfactual Recommendation via Uniform Data",2020,"SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090168276&doi=10.1145%2f3397271.3401083&partnerID=40&md5=ec4a81d2b819623021877f0e1fc752b0","Recommender systems are feedback loop systems, which often face bias problems such as popularity bias, previous model bias and position bias. In this paper, we focus on solving the bias problems in a recommender system via a uniform data. Through empirical studies in online and offline settings, we observe that simple modeling with a uniform data can alleviate the bias problems and improve the performance. However, the uniform data is always few and expensive to collect in a real product. In order to use the valuable uniform data more effectively, we propose a general knowledge distillation framework for counterfactual recommendation that enables uniform data modeling through four approaches: (1) label-based distillation focuses on using the imputed labels as a carrier to provide useful de-biasing guidance; (2) feature-based distillation aims to filter out the representative causal and stable features; (3) sample-based distillation considers mutual learning and alignment of the information of the uniform and non-uniform data; and (4) model structure-based distillation constrains the training of the models from the perspective of embedded representation. We conduct extensive experiments on both public and product datasets, demonstrating that the proposed four methods achieve better performance over the baseline models in terms of AUC and NLL. Moreover, we discuss the relation between the proposed methods and the previous works. We emphasize that counterfactual modeling with uniform data is a rich research area, and list some interesting and promising research topics worthy of further exploration. Note that the source codes are available at\urlhttps://github.com/dgliu/SIGIR20-KDCRec. © 2020 ACM."
"Yang L., Wang C., Cui Y., Belongie S., Xuan Y., Estrin D.","Unbiased offline recommender evaluation for missing-not-at-random implicit feedback",2018,"RecSys 2018 - 12th ACM Conference on Recommender Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056795110&doi=10.1145%2f3240323.3240355&partnerID=40&md5=8edff42e98f6c9e5b99b19b5e4c1db7a","Implicit-feedback Recommenders (ImplicitRec) leverage positive only user-item interactions, such as clicks, to learn personalized user preferences. Recommenders are often evaluated and compared offline using datasets collected from online platforms. These platforms are subject to popularity bias (i.e., popular items are more likely to be presented and interacted with), and therefore logged ground truth data are Missing-Not-At-Random (MNAR). As a result, the widely used Average-Over-All (AOA) evaluator is biased toward accurately recommending trendy items. In this paper, we (a) investigate evaluation bias of AOA and (b) develop an unbiased and practical offline evaluator for implicit MNAR datasets using the Inverse-Propensity-Scoring (IPS) technique. Through extensive experiments using four real-world datasets and four widely used algorithms, we show that (a) popularity bias is widely manifested in item presentation and interaction; (b) evaluation bias due to MNAR data pervasively exists in most cases where AOA is used to evaluate ImplicitRec; and (c) the unbiased estimator significantly reduces the AOA evaluation bias by more than 30% in the Yahoo! music dataset in terms of the Mean Absolute Error (MAE). © 2018 Association for Computing Machinery."
"Pan R., Scholz M.","Mind the gaps: Weighting the unknown in large-scale one-class collaborative filtering",2009,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350623327&doi=10.1145%2f1557019.1557094&partnerID=40&md5=8541b9345c92647d38b182804130474c","One-Class Collaborative Filtering (OCCF) is a task that naturally emerges in recommender system settings. Typical characteristics include: Only positive examples can be observed, classes are highly imbalanced, and the vast majority of data points are missing. The idea of introducing weights for missing parts of a matrix has recently been shown to help in OCCF. While existing weighting approaches rst two problems above, a sparsity preserving solution that would allow to efficiently utilize data sets with e.g., hundred thousands of users and items has not yet been reported. In this paper, we study three dierent collaborative filtering frameworks: Low-rank matrix approximation, probabilistic latent semantic analysis, and maximum-margin matrix factorization. We propose two novel algorithms for large-scale OCCF that allow to weight the unknowns. Our experimental results demonstrate their effectiveness and efficiency on different problems, including the Netflix Prize data."
"Ge Y., Liu S., Gao R., Xian Y., Li Y., Zhao X., Pei C., Sun F., Ge J., Ou W., Zhang Y.","Towards Long-term Fairness in Recommendation",2021,"WSDM 2021 - Proceedings of the 14th ACM International Conference on Web Search and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102991474&doi=10.1145%2f3437963.3441824&partnerID=40&md5=f13c62f704d481d497975ad043933197","As Recommender Systems (RS) influence more and more people in their daily life, the issue of fairness in recommendation is becoming more and more important. Most of the prior approaches to fairness-aware recommendation have been situated in a static or one-shot setting, where the protected groups of items are fixed, and the model provides a one-time fairness solution based on fairness-constrained optimization. This fails to consider the dynamic nature of the recommender systems, where attributes such as item popularity may change over time due to the recommendation policy and user engagement. For example, products that were once popular may become no longer popular, and vice versa. As a result, the system that aims to maintain long-term fairness on the item exposure in different popularity groups must accommodate this change in a timely fashion. Novel to this work, we explore the problem of long-term fairness in recommendation and accomplish the problem through dynamic fairness learning. We focus on the fairness of exposure of items in different groups, while the division of the groups is based on item popularity, which dynamically changes over time in the recommendation process. We tackle this problem by proposing a fairness-constrained reinforcement learning algorithm for recommendation, which models the recommendation problem as a Constrained Markov Decision Process (CMDP), so that the model can dynamically adjust its recommendation policy to make sure the fairness requirement is always satisfied when the environment changes. Experiments on several real-world datasets verify our framework's superiority in terms of recommendation performance, short-term fairness, and long-term fairness. © 2021 ACM."
"Lin X., Zhang M., Zhang Y., Gu Z., Liu Y., Ma S.","Fairness-aware group recommendation with pareto-efficiency",2017,"RecSys 2017 - Proceedings of the 11th ACM Conference on Recommender Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030459584&doi=10.1145%2f3109859.3109887&partnerID=40&md5=0330d1d22b03937e116ddcbceb551079","Group recommendation has attracted significant research efforts for its importance in benefiting a group of users. This paper investigates the Group Recommendation problem from a novel aspect, which tries to maximize the satisfaction of each group member while minimizing the unfairness between them. In this work, we present several semantics of the individual utility and propose two concepts of social welfare and fairness for modeling the overall utilities and the balance between group members. We formulate the problem as a multiple objective optimization problem and show that it is NP-Hard in different semantics. Given the multiple-objective nature of fairness-aware group recommendation problem, we provide an optimization framework for fairness-aware group recommendation from the perspective of Pareto Efficiency. We conduct extensive experiments on real-world datasets and evaluate our algorithm in terms of standard accuracy metrics. The results indicate that our algorithm achieves superior performances and considering fairness in group recommendation can enhance the recommendation accuracy. © 2017 ACM."
"Chen J., Dong H., Qiu Y., He X., Xin X., Chen L., Lin G., Yang K.","AutoDebias: Learning to Debias for Recommendation",2021,"SIGIR 2021 - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111663613&doi=10.1145%2f3404835.3462919&partnerID=40&md5=d02bd20b617d978e4dc82b5932c42644","Recommender systems rely on user behavior data like ratings and clicks to build personalization model. However, the collected data is observational rather than experimental, causing various biases in the data which significantly affect the learned model. Most existing work for recommendation debiasing, such as the inverse propensity scoring and imputation approaches, focuses on one or two specific biases, lacking the universal capacity that can account for mixed or even unknown biases in the data. Towards this research gap, we first analyze the origin of biases from the perspective of risk discrepancy that represents the difference between the expectation empirical risk and the true risk. Remarkably, we derive a general learning framework that well summarizes most existing debiasing strategies by specifying some parameters of the general framework. This provides a valuable opportunity to develop a universal solution for debiasing, e.g., by learning the debiasing parameters from data. However, the training data lacks important signal of how the data is biased and what the unbiased data looks like. To move this idea forward, we propose AotoDebias that leverages another (small) set of uniform data to optimize the debiasing parameters by solving the bi-level optimization problem with meta-learning. Through theoretical analyses, we derive the generalization bound for AutoDebias and prove its ability to acquire the appropriate debiasing strategy. Extensive experiments on two real datasets and a simulated dataset demonstrated effectiveness of AutoDebias. The code is available at https://github.com/DongHande/AutoDebias. © 2021 ACM."
"Karimi F., Génois M., Wagner C., Singer P., Strohmaier M.","Homophily influences ranking of minorities in social networks",2018,"Scientific Reports","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050613676&doi=10.1038%2fs41598-018-29405-7&partnerID=40&md5=ba109f9b86642ae0a1f91a321e3dc88a","Homophily can put minority groups at a disadvantage by restricting their ability to establish links with a majority group or to access novel information. Here, we show how this phenomenon can influence the ranking of minorities in examples of real-world networks with various levels of heterophily and homophily ranging from sexual contacts, dating contacts, scientific collaborations, and scientific citations. We devise a social network model with tunable homophily and group sizes, and demonstrate how the degree ranking of nodes from the minority group in a network is a function of (i) relative group sizes and (ii) the presence or absence of homophilic behaviour. We provide analytical insights on how the ranking of the minority can be improved to ensure the representativeness of the group and correct for potential biases. Our work presents a foundation for assessing the impact of homophilic and heterophilic behaviour on minorities in social networks. © 2018, The Author(s)."
"Li Y., Hu J., Zhai C., Chen Y.","Improving One-Class Collaborative Filtering by incorporating rich user information",2010,"International Conference on Information and Knowledge Management, Proceedings","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651310397&doi=10.1145%2f1871437.1871559&partnerID=40&md5=bc0b0112fb40b1bd0027ca3b57094a7c","One-Class Collaborative Filtering (OCCF) is an emerging setup in collaborative filtering in which only positive examples or implicit feedback can be observed. Compared with the traditional collaborative filtering setting where the data has ratings, OCCF is more realistic in many scenarios when no ratings are available. In this paper, we propose to improve OCCF accuracy by exploiting the rich user information that is often naturally available in community-based interactive information systems, including a user's search query history, purchasing and browsing activities. We propose two ways to incorporate such user information into the OCCF models: one is to linearly combine scores from different sources and the other is to embed user information into collaborative filtering. Experimental results on a large-scale retail data set from a major e-commerce company show that the proposed methods are effective and can improve the performance of the One-Class Collaborative Filtering over baseline methods through leveraging rich user information. © 2010 ACM."
"Rahman T., Surma B., Backes M., Zhang Y.","FairWalk: Towards fair graph embedding",2019,"IJCAI International Joint Conference on Artificial Intelligence","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074933184&doi=10.24963%2fijcai.2019%2f456&partnerID=40&md5=49b57ddcc7736275a4a9356cd1245749","Graph embeddings have gained huge popularity in the recent years as a powerful tool to analyze social networks. However, no prior works have studied potential bias issues inherent within graph embedding. In this paper, we make a first attempt in this direction. In particular, we concentrate on the fairness of node2vec, a popular graph embedding method. Our analyses on two real-world datasets demonstrate the existence of bias in node2vec when used for friendship recommendation. We therefore propose a fairness-aware embedding method, namely Fairwalk, which extends node2vec. Experimental results demonstrate that Fairwalk reduces bias under multiple fairness metrics while still preserving the utility. © 2019 International Joint Conferences on Artificial Intelligence. All rights reserved."
"Singh A., Joachims T.","Policy learning for fairness in ranking",2019,"Advances in Neural Information Processing Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090144797&partnerID=40&md5=6c1c60e22bc2470f5b1e50143a622bc4","Conventional Learning-to-Rank (LTR) methods optimize the utility of the rankings to the users, but they are oblivious to their impact on the ranked items. However, there has been a growing understanding that the latter is important to consider for a wide range of ranking applications (e.g. online marketplaces, job placement, admissions). To address this need, we propose a general LTR framework that can optimize a wide range of utility metrics (e.g. NDCG) while satisfying fairness of exposure constraints with respect to the items. This framework expands the class of learnable ranking functions to stochastic ranking policies, which provides a language for rigorously expressing fairness specifications. Furthermore, we provide a new LTR algorithm called FAIR-PG-RANK for directly searching the space of fair ranking policies via a policy-gradient approach. Beyond the theoretical evidence in deriving the framework and the algorithm, we provide empirical results on simulated and real-world datasets verifying the effectiveness of the approach in individual and group-fairness settings. © 2019 Neural information processing systems foundation. All rights reserved."
"Asudeh A., Jagadish H.V., Stoyanovich J., Das G.","Designing fair ranking schemes",2019,"Proceedings of the ACM SIGMOD International Conference on Management of Data","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061747789&partnerID=40&md5=642f1a90c7a20d1b0ae98e00fcef1369","Items from a database are often ranked based on a combination of criteria. The weight given to each criterion in the combination can greatly affect the fairness of the produced ranking, for example, preferring men over women. A user may have the flexibility to choose combinations that weigh these criteria differently, within limits. In this paper, we develop a system that helps users choose criterion weights that lead to greater fairness. We consider ranking functions that compute the score of each item as a weighted sum of (numeric) attribute values, and then sort items on their score. Each ranking function can be expressed as a point in a multidimensional space. For a broad range of fairness criteria, including proportionality, we show how to efficiently identify regions in this space that satisfy these criteria. Using this identification method, our system is able to tell users whether their proposed ranking function satisfies the desired fairness criteria and, if it does not, to suggest the smallest modification that does. Our extensive experiments on real datasets demonstrate that our methods are able to find solutions that satisfy fairness criteria effectively (usually with only small changes to proposed weight vectors) and efficiently (in interactive time, after some initial pre-processing). © 2019 Association for Computing Machinery."
"Wang X., Zhang R., Sun Y., Qi J.","Doubly robust joint learning for recommendation on data missing not at random",2019,"International Conference on Machine Learning",,[No abstract available]
"Zhu Z., Hu X., Caverlee J.","Fairness-aware tensor-based recommendation",2018,"International Conference on Information and Knowledge Management, Proceedings","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058064495&doi=10.1145%2f3269206.3271795&partnerID=40&md5=e743cb93f60efd16e6587c858ac265c3","Tensor-based methods have shown promise in improving upon traditional matrix factorization methods for recommender systems. But tensors may achieve improved recommendation quality while worsening the fairness of the recommendations. Hence, we propose a novel fairness-aware tensor recommendation framework that is designed to maintain quality while dramatically improving fairness. Four key aspects of the proposed framework are: (i) a new sensitive latent factor matrix for isolating sensitive features; (ii) a sensitive information regularizer that extracts sensitive information which can taint other latent factors; (iii) an effective algorithm to solve the proposed optimization model; and (iv) extension to multi-feature and multi-category cases which previous efforts have not addressed. Extensive experiments on real-world and synthetic datasets show that the framework enhances recommendation fairness while preserving recommendation quality in comparison with state-of-the-art alternatives. © 2018 Association for Computing Machinery."
"Ding J., Quan Y., He X., Li Y., Jin D.","Reinforced negative sampling for recommendation with exposure data",2019,"IJCAI International Joint Conference on Artificial Intelligence","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074909715&doi=10.24963%2fijcai.2019%2f309&partnerID=40&md5=09ff4264f88940f1278eb5442fb9c0ce","In implicit feedback-based recommender systems, user exposure data, which record whether or not a recommended item has been interacted by a user, provide an important clue on selecting negative training samples. In this work, we improve the negative sampler by integrating the exposure data. We propose to generate high-quality negative instances by adversarial training to favour the difficult instances, and by optimizing additional objective to favour the real negatives in exposure data. However, this idea is non-trivial to implement since the distribution of exposure data is latent and the item space is discrete. To this end, we design a novel RNS method (short for Reinforced Negative Sampler) that generates exposure-alike negative instances through feature matching technique instead of directly choosing from exposure data. Optimized under the reinforcement learning framework, RNS is able to integrate user preference signals in exposure data and hard negatives. Extensive experiments on two real-world datasets demonstrate the effectiveness and rationality of our RNS method. Our implementation is available at: https://github.com/dingjingtao/ReinforceNS. © 2019 International Joint Conferences on Artificial Intelligence. All rights reserved."
"Wen H., Zhang J., Wang Y., Lv F., Bao W., Lin Q., Yang K.","Entire Space Multi-Task Modeling via Post-Click Behavior Decomposition for Conversion Rate Prediction",2020,"SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090167763&doi=10.1145%2f3397271.3401443&partnerID=40&md5=2eba675cded7516bd089f0aae0074631","Recommender system, as an essential part of modern e-commerce, consists of two fundamental modules, namely Click-Through Rate (CTR) and Conversion Rate (CVR) prediction. While CVR has a direct impact on the purchasing volume, its prediction is well-known challenging due to the Sample Selection Bias (SSB) and Data Sparsity (DS) issues. Although existing methods, typically built on the user sequential behavior path ""impression->click->purchase"", is effective for dealing with SSB issue, they still struggle to address the DS issue due to rare purchase training samples. Observing that users always take several purchase-related actions after clicking, we propose a novel idea of post-click behavior decomposition. Specifically, disjoint purchase-related Deterministic Action (DAction) and Other Action (OAction) are inserted between click and purchase in parallel, forming a novel user sequential behavior graph ""impression->click->D(O)Action->purchase"". Defining model on this graph enables to leverage all the impression samples over the entire space and extra abundant supervised signals from D(O)Action, which will effectively address the SSB and DS issues together. To this end, we devise a novel deep recommendation model named Elaborated Entire Space Supervised Multi-task Model (ESM2). According to the conditional probability rule defined on the graph, it employs multi-task learning to predict some decomposed sub-targets in parallel and compose them sequentially to formulate the final CVR. Extensive experiments on both offline and online environments demonstrate the superiority of ESM2 over state-of-the-art models. The source code and dataset will be released. © 2020 ACM."
"Wang X., Chen Y., Yang J., Wu L., Wu Z., Xie X.","A Reinforcement Learning Framework for Explainable Recommendation",2018,"Proceedings - IEEE International Conference on Data Mining, ICDM","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061407106&doi=10.1109%2fICDM.2018.00074&partnerID=40&md5=fe54e2e03f3eb210937b51321c1f8138","Explainable recommendation, which provides explanations about why an item is recommended, has attracted increasing attention due to its ability in helping users make better decisions and increasing users' trust in the system. Existing explainable recommendation methods either ignore the working mechanism of the recommendation model or are designed for a specific recommendation model. Moreover, it is difficult for existing methods to ensure the presentation quality of the explanations (e.g., consistency). To solve these problems, we design a reinforcement learning framework for explainable recommendation. Our framework can explain any recommendation model (model-agnostic) and can flexibly control the explanation quality based on the application scenario. To demonstrate the effectiveness of our framework, we show how it can be used for generating sentence-level explanations. Specifically, we instantiate the explanation generator in the framework with a personalized-attention-based neural network. Offline experiments demonstrate that our method can well explain both collaborative filtering methods and deep-learning-based models. Evaluation with human subjects shows that the explanations generated by our method are significantly more useful than the explanations generated by the baselines. © 2018 IEEE."
"Zhao X., Zhang L., Ding Z., Yin D., Zhao Y., Tang J.",[No title available],2017,"Deep Reinforcement Learning for List-Wise Recommendations",,[No abstract available]
"Swaminathan A., Krishnamurthy A., Agarwal A., Dudík M., Langford J., Jose D., Zitouni I.","Off-policy evaluation for slate recommendation",2017,"Advances in Neural Information Processing Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047016992&partnerID=40&md5=99635bbd70be5d7998d3c777816256c1","This paper studies the evaluation of policies that recommend an ordered set of items (e.g., a ranking) based on some context - a common scenario in web search, ads, and recommendation. We build on techniques from combinatorial bandits to introduce a new practical estimator that uses logged data to estimate a policy's performance. A thorough empirical evaluation on real-world data reveals that our estimator is accurate in a variety of settings, including as a subroutine in a learning-to-rank task, where it achieves competitive performance. We derive conditions under which our estimator is unbiased - these conditions are weaker than prior heuristics for slate evaluation - and experimentally demonstrate a smaller bias than parametric approaches, even when these conditions are violated. Finally, our theory and experiments also show exponential savings in the amount of required data compared with general unbiased estimators. © 2017 Neural information processing systems foundation. All rights reserved."
"Jiang R., Chiappa S., Lattimore T., György A., Kohli P.","Degenerate feedback loops in recommender systems",2019,"AIES 2019 - Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070651731&doi=10.1145%2f3306618.3314288&partnerID=40&md5=85653cbfae32b93724722083c1236165","Machine learning is used extensively in recommender systems deployed in products. The decisions made by these systems can influence user beliefs and preferences which in turn affect the feedback the learning system receives - thus creating a feedback loop. This phenomenon can give rise to the so-called “echo chambers” or “filter bubbles” that have user and societal implications. In this paper, we provide a novel theoretical analysis that examines both the role of user dynamics and the behavior of recommender systems, disentangling the echo chamber from the filter bubble effect. In addition, we offer practical solutions to slow down system degeneracy. Our study contributes toward understanding and developing solutions to commonly cited issues in the complex temporal scenario, an area that is still largely unexplored. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM"
"Wang W., Feng F., He X., Wang X., Chua T.-S.","Deconfounded Recommendation for Alleviating Bias Amplification",2021,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113840943&doi=10.1145%2f3447548.3467249&partnerID=40&md5=87c1b9e51107168e8ebfc964c326122b","Recommender systems usually amplify the biases in the data. The model learned from historical interactions with imbalanced item distribution will amplify the imbalance by over-recommending items from the majority groups. Addressing this issue is essential for a healthy ecosystem of recommendation in the long run. Existing work applies bias control to the ranking targets (e.g., calibration, fairness, and diversity), but ignores the true reason for bias amplification and trades off the recommendation accuracy. In this work, we scrutinize the cause-effect factors for bias amplification, identifying the main reason lies in the confounding effect of imbalanced item distribution on user representation and prediction score. The existence of such confounder pushes us to go beyond merely modeling the conditional probability and embrace the causal modeling for recommendation. Towards this end, we propose a Deconfounded Recommender System (DecRS), which models the causal effect of user representation on the prediction score. The key to eliminating the impact of the confounder lies in backdoor adjustment, which is however difficult to do due to the infinite sample space of the confounder. For this challenge, we contribute an approximation operator for backdoor adjustment which can be easily plugged into most recommender models. Lastly, we devise an inference strategy to dynamically regulate backdoor adjustment according to user status. We instantiate DecRS on two representative models FM [32] and NFM [16], and conduct extensive experiments over two benchmarks to validate the superiority of our proposed DecRS. © 2021 ACM."
"Diaz F., Mitra B., Ekstrand M.D., Biega A.J., Carterette B.","Evaluating Stochastic Rankings with Expected Exposure",2020,"International Conference on Information and Knowledge Management, Proceedings","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095863065&doi=10.1145%2f3340531.3411962&partnerID=40&md5=6b296e67abb571293a6e92e2f81fede6","We introduce the concept of expected exposure as the average attention ranked items receive from users over repeated samples of the same query. Furthermore, we advocate for the adoption of the principle of equal expected exposure: given a fixed information need, no item should receive more or less expected exposure than any other item of the same relevance grade. We argue that this principle is desirable for many retrieval objectives and scenarios, including topical diversity and fair ranking. %Leveraging user models from existing retrieval metrics, we propose a general evaluation methodology based on expected exposure and draw connections to related metrics in information retrieval evaluation. Importantly, this methodology relaxes classic information retrieval assumptions, allowing a system, in response to a query, to produce a distribution over rankings instead of a single fixed ranking. We study the behavior of the expected exposure metric and stochastic rankers across a variety of information access conditions, including ad hoc retrieval and recommendation. %We believe that measuring and optimizing expected exposure metrics using randomization opens a new area for retrieval algorithm development and progress. © 2020 ACM."
"Cãamares R., Castells P.","Should i follow the crowd?: A probabilistic analysis of the effectiveness of popularity in recommender systems",2018,"41st International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051540077&doi=10.1145%2f3209978.3210014&partnerID=40&md5=9ec8bc6186ea67295876683829864b03","The use of IR methodology in the evaluation of recommender systems has become common practice in recent years. IR metrics have been found however to be strongly biased towards rewarding algorithms that recommend popular items ""the same bias that state of the art recommendation algorithms display. Recent research has confirmed and measured such biases, and proposed methods to avoid them. The fundamental question remains open though whether popularity is really a bias we should avoid or not; whether it could be a useful and reliable signal in recommendation, or it may be unfairly rewarded by the experimental biases. We address this question at a formal level by identifying and modeling the conditions that can determine the answer, in terms of dependencies between key random variables, involving item rating, discovery and relevance. We find conditions that guarantee popularity to be effective or quite the opposite, and for the measured metric values to reflect a true effectiveness, or qualitatively deviate from it. We exemplify and confirm the theoretical findings with empirical results. We build a crowdsourced dataset devoid of the usual biases displayed by common publicly available data, in which we illustrate contradictions between the accuracy that would be measured in a common biased offline experimental setting, and the actual accuracy that can be measured with unbiased observations. © 2018 ACM."
"Chen H., Dai X., Cai H., Zhang W., Wang X., Tang R., Zhang Y., Yu Y.","Large-scale interactive recommendation with tree-structured policy gradient",2019,"33rd AAAI Conference on Artificial Intelligence, AAAI 2019, 31st Innovative Applications of Artificial Intelligence Conference, IAAI 2019 and the 9th AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090802622&partnerID=40&md5=ebce457bb8d2412c323b9f70f02789cb","Reinforcement learning (RL) has recently been introduced to interactive recommender systems (IRS) because of its nature of learning from dynamic interactions and planning for long-run performance. As IRS is always with thousands of items to recommend (i.e., thousands of actions), most existing RL-based methods, however, fail to handle such a large discrete action space problem and thus become inefficient. The existing work that tries to deal with the large discrete action space problem by utilizing the deep deterministic policy gradient framework suffers from the inconsistency between the continuous action representation (the output of the actor network) and the real discrete action. To avoid such inconsistency and achieve high efficiency and recommendation effectiveness, in this paper, we propose a Tree-structured Policy Gradient Recommendation (TPGR) framework, where a balanced hierarchical clustering tree is built over the items and picking an item is formulated as seeking a path from the root to a certain leaf of the tree. Extensive experiments on carefully-designed environments based on two real-world datasets demonstrate that our model provides superior recommendation performance and significant efficiency improvement over state-of-the-art methods. © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org)."
"Ge Y., Zhao S., Zhou H., Pei C., Sun F., Ou W., Zhang Y.","Understanding Echo Chambers in E-commerce Recommender Systems",2020,"SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090168026&doi=10.1145%2f3397271.3401431&partnerID=40&md5=3839152eb96357c4387246593a9f9532","Personalized recommendation benefits users in accessing contents of interests effectively. Current research on recommender systems mostly focuses on matching users with proper items based on user interests. However, significant efforts are missing to understand how the recommendations influence user preferences and behaviors, e.g., if and how recommendations result in echo chambers. Extensive efforts have been made in examining the phenomenon in online media and social network systems. Meanwhile, there are growing concerns that recommender systems might lead to the self-reinforcing of user's interests due to narrowed exposure of items, which may be the potential cause of echo chamber. In this paper, we aim to analyze the echo chamber phenomenon in Alibaba Taobao-one of the largest e-commerce platforms in the world. Echo chamber means the effect of user interests being reinforced through repeated exposure to similar contents. Based on the definition, we examine the presence of echo chamber in two steps. First, we explore whether user interests have been reinforced. Second, we check whether the reinforcement results from the exposure of similar contents. Our evaluations are enhanced with robust metrics, including cluster validity and statistical significance. Experiments are performed on extensive collections of real-world data consisting of user clicks, purchases, and browse logs from Alibaba Taobao. Evidence suggests the tendency of echo chamber in user click behaviors, while it is relatively mitigated in user purchase behaviors. Insights from the results guide the refinement of recommendation algorithms in real-world e-commerce systems. © 2020 ACM."
"Chen S.-Y., Tan J., Yu Y., Huang H.-K., Da Q., Tang H.-H.","Stabilizing reinforcement learning in dynamic environment with application to online recommendation",2018,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051475415&doi=10.1145%2f3219819.3220122&partnerID=40&md5=4a13b83ae7864ef3418993a28a1ab69a","Deep reinforcement learning has shown great potential in improving system performance autonomously, by learning from iterations with the environment. However, traditional reinforcement learning approaches are designed to work in static environments. In many real-world problems, the environments are commonly dynamic, in which the performance of reinforcement learning approaches can degrade drastically. A direct cause of the performance degradation is the high-variance and biased estimation of the reward, due to the distribution shifting in dynamic environments. In this paper, we propose two techniques to alleviate the unstable reward estimation problem in dynamic environments, the stratified sampling replay strategy and the approximate regretted reward, which address the problem from the sample aspect and the reward aspect, respectively. Integrating the two techniques with Double DQN, we propose the Robust DQN method. We apply Robust DQN in the tip recommendation system in Taobao online retail trading platform. We firstly disclose the highly dynamic property of the recommendation application. We then carried out online A/B test to examine Robust DQN. The results show that Robust DQN can effectively stabilize the value estimation and, therefore, improves the performance in this real-world dynamic environment. © 2018 Association for Computing Machinery."
"Zhou K., Zha H.","Learning binary codes for collaborative filtering",2012,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866013626&doi=10.1145%2f2339530.2339611&partnerID=40&md5=22640331f6fd4bbee995ad315adbe511","This paper tackles the efficiency problem of making recommendations in the context of large user and item spaces. In particular, we address the problem of learning binary codes for collaborative filtering, which enables us to efficiently make recommendations with time complexity that is independent of the total number of items. We propose to construct binary codes for users and items such that the preference of users over items can be accurately preserved by the Hamming distance between their respective binary codes. By using two loss functions measuring the degree of divergence between the training and predicted ratings, we formulate the problem of learning binary codes as a discrete optimization problem. Although this optimization problem is intractable in general, we develop effective relaxations that can be efficiently solved by existing methods. Moreover, we investigate two methods to obtain the binary codes from the relaxed solutions. Evaluations are conducted on three public-domain data sets and the results suggest that our proposed method outperforms several baseline alternatives. © 2012 ACM."
"Li Y., Chen H., Xu S., Ge Y., Zhang Y.","Towards Personalized Fairness based on Causal Notion",2021,"SIGIR 2021 - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111669303&doi=10.1145%2f3404835.3462966&partnerID=40&md5=6d961912a57f4a68f5cc8abaaea6f067","Recommender systems are gaining increasing and critical impacts on human and society since a growing number of users use them for information seeking and decision making. Therefore, it is crucial to address the potential unfairness problems in recommendations. Just like users have personalized preferences on items, users' demands for fairness are also personalized in many scenarios. Therefore, it is important to providepersonalized fair recommendations for users to satisfy theirpersonalized fairness demands. Besides, previous works on fair recommendation mainly focus on association-based fairness. However, it is important to advance from associative fairness notions to causal fairness notions for assessing fairness more properly in recommender systems. Based on the above considerations, this paper focuses on achieving personalized counterfactual fairness for users in recommender systems. To this end, we introduce a framework for achieving counterfactually fair recommendations through adversary learning by generating feature-independent user embeddings for recommendation. The framework allows recommender systems to achieve personalized fairness for users while also covering non-personalized situations. Experiments on two real-world datasets with shallow and deep recommendation algorithms show that our method can generate fairer recommendations for users with a desirable recommendation performance. © 2021 ACM."
"Agarwal A., Wang X., Li C., Najork M., Zaitsev I., Joachims T.","Estimating position bias without intrusive interventions",2019,"WSDM 2019 - Proceedings of the 12th ACM International Conference on Web Search and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061754842&doi=10.1145%2f3289600.3291017&partnerID=40&md5=8e155a656b68d3c084c1473a00561ddf","Presentation bias is one of the key challenges when learning from implicit feedback in search engines, as it confounds the relevance signal. While it was recently shown how counterfactual learning-to-rank (LTR) approaches [18] can provably overcome presentation bias when observation propensities are known, it remains to show how to effectively estimate these propensities. In this paper, we propose the first method for producing consistent propensity estimates without manual relevance judgments, disruptive interventions, or restrictive relevance modeling assumptions. First, we show how to harvest a specific type of intervention data from historic feedback logs of multiple different ranking functions, and show that this data is sufficient for consistent propensity estimation in the position-based model. Second, we propose a new extremum estimator that makes effective use of this data. In an empirical evaluation, we find that the new estimator provides superior propensity estimates in two real-world systems - Arxiv Full-text Search and Google Drive Search. Beyond these two points, we find that the method is robust to a wide range of settings in simulation studies. © 2019 held by the owner/author(s)."
"Abdollahpouri H., Mansoury M., Burke R., Mobasher B.","The unfairness of popularity bias in recommendation",2019,"The unfairness of popularity bias in recommendation",,[No abstract available]
"Agarwal A., Zaitsev I., Takatsu K., Joachims T.","A general framework for counterfactual learning-to-rank",2019,"SIGIR 2019 - Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073781885&doi=10.1145%2f3331184.3331202&partnerID=40&md5=dad1c40214be3f7ed03208a40ac3a4c0","Implicit feedback (e.g., click, dwell time) is an attractive source of training data for Learning-to-Rank, but its naive use leads to learning results that are distorted by presentation bias. For the special case of optimizing average rank for linear ranking functions, however, the recently developed SVM-PropRank method has shown that counterfactual inference techniques can be used to provably overcome the distorting effect of presentation bias. Going beyond this special case, this paper provides a general and theoretically rigorous framework for counterfactual learning-to-rank that enables unbiased training for a broad class of additive ranking metrics (e.g., Discounted Cumulative Gain (DCG)) as well as a broad class of models (e.g., deep networks). Specifically, we derive a relaxation for propensity-weighted rank-based metrics which is subdifferentiable and thus suitable for gradient-based optimization. We demonstrate the effectiveness of this general approach by instantiating two new learning methods. One is a new type of unbiased SVM that optimizes DCG - called SVM PropDCG -, and we show how the resulting optimization problem can be solved via the Convex Concave Procedure (CCP). The other is Deep PropDCG, where the ranking function can be an arbitrary deep network. In addition to the theoretical support, we empirically find that SVM PropDCG significantly outperforms existing linear rankers in terms of DCG. Moreover, the ability to train non-linear ranking functions via Deep PropDCG further improves performance. © 2019 Association for Computing Machinery."
"Wu L., Chen L., Shao P., Hong R., Wang X., Wang M.","Learning fair representations for recommendation: A graph-based perspective",2021,"The Web Conference 2021 - Proceedings of the World Wide Web Conference, WWW 2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106588797&doi=10.1145%2f3442381.3450015&partnerID=40&md5=b7c97fa3ffc664efd7f71fd1997b80ce","As a key application of artificial intelligence, recommender systems are among the most pervasive computer aided systems to help users find potential items of interests. Recently, researchers paid considerable attention to fairness issues for artificial intelligence applications. Most of these approaches assumed independence of instances, and designed sophisticated models to eliminate the sensitive information to facilitate fairness. However, recommender systems differ greatly from these approaches as users and items naturally form a user-item bipartite graph, and are collaboratively correlated in the graph structure. In this paper, we propose a novel graph based technique for ensuring fairness of any recommendation models. Here, the fairness requirements refer to not exposing sensitive feature set in the user modeling process. Specifically, given the original embeddings from any recommendation models, we learn a composition of filters that transform each user's and each item's original embeddings into a filtered embedding space based on the sensitive feature set. For each user, this transformation is achieved under the adversarial learning of a user-centric graph, in order to obfuscate each sensitive feature between both the filtered user embedding and the sub graph structures of this user. Finally, extensive experimental results clearly show the effectiveness of our proposed model for fair recommendation. We publish the source code at https://github.com/newlei/FairGo. Â© 2021 ACM."
"Abdollahpouri H., Mansoury M., Burke R., Mobasher B.","The Connection between Popularity Bias, Calibration, and Fairness in Recommendation",2020,"RecSys 2020 - 14th ACM Conference on Recommender Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092747606&doi=10.1145%2f3383313.3418487&partnerID=40&md5=36f36ae5263048ce4dfcf2e406f1737d","Recently there has been a growing interest in fairness-aware recommender systems including fairness in providing consistent performance across different users or groups of users. A recommender system could be considered unfair if the recommendations do not fairly represent the tastes of a certain group of users while other groups receive recommendations that are consistent with their preferences. In this paper, we use a metric called miscalibration for measuring how a recommendation algorithm is responsive to users' true preferences and we consider how various algorithms may result in different degrees of miscalibration for different users. In particular, we conjecture that popularity bias which is a well-known phenomenon in recommendation is one important factor leading to miscalibration in recommendation. Our experimental results using two real-world datasets show that there is a connection between how different user groups are affected by algorithmic popularity bias and their level of interest in popular items. Moreover, we show that the more a group is affected by the algorithmic popularity bias, the more their recommendations are miscalibrated. © 2020 Owner/Author."
"Devooght R., Kourtellis N., Mantrach A.","Dynamic matrix factorization with priors on unknown values",2015,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954158205&doi=10.1145%2f2783258.2783346&partnerID=40&md5=73616105e4fce25efdeeae87db357738","Advanced and effective collaborative filtering methods based on explicit feedback assume that unknown ratings do not follow the same model as the observed ones (not missing at random). In this work, we build on this assumption, and introduce a novel dynamic matrix factorization framework that allows to set an explicit prior on unknown values. When new ratings, users, or items enter the system, we can update the factorization in time independent of the size of data (number of users, items and ratings). Hence, we can quickly recommend items even to very recent users. We test our methods on three large datasets, including two very sparse ones, in static and dynamic conditions. In each case, we outrank state-of-the-art matrix factorization methods that do not use a prior on unknown ratings. Copyright 2015 ACM."
"Zhu Z., He Y., Zhao X., Zhang Y., Wang J., Caverlee J.","Popularity-Opportunity Bias in Collaborative Filtering",2021,"WSDM 2021 - Proceedings of the 14th ACM International Conference on Web Search and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103048662&doi=10.1145%2f3437963.3441820&partnerID=40&md5=529aecd0257c9eeba693fcbd38674316","This paper connects equal opportunity to popularity bias in implicit recommenders to introduce the problem of popularity-opportunity bias. That is, conditioned on user preferences that a user likes both items, the more popular item is more likely to be recommended (or ranked higher) to the user than the less popular one. This type of bias is harmful, exerting negative effects on the engagement of both users and item providers. Thus, we conduct a three-part study: (i) By a comprehensive empirical study, we identify the existence of the popularity-opportunity bias in fundamental matrix factorization models on four datasets; (ii) coupled with this empirical study, our theoretical study shows that matrix factorization models inherently produce the bias; and (iii) we demonstrate the potential of alleviating this bias by both in-processing and post-processing algorithms. Extensive experiments on four datasets show the effective debiasing performance of these proposed methods compared with baselines designed for conventional popularity bias. © 2021 ACM."
"Wang X., Hoi S.C.H., Ester M., Bu J., Chen C.","Learning personalized preference of strong and weak ties for social recommendation",2017,"26th International World Wide Web Conference, WWW 2017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031936014&doi=10.1145%2f3038912.3052556&partnerID=40&md5=4b9ea52e7877ce56eb5c8b813f15a0ce","Recent years have seen a surge of research on social recommendation techniques for improving recommender systems due to the growing influence of social networks to our daily life. The intuition of social recommendation is that users tend to show affinities with items favored by their social ties due to social influence. Despite the extensive studies, no existing work has attempted to distinguish and learn the personalized preferences between strong and weak ties, two important terms widely used in social sciences, for each individual in social recommendation. In this paper, we first highlight the importance of different types of ties in social relations originated from social sciences, and then propose a novel social recommendation method based on a new Probabilistic Matrix Factorization model that incorporates the distinction of strong and weak ties for improving recommendation performance. The proposed method is capable of simultaneously classifying different types of social ties in a social network w.r.t. optimal recommendation accuracy, and learning a personalized tie type preference for each user in addition to other parameters. We conduct extensive experiments on four real-world datasets by comparing our method with state-of-the-art approaches, and find encouraging results that validate the efficacy of the proposed method in exploiting the personalized preferences of strong and weak ties for social recommendation. © 2017 International World Wide Web Conference Committee (IW3C2)."
"Zhu Z., Wang J., Caverlee J.","Measuring and Mitigating Item Under-Recommendation Bias in Personalized Ranking Systems",2020,"SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090112970&doi=10.1145%2f3397271.3401177&partnerID=40&md5=c1d0f0d2f42fcc7d887acde4d707499d","Recommendation algorithms typically build models based on user-item interactions (e.g., clicks, likes, or ratings) to provide a personalized ranked list of items. These interactions are often distributed unevenly over different groups of items due to varying user preferences. However, we show that recommendation algorithms can inherit or even amplify this imbalanced distribution, leading to item under-recommendation bias. Concretely, we formalize the concepts of ranking-based statistical parity and equal opportunity as two measures of item under-recommendation bias. Then, we empirically show that one of the most widely adopted algorithms-Bayesian Personalized Ranking-produces biased recommendations, which motivates our effort to propose the novel debiased personalized ranking model. The debiased model is able to improve the two proposed bias metrics while preserving recommendation performance. Experiments on three public datasets show strong bias reduction of the proposed model versus state-of-the-art alternatives. © 2020 ACM."
"Wang H., Wu Q., Wang H.","Factorization bandits for interactive recommendation",2017,"31st AAAI Conference on Artificial Intelligence, AAAI 2017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030464759&partnerID=40&md5=a191386cb84d8e11515252934789b0e5","We perform online interactive recommendation via a factorization-based bandit algorithm. Low-rank matrix completion is performed over an incrementally constructed useritem preference matrix, where an upper confidence bound based item selection strategy is developed to balance the exploit/explore trade-off during online learning. Observable contextual features and dependency among users (e.g., social influence) are leveraged to improve the algorithm's convergence rate and help conquer cold-start in recommendation. A high probability sublinear upper regret bound is proved for the developed algorithm, where considerable regret reduction is achieved on both user and item sides. Extensive experimentations on both simulations and large-scale real-world datasets confirmed the advantages of the proposed algorithm compared with several state-of-the-art factorization-based and bandit-based collaborative filtering methods. © Copyright 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved."
"Hofmann K., Schuth A., Whiteson S., De Rijke M.","Reusing historical interaction data for faster online learning to rank for IR",2013,"WSDM 2013 - Proceedings of the 6th ACM International Conference on Web Search and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874275961&doi=10.1145%2f2433396.2433419&partnerID=40&md5=4a94ced4916e019684e121adf95ebb78","Online learning to rank for information retrieval (IR) holds promise for allowing the development of ""self-learning"" search engines that can automatically adjust to their users. With the large amount of e.g., click data that can be collected in web search settings, such techniques could enable highly scalable ranking optimization. However, feedback obtained from user interactions is noisy, and developing approaches that can learn from this feedback quickly and reliably is a major challenge. In this paper we investigate whether and how previously collected (historical) interaction data can be used to speed up learning in online learning to rank for IR. We devise the first two methods that can utilize historical data (1) to make feedback available during learning more reliable and (2) to preselect candidate ranking functions to be evaluated in interactions with users of the retrieval system. We evaluate both approaches on 9 learning to rank data sets and find that historical data can speed up learning, leading to substantially and significantly higher online performance. In particular, our pre-selection method proves highly effective at compensating for noise in user feedback. Our results show that historical data can be used to make online learning to rank for IR much more effective than previously possible, especially when feedback is noisy. © 2013 ACM."
"Ekstrand M.D., Tian M., Imran Kazi M.R., Mehrpouyan H., Kluver D.","Exploring author gender in book rating and recommendation",2018,"RecSys 2018 - 12th ACM Conference on Recommender Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056759148&doi=10.1145%2f3240323.3240373&partnerID=40&md5=5b586000fb0b71495751135c85ffdb85","Collaborative filtering algorithms find useful patterns in rating and consumption data and exploit these patterns to guide users to good items. Many of the patterns in rating datasets reflect important real-world differences between the various users and items in the data; other patterns may be irrelevant or possibly undesirable for social or ethical reasons, particularly if they reflect undesired discrimination, such as gender or ethnic discrimination in publishing. In this work, we examine the response of collaborative filtering recommender algorithms to the distribution of their input data with respect to a dimension of social concern, namely content creator gender. Using publicly-available book ratings data, we measure the distribution of the genders of the authors of books in user rating profiles and recommendation lists produced from this data. We find that common collaborative filtering algorithms differ in the gender distribution of their recommendation lists, and in the relationship of that output distribution to user profile distribution. © 2018 Copyright held by the owner/author(s)."
"Saito Y.","Asymmetric Tri-training for Debiasing Missing-Not-At-Random Explicit Feedback",2020,"SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090151684&doi=10.1145%2f3397271.3401114&partnerID=40&md5=7dcc43539208e11301df9e7bc15c7fd5","In most real-world recommender systems, the observed rating data are subject to selection bias, and the data are thus missing-not-at-random. Developing a method to facilitate the learning of a recommender with biased feedback is one of the most challenging problems, as it is widely known that naive approaches under selection bias often lead to suboptimal results. A well-established solution for the problem is using propensity scoring techniques. The propensity score is the probability of each data being observed, and unbiased performance estimation is possible by weighting each data by the inverse of its propensity. However, the performance of the propensity-based unbiased estimation approach is often affected by choice of the propensity estimation model or the high variance problem. To overcome these limitations, we propose a model-agnostic meta-learning method inspired by the asymmetric tri-training framework for unsupervised domain adaptation. The proposed method utilizes two predictors to generate data with reliable pseudo-ratings and another predictor to make the final predictions. In a theoretical analysis, a propensity-independent upper bound of the true performance metric is derived, and it is demonstrated that the proposed method can minimize this bound. We conduct comprehensive experiments using public real-world datasets. The results suggest that the previous propensity-based methods are largely affected by the choice of propensity models and the variance problem caused by the inverse propensity weighting. Moreover, we show that the proposed meta-learning method is robust to these issues and can facilitate in developing effective recommendations from biased explicit feedback. © 2020 ACM."
"Chen Z., Xiao R., Li C., Ye G., Sun H., Deng H.","ESAM: Discriminative Domain Adaptation with Non-Displayed Items to Improve Long-Tail Performance",2020,"SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090142600&doi=10.1145%2f3397271.3401043&partnerID=40&md5=3865664cbe47b96365b6633adb61771a","Most of ranking models are trained only with displayed items (most are hot items), but they are utilized to retrieve items in the entire space which consists of both displayed and non-displayed items (most are long-tail items). Due to the sample selection bias, the long-tail items lack sufficient records to learn good feature representations, ie data sparsity and cold start problems. The resultant distribution discrepancy between displayed and non-displayed items would cause poor long-tail performance. To this end, we propose an entire space adaptation model (ESAM) to address this problem from the perspective of domain adaptation (DA). ESAM regards displayed and non-displayed items as source and target domains respectively. Specifically, we design the attribute correlation alignment that considers the correlation between high-level attributes of the item to achieve distribution alignment. Furthermore, we introduce two effective regularization strategies, ie center-wise clustering andself-training to improve DA process. Without requiring any auxiliary information and auxiliary domains, ESAM transfers the knowledge from displayed items to non-displayed items for alleviating the distribution inconsistency. Experiments on two public datasets and a large-scale industrial dataset collected from Taobao demonstrate that ESAM achieves state-of-the-art performance, especially in the long-tail space. Besides, we deploy ESAM to the Taobao search engine, leading to significant improvement on online performance. The code is available at https://github.com/A-bone1/ESAM.git. © 2020 ACM."
"Ovaisi Z., Ahsan R., Zhang Y., Vasilaky K., Zheleva E.","Correcting for Selection Bias in Learning-to-rank Systems",2020,"The Web Conference 2020 - Proceedings of the World Wide Web Conference, WWW 2020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086581355&doi=10.1145%2f3366423.3380255&partnerID=40&md5=7fc48be554eee31c8efe1335a5343fa8","Click data collected by modern recommendation systems are an important source of observational data that can be utilized to train learning-to-rank (LTR) systems. However, these data suffer from a number of biases that can result in poor performance for LTR systems. Recent methods for bias correction in such systems mostly focus on position bias, the fact that higher ranked results (e.g., top search engine results) are more likely to be clicked even if they are not the most relevant results given a user's query. Less attention has been paid to correcting for selection bias, which occurs because clicked documents are reflective of what documents have been shown to the user in the first place. Here, we propose new counterfactual approaches which adapt Heckman's two-stage method and accounts for selection and position bias in LTR systems. Our empirical evaluation shows that our proposed methods are much more robust to noise and have better accuracy compared to existing unbiased LTR algorithms, especially when there is moderate to no position bias. © 2020 ACM."
"Park D.H., Chang Y.","Adversarial sampling and training for semi-supervised information retrieval",2019,"The Web Conference 2019 - Proceedings of the World Wide Web Conference, WWW 2019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066914832&doi=10.1145%2f3308558.3313416&partnerID=40&md5=dad5b35177ed13148e09fc959a4ec2d5","Ad-hoc retrieval models with implicit feedback often have problems, e.g., the imbalanced classes in the data set. Too few clicked documents may hurt generalization ability of the models, whereas too many non-clicked documents may harm effectiveness of the models and efficiency of training. In addition, recent neural network-based models are vulnerable to adversarial examples due to the linear nature in them. To solve the problems at the same time, we propose an adversarial sampling and training framework to learn ad-hoc retrieval models with implicit feedback. Our key idea is (i) to augment clicked examples by adversarial training for better generalization and (ii) to obtain very informational non-clicked examples by adversarial sampling and training. Experiments are performed on benchmark data sets for common ad-hoc retrieval tasks such as Web search, item recommendation, and question answering. Experimental results indicate that the proposed approaches significantly outperform strong baselines especially for high-ranked documents, and they outperform IRGAN in NDCG@5 using only 5% of labeled data for the Web search task. © 2019 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY 4.0 License."
"Ding J., Feng F., He X., Yu G., Li Y., Jin D.","An Improved Sampler for Bayesian Personalized Ranking by Leveraging View Data",2018,"The Web Conference 2018 - Companion of the World Wide Web Conference, WWW 2018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051492805&doi=10.1145%2f3184558.3186905&partnerID=40&md5=e0cc2efc70758afb7cc9451381df6500","Bayesian Personalized Ranking (BPR) is a representative pairwise learning method for optimizing recommendation models. It is widely known that the performance of BPR depends largely on the quality of the negative sampler. In this short paper, we make two contributions with respect to BPR. First, we find that sampling negative items from the whole space is unnecessary and may even degrade the performance. Second, focusing on the purchase feedback of the E-commerce domain, we propose a simple yet effective sampler for BPR by leveraging the additional view data. Compared to the vanilla BPR that applies a uniform sampler on all candidates, our view-aware sampler enhances BPR with a relative improvement of 27.36% and 69.54% on two real-world datasets respectively. © 2018 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC BY 4.0 License."
"Schuth A., Oosterhuis H., Whiteson S., De Rijke M.","Multileave gradient descent for fast online learning to rank",2016,"WSDM 2016 - Proceedings of the 9th ACM International Conference on Web Search and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964336704&doi=10.1145%2f2835776.2835804&partnerID=40&md5=02265bbb64bccb1b9851ba4cf1376202","Modern search systems are based on dozens or even hundreds of ranking features. The dueling bandit gradient descent (DBGD) algorithm has been shown to effectively learn combinations of these features solely from user interactions. DBGD explores the search space by comparing a possibly improved ranker to the current production ranker. To this end, it uses interleaved comparison methods, which can infer with high sensitivity a preference between two rankings based only on interaction data. A limiting factor is that it can compare only to a single exploratory ranker. We propose an online learning to rank algorithm called multileave gradient descent (MGD) that extends DBGD to learn from so-called multileaved comparison methods that can compare a set of rankings instead of merely a pair. We show experimentally that MGD allows for better selection of candidates than DBGD without the need for more comparisons involving users. An important implication of our results is that orders of magnitude less user interaction data is required to find good rankers when multileaved comparisons are used within online learning to rank. Hence, fewer users need to be exposed to possibly inferior rankers and our method allows search engines to adapt more quickly to changes in user preferences. Copyright is held by the owner/author(s)."
"Zhu Z.A., Chen W., Minka T., Zhu C., Chen Z.","A novel click model and its applications to online advertising",2010,"WSDM 2010 - Proceedings of the 3rd ACM International Conference on Web Search and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950884579&doi=10.1145%2f1718487.1718528&partnerID=40&md5=503380594b01addfb32c9886f7a40157","Recent advances in click model have positioned it as an attractive method for representing user preferences in web search and online advertising. Yet, most of the existing works focus on training the click model for individual queries, and cannot accurately model the tail queries due to the lack of training data. Simultaneously, most of the existing works consider the query, url and position, neglecting some other important attributes in click log data, such as the local time. Obviously, the click through rate is different between daytime and midnight. In this paper, we propose a novel click model based on Bayesian network, which is capable of modeling the tail queries because it builds the click model on attribute values, with those values being shared across queries. We called our work General Click Model (GCM) as we found that most of the existing works can be special cases of GCM by assigning different parameters. Experimental results on a large-scale commercial advertisement dataset show that GCM can significantly and consistently lead to better results as compared to the state-of-the-art works. Copyright 2010 ACM."
"Stoica A.-A., Riederer C., Chaintreau A.","Algorithmic glass ceiling in social networks: The effects of social recommendations on network diversity",2018,"The Web Conference 2018 - Proceedings of the World Wide Web Conference, WWW 2018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056796444&doi=10.1145%2f3178876.3186140&partnerID=40&md5=151f352e3cfbedd8580c78538e7fef32","As social recommendations such as friend suggestions and people to follow become increasingly popular and influential on the growth of social media, we find that prominent social recommendation algorithms can exacerbate the under-representation of certain demographic groups at the top of the social hierarchy. To study this imbalance in online equal opportunities, we leverage new Instagram data and offer for the first time an analysis that studies the effect of gender, homophily and growth dynamics under social recommendations. Our mathematical analysis demonstrates the existence of an algorithmic glass ceiling that exhibits all the properties of the metaphorical social barrier that hinders groups like women or people of color from attaining equal representation. What raises concern is that our proof shows that under fixed minority and homophily parameters the algorithmic effect is systematically larger than the glass ceiling generated by the spontaneous growth of social networks. We discuss ways to address this concern in future design. © 2018 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC BY 4.0 License."
"Zhao X., Xia L., Tang J., Yin D.","Deep reinforcement learning for search, recommendation, and online advertising: a survey",2019,"ACM SIGWEB Newsletter Spring",,[No abstract available]
"Wang X., Zhang R., Sun Y., Qi J.","Combating Selection Biases in Recommender Systems with a Few Unbiased Ratings",2021,"WSDM 2021 - Proceedings of the 14th ACM International Conference on Web Search and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103005101&doi=10.1145%2f3437963.3441799&partnerID=40&md5=216ca1c1d3affa7722126a46d690f848","Recommendation datasets are prone to selection biases due to self-selection behavior of users and item selection process of systems. This makes explicitly combating selection biases an essential problem in training recommender systems. Most previous studies assume no unbiased data available for training. We relax this assumption and assume that a small subset of training data is unbiased. Then, we propose a novel objective that utilizes the unbiased data to adaptively assign propensity weights to biased training ratings. This objective, combined with unbiased performance estimators, alleviates the effects of selection biases on the training of recommender systems. To optimize the objective, we propose an efficient algorithm that minimizes the variance of propensity estimates for better generalized recommender systems. Extensive experiments on two real-world datasets confirm the advantages of our approach in significantly reducing both the error of rating prediction and the variance of propensity estimation. © 2021 ACM."
"Bose A., Hamilton W.","Compositional fairness constraints for graph embeddings",2019,"International Conference on Machine Learning",,[No abstract available]
"Hernández-Lobato J.M., Houlsby N., Ghahramani Z.","Probabilistic matrix factorization with non-random missing data",2014,"ICML",,[No abstract available]
"Abdollahpouri H.","Popularity bias in ranking and recommendation",2019,"AIES 2019 - Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066885419&doi=10.1145%2f3306618.3314309&partnerID=40&md5=fb15a64ff434a85431d3f9bf4e303852","Many recommender systems suffer from popularity bias: popular items are recommended frequently while less popular, niche products, are recommended rarely or not at all. However, recommending the ignored products in the “long tail” is critical for businesses as they are less likely to be discovered. Popularity bias is also against social justice where the entities need to have a fair chance of being served and represented. In this work, I investigate the problem of popularity bias in recommender systems and develop algorithms to address this problem. © 2019 Copyright held by the owner/author(s)."
"Wu Y., Zhang L., Wu X.","Counterfactual fairness: Unidentification, bound and algorithm",2019,"IJCAI International Joint Conference on Artificial Intelligence","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074920212&doi=10.24963%2fijcai.2019%2f199&partnerID=40&md5=30327f6cbdfc10a4959804b4c78fea8f","Fairness-aware learning studies the problem of building machine learning models that are subject to fairness requirements. Counterfactual fairness is a notion of fairness derived from Pearl's causal model, which considers a model is fair if for a particular individual or group its prediction in the real world is the same as that in the counterfactual world where the individual(s) had belonged to a different demographic group. However, an inherent limitation of counterfactual fairness is that it cannot be uniquely quantified from the observational data in certain situations, due to the unidentifiability of the counterfactual quantity. In this paper, we address this limitation by mathematically bounding the unidentifiable counterfactual quantity, and develop a theoretically sound algorithm for constructing counterfactually fair classifiers. We evaluate our method in the experiments using both synthetic and real-world datasets, as well as compare with existing methods. The results validate our theory and show the effectiveness of our method. © 2019 International Joint Conferences on Artificial Intelligence. All rights reserved."
"Krishnan S., Patel J., Franklin M.J., Goldberg K.","A methodology for learning, analyzing, and mitigating social influence bias in recommender systems",2014,"RecSys 2014 - Proceedings of the 8th ACM Conference on Recommender Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908879669&doi=10.1145%2f2645710.2645740&partnerID=40&md5=b7b58d9b143e61acf03b5609e0fcba4d","The seminal 2003 paper by Cosley, Lab, Albert, Konstan, and Reidl, demonstrated the susceptibility of recommender systems to rating biases. To facilitate browsing and selec- tion, almost all recommender systems display average rat- ings before accepting ratings from users which has been shown to bias ratings. This effiect is called Social In uence Bias (SIB); the tendency to conform to the perceived\norm"" in a community. We propose a methodology to 1) learn, 2) analyze, and 3) mitigate the effiect of SIB in recommender systems. In the Learning phase, we build a baseline dataset by allowing users to rate twice: before and after seeing the average rating. In the Analysis phase, we apply a new non- parametric significance test based on the Wilcoxon statistic to test whether the data is consistent with SIB. If significant, we propose a Mitigation phase using polynomial regression and the Bayesian Information Criterion (BIC) to predict unbiased ratings. We evaluate our approach on a dataset of 9390 ratings from the California Report Card (CRC), a rating-based system designed to encourage political engage- ment. We found statistically significant evidence of SIB. Mitigating models were able to predict changed ratings with a normalized RMSE of 12.8% and reduce bias by 76.3%. Copyright © 2014 ACM."
"Zhang W., Bao W., Liu X.-Y., Yang K., Lin Q., Wen H., Ramezani R.","Large-scale Causal Approaches to Debiasing Post-click Conversion Rate Estimation with Multi-task Learning",2020,"The Web Conference 2020 - Proceedings of the World Wide Web Conference, WWW 2020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086580982&doi=10.1145%2f3366423.3380037&partnerID=40&md5=313ca70c3fdc436d0c6a00d0121e003b","Post-click conversion rate (CVR) estimation is a critical task in e-commerce recommender systems. This task is deemed quite challenging under industrial setting with two major issues: 1) selection bias caused by user self-selection, and 2) data sparsity due to the rare click events. A successful conversion typically has the following sequential events: ""exposure → click → conversion"". Conventional CVR estimators are trained in the click space, but inference is done in the entire exposure space. They fail to account for the causes of the missing data and treat them as missing at random. Hence, their estimations are highly likely to deviate from the real values by large. In addition, the data sparsity issue can also handicap many industrial CVR estimators which usually have large parameter spaces. In this paper, we propose two principled, efficient and highly effective CVR estimators for industrial CVR estimation, namely, Multi-IPW and Multi-DR. The proposed models approach the CVR estimation from a causal perspective and account for the causes of missing not at random. In addition, our methods are based on the multi-task learning framework and mitigate the data sparsity issue. Extensive experiments on industrial-level datasets show that our methods outperform the state-of-the-art CVR models. © 2020 ACM."
"Agarwal A., Wang X., Li C., Bendersky M., Najork M.","Addressing trust bias for unbiased learning-to-rank",2019,"The Web Conference 2019 - Proceedings of the World Wide Web Conference, WWW 2019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066826489&doi=10.1145%2f3308558.3313707&partnerID=40&md5=850c506fe81c4b618d981e4f4e4c43c2","Existing unbiased learning-to-rank models use counterfactual inference, notably Inverse Propensity Scoring (IPS), to learn a ranking function from biased click data. They handle the click incompleteness bias, but usually assume that the clicks are noise-free, i.e., a clicked document is always assumed to be relevant. In this paper, we relax this unrealistic assumption and study click noise explicitly in the unbiased learning-to-rank setting. Specifically, we model the noise as the position-dependent trust bias and propose a noise-aware Position-Based Model, named TrustPBM, to better capture user click behavior. We propose an Expectation-Maximization algorithm to estimate both examination and trust bias from click data in TrustPBM. Furthermore, we show that it is difficult to use a pure IPS method to incorporate click noise and thus propose a novel method that combines a Bayes rule application with IPS for unbiased learning-to-rank. We evaluate our proposed methods on three personal search data sets and demonstrate that our proposed model can significantly outperform the existing unbiased learning-to-rank methods. © 2019 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY-NC-ND 4.0 License."
"Klöckner K., Wirschum N., Jameson A.","Depth- and breadth-first processing of search result lists",2004,"Conference on Human Factors in Computing Systems - Proceedings","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876757191&doi=10.1145%2f985921.986115&partnerID=40&md5=1b2ffc38bbb8d87c55ed3acd0af2647d",[No abstract available]
"Lian D., Liu R., Ge Y., Zheng K., Xie X., Cao L.","Discrete content-aware matrix factorization",2017,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029047321&doi=10.1145%2f3097983.3098008&partnerID=40&md5=a7c681f79a80c3af9bf538128d57b9b3","Precisely recommending relevant items from massive candidates to a large number of users is an indispensable yet computationally expensive task in many online platforms (e.g., Amazon.com and Netfix.com). A promising way is to project users and items into a Hamming space and then recommend items via Hamming distance. However, previous studies didn't address the cold-start challenges and couldn't make the best use of preference data like implicit feedback. To fill this gap, we propose a Discrete Content-aware Matrix Factorization (DCMF) model, 1) to derive compact yet informative binary codes at the presence of user/item content information; 2) to support the classification task based on a local upper bound of logit loss; 3) to introduce an interaction regularization for dealing with the sparsity issue. We further develop an eficient discrete optimization algorithm for parameter learning. Based on extensive experiments on three real-world datasets, we show that DCFM outperforms the state-of-the-arts on both regression and classification tasks. © 2017 ACM."
"Liu D., Cheng P., Zhu H., Dong Z., He X., Pan W., Ming Z.","Mitigating confounding bias in recommendation via information bottleneck",2021,"RecSys 2021 - 15th ACM Conference on Recommender Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115630682&doi=10.1145%2f3460231.3474263&partnerID=40&md5=5dad636c40691fab9aeda294c4ef5117","How to effectively mitigate the bias of feedback in recommender systems is an important research topic. In this paper, we first describe the generation process of the biased and unbiased feedback in recommender systems via two respective causal diagrams, where the difference between them can be regarded as the source of bias. We then define this difference as a confounding bias, which can be regarded as a collection of some specific biases that have previously been studied. For the case with biased feedback alone, we derive the conditions that need to be satisfied to obtain a debiased representation from the causal diagrams. Based on information theory, we propose a novel method called debiased information bottleneck (DIB) to optimize these conditions and then find a tractable solution for it. In particular, the proposed method constrains the model to learn a biased embedding vector with independent biased and unbiased components in the training phase, and uses only the unbiased component in the test phase to deliver more accurate recommendations. Finally, we conduct extensive experiments on a public dataset and a real product dataset to verify the effectiveness of the proposed method and discuss its properties. © 2021 ACM."
"Islam R., Keya K.N., Zeng Z., Pan S., Foulds J.","Debiasing career recommendations with neural fair collaborative filtering",2021,"The Web Conference 2021 - Proceedings of the World Wide Web Conference, WWW 2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106433978&doi=10.1145%2f3442381.3449904&partnerID=40&md5=45cc3e4f7176c994c9cac83ab0d70071","A growing proportion of human interactions are digitized on social media platforms and subjected to algorithmic decision-making, and it has become increasingly important to ensure fair treatment from these algorithms. In this work, we investigate gender bias in collaborative-filtering recommender systems trained on social media data. We develop neural fair collaborative filtering (NFCF), a practical framework for mitigating gender bias in recommending career-related sensitive items (e.g. jobs, academic concentrations, or courses of study) using a pre-training and fine-tuning approach to neural collaborative filtering, augmented with bias correction techniques. We show the utility of our methods for gender de-biased career and college major recommendations on the MovieLens dataset and a Facebook dataset, respectively, and achieve better performance and fairer behavior than several state-of-the-art models. Â© 2021 ACM."
"Sun W., Nasraoui O., Khenissi S., Shafto P.","Debiasing the human-recommender system feedback loop in collaborative filtering",2019,"The Web Conference 2019 - Companion of the World Wide Web Conference, WWW 2019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066883690&doi=10.1145%2f3308560.3317303&partnerID=40&md5=6fafc1719c32e0dec814c7df4b246df3","Recommender Systems (RSs) are widely used to help online users discover products, books, news, music, movies, courses, restaurants, etc. Because a traditional recommendation strategy always shows the most relevant items (thus with highest predicted rating), traditional RS's are expected to make popular items become even more popular and non-popular items become even less popular which in turn further divides the haves (popular) from the have-nots (unpopular). Therefore, a major problem with RSs is that they may introduce biases affecting the exposure of items, thus creating a popularity divide of items during the feedback loop that occurs with users, and this may lead the RS to make increasingly biased recommendations over time. In this paper, we view the RS environment as a chain of events that are the result of interactions between users and the RS. Based on that, we propose several debiasing algorithms during this chain of events, and evaluate how these algorithms impact the predictive behavior of the RS, as well as trends in the popularity distribution of items over time. We also propose a novel blind-spot-aware matrix factorization (MF) algorithm to debias the RS. Results show that propensity matrix factorization achieved a certain level of debiasing of the RS while active learning combined with the propensity MF achieved a higher debiasing effect on recommendations. � 2019 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY-NC-ND 4.0 License."
"Krishnan A., Sharma A., Sankar A., Sundaram H.","An adversarial approach to improve long-tail performance in neural collaborative filtering",2018,"International Conference on Information and Knowledge Management, Proceedings","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058006545&doi=10.1145%2f3269206.3269264&partnerID=40&md5=06a8b6560196c68c44930cb41f3bfe25","In recent times, deep neural networks have found success in Collaborative Filtering (CF) based recommendation tasks. By parametrizing latent factor interactions of users and items with neural architectures, they achieve significant gains in scalability and performance over matrix factorization. However, the long-tail phenomenon in recommender performance persists on the massive inventories of online media or retail platforms. Given the diversity of neural architectures and applications, there is a need to develop a generalizable and principled strategy to enhance long-tail item coverage. In this paper, we propose a novel adversarial training strategy to enhance long-tail recommendations for users with Neural CF (NCF) models. The adversary network learns the implicit association structure of entities in the feedback data while the NCF model is simultaneously trained to reproduce these associations and avoid the adversarial penalty, resulting in enhanced long-tail performance. Experimental results show that even without auxiliary data, adversarial training can boost long-tail recall of state-of-the-art NCF models by up to 25%, without trading-off overall performance. We evaluate our approach on two diverse platforms, content tag recommendation in Q&A forums and movie recommendation. © 2018 Association for Computing Machinery."
"Chen J., Wang C., Zhou S., Shi Q., Feng Y., Chen C.","SamWalker: Social recommendation with informative sampling strategy",2019,"The Web Conference 2019 - Proceedings of the World Wide Web Conference, WWW 2019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066908336&doi=10.1145%2f3308558.3313582&partnerID=40&md5=ce7a0179972078789421ae8fdb7b4e3b","Recommendation from implicit feedback is a highly challenging task due to the lack of reliable negative feedback data. Only positive feedback are observed and the unobserved feedback can be attributed to two reasons: unknow or dislike. Existing methods address this challenge by treating all the un-observed data as negative (dislike) but downweight the confidence of these data. However, this treatment causes two problems: (1) Confidence weights of the unobserved data are usually assigned manually, which lack flexible and may create empirical bias in evaluating user's preference. (2) To handle massive volume of the unobserved feedback data, most of the existing methods rely on stochastic inference and data sampling strategies. However, since users are only aware of a very small fraction of items in a large dataset, it is difficult for existing samplers to select informative training instances in which the user really dislikes the item rather than does not know it. To address the above two problems, we propose a new recommendation method SamWalker that leverages social information to infer data confidence and guide the sampling process. By modeling data confidence with a social context-aware function, SamWalker can adaptively specify different weights to different data based on users' social contexts. Further, a personalized random-walk-based sampling strategy is developed to adaptively draw informative training instances, which can speed up gradient estimation and reduce sampling variance. Extensive experiments on three real-world datasets demonstrate the superiority of the proposed SamWalker method and its sampling strategy. © 2019 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY 4.0 License."
"Zhao X., Zheng X., Yang X., Liu X., Tang J.","Jointly Learning to Recommend and Advertise",2020,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090163370&doi=10.1145%2f3394486.3403384&partnerID=40&md5=a7d793f23844c1a5deb438cfa5546b5f","Online recommendation and advertising are two major income channels for online recommendation platforms (e.g. e-commerce and news feed site). However, most platforms optimize recommending and advertising strategies by different teams separately via different techniques, which may lead to suboptimal overall performances. To this end, in this paper, we propose a novel two-level reinforcement learning framework to jointly optimize the recommending and advertising strategies, where the first level generates a list of recommendations to optimize user experience in the long run; then the second level inserts ads into the recommendation list that can balance the immediate advertising revenue from advertisers and the negative influence of ads on long-term user experience. To be specific, the first level tackles high combinatorial action space problem that selects a subset items from the large item space; while the second level determines three internally related tasks, i.e., (i) whether to insert an ad, and if yes, (ii) the optimal ad and (iii) the optimal location to insert. The experimental results based on real-world data demonstrate the effectiveness of the proposed framework. We have released the implementation code to ease reproductivity. © 2020 ACM."
"Saito Y.","Doubly Robust Estimator for Ranking Metrics with Post-Click Conversions",2020,"RecSys 2020 - 14th ACM Conference on Recommender Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092731115&doi=10.1145%2f3383313.3412262&partnerID=40&md5=32d665af889e41abed7a297205182e85","Post-click conversion, a pre-defined action on a web service after a click, is an essential form of feedback, as it directly contributes to the final revenue and accurately captures user preferences for items, compared with the ambiguous click. However, naively using post-click conversions can lead to severe bias when learning or evaluating recommenders because of the selection bias between clicked and unclicked data. In this study, we address the offline evaluation problem of algorithmic recommendations with biased post-click conversions. A possible solution to address this bias is to use the inverse propensity score estimator, as it can provide an unbiased evaluation even with the selection bias. However, this estimator is known to be subject to variance and instability problems, which can be severe in the recommendation setting, as feedback is often highly sparse. To address these limitations with the previous unbiased estimator, we propose a doubly robust estimator for the ground-truth ranking performance of a given recommender. The proposed estimator is unbiased against the ground-truth ranking metric and improves the variance and estimation error tail bound of the existing unbiased estimator. Finally, to evaluate the empirical efficacy of the proposed estimator, we conduct empirical evaluations using semi-synthetic and two public real-world datasets. The results show that the proposed metric reveals a better model evaluation performance compared with existing baseline metrics, particularly in a situation with severe selection bias. © 2020 ACM."
"Liu W., Guo J., Sonboli N., Burke R., Zhang S.","Personalized fairness-aware re-ranking for microlending",2019,"RecSys 2019 - 13th ACM Conference on Recommender Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073347949&doi=10.1145%2f3298689.3347016&partnerID=40&md5=295b9340a573b99e4cb7dfae249a2a46","Microlending can lead to improved access to capital in impoverished countries. Recommender systems could be used in microlending to provide efficient and personalized service to lenders. However, increasing concerns about discrimination in machine learning hinder the application of recommender systems to the microfinance industry. Most previous recommender systems focus on pure personalization, with fairness issue largely ignored. A desirable fairness property in microlending is to give borrowers from different demographic groups a fair chance of being recommended, as stated by Kiva. To achieve this goal, we propose a Fairness-Aware Re-ranking (FAR) algorithm to balance ranking quality and borrower-side fairness. Furthermore, we take into consideration that lenders may differ in their receptivity to the diversification of recommended loans, and develop a Personalized Fairness-Aware Re-ranking (PFAR) algorithm. Experiments on a real-world dataset from Kiva.org show that our re-ranking algorithm can significantly promote fairness with little sacrifice in accuracy, and be attentive to individual lender preference on loan diversity. © 2019 Association for Computing Machinery."
"Yu H.-F., Bilenko M., Lin C.-J.","Selection of negative samples for one-class matrix factorization",2017,"Proceedings of the 17th SIAM International Conference on Data Mining, SDM 2017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027862854&partnerID=40&md5=0c6c838824613d42c919416d646b2776","Many recommender systems have only implicit user feedback. The two possible ratings are positive and negative, but only part of positive entries are observed. One-class matrix factorization (MF) is a popular approach for such scenarios by treating some missing entries as negative. Two major ways to select negative entries are by sub-sampling a set with similar size to that of observed positive entries or by including all missing entries as negative. They are referred to as ""subsampled"" and ""full"" approaches in this work, respectively. Currently detailed comparisons between these two selection schemes on large-scale data are still lacking. One important reason is that the ""full"" approach leads to a hard optimization problem after treating all missing entries as negative. In this paper, we successfully develop efficient optimization techniques to solve this challenging problem so that the ""full"" approach becomes practically viable. We then compare in detail the two approaches ""subsampled"" and ""full"" for selecting negative entries. Results show that the ""full"" approach of including much more missing entries as negative yields better results. Copyright © by SIAM."
"Liu Y., Cao X., Yu Y.","Are you influenced by others when rating? Improve rating prediction by conformity modeling",2016,"RecSys 2016 - Proceedings of the 10th ACM Conference on Recommender Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991209874&doi=10.1145%2f2959100.2959141&partnerID=40&md5=ae8a16f548ae74ba63cc1c6e238f6c67","Conformity has a strong inuence to user behaviors, even in online environment. When surfing online, users are usu- ally ooded with others' opinions. These opinions implic- itly contribute to the user's ongoing behaviors. However, there is no research work modeling online conformity yet. In this paper, we model user's conformity in online rat- ing sites. We conduct analysis using real data to show the existence and strength of conformity in these scenarios. We propose a matrix-factorization-based conformity mod- eling technique to improve the accuracy of rating predic- tion. Experiments show that our model outperforms ex- isting works significantly (with a relative improvement of 11.72% on RMSE). Therefore, we draw the conclusion that conformity modeling is important for understanding user be- haviors and can contribute to further improve the online recommender systems. © 2016 ACM."
"Beigi G., Mosallanezhad A., Guo R., Alvari H., Nou A., Liu H.","Privacy-aware recommendation with private-attribute protection using adversarial learning",2020,"WSDM 2020 - Proceedings of the 13th International Conference on Web Search and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079515718&doi=10.1145%2f3336191.3371832&partnerID=40&md5=e74e5771445a2fe239befdfac8677682","Recommendation is one of the critical applications that helps users find information relevant to their interests. However, a malicious attacker can infer users’ private information via recommendations. Prior work obfuscates user-item data before sharing it with recommendation system. This approach does not explicitly address the quality of recommendation while performing data obfuscation. Moreover, it cannot protect users against private-attribute inference attacks based on recommendations. This work is the first attempt to build a Recommendation with Attribute Protection (RAP) model which simultaneously recommends relevant items and counters private-attribute inference attacks. The key idea of our approach is to formulate this problem as an adversarial learning problem with two main components: the private attribute inference attacker, and the Bayesian personalized recommender. The attacker seeks to infer users’ private-attribute information according to their items list and recommendations. The recommender aims to extract users’ interests while employing the attacker to regularize the recommendation process. Experiments show that the proposed model both preserves the quality of recommendation service and protects users against private-attribute inference attacks. © 2020 Association for Computing Machinery."
"Chen J., Wang C., Zhou S., Shi Q., Chen J., Feng Y., Chen C.","Fast adaptivelyweighted matrix factorization for recommendation with implicit feedback",2020,"AAAI 2020 - 34th AAAI Conference on Artificial Intelligence","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095498688&partnerID=40&md5=fb70ec6384e85c33c75aaa3a0a0dc7e5","Recommendation from implicit feedback is a highly challenging task due to the lack of the reliable observed negative data. A popular and effective approach for implicit recommendation is to treat unobserved data as negative but downweight their confidence. Naturally, how to assign confidence weights and how to handle the large number of the unobserved data are two key problems for implicit recommendation models. However, existing methods either pursuit fast learning by manually assigning simple confidence weights, which lacks flexibility and may create empirical bias in evaluating user's preference; or adaptively infer personalized confidence weights but suffer from low efficiency. To achieve both adaptive weights assignment and efficient model learning, we propose a fast adaptively weighted matrix factorization (FAWMF) based on variational auto-encoder. The personalized data confidence weights are adaptively assigned with a parameterized neural network (function) and the network can be inferred from the data. Further, to support fast and stable learning of FAWMF, a new specific batchbased learning algorithm fBGD has been developed, which trains on all feedback data but its complexity is linear to the number of observed data. Extensive experiments on realworld datasets demonstrate the superiority of the proposed FAWMF and its learning algorithm fBGD. © 2020, Association for the Advancement of Artificial Intelligence."
"Wang M., Zheng X., Yang Y., Zhang K.","Collaborative filtering with social exposure: A modular approach to social recommendation",2018,"32nd AAAI Conference on Artificial Intelligence, AAAI 2018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058064449&partnerID=40&md5=e845a983713c3c01292ace5c2c4487ee","This paper is concerned with how to make efficient use of social information to improve recommendations. Most existing social recommender systems assume people share similar preferences with their social friends. Which, however, may not hold true due to various motivations of making online friends and dynamics of online social networks. Inspired by recent causal process based recommendations that first model user exposures towards items and then use these exposures to guide rating prediction, we utilize social information to capture user exposures rather than user preferences. We assume that people get information of products from their online friends and they do not have to share similar preferences, which is less restrictive and seems closer to reality. Under this new assumption, in this paper, we present a novel recommendation approach (named SERec) to integrate social exposure into collaborative filtering. We propose two methods to implement SERec, namely social regularization and social boosting, each with different ways to construct social exposures. Experiments on four real-world datasets demonstrate that our methods outperform the state-of-the-art methods on top-N recommendations. Further study compares the robustness and scalability of the two proposed methods. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved."
"Yuan B., Zhu H., Hsia J.-Y., Chang C.-Y., Lin C.-J., Yang M.-Y., Dong Z.","Improving ad click prediction by considering non-displayed events",2019,"International Conference on Information and Knowledge Management, Proceedings","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075440903&doi=10.1145%2f3357384.3358058&partnerID=40&md5=d423f72d59df787bc44a7fe82b38fe6b","Click-through rate (CTR) prediction is the core problem of building advertising systems. Most existing state-of-the-art approaches model CTR prediction as binary classification problems, where displayed events with and without click feedbacks are respectively considered as positive and negative instances for training and offline validation. However, due to the selection mechanism applied in most advertising systems, a selection bias exists between distributions of displayed and non-displayed events. Conventional CTR models ignoring the bias may have inaccurate predictions and cause a loss of the revenue. To alleviate the bias, we need to conduct counterfactual learning by considering not only displayed events but also non-displayed events. In this paper, through a review of existing approaches of counterfactual learning, we point out some difficulties for applying these approaches for CTR prediction in a real-world advertising system. To overcome these difficulties, we propose a novel framework for counterfactual CTR prediction. In experiments, we compare our proposed framework against state-of-the-art conventional CTR models and existing counterfactual learning approaches. Experimental results show significant improvements. © 2019 Association for Computing Machinery."
"Zhu Z., He Y., Zhao X., Caverlee J.","Popularity Bias in Dynamic Recommendation",2021,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114929443&doi=10.1145%2f3447548.3467376&partnerID=40&md5=82826b7d1091757d64bc6f0d715760f4","Popularity bias is a long-standing challenge in recommender systems: popular items are overly recommended at the expense of less popular items that users may be interested in being under-recommended. Such a bias exerts detrimental impact on both users and item providers, and many efforts have been dedicated to studying and solving such a bias. However, most existing works situate the popularity bias in a static setting, where the bias is analyzed only for a single round of recommendation with logged data. These works fail to take account of the dynamic nature of real-world recommendation process, leaving several important research questions unanswered: how does the popularity bias evolve in a dynamic scenario? what are the impacts of unique factors in a dynamic recommendation process on the bias? and how to debias in this long-term dynamic process? In this work, we investigate the popularity bias in dynamic recommendation and aim to tackle these research gaps. Concretely, we conduct an empirical study by simulation experiments to analyze popularity bias in the dynamic scenario and propose a dynamic debiasing strategy and a novel False Positive Correction method utilizing false positive signals to debias, which show effective performance in extensive experiments. © 2021 ACM."
"Fang Z., Agarwal A., Joachims T.","Intervention harvesting for context-dependent examination-bias estimation",2019,"SIGIR 2019 - Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073788486&doi=10.1145%2f3331184.3331238&partnerID=40&md5=114916d16155fc14c7f369c653c50280","Accurate estimates of examination bias are crucial for unbiased learning-to-rank from implicit feedback in search engines and recommender systems, since they enable the use of Inverse Propensity Score (IPS) weighting techniques to address selection biases and missing data. Unfortunately, existing examination-bias estimators are limited to the Position-Based Model (PBM), where the examination bias may only depend on the rank of the document. To overcome this limitation, we propose a Contextual Position-Based Model (CPBM) where the examination bias may also depend on a context vector describing the query and the user. Furthermore, we propose an effective estimator for the CPBM based on intervention harvesting. A key feature of the estimator is that it does not require disruptive interventions but merely exploits natural variation resulting from the use of multiple historic ranking functions. Real-world experiments on the ArXiv search engine and semi-synthetic experiments on the Yahoo Learning-To-Rank dataset demonstrate the superior effectiveness and robustness of the new approach. © 2019 Association for Computing Machinery."
"Vardasbi A., Oosterhuis H., De Rijke M.","When Inverse Propensity Scoring does not Work: Affine Corrections for Unbiased Learning to Rank",2020,"International Conference on Information and Knowledge Management, Proceedings","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095865666&doi=10.1145%2f3340531.3412031&partnerID=40&md5=63a41e32906a59e266320abb946fc789","Besides position bias, which has been well-studied, trust bias is another type of bias prevalent in user interactions with rankings: users are more likely to click incorrectly w.r.t. their preferences on highly ranked items because they trust the ranking system. While previous work has observed this behavior in users, we prove that existing Counterfactual Learning to Rank (CLTR) methods do not remove this bias, including methods specifically designed to mitigate this type of bias. Moreover, we prove that Inverse Propensity Scoring (IPS) is principally unable to correct for trust bias under non-trivial circumstances. Our main contribution is a new estimator based on affine corrections: it both reweights clicks and penalizes items displayed on ranks with high trust bias. Our estimator is the first estimator that is proven to remove the effect of both trust bias and position bias. Furthermore, we show that our estimator is a generalization of the existing (CLTR) framework: if no trust bias is present, it reduces to the original (IPS) estimator. Our semi-synthetic experiments indicate that by removing the effect of trust bias in addition to position bias, (CLTR) can approximate the optimal ranking system even closer than previously possible. © 2020 ACM."
"Wang Y., Liang D., Charlin L., Blei D.M.","The deconfounded recommender: A causal inference approach to recommendation",2018,"The deconfounded recommender: A causal inference approach to recommendation",,[No abstract available]
"Kamishima T., Akaho S., Asoh H., Sakuma J.","Enhancement of the neutrality in recommendation",2012,"CEUR Workshop Proceedings","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892617726&partnerID=40&md5=57a10b228f0d3e6917f978ea187527a9","This paper proposes an algorithm for making recommendation so that the neutrality toward the viewpoint specified by a user is enhanced. This algorithm is useful for avoiding to make decisions based on biased information. Such a problem is pointed out as the filter bubble, which is the inuence in social decisions biased by a personalization technology. To provide such a recommendation, we assume that a user specifies a viewpoint toward which the user want to enforce the neutrality, because recommendation that is neutral from any information is no longer recommendation. Given such a target viewpoint, we implemented information neutral recommendation algorithm by introducing a penalty term to enforce the statistical independence between the target viewpoint and a preference score. We empirically show that our algorithm enhances the independence toward the specified viewpoint by and then demonstrate how sets of recommended items are changed."
"Yang M., Dai Q., Dong Z., Chen X., He X., Wang J.","Top-N Recommendation with Counterfactual User Preference Simulation",2021,"International Conference on Information and Knowledge Management, Proceedings","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119179447&doi=10.1145%2f3459637.3482305&partnerID=40&md5=f518ac1266142da1258c1edd9199eaaa","Top-N recommendation, which aims to learn user ranking-based preference, has long been a fundamental problem in a wide range of applications. Traditional models usually motivate themselves by designing complex or tailored architectures based on different assumptions. However, the training data of recommender system can be extremely sparse and imbalanced, which poses great challenges for boosting the recommendation performance. To alleviate this problem, in this paper, we propose to reformulate the recommendation task within the causal inference framework, which enables us to counterfactually simulate user ranking-based preferences to handle the data scarce problem. The core of our model lies in the counterfactual question: ""what would be the user's decision if the recommended items had been different?''. To answer this question, we firstly formulate the recommendation process with a series of structural equation models (SEMs), whose parameters are optimized based on the observed data. Then, we actively indicate many recommendation lists (called intervention in the causal inference terminology) which are not recorded in the dataset, and simulate user feedback according to the learned SEMs for generating new training samples. Instead of randomly intervening on the recommendation list, we design a learning-based method to discover more informative training samples. Considering that the learned SEMs can be not perfect, we, at last, theoretically analyze the relation between the number of generated samples and the model prediction error, based on which a heuristic method is designed to control the negative effect brought by the prediction error. Extensive experiments are conducted based on both synthetic and real-world datasets to demonstrate the effectiveness of our framework. © 2021 ACM."
"Oosterhuis H.","Computationally Efficient Optimization of Plackett-Luce Ranking Models for Relevance and Fairness",2021,"SIGIR 2021 - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111682866&doi=10.1145%2f3404835.3462830&partnerID=40&md5=ec18a55906816361a911bc1c07ce21e4","Recent work has proposed stochastic Plackett-Luce (PL) ranking models as a robust choice for optimizing relevance and fairness metrics. Unlike their deterministic counterparts that require heuristic optimization algorithms, PL models are fully differentiable. Theoretically, they can be used to optimize ranking metrics via stochastic gradient descent. However, in practice, the computation of the gradient is infeasible because it requires one to iterate over all possible permutations of items. Consequently, actual applications rely on approximating the gradient via sampling techniques. In this paper, we introduce a novel algorithm: PL-Rank, that estimates the gradient of a PL ranking model w.r.t. both relevance and fairness metrics. Unlike existing approaches that are based on policy gradients, PL-Rank makes use of the specific structure of PL models and ranking metrics. Our experimental analysis shows that PL-Rank has a greater sample-efficiency and is computationally less costly than existing policy gradients, resulting in faster convergence at higher performance. PL-Rank further enables the industry to apply PL models for more relevant and fairer real-world ranking systems. © 2021 Owner/Author."
"Sinha A., Gleich D.F., Ramani K.","Deconvolving feedback loops in recommender systems",2016,"Advances in Neural Information Processing Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019246764&partnerID=40&md5=abb290c6d4d111ddf5f3a24748985299","Collaborative filtering is a popular technique to infer users' preferences on new content based on the collective information of all users preferences. Recommender systems then use this information to make personalized suggestions to users. When users accept these recommendations it creates a feedback loop in the recommender system, and these loops iteratively influence the collaborative filtering algorithm's predictions over time. We investigate whether it is possible to identify items affected by these feedback loops. We state sufficient assumptions to deconvolve the feedback loops while keeping the inverse solution tractable. We furthermore develop a metric to unravel the recommender system's influence on the entire user-item rating matrix. We use this metric on synthetic and real-world datasets to (1) identify the extent to which the recommender system affects the final rating matrix, (2) rank frequently recommended items, and (3) distinguish whether a user's rated item was recommended or an intrinsic preference. Our results indicate that it is possible to recover the ratings matrix of intrinsic user preferences using a single snapshot of the ratings matrix without any temporal information. © 2016 NIPS Foundation - All Rights Reserved."
"Jagerman R., Markov I., De Rijke M.","When people change their mind: Off-policy evaluation in non-stationary recommendation environments",2019,"WSDM 2019 - Proceedings of the 12th ACM International Conference on Web Search and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061745088&doi=10.1145%2f3289600.3290958&partnerID=40&md5=cb4ce7e1fbea590c925f47cb1619e7be","We consider the novel problem of evaluating a recommendation policy offline in environments where the reward signal is non-stationary. Non-stationarity appears in many Information Retrieval (IR) applications such as recommendation and advertising, but its effect on off-policy evaluation has not been studied at all. We are the first to address this issue. First, we analyze standard off-policy estimators in non-stationary environments and show both theoretically and experimentally that their bias grows with time. Then, we propose new off-policy estimators with moving averages and show that their bias is independent of time and can be bounded. Furthermore, we provide a method to trade-off bias and variance in a principled way to get an off-policy estimator that works well in both non-stationary and stationary environments. We experiment on publicly available recommendation datasets and show that our newly proposed moving average estimators accurately capture changes in non-stationary environments, while standard off-policy estimators fail to do so. © 2019 held by the owner/author(s). Publication rights licensed to ACM."
"Abdollahpouri H., Mansoury M.","Multi-sided Exposure Bias in Recommendation",2020,"Multi-sided Exposure Bias in Recommendation",,[No abstract available]
"Li S., Muthukrishnan S., Abbasi-Yadkori Y., Vinay V., Kveton B., Wen Z.","Offline evaluation of ranking policies with click models",2018,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051464560&doi=10.1145%2f3219819.3220028&partnerID=40&md5=f3aa787089112b5baccb93ba62b3fd9f","Many web systems rank and present a list of items to users, from recommender systems to search and advertising. An important problem in practice is to evaluate new ranking policies offline and optimize them before they are deployed. We address this problem by proposing evaluation algorithms for estimating the expected number of clicks on ranked lists from historical logged data. The existing algorithms are not guaranteed to be statistically efficient in our problem because the number of recommended lists can grow exponentially with their length. To overcome this challenge, we use models of user interaction with the list of items, the so-called click models, to construct estimators that learn statistically efficiently. We analyze our estimators and prove that they are more efficient than the estimators that do not use the structure of the click model, under the assumption that the click model holds. We evaluate our estimators in a series of experiments on a real-world dataset and show that they consistently outperform prior estimators. © 2018 Association for Computing Machinery."
"O'Brien M., Keane M.T.","Modeling result-list searching in the world wide web: The role of relevance topologies and trust bias",2006,"Proceedings of the 28th Annual Conference of the Cognitive Science Society",,[No abstract available]
"Vardasbi A., De Rijke M., Markov I.","Cascade Model-based Propensity Estimation for Counterfactual Learning to Rank",2020,"SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090164378&doi=10.1145%2f3397271.3401299&partnerID=40&md5=8b9ded5f2e39412cc420559768f96722","Unbiased counterfactual learning to rank (CLTR) requires click propensities to compensate for the difference between user clicks and true relevance of search results via inverse propensity scoring (IPS). Current propensity estimation methods assume that user click behavior follows the position-based click model (PBM) and estimate click propensities based on this assumption. However, in reality, user clicks often follow the cascade model (CM), where users scan search results from top to bottom and where each next click depends on the previous one. In this cascade scenario, PBM-based estimates of propensities are not accurate, which, in turn, hurts CLTR performance. In this paper, we propose a propensity estimation method for the cascade scenario, called cascade model-based inverse propensity scoring (CM-IPS). We show that CM-IPS keeps CLTR performance close to the full-information performance in case the user clicks follow the CM, while PBM-based CLTR has a significant gap towards the full-information. The opposite is true if the user clicks follow PBM instead of the CM. Finally, we suggest a way to select between CM-and PBM-based propensity estimation methods based on historical user clicks. © 2020 ACM."
"Haussler D.","Probably approximately correct learning",1990,"National Conference on Artificial Intelligence",,[No abstract available]
"Chen J., Feng Y., Ester M., Zhou S., Chen C., Wang C.","Modeling users' exposure with social knowledge influence and consumption influence for recommendation",2018,"International Conference on Information and Knowledge Management, Proceedings","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058010986&doi=10.1145%2f3269206.3271742&partnerID=40&md5=9639ba832a80acc3b63b260ba5326b3d","Users' consumption behaviors are affected by both their personal preference and their exposure to items (i.e. whether a user knows the items). Most of the recent works in social recommendation assume that people share similar preference with their socially connected friends. However, this assumption may not hold due to the diversity of social relations, and modeling social influence on users' preference may not be suitable for implicit feedback data (i.e. whether a user has consumed certain items). Since users often share item information with their social relations, it will be less restrictive to model social influence on users' exposure to items. We notice that a user's exposure is affected by the exposure of the other users in his social communities and by the consumption of his connected friends. In this paper, we propose a novel social exposure-based recommendation model SoEXBMF by integrating two kinds of social influence on users' exposure, i.e. social knowledge influence and social consumption influence, into basic EXMF model for better recommendation performance. Furthermore, SoEXBMF uses Bernoulli distribution instead of Gaussian distribution in EXMF to better model the binary implicit feedback data. A variational inference method has been developed for the proposed SoEXBMF model to infer the posterior and make the recommendations. Extensive experiments on three real-world datasets demonstrate the superiority of our method over existing methods in various evaluation metrics. © 2018 Association for Computing Machinery."
"McInerney J., Brost B., Chandar P., Mehrotra R., Carterette B.","Counterfactual Evaluation of Slate Recommendations with Sequential Reward Interactions",2020,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090403335&doi=10.1145%2f3394486.3403229&partnerID=40&md5=2e3ca6e0e71a2389bb7db7965ed07907","Users of music streaming, video streaming, news recommendation, and e-commerce services often engage with content in a sequential manner. Providing and evaluating good sequences of recommendations is therefore a central problem for these services. Prior reweighting-based counterfactual evaluation methods either suffer from high variance or make strong independence assumptions about rewards. We propose a new counterfactual estimator that allows for sequential interactions in the rewards with lower variance in an asymptotically unbiased manner. Our method uses graphical assumptions about the causal relationships of the slate to reweight the rewards in the logging policy in a way that approximates the expected sum of rewards under the target policy. Extensive experiments in simulation and on a live recommender system show that our approach outperforms existing methods in terms of bias and data efficiency for the sequential track recommendations problem. © 2020 ACM."
"Wu Y., Zhang L., Wu X.","On discrimination discovery and removal in ranked data using causal graph",2018,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051505227&doi=10.1145%2f3219819.3220087&partnerID=40&md5=a847f868b4c0679f79f9b09e5a5e2abf","Predictive models learned from historical data are widely used to help companies and organizations make decisions. However, they may digitally unfairly treat unwanted groups, raising concerns about fairness and discrimination. In this paper, we study the fairness-aware ranking problem which aims to discover discrimination in ranked datasets and reconstruct the fair ranking. Existing methods in fairness-aware ranking are mainly based on statistical parity that cannot measure the true discriminatory effect since discrimination is causal. On the other hand, existing methods in causal-based anti-discrimination learning focus on classification problems and cannot be directly applied to handle the ranked data. To address these limitations, we propose to map the rank position to a continuous score variable that represents the qualification of the candidates. Then, we build a causal graph that consists of both the discrete profile attributes and the continuous score. The path-specific effect technique is extended to the mixed-variable causal graph to identify both direct and indirect discrimination. The relationship between the path-specific effects for the ranked data and those for the binary decision is theoretically analyzed. Finally, algorithms for discovering and removing discrimination from a ranked dataset are developed. Experiments using the real-world dataset show the effectiveness of our approaches. © 2018 Association for Computing Machinery."
"Joseph M., Kearns M., Morgenstern J., Neel S., Roth A.",[No title available],2016,"Rawlsian fairness for machine learning",,[No abstract available]
"Yang H., Ling G., Su Y., Lyu M.R., King I.","Boosting Response Aware Model-Based Collaborative Filtering",2015,"IEEE Transactions on Knowledge and Data Engineering","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936877686&doi=10.1109%2fTKDE.2015.2405556&partnerID=40&md5=a012394bc928d379f40acb5e3688c67d","Recommender systems are promising for providing personalized favorite services. Collaborative filtering (CF) technologies, making prediction of users' preference based on users' previous behaviors, have become one of the most successful techniques to build modern recommender systems. Several challenging issues occur in previously proposed CF methods: 1) most CF methods ignore users' response patterns and may yield biased parameter estimation and suboptimal performance; 2) some CF methods adopt heuristic weight settings, which lacks a systematical implementation; and 3) the multinomial mixture models may weaken the computational ability of matrix factorization for generating the data matrix, thus increasing the computational cost of training. To resolve these issues, we incorporate users' response models into the probabilistic matrix factorization (PMF), a popular matrix factorization CF model, to establish the response aware probabilistic matrix factorization (RAPMF) framework. More specifically, we make the assumption on the user response as a Bernoulli distribution which is parameterized by the rating scores for the observed ratings while as a step function for the unobserved ratings. Moreover, we speed up the algorithm by a mini-batch implementation and a crafting scheduling policy. Finally, we design different experimental protocols and conduct systematical empirical evaluation on both synthetic and real-world datasets to demonstrate the merits of the proposed RAPMF and its mini-batch implementation. © 2015 IEEE."
"Kiyohara H., Saito Y., Matsuhiro T., Narita Y., Shimizu N., Yamamoto Y.","Doubly robust off-policy evaluation for ranking policies under the cascade behavior model",2022,"WSDM 2022 - Proceedings of the 15th ACM International Conference on Web Search and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125768357&doi=10.1145%2f3488560.3498380&partnerID=40&md5=5683592aa8fb3bad4d50092732f87267","In real-world recommender systems and search engines, optimizing ranking decisions to present a ranked list of relevant items is critical. Off-policy evaluation (OPE) for ranking policies is thus gaining a growing interest because it enables performance estimation of new ranking policies using only logged data. Although OPE in contextual bandits has been studied extensively, its naive application to the ranking setting faces a critical variance issue due to the huge item space. To tackle this problem, previous studies introduce some assumptions on user behavior to make the combinatorial item space tractable. However, an unrealistic assumption may, in turn, cause serious bias. Therefore, appropriately controlling the bias-variance tradeoff by imposing a reasonable assumption is the key for success in OPE of ranking policies. To achieve a well-balanced bias-variance tradeoff, we propose the Cascade Doubly Robust estimator building on the cascade assumption, which assumes that a user interacts with items sequentially from the top position in a ranking. We show that the proposed estimator is unbiased in more cases compared to existing estimators that make stronger assumptions on user behavior. Furthermore, compared to a previous estimator based on the same cascade assumption, the proposed estimator reduces the variance by leveraging a control variate. Comprehensive experiments on both synthetic and real-world e-commerce data demonstrate that our estimator leads to more accurate OPE than existing estimators in a variety of settings. © 2022 ACM."
"Buyl M., De Bie T.","Debayes: a bayesian method for debiasing network embeddings",2020,"International Conference on Machine Learning",,[No abstract available]
"Qin Z., Chen S.J., Metzler D., Noh Y., Qin J., Wang X.","Attribute-based Propensity for Unbiased Learning in Recommender Systems: Algorithm and Case Studies",2020,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090414680&doi=10.1145%2f3394486.3403285&partnerID=40&md5=28fe01cf5fd8d69629bfa7bb4b992fe1","Many modern recommender systems train their models based on a large amount of implicit user feedback data. Due to the inherent bias in this data (e.g., position bias), learning from it directly can lead to suboptimal models. Recently, unbiased learning was proposed to address such problems by leveraging counterfactual techniques like inverse propensity weighting (IPW). In these methods, propensity scores estimation is usually limited to item's display position in a single user interface (UI). In this paper, we generalize the traditional position bias model to an attribute-based propensity framework. Our methods estimate propensity scores based on offline data and allow propensity estimation across a broad range of implicit feedback scenarios, e.g., feedback beyond recommender system UI. We demonstrate this by applying this framework to three real-world large-scale recommender systems in Google Drive that serve millions of users. For each system, we conduct both offline and online evaluation. Our results show that the proposed framework is able to significantly improve upon strong production baselines across a diverse range of recommendation item types (documents, people-document pairs, and queries), UI layouts (horizontal, vertical, and grid layouts), and underlying learning algorithms (gradient boosted decision trees and neural networks), all without the need to intervene and degrade the user experience. The proposed models have been deployed in the production systems with ease since no serving infrastructure change is needed. © 2020 Owner/Author."
"Wasilewski J., Hurley N.","Incorporating diversity in a learning to rank recommender system",2016,"Proceedings of the 29th International Florida Artificial Intelligence Research Society Conference, FLAIRS 2016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85004109091&partnerID=40&md5=47e3acafbc18287c899c38bd112ff850","Regularisation is typically applied to the optimisation objective of matrix factorisation methods in order to avoid over-fitting. In this paper, we explore the use of regularisation to enhance the diversity of the recommendations produced by these methods. Given a matrix of pairwise item distances, we add regularisation terms dependent on the item distances to the accuracy objective of a learning to rank matrix factorisation formulation. We examine the impact of these regularisers on the latent factors produced by the algorithm and show that such regularisation does indeed promote diversity. The regularisation comes at a cost of performance in terms of accuracy and ultimately the approach cannot greatly enhance diversity without a consequent fall-off in accuracy. Copyright © 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All right reserved."
"Lin J., Liu W., Dai X., Zhang W., Li S., Tang R., He X., Hao J., Yu Y.","A Graph-Enhanced Click Model for Web Search",2021,"SIGIR 2021 - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111704709&doi=10.1145%2f3404835.3462895&partnerID=40&md5=cbe3d2a8df2b91e8de8e64bd6f0c1486","To better exploit search logs and model users' behavior patterns, numerous click models are proposed to extract users' implicit interaction feedback. Most traditional click models are based on the probabilistic graphical model (PGM) framework, which requires manually designed dependencies and may oversimplify user behaviors. Recently, methods based on neural networks are proposed to improve the prediction accuracy of user behaviors by enhancing the expressive ability and allowing flexible dependencies. However, they still suffer from the data sparsity and cold-start problems. In this paper, we propose a novel graph-enhanced click model (GraphCM) for web search. Firstly, we regard each query or document as a vertex, and propose novel homogeneous graph construction methods for queries and documents respectively, to fully exploit both intra-session and inter-session information for the sparsity and cold-start problems. Secondly, following the examination hypothesis, we separately model the attractiveness estimator and examination predictor to output the attractiveness scores and examination probabilities, where graph neural networks and neighbor interaction techniques are applied to extract the auxiliary information encoded in the pre-constructed homogeneous graphs. Finally, we apply combination functions to integrate examination probabilities and attractiveness scores into click predictions. Extensive experiments conducted on three real-world session datasets show that GraphCM not only outperforms the state-of-art models, but also achieves superior performance in addressing the data sparsity and cold-start problems. © 2021 ACM."
"Yao S., Huang B.","New fairness metrics for recommendation that embrace differences",2017,"New Fairness Metrics for Recommendation That Embrace Differences",,[No abstract available]
"Zhu Z., He Y., Zhang Y., Caverlee J.","Unbiased Implicit Recommendation and Propensity Estimation via Combinational Joint Learning",2020,"RecSys 2020 - 14th ACM Conference on Recommender Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092690634&doi=10.1145%2f3383313.3412210&partnerID=40&md5=537aad42b99f5a7bad5278547535f1f0","This paper focuses on how to generate unbiased recommendations based on biased implicit user-item interactions. We propose a combinational joint learning framework to simultaneously learn unbiased user-item relevance and unbiased propensity. More specifically, we first present a new unbiased objective function for estimating propensity. We then show how a naïve joint learning approach faces an estimation-training overlap problem. Hence, we propose to jointly train multiple sub-models from different parts of the training dataset to avoid this problem. Finally, we show how to incorporate residual components trained by the complete training data to complement the relevance and propensity sub-models. Extensive experiments on two public datasets demonstrate the effectiveness of the proposed model with an improvement of 4% on average over the best alternatives. © 2020 ACM."
"Yadav H., Du Z., Joachims T.","Policy-Gradient Training of Fair and Unbiased Ranking Functions",2021,"SIGIR 2021 - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111669181&doi=10.1145%2f3404835.3462953&partnerID=40&md5=92ba8182aea0e1157313a8b1f124c200","While implicit feedback (e.g., clicks, dwell times, etc.) is an abundant and attractive source of data for learning to rank, it can produce unfair ranking policies for both exogenous and endogenous reasons. Exogenous reasons typically manifest themselves as biases in the training data, which then get reflected in the learned ranking policy and often lead to rich-get-richer dynamics. Moreover, even after the correction of such biases, reasons endogenous to the design of the learning algorithm can still lead to ranking policies that do not allocate exposure among items in a fair way. To address both exogenous and endogenous sources of unfairness, we present the first learning-to-rank approach that addresses both presentation bias and merit-based fairness of exposure simultaneously. Specifically, we define a class of amortized fairness-of-exposure constraints that can be chosen based on the needs of an application, and we show how these fairness criteria can be enforced despite the selection biases in implicit feedback data. The key result is an efficient and flexible policy-gradient algorithm, called FULTR, which is the first to enable the use of counterfactual estimators for both utility estimation and fairness constraints. Beyond the theoretical justification of the framework, we show empirically that the proposed algorithm can learn accurate and fair ranking policies from biased and noisy feedback. © 2021 ACM."
"Li R.Z., Urbano J., Hanjalic A.","Leave No User Behind: Towards Improving the Utility of Recommender Systems for Non-mainstream Users",2021,"WSDM 2021 - Proceedings of the 14th ACM International Conference on Web Search and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103045319&doi=10.1145%2f3437963.3441769&partnerID=40&md5=0f386514e931bbe714c6a4d503a1bff3","In a collaborative-filtering recommendation scenario, biases in the data will likely propagate in the learned recommendations. In this paper we focus on the so-called mainstream bias: the tendency of a recommender system to provide better recommendations to users who have a mainstream taste, as opposed to non-mainstream users. We propose NAECF, a conceptually simple but effective idea to address this bias. The idea consists of adding an autoencoder (AE) layer when learning user and item representations with text-based Convolutional Neural Networks. The AEs, one for the users and one for the items, serve as adversaries to the process of minimizing the rating prediction error when learning how to recommend. They enforce that the specific unique properties of all users and items are sufficiently well incorporated and preserved in the learned representations. These representations, extracted as the bottlenecks of the corresponding AEs, are expected to be less biased towards mainstream users, and to provide more balanced recommendation utility across all users. Our experimental results confirm these expectations, significantly improving the recommendations for non-mainstream users while maintaining the recommendation quality for mainstream users. Our results emphasize the importance of deploying extensive content-based features, such as online reviews, in order to better represent users and items to maximize the de-biasing effect. © 2021 Owner/Author."
"Saito Y.","Unbiased Pairwise Learning from Biased Implicit Feedback",2020,"ICTIR 2020 - Proceedings of the 2020 ACM SIGIR International Conference on Theory of Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093109099&doi=10.1145%2f3409256.3409812&partnerID=40&md5=b099df5a94d4547e6f7eca676f91eb12","Implicit feedback is prevalent in real-world scenarios and is widely used in the construction of recommender systems. However, the application of implicit feedback data is much more complicated than its explicit counterpart because it provides only positive feedback, and we cannot know whether the non-interacted feedback is positive or negative. Furthermore, positive feedback for rare items is observed less frequently than popular items. The relevance of such rare items is often underestimated. Existing solutions to such challenges are subject to bias toward the ideal loss function of interest or accept a simple pointwise approach, which is inappropriate for a ranking task. In this study, we first define an ideal pairwise loss function defined using the ground-truth relevance parameters that should be used to optimize the ranking metrics. Subsequently, we propose a theoretically grounded unbiased estimator for this ideal pairwise loss and a corresponding algorithm, Unbiased Bayesian Personalized Ranking. A pairwise algorithm addressing the two major difficulties in using implicit feedback has yet to be investigated, and the proposed algorithm is the first pairwise method for solving these challenges in a theoretically principal manner. Through theoretical analysis, we provide the critical statistical properties of the proposed unbiased estimator and a practical variance reduction technique. Empirical evaluations using real-world datasets demonstrate the practical strength of our approach. © 2020 ACM."
"Chen J., Wang C., Ester M., Shi Q., Feng Y., Chen C.","Social Recommendation with Missing Not at Random Data",2018,"Proceedings - IEEE International Conference on Data Mining, ICDM","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061347504&doi=10.1109%2fICDM.2018.00018&partnerID=40&md5=f3f0969a7d41f16f4208a6818b281aef","With the explosive growth of online social networks, many social recommendation methods have been proposed and demonstrated that social information has potential to improve the recommendation performance. However, existing social recommendation methods always assume that the data is missing at random (MAR) but this is rarely the case. In fact, by analysing two real-world social recommendation datasets, we observed the following interesting phenomena: (1) users tend to consume and rate the items that they like and the items that have been consumed by their friends. (2) When the items have been consumed by more friends, the average values of the observed ratings will become smaller, not larger as assumed by the existing models. To model these phenomena, we integrate the missing not at random (MNAR) assumption in social recommendation and propose a new social recommendation method SPMF-MNAR, which models the observation process of rating data based on user's preference and social influence. Extensive experiments conducted on large real-world datasets validate that SPMF-MNAR achieves better performance than existing social recommendation methods and the non-social methods based on MNAR assumption. © 2018 IEEE."
"Kamishima T., Akaho S., Asoh H., Sakuma J.","Correcting popularity bias by enhancing recommendation neutrality",2014,"Poster Proceedings of the 8th ACM Conference on Recommender Systems, RecSys 2014",,[No abstract available]
"Guo R., Zhao X., Henderson A., Hong L., Liu H.","Debiasing Grid-based Product Search in E-commerce",2020,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090401435&doi=10.1145%2f3394486.3403336&partnerID=40&md5=5783dea641ecc7b8069903b47ae409b0","The widespread usage of e-commerce websites in daily life and the resulting wealth of implicit feedback data form the foundation for systems that train and test e-commerce search ranking algorithms. While convenient to collect, implicit feedback data inherently suffers from various types of bias since user feedback is limited to products they are exposed to by existing search ranking algorithms and impacted by how the products are displayed. In the literature, a vast majority of existing methods have been proposed towards unbiased learning to rank for list-based web search scenarios. However, such methods cannot be directly adopted by e-commerce websites mainly for two reasons. First, in e-commerce websites, search engine results pages (SERPs) are displayed in 2-dimensional grids. The existing methods have not considered the difference in user behavior between list-based web search and grid-based product search. Second, there can be multiple types of implicit feedback (e.g., clicks and purchases) on e-commerce websites. We aim to utilize all types of implicit feedback as the supervision signals. In this work, we extend unbiased learning to rank to the world of e-commerce search via considering a grid-based product search scenario. We propose a novel framework which (1) forms the theoretical foundations to allow multiple types of implicit feedback in unbiased learning to rank and (2) incorporates the row skipping and slower decay click models to capture unique user behavior patterns in grid-based product search for inverse propensity scoring. Through extensive experiments on real-world e-commerce search log datasets across browsing devices and product taxonomies, we show that the proposed framework outperforms the state of the art unbiased learning to rank algorithms. These results also reveal important insights on how user behavior patterns vary in e-commerce SERPs across browsing devices and product taxonomies. © 2020 ACM."
"Wang X., Hoi S.C.H., Liu C., Ester M.","Interactive social recommendation",2017,"International Conference on Information and Knowledge Management, Proceedings","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037361834&doi=10.1145%2f3132847.3132880&partnerID=40&md5=0ed734c2956a1939fa305af25176bf60","Social recommendation has been an active research topic over the last decade, based on the assumption that social information from friendship networks is beneficial for improving recommendation accuracy, especially when dealing with cold-start users who lack sufficient past behavior information for accurate recommendation. However, it is nontrivial to use such information, since some of a person's friends may share similar preferences in certain aspects, but others may be totally irrelevant for recommendations. .us one challenge is to explore and exploit the extend to which a user trusts his/her friends when utilizing social information to improve recommendations. On the other hand, most existing social recommendation models are non-interactive in that their algorithmic strategies are based on batch learning methodology, which learns to train the model in an offine manner from a collection of training data which are accumulated from usersfi historical interactions with the recommender systems. In the real world, new users may leave the systems for the reason of being recommended with boring items before enough data is collected for training a good model, which results in an inefficient customer retention. To tackle these challenges, we propose a novel method for interactive social recommendation, which not only simultaneously explores user preferences and exploits the effectiveness of personalization in an interactive way,but also adaptively learns different weights for different friends. In addition, we also give analyses on the complexity and regret of the proposed model. Extensive experiments on three real-world datasets illustrate the improvement of our proposed method against the state-of-the-art algorithms. © 2017 ACM."
"Kamishima T., Akaho S., Asoh H., Sakuma J.","Efficiency improvement of neutrality-enhanced recommendation",2013,"CEUR Workshop Proceedings","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924995114&partnerID=40&md5=3d7edb81f9b00ba67ca07fd04ef7d15f","This paper proposes an algorithm for making recommendations so that neutrality from a viewpoint specified by the user is enhanced. This algorithm is useful for avoiding decisions based on biased information. Such a problem is pointed out as the filter bubble, which is the influence in social decisions biased by personalization technologies. To provide a neutrality-enhanced recommendation, we must first assume that a user can specify a particular viewpoint from which the neutrality can be applied, because a recommendation that is neutral from all viewpoints is no longer a recommendation. Given such a target viewpoint, we implement an information-neutral recommendation algorithm by introducing a penalty term to enforce statistical independence between the target viewpoint and a rating. We empirically show that our algorithm enhances the independence from the specified viewpoint. Copyright © 2013 for the individual papers by the papers' authors."
"Chen J., Wang X., Feng F., He X.","Bias issues and solutions in recommender system: Tutorial on the RecSys 2021",2021,"RecSys 2021 - 15th ACM Conference on Recommender Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115649852&doi=10.1145%2f3460231.3473321&partnerID=40&md5=b78c36570e1fdd01b9b60502ff1e72e1","Recommender systems (RS) have demonstrated great success in information seeking. Recent years have witnessed a large number of work on inventing recommendation models to better fit user behavior data. However, user behavior data is observational rather than experimental. This makes various biases widely exist in the data, including but not limited to selection bias, position bias, exposure bias. Blindly fitting the data without considering the inherent biases will result in many serious issues, e.g., the discrepancy between offline evaluation and online metrics, hurting user satisfaction and trust on the recommendation service, etc. To transform the large volume of research models into practical improvements, it is highly urgent to explore the impacts of the biases and develop debiasing strategies when necessary. Therefore, bias issues and solutions in recommender systems have drawn great attention from both academic and industry. In this tutorial, we aim to provide an systemic review of existing work on this topic. We will introduce six types of biases in recommender system, along with their definitions and characteristics; review existing debiasing solutions, along with their strengths and weaknesses; and identify some open challenges and future directions. We hope this tutorial could stimulate more ideas on this topic and facilitate the development of debiasing recommender systems. © 2021 ACM."
"Wang T., Wang D.","Why Amazon's ratings might mislead you: The story of herding effects",2014,"Big Data","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991806460&doi=10.1089%2fbig.2014.0063&partnerID=40&md5=0fe4c850e03e17466a989fa384a0bb38","Our society is increasingly relying on digitalized, aggregated opinions of individuals to make decisions (e.g., product recommendation based on collective ratings). One key requirement of harnessing this ""wisdom of crowd"" is the independency of individuals' opinions; yet, in real settings, collective opinions are rarely simple aggregations of independent minds. Recent experimental studies document that disclosing prior collective ratings distorts individuals' decision making as well as their perceptions of quality and value, highlighting a fundamental discrepancy between our perceived values from collective ratings and products' intrinsic values. Here we present a mechanistic framework to describe herding effects of prior collective ratings on subsequent individual decision making. Using large-scale longitudinal customer rating datasets, we find that our method successfully captures the dynamics of ratings growth, helping us separate social influence bias from inherent values. Leveraging the proposed framework, we quantitatively characterize the herding effects existing in product rating systems and promote strategies to untangle manipulations and social biases. © Mary Ann Liebert, Inc. 2014."
"Kim Y.-D., Choi S.","Bayesian binomial mixture model for collaborative prediction with non-random missing data",2014,"RecSys 2014 - Proceedings of the 8th ACM Conference on Recommender Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908872181&doi=10.1145%2f2645710.2645754&partnerID=40&md5=0f22a9a34bdde10bb8e94929a8d7a8fe","Collaborative prediction involves filling in missing entries of a useritem matrix to predict preferences of users based on their observed preferences. Most of existing models assume that the data is missing at random (MAR), which is often violated in recommender systems in practice. Incorrect assumption on missing data ignores the missing data mechanism, leading to biased inferences and prediction. In this paper we present a Bayesian binomial mixture model for collaborative prediction, where the generative process for data and missing data mechanism are jointly modeled to handle nonrandom missing data. Missing data mechanism is modeled by three factors, each of which is related to users, items, and rating values. Each factor is modeled by Bernoulli random variable, and the observation of rating value is determined by the Boolean OR operation of three binary variables. We develop computationallyefficient variational inference algorithms, where variational parameters have closed-form update rules and the computational complexity depends on the number of observed ratings, instead of the size of the rating data matrix. We also discuss implementation issues on hyperparameter tuning and estimation based on empirical Bayes. Experiments on Yahoo! Music and MovieLens datasets confirm the useful behavior of our model by demonstrating that: (1) it outperforms state-of-the-art methods in yielding higher predictive performance; (2) it finds meaningful solutions instead of undesirable boundary solutions; (3) it provides rating trend analysis on why ratings are observed. Copyright © 2014 ACM."
"Collins A., Tkaczyk D., Aizawa A., Beel J.",[No title available],2018,"A Study of Position Bias in Digital Library Recommender Systems",,[No abstract available]
"Yu J., Zhu H., Chang C.-Y., Feng X., Yuan B., He X., Dong Z.","Influence Function for Unbiased Recommendation",2020,"SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090125344&doi=10.1145%2f3397271.3401321&partnerID=40&md5=d7fe07be67d91186e4cd01878602714d","Recommender system is one of the most successful machine learning technologies for commerce. However, it can reinforce the closed feedback loop problem, where the recommender system generates items to users, then the further recommendation model is trained with the data that users' feedback to the items. Such self-reinforcing pattern can cause data bias problems. There are several debiasing methods, inverse-propensity-scoring (IPS) is a practical one for industry product. Since it is relatively easy to reweight training samples, and ameliorate the distribution shift problem. However,because of deterministic policy problem and confoundings in real-world data, it is hard to predict propensity score accurately. Inspired by the sample reweight work for robust deep learning, we propose a novel influence function based method for recommendation modeling, and analyze how the influence function corrects the bias. In the experiments, our proposed method achieves better performance against the state-of-the-art approaches. © 2020 ACM."
"Mansoury M., Abdollahpouri H., Pechenizkiy M., Mobasher B., Burke R.",[No title available],2020,"Feedback Loop and Bias Amplification in Recommender Systems",,[No abstract available]
"Farnadi Golnoosh, Kouki Pigi, Thompson Spencer K., Srinivasan Sriram, Getoor Lise",[No title available],2018,"A Fairness-aware Hybrid Recommender System",,[No abstract available]
"Bao W., Wen H., Li S., Liu X.-Y., Lin Q., Yang K.","GMCM: Graph-based Micro-behavior Conversion Model for Post-click Conversion Rate Estimation",2020,"SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090118999&doi=10.1145%2f3397271.3401425&partnerID=40&md5=16e692cd8736745e6a615cfd05f75d6b","Purchase-related micro-behaviors, e.g., favorite, add to cart, read reviews, etc., provide implicit feedback of users' decision-making process. Such informative feedback can lead to fine-grained post-click conversion rate (CVR) modeling of the buying process. However, most existing works on CVR estimation either neglect these informative feedback, or model them as a sequential pattern with Recurrent Neural Networks. We argue such modeling could be inappropriate since different orders of micro-behaviors may represent similar user buying intention, and micro-behaviors often correlate with each other. To this end, we propose to represent user micro-behaviors as a Purchase-related Micro-behavior Graph (PMG). Specifically, each node stands for one micro-behavior, and edge weights denote the connection strength. Based on this graph representation, we frame CVR estimation as a graph classification problem over the PMG instances. We propose a novel CVR model, namely, Graph-based Micro-behavior Conversion Model (GMCM), that utilizes Graph Convolutional networks (GCN) to enhance the conventional CVR modeling. In addition, we adopt multi-task learning and inverse propensity weighting to tackle two well-recognized issues in CVR estimation: data sparsity and sample selection bias. Extensive experiments on six large-scale production datasets demonstrate that the proposed methods outperform the state-of-the-art CVR methods under industrial setting. © 2020 ACM."
"Kamishima T., Akaho S., Asoh H., Sato I.","Model-Based Approaches for Independence-Enhanced Recommendation",2016,"IEEE International Conference on Data Mining Workshops, ICDMW","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015179218&doi=10.1109%2fICDMW.2016.0127&partnerID=40&md5=82798405bc5b29311bf768c711aa2fc8","This paper studies a new approach to enhance recommendation independence. Such approaches are useful in ensuring adherence to laws and regulations, fair treatment of content providers, and exclusion of unwanted information. For example, recommendations that match an employer with a job applicant should not be based on socially sensitive information, such as gender or race, from the perspective of social fairness. An algorithm that could exclude the influence of such sensitive information would be useful in this case. We previously gave a formal definition of recommendation independence and proposed a method adopting a regularizer that imposes such an independence constraint. As no other options than this regularization approach have been put forward, we here propose a new model-based approach, which is based on a generative model that satisfies the constraint of recommendation independence. We apply this approach to a latent class model and empirically show that the model-based approach can enhance recommendation independence. Recommendation algorithms based on generative models, such as topic models, are important, because they have a flexible functionality that enables them to incorporate a wide variety of information types. Our new model-based approach will broaden the applications of independence-enhanced recommendation by integrating the functionality of generative models. © 2016 IEEE."
"Wang N., Qin Z., Wang X., Wang H.","Non-Clicks Mean Irrelevant? Propensity Ratio Scoring As a Correction",2021,"WSDM 2021 - Proceedings of the 14th ACM International Conference on Web Search and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103043721&doi=10.1145%2f3437963.3441798&partnerID=40&md5=647c56a2aa3caa5a3e50ebc16439e043","Recent advances in unbiased learning to rank (LTR) count on Inverse Propensity Scoring (IPS) to eliminate bias in implicit feedback. Though theoretically sound in correcting the bias introduced by treating clicked documents as relevant, IPS ignores the bias caused by (implicitly) treating non-clicked ones as irrelevant. In this work, we first rigorously prove that such use of click data leads to unnecessary pairwise comparisons between relevant documents, which prevent unbiased ranker optimization. Based on the proof, we derive a simple yet well justified new weighting scheme, called Propensity Ratio Scoring (PRS), which provides treatments on both clicks and non-clicks. Besides correcting the bias in clicks, PRS avoids relevant-relevant document comparisons in LTR training and enjoys a lower variability. Our extensive empirical evaluations confirm that PRS ensures a more effective use of click data and improved performance in both synthetic data from a set of LTR benchmarks, as well as in the real-world large-scale data from GMail search. © 2021 Owner/Author."
"Chen M., Liu C., Sun J., Hoi S.C.H.","Adapting Interactional Observation Embedding for Counterfactual Learning to Rank",2021,"SIGIR 2021 - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111684159&doi=10.1145%2f3404835.3462901&partnerID=40&md5=a94fc78900d8d20a3abf824ea59ca2f6","Counterfactual Learning to Rank (CLTR) becomes an attractive research topic due to its capability of training ranker with click logs. However, CLTR inherently suffers from a large amount of bias caused by confounders, variables that affect both the observation (examination) behavior and click behavior. Recent efforts to correct bias mostly focus on position bias, which assumes that each observation in a ranking list is isolated and only depends on the position. Though effective, users often engage with documents in an interactive manner. Ignoring the interactions between observations/clicks would incur a large interactional observation bias no matter how much data is collected. In this work, we leverage the embedding method to develop an Interactional Observation-Based Model (IOBM) to estimate the observation probability. We argue that while there exist complex observed and unobserved confounders for observation/click interactions, it is sufficient to use the embedding as a proxy confounder to uncover the relevant information for the prediction of the observation propensity. Moreover, the embedding could offer an alternative to the fully specified generative model for observation and decouples the complex interaction structure of observations/clicks. In our IOBM, we first learn the individual observation embedding to capture position and click information. Then, we learn the interactional observation embedding to uncover their local interaction structure. To filter out irrelevant information and reduce contextual bias, we utilize query context information and propose the intra-observation attention and the inter-observation attention, respectively. We conduct extensive experiments on two LTR benchmark datasets, demonstrating that the proposed IOBM consistently achieves better performance over the baseline models in various click situations and verifying its effectiveness of eliminating interactional observation bias. © 2021 ACM."
"Kamishima T., Akaho S.","Considerations on recommendation independence for a find-good-items task",2017,"Workshop on Responsible Recommendation",,[No abstract available]
"Bressan M., Leucci S., Panconesi A., Raghavan P., Terolli E.","The limits of popularity-based recommendations, and the role of social ties",2016,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984945114&doi=10.1145%2f2939672.2939797&partnerID=40&md5=56162e9ab7d02596628ae636b7972306","In this paper we introduce a mathematical model that captures some of the salient features of recommender systems that are based on popularity and that try to exploit social ties among the users. We show that, under very general conditions, the market always converges to a steady state, for which we are able to give an explicit form. Thanks to this we can tell rather precisely how much a market is altered by a recommendation system, and determine the power of users to influence others. Our theoretical results are complemented by experiments with real world social networks showing that social graphs prevent large market distortions in spite of the presence of highly influential users. © 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM."
"Jeunen O., Rohde D., Vasile F., Bompaire M.","Joint Policy-Value Learning for Recommendation",2020,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090411680&doi=10.1145%2f3394486.3403175&partnerID=40&md5=fccfe0a9f62f33a40f26cacd23657fa8","Conventional approaches to recommendation often do not explicitly take into account information on previously shown recommendations and their recorded responses. One reason is that, since we do not know the outcome of actions the system did not take, learning directly from such logs is not a straightforward task. Several methods for off-policy or counterfactual learning have been proposed in recent years, but their efficacy for the recommendation task remains understudied. Due to the limitations of offline datasets and the lack of access of most academic researchers to online experiments, this is a non-trivial task. Simulation environments can provide a reproducible solution to this problem. In this work, we conduct the first broad empirical study of counterfactual learning methods for recommendation, in a simulated environment. We consider various different policy-based methods that make use of the Inverse Propensity Score (IPS) to perform Counterfactual Risk Minimisation (CRM), as well as value-based methods based on Maximum Likelihood Estimation (MLE). We highlight how existing off-policy learning methods fail due to stochastic and sparse rewards, and show how a logarithmic variant of the traditional IPS estimator can solve these issues, whilst convexifying the objective and thus facilitating its optimisation. Additionally, under certain assumptions the value- and policy-based methods have an identical parameterisation, allowing us to propose a new model that combines both the MLE and CRM objectives. Extensive experiments show that this ""Dual Bandit"" approach achieves state-of-the-art performance in a wide range of scenarios, for varying logging policies, action spaces and training sample sizes. © 2020 ACM."
"Wang N., Chen L.","User bias in beyond-accuracy measurement of recommendation algorithms",2021,"RecSys 2021 - 15th ACM Conference on Recommender Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115631874&doi=10.1145%2f3460231.3474244&partnerID=40&md5=c08466be0c2f36bd0362696636fb7fea","There are various biases in recommender systems. Recognizing biases, as well as unfairness caused by problematic biases, is the first step of system optimization. Related studies on algorithmic biases are mainly from the perspective of either items or users. For the latter (we call it ""algorithmic user bias""), existing works have considered algorithms' accuracy performances measured by accuracy metrics like RMSE. However, algorithmic user biases in beyond-accuracy measurements have rarely been studied, even though beyond-accuracy oriented recommendation algorithms have been increasingly investigated, with the purpose of breaking through the personalization limits of traditional accuracy-oriented algorithms (such as the typical ""filter bubble""phenomenon). To fill in the research gap, in this work, we employ a large-scale survey dataset collected from a commercial platform, in which more than 11,000 users' ratings on the recommendation's 5 performance objectives (i.e., relevance, diversity, novelty, unexpectedness, and serendipity) and 8 kinds of user characteristics (i.e., gender, age, big-5 personality traits, and curiosity) are available. We study user biases of four algorithms (i.e., HOT, Rel-CF, Nov-CF, and Ser-CF) in terms of those five measurements between user groups of the eight user characteristics. We further look into users' behavior patterns like the preference of using more positive ratings, in order to interpret the observed biases. Finally, based on the observed algorithmic user bias and users' behavior patterns, we analyze the possible factors leading to the biases and recognize problematic biases that may lead to unfairness. © 2021 ACM."
"Rosenfeld N., Mansour Y., Yom-Tov E.","Predicting counterfactuals from large historical data and small randomized trials",2017,"26th International World Wide Web Conference 2017, WWW 2017 Companion","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050202820&doi=10.1145%2f3041021.3054190&partnerID=40&md5=f3c43c576614d7604845bb6199c8e38d","When a new treatment is considered for use, whether a pharmaceutical drug or a search engine ranking algorithm, a typical question that arises is, will its performance exceed that of the current treatment? The conventional way to answer this counterfactual question is to estimate the effect of the new treatment in comparison to that of the conventional treatment by running a controlled, randomized experiment. While this approach theoretically ensures an unbiased estimator, it suffers from several drawbacks, including the difficulty in finding representative experimental populations as well as the cost of running randomized trials. Moreover, such trials neglect the huge quantities of available control-condition data, which in principle can be utilized for the harder task of predicting individualized effects. In this paper we propose a discriminative framework for predicting the outcomes of a new treatment from a large dataset of the control condition and data from a small (and possibly unrepresentative) randomized trial comparing new and old treatments. Our learning objective, which requires minimal assumptions on the treatments, models the relation between the outcomes of the different conditions. This allows us to not only estimate mean effects but also to generate individual predictions for examples outside the small randomized sample. We demonstrate the utility of our approach through experiments in three areas: search engine operation, treatments to diabetes patients, and market value estimation of houses. Our results demonstrate that our approach can reduce the number and size of the currently performed randomized controlled experiments, thus saving significant time, money and effort on the part of practitioners. © 2017 International World Wide Web Conference Committee (IW3C2), published under Creative Commons CC BY 4.0 License."
"Zhu Z., Caverlee J.","Fighting mainstream bias in recommender systems via local fine tuning",2022,"WSDM 2022 - Proceedings of the 15th ACM International Conference on Web Search and Data Mining","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125811612&doi=10.1145%2f3488560.3498427&partnerID=40&md5=8a2e686f517af3e3165c2a10dd72faf8","In collaborative filtering, the quality of recommendations critically relies on how easily a model can find similar users for a target user. Hence, a niche user who prefers items out of the mainstream may receive poor recommendations, while a mainstream user sharing interests with many others will likely receive recommendations of higher quality. In this work, we study this mainstream bias centering around three key thrusts. First, to distinguish mainstream and niche users, we explore four approaches based on outlier detection techniques to identify a mainstream score indicating the mainstream level for each user. Second, we empirically show that severe mainstream bias is produced by conventional recommendation models. Last, we explore both global and local methods to mitigate the bias. Concretely, we propose two global models: Distribution Calibration (DC) and Weighted Loss (WL) methods; and one local method: Local Fine Tuning (LFT) method. Extensive experiments show the effectiveness of the proposed methods to improve utility for niche users and also show that the proposed LFT can improve the utility for mainstream users at the same time. © 2022 ACM."
"del Barrio E., Gordaliza P., Loubes J.-M.",[No title available],2020,"Review of Mathematical frameworks for Fairness in Machine Learning",,[No abstract available]
"Ovaisi Z., Vasilaky K., Zheleva E.","Propensity-Independent Bias Recovery in Offline Learning-to-Rank Systems",2021,"SIGIR 2021 - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111696047&doi=10.1145%2f3404835.3463097&partnerID=40&md5=5f10e260c897673d33dcdde23f2fa762","Learning-to-rank systems often utilize user-item interaction data (e.g., clicks) to provide users with high-quality rankings. However, this data suffers from several biases, and if naively used as training data, it can lead to suboptimal ranking algorithms. Most existing bias-correcting methods focus on position bias, the fact that higher-ranked results are more likely to receive interaction, and address this bias by leveraging inverse propensity weighting. However, it is not always possible to accurately estimate propensity scores, and in addition to position bias, selection bias is often encountered in real-world recommender systems. Selection bias occurs because users are exposed to a truncated list of results, which gives a zero chance for some items to be observed and, therefore, interacted with, even if they are relevant. Here, we propose a new counterfactual method that uses a two-stage correction approach and jointly addresses selection and position bias in learning-to-rank systems without relying on propensity scores. Our experimental results show that our method is better than state-of-the-art propensity-independent methods and either better than or comparable to methods that make the strong assumption for which the propensity model is known. © 2021 ACM."
"Xu Shuyuan, Tan Juntao, Heinecke Shelby, Li Jia, Zhang Yongfeng",[No title available],2021,"Deconfounded Causal Collaborative Filtering",,[No abstract available]
"Zhang X., Liu M.",[No title available],2020,"Fairness in Learning-Based Sequential Decision Algorithms: A Survey",,[No abstract available]
"Raman K., Joachims T.","Learning socially optimal information systems from egoistic users",2013,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886455225&doi=10.1007%2f978-3-642-40991-2_9&partnerID=40&md5=790e8f57a0a0c20a53b36101cbc6ef96","Many information systems aim to present results that maximize the collective satisfaction of the user population. The product search of an online store, for example, needs to present an appropriately diverse set of products to best satisfy the different tastes and needs of its user population. To address this problem, we propose two algorithms that can exploit observable user actions (e.g. clicks) to learn how to compose diverse sets (and rankings) that optimize expected utility over a distribution of utility functions. A key challenge is that individual users evaluate and act according to their own utility function, but that the system aims to optimize collective satisfaction. We characterize the behavior of our algorithms by providing upper bounds on the social regret for a class of submodular utility functions in the coactive learning model. Furthermore, we empirically demonstrate the efficacy and robustness of the proposed algorithms for the problem of search result diversification. © 2013 Springer-Verlag."
"Schnabel T., Bennett P.N.","Debiasing Item-to-Item Recommendations with Small Annotated Datasets",2020,"RecSys 2020 - 14th ACM Conference on Recommender Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092731701&doi=10.1145%2f3383313.3412265&partnerID=40&md5=8e18dee556cf7f058ce6e0ef9604caa1","Item-to-item recommendation (e.g., ""People who like this also like..."") is a ubiquitous and important type of recommendation in real-world systems. Observational data from historical interaction logs abound in these settings. However, since virtually all observational data exhibit biases, such as time-in-inventory or interface biases, it is crucial that recommender algorithms account for these biases. In this paper, we develop a principled approach for item-to-item recommendation based on causal inference and present a practical and highly effective method for estimating the causal parameters from a small annotated dataset. Empirically, we find that our approach substantially improves upon existing methods while requiring only small amounts of annotated data. © 2020 ACM."
"Lederrey G., West R.","When sheep shop: Measuring herding effects in product ratings with natural experiments",2018,"The Web Conference 2018 - Proceedings of the World Wide Web Conference, WWW 2018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066916849&doi=10.1145%2f3178876.3186160&partnerID=40&md5=da823bc969b8f68107b596bddda8f701","As online shopping becomes ever more prevalent, customers rely increasingly on product rating websites for making purchase decisions. The reliability of online ratings, however, is potentially compromised by the so-called herding effect: when rating a product, customers may be biased to follow other customers' previous ratings of the same product. This is problematic because it skews long-term customer perception through haphazard early ratings. The study of herding poses methodological challenges. In particular, observational studies are impeded by the lack of counterfactuals: simply correlating early with subsequent ratings is insufficient because we cannot know what the subsequent ratings would have looked like had the first ratings been different. The methodology introduced here exploits a setting that comes close to an experiment, although it is purely observational - -a natural experiment. Our key methodological device consists in studying the same product on two separate rating sites, focusing on products that received a high first rating on one site, and a low first rating on the other. This largely controls for confounds such as a product»s inherent quality, advertising, and producer identity, and lets us isolate the effect of the first rating on subsequent ratings. In a case study, we focus on beers as products and jointly study two beer rating sites, but our method applies to any pair of sites across which products can be matched. We find clear evidence of herding in beer ratings. For instance, if a beer receives a very high first rating, its second rating is on average half a standard deviation higher, compared to a situation where the identical beer receives a very low first rating. Moreover, herding effects tend to last a long time and are noticeable even after 20 or more ratings. Our results have important implications for the design of better rating systems. © 2018 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC BY 4.0 License."
"Burke Robin, Sonboli Nasim, Mansoury Masoud, Ordoñez-Gauger Aldo","Balanced neighborhoods for fairness-aware collaborative recommendation",2017,"Workshop on Responsible Recommendation (FATRec)",,[No abstract available]
"Lin Z., Liu D., Pan W., Ming Z.","Transfer learning in collaborative recommendation for bias reduction",2021,"RecSys 2021 - 15th ACM Conference on Recommender Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115631721&doi=10.1145%2f3460231.3478860&partnerID=40&md5=f9f82b36028beae2970a965904a17c08","In a recommender system, a user's interaction is often biased by the items' displaying positions and popularity, as well as the user's self-selection. Most existing recommendation models are built using such a biased user-system interaction data. In this paper, we first additionally introduce a specially collected unbiased data and then propose a novel transfer learning solution, i.e., transfer via joint reconstruction (TJR), to achieve knowledge transfer and sharing between the biased data and unbiased data. Specifically, in our TJR, we refine the prediction via the latent features containing bias information in order to obtain a more accurate and unbiased prediction. Moreover, we integrate the two data by reconstructing their interaction in a joint learning manner. We then adopt three representative methods as the backbone models of our TJR and conduct extensive empirical studies on two public datasets, showcasing the effectiveness of our transfer learning solution over some very competitive baselines. © 2021 Owner/Author."
"Damak K., Khenissi S., Nasraoui O.","Debiased explainable pairwise ranking from implicit feedback",2021,"RecSys 2021 - 15th ACM Conference on Recommender Systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115623540&doi=10.1145%2f3460231.3474274&partnerID=40&md5=ca067956f35175a91cde2ecf10d2f4e4","Recent work in recommender systems has emphasized the importance of fairness, with a particular interest in bias and transparency, in addition to predictive accuracy. In this paper, we focus on the state of the art pairwise ranking model, Bayesian Personalized Ranking (BPR), which has previously been found to outperform pointwise models in predictive accuracy, while also being able to handle implicit feedback. Specifically, we address two limitations of BPR: (1) BPR is a black box model that does not explain its outputs, thus limiting the user's trust in the recommendations, and the analyst's ability to scrutinize a model's outputs; and (2) BPR is vulnerable to exposure bias due to the data being Missing Not At Random (MNAR). This exposure bias usually translates into an unfairness against the least popular items because they risk being under-exposed by the recommender system. In this work, we first propose a novel explainable loss function and a corresponding Matrix Factorization-based model called Explainable Bayesian Personalized Ranking (EBPR) that generates recommendations along with item-based explanations. Then, we theoretically quantify additional exposure bias resulting from the explainability, and use it as a basis to propose an unbiased estimator for the ideal EBPR loss. The result is a ranking model that aptly captures both debiased and explainable user preferences. Finally, we perform an empirical study on three real-world datasets that demonstrate the advantages of our proposed models. © 2021 ACM."
"Zhao Zihao, Chen Jiawei, Zhou Sheng, He Xiangnan, Cao Xuezhi, Zhang Fuzheng, Wu Wei",[No title available],2021,"Popularity Bias Is Not Always Evil: Disentangling Benign and Harmful Bias for Recommendation",,[No abstract available]
"Wang W., Feng F., He X., Zhang H., Chua T.-S.",[No title available],2020,"click” is not equal to” like”: Counterfactual recommendation for mitigating clickbait issue",,[No abstract available]
"Kim J.S., Chen J., Talwalka A.","FACT: A Diagnostic for Group Fairness Trade-offs",2020,"37th International Conference on Machine Learning, ICML 2020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104579136&partnerID=40&md5=ed7d27fb99e73e7db311318e6f09e52a","Group fairness, a class of fairness notions that measure how different groups of individuals are treated differently according to their protected attributes, has been shown to conflict with one another, often with a necessary cost in loss of model's predictive performance. We propose a general diagnostic that enables systematic characterization of these trade-offs in group fairness. We observe that the majority of group fairness notions can be expressed via the fairness-confusion tensor, which is the confusion matrix split according to the protected attribute values. We frame several optimization problems that directly optimize both accuracy and fairness objectives over the elements of this tensor, which yield a general perspective for understanding multiple trade-offs including group fairness incompatibilities. It also suggests an alternate post-processing method for designing fair classifiers. On synthetic and real datasets, we demonstrate the use cases of our diagnostic, particularly on understanding the trade-off landscape between accuracy and fairness. © 2020 by the Authors."
"Wang C., Chen J., Zhou S., Shi Q., Feng Y., Chen C.","SamWalker++: recommendation with informative sampling strategy",2021,"IEEE Transactions on Knowledge and Data Engineering",,[No abstract available]
"Lin K., Sonboli N., Mobasher B., Burke R.","Crank up the volume: Preference bias amplification in collaborative recommendation",2019,"CEUR Workshop Proceedings","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072724585&partnerID=40&md5=3f07b7ef67ea74f12b881c12249c62df","Recommender systems are personalized: we expect the results given to a particular user to reflect that user’s preferences. Some researchers have studied the notion of calibration, how well recommendations match users’ stated preferences, and bias disparity the extent to which mis-calibration affects different user groups. In this paper, we examine bias disparity over a range of different algorithms and for different item categories and demonstrate significant differences between model-based and memory-based algorithms. © Copyright 2019 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0)."
"Jin J., Fang Y., Zhang W., Ren K., Zhou G., Xu J., Yu Y., Wang J., Zhu X., Gai K.",[No title available],2020,"A deep recurrent survival model for unbiased ranking",,[No abstract available]
"West Robert, Bhagat Smriti, Groth Paul, Zitnik Marinka, Couto Francisco M, Lisena Pasquale, Meroño-Peñuela Albert, Zhao Xiangyu, Fan Wenqi, Yin Dawei","Summary of Tutorials at The Web Conference 2021",2021,"Companion Proceedings of the Web Conference 2021",,[No abstract available]
"Vivian Zhang W., Jones R.","Comparing click logs and editorial labels for training query rewriting",2007,"WWW",,[No abstract available]
