Database,Title,Authors,Venue,Year,Abstract,Link
Google,A gender identification of text author in mixture of Russian multi-genre texts with distortions on base of data-driven approach using machine learning models,"['A Sboev', 'D Gudovskikh', 'I Moloshnikov']",AIP Conference …,2019.0,gender identification of text author. In this paper we investigate the questions: 1) to what extent  the machine learning  and gender deceptions worsen the results of gender identification.,https://pubs.aip.org/aip/acp/article-abstract/2116/1/270006/759909
Scopus,A gender identification of text author in mixture of Russian multi-genre texts with distortions on base of data-driven approach using machine learning models,Sboev A.; Gudovskikh D.; Moloshnikov I.; Rybka R.,AIP Conference Proceedings,2019.0,"In this work we investigate a wide set of machine learning models of data-driven approaches (Long Short-Term Memory networks, Convolutional neural networks, multilayer perceptrons, Random Forest Classifiers, Logistic Regression and Gradient Boosting Classifiers with different sets of features) to identify the gender of author in Russian multi-genre texts in the case of existing style distortions and gender deceptions in training and testing sets. We consider and evaluate accuracy for the following situations: the influence of style distortions and gender deceptions in training texts for different genre, and the case when such deception is present only in test results. A comparison with known literature data is presented. The set of data corpora includes: one collected by a crowdsourcing platform, essays of Russian students (RusPersonality), Gender Imitation corpus, and the corpora used at Forum for Information Retrieval Evaluation 2017 (FIRE), containing texts from Facebook, Twitter and Reviews. We present the analysis of numerical experiments based on different features (morphological data, vector of character n-gram frequencies, LIWC and others) of input texts along with various machine learning models. The presented results, obtained on a wide set of data-driven models, establish the accuracy level for the task to identify gender of an author of a Russian text in the multi-genre case and analyzed the effect of the presence of deception in the test and training sets. © 2019 Author(s).",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069962400&doi=10.1063%2f1.5114280&partnerID=40&md5=2a10f51dd15177a0aa56ed150ad628f2
Google,A machine learning approach for gender identification of Greek tweet authors,"['S Baxevanakis', 'S Gavras', 'D Mouratidis']",Proceedings of the 13th …,2020.0,a machine learning framework in order to predict the gender of Greek author’s tweets. While   In this paper an ML approach is presented for predicting the gender of Greek tweet authors.,https://dl.acm.org/doi/abs/10.1145/3389189.3397992
Scopus,A machine learning approach for gender identification of Greek tweet authors,Baxevanakis S.; Gavras S.; Mouratidis D.; Kermanidis K.L.,ACM International Conference Proceeding Series,2020.0,Digital communities and social media are widely used and produce a huge amount of information every second. Text analysis has been widely used by researchers and machine learning (ML) engineers for automating the author profiling task. Author profiling can be used in marketing and business intelligence frameworks but also remains a strong factor in crime investigations gaining more insight regarding the suspect. In this paper we describe the process we used in obtaining a new Twitter corpus and propose an ML approach to determine the gender of Greek author's tweets. The best result (0.7 accuracy) was obtained using SVMs and TF-IDF encoding. © 2020 ACM.,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088371912&doi=10.1145%2f3389189.3397992&partnerID=40&md5=dfb7be61c16b0abdb84d3de8b3d5cb3c
Scopus,Algorithmic bias and research integrity; the role of nonhuman authors in shaping scientific knowledge with respect to artificial intelligence: a perspective,Oduoye M.O.; Javed B.; Gupta N.; Valentina Sih C.M.,"International journal of surgery (London, England)",2023.0,"Artificial intelligence technologies were developed to assist authors in bettering the organization and caliber of their published papers, which are both growing in quantity and sophistication. Even though the usage of artificial intelligence tools in particular ChatGPT's natural language processing systems has been shown to be beneficial in research, there are still concerns about accuracy, responsibility, and transparency when it comes to the norms regarding authorship credit and contributions. Genomic algorithms quickly examine large amounts of genetic data to identify potential disease-causing mutations. By analyzing millions of medications for potential therapeutic benefits, they can quickly and relatively economically find novel approaches to treatment. Researchers from several fields can collaborate on difficult tasks with the assistance of nonhuman writers, promoting interdisciplinary research. Sadly, there are a number of significant disadvantages associated with employing nonhuman authors, including the potential for algorithmic prejudice. Biased data may be reinforced by the algorithm since machine learning algorithms can only be as objective as the data they are trained on. It is overdue that scholars bring forth basic moral concerns in the fight against algorithmic prejudice. Overall, even if the use of nonhuman authors has the potential to significantly improve scientific research, it is crucial for scientists to be aware of these drawbacks and take precautions to avoid bias and limits. To provide accurate and objective results, algorithms must be carefully designed and implemented, and researchers need to be mindful of the larger ethical ramifications of their usage. Copyright © 2023 The Author(s). Published by Wolters Kluwer Health, Inc.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173984430&doi=10.1097%2fJS9.0000000000000552&partnerID=40&md5=4d5c1553add644527ae9237dfccee98b
Google,Algorithmic bias and research integrity; the role of nonhuman authors in shaping scientific knowledge with respect to artificial intelligence: a perspective,"['MO Oduoye', 'B Javed', 'N Gupta']",International Journal of …,2023.0,"A basic example of one ethical principle is to treat everyone with respect 19,20 . AI ethics is   ought to operate in order to reduce the ethical problems that AI in human society may cause,",https://journals.lww.com/international-journal-of-surgery/fulltext/2023/10000/algorithmic_bias_and_research_integrity__the_role.12.aspx
Scopus,Automatic gender identification of author of Russian text by machine learning and neural net algorithms in case of gender deception,Sboev A.; Moloshnikov I.; Gudovskikh D.; Selivanov A.; Rybka R.; Litvinova T.,Procedia Computer Science,2018.0,"We present the analysis of approaches to solve an author gender identification task for Russian-language texts with gender deception, using different Data-Driven models based on conventional machine learning (Support Vector Classifier, Decision Tree, Gradient Boosting) and neuronet algorithms (convolutional layers, long short-term memory layers, etc.) The source of training and testing data are collections of texts from the Gender Imitation corpus, expanded by crowd-sourcing and supplemented with files of RusProfiling and RusPersonality corpora. The reached accuracy of this task milestone is presented and discussed. © 2018 The Authors.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045661273&doi=10.1016%2fj.procs.2018.01.064&partnerID=40&md5=8c621c77c36dedba24eb0284d752568d
Google,Automatic gender identification of author of Russian text by machine learning and neural net algorithms in case of gender deception,"['A Sboev', 'I Moloshnikov', 'D Gudovskikh']",Procedia computer …,2018.0,"to solve an author gender identification task for Russianlanguage texts with gender  deception, using different Data-Driven models based on conventional machine learning (Support",https://www.sciencedirect.com/science/article/pii/S1877050918300656
Scopus,ChatGPT as Co-Author? AI and Research Ethics,Sharifzadeh R.,Ethics in Progress,2024.0,"Should ChatGPT be viewed merely as a supportive tool for writers, or does it qualify as a co-author? As ChatGPT and similar language models are likely to become more prevalent in assisting with academic writing and research, it seems that we will face with two possibilities: an increase in ghostwriting that could finally undermine the integrity of the knowledge system, or the need to theoretical preparation to recognize the role of non-human contributors. Drawing on Actor-Network Theory, this article examines the question of whether this Chatbot meets, in principle, the requirements for co-authorship. Answering this question in affirmative, it delves into philosophical discussions concerning the agency, moral agency, and moral accountability of such technological entities. © 2024, Adam Mickiewicz University, Faculty of Philosophy. All rights reserved.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199256352&doi=10.14746%2feip.2024.1.8&partnerID=40&md5=5f025b9e2e12e5f5cf27f538a75ad3db
Google,ChatGPT as Co-Author? AI and Research Ethics,['R Sharifzadeh'],Ethics in Progress,2024.0,justify the presence of non-human authors in some specific and ethically acceptable ways.   -human author’ and discuss how an artificial intelligence can be considered as a coauthor. I,https://www.ceeol.com/search/article-detail?id=1256526
Scopus,Dealing with Popularity Bias in Recommender Systems for Third-party Libraries: How far Are We?,Nguyen P.T.; Rubei R.; Di Rocco J.; Di Sipio C.; Di Ruscio D.; Di Penta M.,"Proceedings - 2023 IEEE/ACM 20th International Conference on Mining Software Repositories, MSR 2023",2023.0,"Recommender systems for software engineering (RSSEs) assist software engineers in dealing with a growing information overload when discerning alternative development solutions. While RSSEs are becoming more and more effective in suggesting handy recommendations, they tend to suffer from popularity bias, i.e., favoring items that are relevant mainly because several developers are using them. While this rewards artifacts that are likely more reliable and well-documented, it would also mean that missing artifacts are rarely used because they are very specific or more recent. This paper studies popularity bias in Third-Party Library (TPL) RSSEs. First, we investigate whether state-of-the-art research in RSSEs has already tackled the issue of popularity bias. Then, we quantitatively assess four existing TPL RSSEs, exploring their capability to deal with the recommendation of popular items. Finally, we propose a mechanism to defuse popularity bias in the recommendation list. The empirical study reveals that the issue of dealing with popularity in TPL RSSEs has not received adequate attention from the software engineering community. Among the surveyed work, only one starts investigating the issue, albeit getting a low prediction performance.  © 2023 IEEE.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166303384&doi=10.1109%2fMSR59073.2023.00016&partnerID=40&md5=0434bc58e58bc13c8f491a92d7dec41a
Google,Dealing with Popularity Bias in Recommender Systems for Third-party Libraries: How far Are We?,"['PT Nguyen', 'R Rubei', 'J Di Rocco']",2023 IEEE/ACM 20th …,2023.0,"popularity bias. – Through a quantitative study on four TPL RSSEs, we assess their sensitivity  to  bias. – We propose a practical solution to increase fairness in the recommendation lists.",https://ieeexplore.ieee.org/abstract/document/10174041/
Google,Enhanced access to recommendations from the Cochrane Handbook for improving authors' judgments about risk of bias: A randomized controlled trial,"['O Barcot', 'M Ivanda', 'I Buljan', 'D Pieper']",Research synthesis …,2021.0,"In the Cochrane Handbook, the table contains the criteria for judging the risk of bias in the   to the authors was our intervention – the enhanced access to recommendations from the",https://onlinelibrary.wiley.com/doi/abs/10.1002/jrsm.1499
Scopus,Enhanced access to recommendations from the Cochrane Handbook for improving authors' judgments about risk of bias: A randomized controlled trial,Barcot O.; Ivanda M.; Buljan I.; Pieper D.; Puljak L.,Research Synthesis Methods,2021.0,"This randomized controlled trial (RCT) aimed to test the efficacy of enhanced access to Cochrane Handbook (Handbook) recommendations for judging the 2011 Cochrane risk of bias (RoB) domains for improving the adequacy of RoB judgments. Parallel-group RCT with a 1:1 allocation ratio (N = 2271 per group) was conducted. Eligible participants were corresponding authors of all published Cochrane reviews and protocols. After allocation by a random number generator, participants received 20 scenarios for assessing RoB. The intervention group was shown tables from the Handbook with instructions for assessing 2011 RoB tool together with scenarios they were supposed to assess—enhanced access to the Handbook. The control group was shown only a general link to the Handbook. The primary outcome was the proportion of participants that made an adequate judgment of RoB scenarios for analyzed domains. There were 240 responses out of 2020 delivered e-mail invitations in the intervention and 197/2254 in the control group. Only five participants from the intervention group judged RoB adequately in all the 20 scenarios and no one in the control group. The proportion of participants who adequately assessed all the scenarios within a domain was significantly higher in the intervention than in the control group. The frequency of adequate RoB judgments was 7.1% (95% CI: 5.0–9.3%, p < 0.001) higher in the intervention group (76.2%) than in the control group (69.0%). The enhanced access yields more adequate RoB assessments and could be incorporated in software supporting the RoB tool. © 2021 John Wiley & Sons Ltd.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108084971&doi=10.1002%2fjrsm.1499&partnerID=40&md5=a2051e22589d452bf6bcdd4b76236fc9
Scopus,Ethical Recommenders in the Public Library Sector,Daniil S.,"AIES 2022 - Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society",2022.0,"Recommender Systems as an algorithmic class hide lurking risks despite their prevalence in academic and commercial circles. My specific research revolves around tracking and mitigating potential risks specifically in the Public Library domain. In collaboration with the National Library of The Netherlands, I am working on investigating whether the incorporation of Recommenders in a library's loaning system serves their social responsibility and purpose, with securing inclusivity being the main point of interest.  © 2022 Owner/Author.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137157847&doi=10.1145%2f3514094.3539536&partnerID=40&md5=2ac320ac8aa9313226af62b3ab7a5afb
Google,Ethical Recommenders in the Public Library Sector,['S Daniil'],"… of the 2022 AAAI/ACM Conference on AI, Ethics, and …",2022.0,"(Google Books,  the author when publicly available (eg, gender, nationality, age). Concurrently,  I am conducting research on diversity measures that have been used in Recommenders",https://dl.acm.org/doi/abs/10.1145/3514094.3539536
Scopus,Ethical artificial intelligence (AI): confronting bias and discrimination in the library and information industry,Saeidnia H.R.,Library Hi Tech News,2023.0,"Purpose: The purpose of this study is to raise awareness about the ethical implications of artificial intelligence (AI) in the library and information industry, specifically focusing on bias and discrimination. It aims to highlight the need for proactive measures to mitigate these issues and ensure that AI technology is developed and implemented in an ethical and unbiased manner. Design/methodology/approach: This viewpoint paper presents a critical analysis of the ethical implications of bias and discrimination in the library and information industry with respect to AI. It explores current practices and challenges in AI implementation and proposes strategies to address bias and discrimination in AI systems. Findings: The findings of this study reveal that bias and discrimination are significant concerns in AI systems used in the library and information industry. These biases can perpetuate existing inequalities, hinder access to information and reinforce discriminatory practices. This study identifies key strategies such as data collection and representation, algorithmic transparency and inclusive design to address these issues. Originality/value: This study contributes to the existing literature by examining the specific challenges of bias and discrimination in AI implementation within the library and information industry. It provides valuable insights into the ethical implications of AI technology and offers practical recommendations for professionals to confront and mitigate bias and discrimination in AI systems, ensuring equitable access to information for all users. © 2023, Emerald Publishing Limited.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174622130&doi=10.1108%2fLHTN-10-2023-0182&partnerID=40&md5=77f9407e58067392f54c2cfd52c9fe22
Google,Ethical artificial intelligence (AI): confronting bias and discrimination in the library and information industry,['HR Saeidnia'],Library Hi Tech News,2023.0,"the ethical implications of artificial intelligence (AI) in the library and information industry,  specifically focusing on bias  that AI technology is developed and implemented in an ethical and",https://www.emerald.com/insight/content/doi/10.1108/LHTN-10-2023-0182/full/html
Google,Exploring and mitigating gender bias in book recommender systems with explicit feedback,"['S Saxena', 'S Jain']",Journal of Intelligent Information Systems,2024.0,"In this paper, we address the problem of gender bias in recommender systems  gender  bias present in book rating datasets and in the recommendations produced by the recommender",https://link.springer.com/article/10.1007/s10844-023-00827-8
Scopus,Exploring and mitigating gender bias in book recommender systems with explicit feedback,Saxena S.; Jain S.,Journal of Intelligent Information Systems,2024.0,"Recommender systems are indispensable because they influence our day-to-day behavior and decisions by giving us personalized suggestions. Services like Kindle, YouTube, and Netflix depend heavily on the performance of their recommender systems to ensure that their users have a good experience and to increase revenues. Despite their popularity, it has been shown that recommender systems reproduce and amplify the bias present in the real world. The resulting feedback creates a self-perpetuating loop that deteriorates the user experience and results in homogenizing recommendations over time. Further, biased recommendations can also reinforce stereotypes based on gender or ethnicity, thus reinforcing the filter bubbles that we live in. In this paper, we address the problem of gender bias in recommender systems with explicit feedback. We propose a model to quantify the gender bias present in book rating datasets and in the recommendations produced by the recommender systems. Our main contribution is to provide a principled approach to mitigate the bias being produced in the recommendations. We theoretically show that the proposed approach provides unbiased recommendations despite biased data. Through empirical evaluation of publicly available book rating datasets, we further show that the proposed model can significantly reduce bias without significant impact on accuracy and outperforms the existing model in terms of bias. Our method is model-agnostic and can be applied to any recommender system. To demonstrate the performance of our model, we present the results on four recommender algorithms, two from the K-nearest neighbors family, UserKNN and ItemKNN, and the other two from the matrix factorization family, Alternating Least Square and Singular Value Decomposition. The extensive simulations of various recommender algorithms show the generality of the proposed approach. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188446080&doi=10.1007%2fs10844-023-00827-8&partnerID=40&md5=cb331d7edaab35b9237edb4b854f3506
Scopus,Exploring author gender in book rating and recommendation,Ekstrand M.D.; Tian M.; Imran Kazi M.R.; Mehrpouyan H.; Kluver D.,RecSys 2018 - 12th ACM Conference on Recommender Systems,2018.0,"Collaborative filtering algorithms find useful patterns in rating and consumption data and exploit these patterns to guide users to good items. Many of the patterns in rating datasets reflect important real-world differences between the various users and items in the data; other patterns may be irrelevant or possibly undesirable for social or ethical reasons, particularly if they reflect undesired discrimination, such as gender or ethnic discrimination in publishing. In this work, we examine the response of collaborative filtering recommender algorithms to the distribution of their input data with respect to a dimension of social concern, namely content creator gender. Using publicly-available book ratings data, we measure the distribution of the genders of the authors of books in user rating profiles and recommendation lists produced from this data. We find that common collaborative filtering algorithms differ in the gender distribution of their recommendation lists, and in the relationship of that output distribution to user profile distribution. © 2018 Copyright held by the owner/author(s).",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056759148&doi=10.1145%2f3240323.3240373&partnerID=40&md5=5b586000fb0b71495751135c85ffdb85
Scopus,Exploring author gender in book rating and recommendation,Ekstrand M.D.; Kluver D.,User Modeling and User-Adapted Interaction,2021.0,"Collaborative filtering algorithms find useful patterns in rating and consumption data and exploit these patterns to guide users to good items. Many of these patterns reflect important real-world phenomena driving interactions between the various users and items; other patterns may be irrelevant or reflect undesired discrimination, such as discrimination in publishing or purchasing against authors who are women or ethnic minorities. In this work, we examine the response of collaborative filtering recommender algorithms to the distribution of their input data with respect to one dimension of social concern, namely content creator gender. Using publicly available book ratings data, we measure the distribution of the genders of the authors of books in user rating profiles and recommendation lists produced from this data. We find that common collaborative filtering algorithms tend to propagate at least some of each user’s tendency to rate or read male or female authors into their resulting recommendations, although they differ in both the strength of this propagation and the variance in the gender balance of the recommendation lists they produce. The data, experimental design, and statistical methods are designed to be reusable for studying potentially discriminatory social dimensions of recommendations in other domains and settings as well. © 2021, Springer Nature B.V.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100480096&doi=10.1007%2fs11257-020-09284-2&partnerID=40&md5=7991afa561912376badc656d08226e18
Google,Exploring author gender in book rating and recommendation,"['MD Ekstrand', 'M Tian', 'MRI Kazi']",… on recommender …,2018.0,"is a prerequisite to assessing the ethical, legal, moral, and  how recommender systems  interact with author gender in book  the distribution of author genders in existing book data sets",https://dl.acm.org/doi/abs/10.1145/3240323.3240373
Google,I Recommend You to Read: XI. Recent Books on Christian Ethics,['CRH Preston'],The Expository Times,1968.0,"Ethics if one judges by the number of books written within its broad fields of study. Quite  recently the chief assistant in a religious book  these days, and that the books sold well. She had",https://journals.sagepub.com/doi/abs/10.1177/001452466807900502
Scopus,I Recommend You to Read: XI. Recent Books on Christian Ethics,Preston C.R.H.,The Expository Times,1968.0,[No abstract available],https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976926222&doi=10.1177%2f001452466807900502&partnerID=40&md5=25dc1e57bf30fdc9fbe46c680ed9ad69
Scopus,Investigation on human rights ethics in artificial intelligence researches with library literature analysis method,Miao Z.,Electronic Library,2019.0,"Purpose: The purpose of this paper was to identify whether artificial intelligence (AI) products can possess human rights, how to define their rights and obligations and what ethical standards they should follow. In this study, the human rights ethical dilemma encountered in the application and development of AI technology has been focused on and analyzed in detail in the light of the existing research status of AI ethics. Design/methodology/approach: In this study, first of all, the development and application of AI technology, as well as the concept and characteristics of human rights ethics, are introduced. Second, the human rights ethics of AI technology are introduced in detail, including the human rights endowment of AI machines, the fault liability of AI machines and the moral orientation of AI machines. Finally, the approaches to human rights ethics are proposed to ensure that AI technology serves human beings. Every link of its research, production and application should be strictly managed and supervised. Findings: The results show that the research in this study can provide help for the related problems encountered in AI practice. Intelligent library integrates human rights protection organically so that readers or users can experience more intimate service in this system. It is a kind of library operation mode with more efficient and convenient characteristics, which is based on digital, networked and intelligent information science. It aims at using the greenest way and digital means to realize the reading and research of human rights protection literature in the literature analysis method. Originality/value: Intelligent library is the future development mode of new libraries, which can realize broad interconnection and sharing. It is people-oriented and can make intelligent management and service and establish the importance of the principle of human rights protection and the specific idea of the principle. The development of science and technology brings not only convenience to people's social life but also questions to be thought. People should reduce its potential harm, so as to make AI technology continue to benefit humankind. © 2019, Emerald Publishing Limited.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074440092&doi=10.1108%2fEL-04-2019-0089&partnerID=40&md5=1423956d9453b51fa2a869d719c8399d
Google,Investigation on human rights ethics in artificial intelligence researches with library literature analysis method,['Z Miao'],The Electronic Library,2019.0,ethical dilemma encountered in the application and development of AI technology has  been focused on and analyzed in detail in the light of the existing research status of AI ethics.,https://www.emerald.com/insight/content/doi/10.1108/EL-04-2019-0089/full/html
Scopus,Is AI my co-author? The ethics of using artificial intelligence in scientific publishing,Moffatt B.; Hall A.,Accountability in Research,2024.0,"The recent emergence of Large Language Models (LLMs) and other forms of Artificial Intelligence (AI) has led people to wonder whether they could act as an author on a scientific paper. This paper argues that AI systems should not be included on the author by-line. We agree with current commentators that LLMs are incapable of taking responsibility for their work and thus do not meet current authorship guidelines. We identify other problems with responsibility and authorship. In addition, the problems go deeper as AI tools also do not write in a meaningful sense nor do they have persistent identities. From a broader publication ethics perspective, adopting AI authorship would have detrimental effects on an already overly competitive and stressed publishing ecosystem. Deterrence is possible as backward-looking tools will likely be able to identify past AI usage. Finally, we question the value of using AI to produce more research simply for publication’s sake. © 2024 Informa UK Limited, trading as Taylor & Francis Group.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200789044&doi=10.1080%2f08989621.2024.2386285&partnerID=40&md5=bc0f14408d445e893e656d2af2fdb4bd
Google,Is AI my co-author? The ethics of using artificial intelligence in scientific publishing,"['B Moffatt', 'A Hall']",Accountability in Research,2024.0,use AI tools  the ethical issues of using new artificial intelligence products in manuscript  writing. We first consider some of the existing arguments disqualifying LLMs as scientific authors,https://www.tandfonline.com/doi/abs/10.1080/08989621.2024.2386285
Scopus,Is there any gender/race bias in hep-lat primary publication? Machine-Learning Evaluation of Author Ethnicity and Gender,Lin H.-W.,Proceedings of Science,2022.0,"In this work, we analyze papers that are classified as primary hep-lat to study whether there is any race or gender bias in the journal-publication process. We implement machine learning to predict the race and gender of authors based on their names and look for measurable differences between publication outcomes based on author classification. We would like to invite discussion on how journals can make improvements in their editorial process and how institutions or grant offices should account for these publication differences in gender and race. © Copyright owned by the author(s) under the terms of the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License (CC BY-NC-ND 4.0)",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134429742&partnerID=40&md5=10806827741100a29e0160ffaabe8fcf
Google,Is there any gender/race bias in hep-lat primary publication? Machine-Learning Evaluation of Author Ethnicity and Gender,['HW Lin'],arXiv preprint arXiv:2107.12991,2021.0,"machine learning on author ethnicity, we attempt to study author gender using machine  learning Prior to beginning this phase, we thought machine learning would work well for this",https://arxiv.org/abs/2107.12991
Google,Machine learning optimization of candidate antibody yields highly diverse sub-nanomolar affinity antibody libraries,"['L Li', 'E Gupta', 'J Spaeth', 'L Shing', 'R Jaimes']",Nature …,2023.0,"By comparing a library’s predicted success to actual measurements, we demonstrate  library  success and diversity. Results of our work highlight the significant impact machine learning",https://www.nature.com/articles/s41467-023-39022-2
Scopus,Machine learning optimization of candidate antibody yields highly diverse sub-nanomolar affinity antibody libraries,Li L.; Gupta E.; Spaeth J.; Shing L.; Jaimes R.; Engelhart E.; Lopez R.; Caceres R.S.; Bepler T.; Walsh M.E.,Nature Communications,2023.0,"Therapeutic antibodies are an important and rapidly growing drug modality. However, the design and discovery of early-stage antibody therapeutics remain a time and cost-intensive endeavor. Here we present an end-to-end Bayesian, language model-based method for designing large and diverse libraries of high-affinity single-chain variable fragments (scFvs) that are then empirically measured. In a head-to-head comparison with a directed evolution approach, we show that the best scFv generated from our method represents a 28.7-fold improvement in binding over the best scFv from the directed evolution. Additionally, 99% of designed scFvs in our most successful library are improvements over the initial candidate scFv. By comparing a library’s predicted success to actual measurements, we demonstrate our method’s ability to explore tradeoffs between library success and diversity. Results of our work highlight the significant impact machine learning models can have on scFv development. We expect our method to be broadly applicable and provide value to other protein engineering tasks. © 2023, The Author(s).",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161922820&doi=10.1038%2fs41467-023-39022-2&partnerID=40&md5=2589aac293c08cc18014db0f3568ed21
Google,Machine learning-based library design improves packaging and diversity of adeno-associated virus (AAV) libraries,['J Listgarten'],,,libraries to design libraries that optimally trade off diversity with packaging fitness; (iii) and  that these designed libraries  libraries used today. Our approach can also be used to optimize,https://pdfs.semanticscholar.org/3445/693405442e1b02b48ea85c05e3cf24c15c79.pdf
Google,Machine learning-based library design improves packaging and diversity of adeno-associated virus (AAV) libraries,"['D Zhu', 'DH Brookes', 'A Busia', 'A Carneiro', 'C Fannjiang']",bioRxiv,2021.0,effort while maintaining diversity of the library. Our overall workflow to enhance a library was  to (i)  to improving packaging and diversity of AAV libraries with machine learning. David V.,https://www.biorxiv.org/content/biorxiv/early/2021/11/04/2021.11.02.467003.1.full.pdf
Google,Machine learning-guided co-optimization of fitness and diversity facilitates combinatorial library design in enzyme engineering,"['K Ding', 'M Chin', 'Y Zhao', 'W Huang', 'BK Mai']",Nature …,2024.0,"To obtain the best experience, we recommend you use a more up to date browser (or turn  off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we",https://www.nature.com/articles/s41467-024-50698-y
Scopus,Machine learning-guided co-optimization of fitness and diversity facilitates combinatorial library design in enzyme engineering,Ding K.; Chin M.; Zhao Y.; Huang W.; Mai B.K.; Wang H.; Liu P.; Yang Y.; Luo Y.,Nature Communications,2024.0,"The effective design of combinatorial libraries to balance fitness and diversity facilitates the engineering of useful enzyme functions, particularly those that are poorly characterized or unknown in biology. We introduce MODIFY, a machine learning (ML) algorithm that learns from natural protein sequences to infer evolutionarily plausible mutations and predict enzyme fitness. MODIFY co-optimizes predicted fitness and sequence diversity of starting libraries, prioritizing high-fitness variants while ensuring broad sequence coverage. In silico evaluation shows that MODIFY outperforms state-of-the-art unsupervised methods in zero-shot fitness prediction and enables ML-guided directed evolution with enhanced efficiency. Using MODIFY, we engineer generalist biocatalysts derived from a thermostable cytochrome c to achieve enantioselective C-B and C-Si bond formation via a new-to-nature carbene transfer mechanism, leading to biocatalysts six mutations away from previously developed enzymes while exhibiting superior or comparable activities. These results demonstrate MODIFY’s potential in solving challenging enzyme engineering problems beyond the reach of classic directed evolution. © The Author(s) 2024.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199981329&doi=10.1038%2fs41467-024-50698-y&partnerID=40&md5=326d730eddebcb8b6d2bdad5498db21f
Google,Measuring Gender: A Machine Learning Approach to Social Media Demographics and Author Profiling,"['ER Kovacs', 'LA Cotfas', 'C Delcea']",International Conference on …,2023.0,"is the gender distribution of users. We propose an ensemble of multiple machine learning   an F1 score of 90.24%, then predict the gender of the user based on their name, obtaining an",https://link.springer.com/chapter/10.1007/978-3-031-41456-5_26
Scopus,Measuring Gender: A Machine Learning Approach to Social Media Demographics and Author Profiling,Kovacs E.-R.; Cotfas L.-A.; Delcea C.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2023.0,"Social media has become a preeminent medium of communication during the early 21st century, facilitating dialogue between the political sphere, businesses, scientific experts, and everyday people. Researchers in the social sciences are focusing their attention on social media as a central site of social discourse, but such approaches are hampered by the lack of demographic data that could help them connect phenomena originating in social media spaces to their larger social context. Computational social science methods which use machine learning and deep learning natural language processing (NLP) tools for the task of author profiling (AP) can serve as an essential complement to such research. One of the major demographic categories of interest concerning social media is the gender distribution of users. We propose an ensemble of multiple machine learning classifiers able to distinguish whether a user is anonymous with an F1 score of 90.24%, then predict the gender of the user based on their name, obtaining an F1 score of 89.22%. We apply the classification pipeline to a set of approximately 44,000,000 posts related to COVID-19 extracted from the social media platform Twitter, comparing our results to a benchmark classifier trained on the PAN18 Author Profiling dataset, showing the validity of the proposed approach. An n-gram analysis on the text of the tweets to further compare the two methods has been performed. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172416915&doi=10.1007%2f978-3-031-41456-5_26&partnerID=40&md5=064c6bff1f2ba6d34bf2627000a6bc0d
Scopus,Novel molecular inhibitor design for Plasmodium falciparum Lactate dehydrogenase enzyme using machine learning generated library of diverse compounds,Kuldeep J.; Chaturvedi N.; Gupta D.,Molecular Diversity,2024.0,"Generative machine learning models offer a novel strategy for chemogenomics and de novo drug design, allowing researchers to streamline their exploration of the chemical space and concentrate on specific regions of interest. In cases with limited inhibitor data available for the target of interest, de novo drug design plays a crucial role. In this study, we utilized a package called 'mollib,' trained on ChEMBL data containing approximately 365,000 bioactive molecules. By leveraging transfer learning techniques with this package, we generated a series of compounds, starting from five initial compounds, which are potential Plasmodium falciparum (Pf) Lactate dehydrogenase inhibitors. The resulting compounds exhibit structural diversity and hold promise as potential novel Pf Lactate dehydrogenase inhibitors. Graphical Abstract: (Figure presented.). © The Author(s), under exclusive licence to Springer Nature Switzerland AG 2024.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201644438&doi=10.1007%2fs11030-024-10960-3&partnerID=40&md5=6a73dbdf178004b99bf18cfdc0211729
Google,Novel molecular inhibitor design for Plasmodium falciparum Lactate dehydrogenase enzyme using machine learning generated library of diverse compounds,"['J Kuldeep', 'N Chaturvedi', 'D Gupta']",Molecular Diversity,2024.0,have not integrated both machine learning and structure-based  combines the power of  generative AI with structure-based  unique and diverse virtual compound libraries to identify,https://link.springer.com/article/10.1007/s11030-024-10960-3
Google,Position bias in recommender systems for digital libraries,"['A Collins', 'D Tkaczyk', 'A Aizawa', 'J Beel']",International Conference on …,2018.0,Our research confirms that position bias exists for recommender systems in digital libraries.  The analysis shows that articles recommended at higher positions received significantly,https://link.springer.com/chapter/10.1007/978-3-319-78105-1_37
Scopus,Position bias in recommender systems for digital libraries,Collins A.; Tkaczyk D.; Aizawa A.; Beel J.,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),2018.0,"“Position bias” describes the tendency of users to interact with items on top of a list with higher probability than with items at a lower position in the list, regardless of the items’ actual relevance. In the domain of recommender systems, particularly recommender systems in digital libraries, position bias has received little attention. We conduct a study in a real-world recommender system that delivered ten million related-article recommendations to the users of the digital library Sowiport, and the reference manager JabRef. Recommendations were randomly chosen to be shuffled or non-shuffled, and we compared click-through rate (CTR) for each rank of the recommendations. According to our analysis, the CTR for the highest rank in the case of Sowiport is 53% higher than expected in a hypothetical non-biased situation (0.189% vs. 0.123%). Similarly, in the case of Jabref the highest rank received a CTR of 1.276%, which is 87% higher than expected (0.683%). A chi-squared test confirms the strong relationship between the rank of the recommendation shown to the user and whether the user decided to click it (p < 0.01 for both Jabref and Sowiport). Our study confirms the findings from other domains, that recommendations in the top positions are more often clicked, regardless of their actual relevance. © Springer International Publishing AG, part of Springer Nature 2018.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044426402&doi=10.1007%2f978-3-319-78105-1_37&partnerID=40&md5=d27cebecd9eb33a958f1cfe5bd3c82a9
Scopus,Predicting author gender using machine learning algorithms: Looking beyond the binary,Land K.,Digital Studies/ Le Champ Numerique,2020.0,"This paper explores the relationship between digital humanities studies that utilize computer algorithms to identify author gender and feminist and queer literary theory. I argue that utilizing computer algorithms to sort literature into the categories ""authored by a male""or ""authored by a female""is too reductive in its treatment of gender as binary. However, I suggest computer algorithms could be utilized to explore the performative aspects of author gender and to ask larger questions about algorithmic criticism, the author as a subject, and the relationship between morphological and cultural properties of texts. © 2020 The Author(s).",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099109192&doi=10.16995%2fDSCN.362&partnerID=40&md5=256c2a24a6e8683a08d6aaad28322901
Google,Predicting author gender using machine learning algorithms: Looking beyond the binary,['K Land'],Digital Studies/Le champ numérique,2020.0,studies that use machine learning algorithms to identify the gender of the author of fictional   of dividing texts by author gender not only confirms gender stereotypes but reinforces them,https://www.digitalstudies.org/article/10.16995/dscn.362/
Scopus,"Recommendations for the ethical guidelines for publication of scientific studies: The responsibilities of editors, reviewers and the authors",Akbulut S.; Sahin T.T.,Annals of Medicine and Surgery,2021.0,"Objective: We aimed to evaluate the role of anesthesiologist in the management of hydatid disease from the perspective of the editors, reviewers and the authors. Methods: We searched the PubMed/Medline database using the following keywords: (hydatid* OR echinococc*) AND (disease OR cyst) AND (anesthesiology). We have evaluated the authors, their institutions and department, and the aim of the studies. We also evaluated the studies published by anesthesiologists in terms of content. Results: The literature search showed 6344 articles published between February 2010 to 2021. Sixty-three had at least one anesthesiologist in the author list. Anesthesiologists were leading authors in 35 studies; and in 19 of them, all the authors were anesthesiologist. Sixteen (84.2%) of these articles defined the outcomes of surgical therapy and there was no information regarding anesthesia technique. Conclusion: The results of our study emphasize an important controversy regarding jurisdiction of different departments in terms of scientific research ethics. We believe that different disciplines can work together to evaluate a scientific problem and can publish a study in collaboration. But collaboration is very important and violating the subject of another field without collaboration is a deontological problem. © 2021",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119080099&doi=10.1016%2fj.amsu.2021.103047&partnerID=40&md5=0c270e5b96ef17b427db4abf4a9151e4
Google,"Recommendations for the ethical guidelines for publication of scientific studies: The responsibilities of editors, reviewers and the authors","['S Akbulut', 'TT Sahin']",Annals of Medicine and Surgery,2021.0,"designated as authors should meet all four criteria for authorship '' [11]. The authors of the   , we would like to give our recommendations for authors, editors and the reviewers in order to",https://www.sciencedirect.com/science/article/pii/S2049080121009973
Scopus,Research ethics and issues regarding the use of ChatGPT-like artificial intelligence platforms by authors and reviewers: a narrative review,Kim S.-J.,Science Editing,2024.0,"While generative artificial intelligence (AI) technology has become increasingly competitive since OpenAI introduced ChatGPT, its widespread use poses significant ethical challenges in research. Excessive reliance on tools like ChatGPT may intensify ethical concerns in scholarly articles. Therefore, this article aims to provide a comprehensive narrative review of the ethical issues associated with using AI in academic writing and to inform researchers of current trends. Our methodology involved a detailed examination of literature on ChatGPT and related research trends. We conducted searches in major databases to identify additional relevant articles and cited literature, from which we collected and analyzed papers. We identified major issues from the literature, categorized into problems faced by authors using nonacademic AI platforms in writing and challenges related to the detection and acceptance of AI-generated content by reviewers and editors. We explored eight specific ethical problems highlighted by authors and reviewers and conducted a thorough review of five key topics in research ethics. Given that nonacademic AI platforms like ChatGPT often do not disclose their training data sources, there is a substantial risk of unattributed content and plagiarism. Therefore, researchers must verify the accuracy and authenticity of AI-generated content before incorporating it into their article, ensuring adherence to principles of research integrity and ethics, including avoidance of fabrication, falsification, and plagiarism. Copyright © 2024 Korean Council of Science Editors",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201892827&doi=10.6087%2fkcse.343&partnerID=40&md5=14db9fe258c8832cdf7b5783da45428a
Google,Research ethics and issues regarding the use of ChatGPT-like artificial intelligence platforms by authors and reviewers: a narrative review,['SJ Kim'],Science Editing,2024.0,of AI-generated content by reviewers and editors. We explored eight specific ethical problems  highlighted by authors  review of five key topics in research ethics. Given that nonacademic,http://escienceediting.org/journal/view.php?number=344
Google,"Responsible Operations: Data Science, Machine Learning, and AI in Libraries",['R MacGregor'],the american archivist,2020.0,"data science, machine learning, and AI have on libraries.  ethics of machine learning and  AI in libraries and information has global reach and impact in a digital world, where all libraries",https://meridian.allenpress.com/american-archivist/article-abstract/83/2/483/462529
Scopus,"Responsible Operations: Data Science, Machine Learning, and AI in Libraries",Macgregor R.,American Archivist,2020.0,[No abstract available],https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161958180&doi=10.17723%2f0360-9081-83.2.483&partnerID=40&md5=004340fbe235dde0173019150a011403
Google,"Responsible Operations: Data Science, Machine Learning, and AI in Libraries",['P Thomas'],,,,missing
Scopus,Reviewer recommendations and editors' decisions for a conservation journal: Is it just a crapshoot? And do Chinese authors get a fair shot?,Campos-Arceiz A.; Primack R.B.; Koh L.P.,Biological Conservation,2015.0,"An important topic in the scientific publication process is how well reviewers evaluate the quality of papers and how their recommendations influence editors' decisions to accept or reject papers. Additionally, a particular concern for researchers from China and other countries with rapidly developing scientific communities is whether there are potential biases affecting their manuscripts in the review process. To address these topics, we examined 4575 manuscripts submitted to the journal Biological Conservation. For the 2093 papers sent out for review, reviewer recommendations strongly influenced the outcome of the review process. Reviewer recommendations of accept and minor revision were similar in their positive effects on editor decisions, while papers receiving at least one recommendation of reject (""the kiss of death"") were almost always rejected. Papers with more consistent reviews (e.g. both reviewers recommending a major revision) had a greater chance of acceptance than did papers with more variation (e.g. minor revision and reject). We found no evidence of editor bias against papers from China; however, reviewer recommendation for papers from China had a greater degree of agreement than did reviewers of papers from English-speaking countries (e.g. intra-class correlation of 0.25 vs. 0.55), due to reviewers of papers from China often agreeing that papers should be rejected or require major revision. Reviewers from China judged papers from China more harshly than did reviewers from other countries. Our results demonstrate that the review process is not a crapshoot; reviewers are providing useful information and editors are using this information to make reasonable decisions. © 2015 Elsevier Ltd.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924954578&doi=10.1016%2fj.biocon.2015.02.025&partnerID=40&md5=f49872d228e6328ef9c521501920f865
Google,Reviewer recommendations and editors' decisions for a conservation journal: Is it just a crapshoot? And do Chinese authors get a fair shot?,"['A Campos-Arceiz', 'RB Primack', 'LP Koh']",Biological Conservation,2015.0,"Papers with more consistent reviews (eg both reviewers recommending a major revision)   of editor bias against papers from China; however, reviewer recommendation for papers from",https://www.sciencedirect.com/science/article/pii/S0006320715000956
Google,“What could go wrong?”: An evaluation of ethical foresight analysis as a tool to identify problems of AI in libraries,"['H Bubinger', 'JD Dinneen']",The Journal of Academic Librarianship,2024.0,a tool for identifying potential ethical issues with AI applications in libraries. In  ethical issues  of AI in academic libraries by applying it via an ethical Delphi study of a pilot project using AI,https://www.sciencedirect.com/science/article/pii/S0099133324001046
Scopus,“What could go wrong?”: An evaluation of ethical foresight analysis as a tool to identify problems of AI in libraries,Bubinger H.; Dinneen J.D.,Journal of Academic Librarianship,2024.0,"Artificial intelligence (AI) has entered libraries in various ways and raised concern about its potential ethical consequences therein. A number of approaches have been developed to encourage ethical AI and audit the ethics of specific AI applications, but very few approaches have been applied or tested, especially in a library setting, and so it remains unclear which, if any approaches are suitable or useful for encouraging ethical AI in libraries. We applied Ethical Foresight Analysis as an approach to identify possible ethical risks of an AI project for (semi-)automated subject indexing in a large research library. Specifically, to identify risks we conducted a two-round ethical Delphi study wherein experts on AI development, library practices, and AI ethics sought consensus on potential risks and their relative importance. The experts' post-test reflections on the procedure were then collected to inform an evaluation of the approach's feasibility. A variety of ethical risks of the specific project and of general AI indexing were indeed identified, most notably discrimination and under-representation stemming from attributes of the bibliographic training data provided by the library (e.g. varied historical contexts and gaps left by unindexed items). However, we identified some drawbacks of the approach tested: (1) it is time-consuming, which is likely prohibitive for many libraries, and (2) the identified risks were mainly well-known issues of AI and its training data rather than the subtle, application-specific, and human-centred issues that ethical foresight analysis might be employed to identify. Thus, although libraries should continue to model ethical AI through careful planning and auditing, alternative development and auditing approaches may be more practical to undertake and more effective at identifying novel or application-specific issues. © 2024 Elsevier Inc.",https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201900173&doi=10.1016%2fj.acalib.2024.102943&partnerID=40&md5=5767da29ced175a74cf75f28f65c0d8e
Google,… theory; Part III. Diversification and Subjective Views; 7. Diversification in modern portfolio theory; 8. Stability: a first look; 9. Diversification and stability in …,"['R Rebonato', 'A Denev']",,2013.0,,missing
Google,… theory; Part III. Diversification and Subjective Views; 7. Diversification in modern portfolio theory; 8. Stability: a first look; 9. Diversification and stability in …,"['R Rebonato', 'A Denev']",,2014.0,,missing
