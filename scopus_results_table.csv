"Authors","Author full names","Author(s) ID","Title","Year","Source title","DOI","Link","Abstract"
"Naghiaei M.; Rahmani H.A.; Dehghan M.","Naghiaei, Mohammadmehdi (57540495200); Rahmani, Hossein A. (57211506304); Dehghan, Mahdi (57207193607)","57540495200; 57211506304; 57207193607","The Unfairness of Popularity Bias in Book Recommendation","2022","Communications in Computer and Information Science","10.1007/978-3-031-09316-6_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134358321&doi=10.1007%2f978-3-031-09316-6_7&partnerID=40&md5=548f25798dbb919d482bf020f932d01b","Recent studies have shown that recommendation systems commonly suffer from popularity bias. Popularity bias refers to the problem that popular items (i.e., frequently rated items) are recommended frequently while less popular items are recommended rarely or not at all. Researchers adopted two approaches to examining popularity bias: (i) from the users’ perspective, by analyzing how far a recommendation system deviates from user’s expectations in receiving popular items, and (ii) by analyzing the amount of exposure that long-tail items receive, measured by overall catalog coverage and novelty. In this paper, we examine the first point of view in the book domain, although the findings may be applied to other domains as well. To this end, we analyze the well-known Book-Crossing dataset and define three user groups based on their tendency towards popular items (i.e., Niche, Diverse, Bestseller-focused). Further, we evaluate the performance of nine state-of-the-art recommendation algorithms and two baselines (i.e., Random, MostPop) from both the accuracy (e.g., NDCG, Precision, Recall) and popularity bias perspectives. Our results indicate that most state-of-the-art recommendation algorithms suffer from popularity bias in the book domain, and fail to meet users’ expectations with Niche and Diverse tastes despite having a larger profile size. Conversely, Bestseller-focused users are more likely to receive high-quality recommendations, both in terms of fairness and personalization. Furthermore, our study shows a tradeoff between personalization and unfairness of popularity bias in recommendation algorithms for users belonging to the Diverse and Bestseller groups, that is, algorithms with high capability of personalization suffer from the unfairness of popularity bias. Finally, across the models, our results show that WMF and VAECF can provide a higher quality recommendation when considering both accuracy and fairness perspectives. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG."
"Ekstrand M.D.; Kluver D.","Ekstrand, Michael D. (35302511500); Kluver, Daniel (55386812200)","35302511500; 55386812200","Exploring author gender in book rating and recommendation","2021","User Modeling and User-Adapted Interaction","10.1007/s11257-020-09284-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100480096&doi=10.1007%2fs11257-020-09284-2&partnerID=40&md5=7991afa561912376badc656d08226e18","Collaborative filtering algorithms find useful patterns in rating and consumption data and exploit these patterns to guide users to good items. Many of these patterns reflect important real-world phenomena driving interactions between the various users and items; other patterns may be irrelevant or reflect undesired discrimination, such as discrimination in publishing or purchasing against authors who are women or ethnic minorities. In this work, we examine the response of collaborative filtering recommender algorithms to the distribution of their input data with respect to one dimension of social concern, namely content creator gender. Using publicly available book ratings data, we measure the distribution of the genders of the authors of books in user rating profiles and recommendation lists produced from this data. We find that common collaborative filtering algorithms tend to propagate at least some of each user’s tendency to rate or read male or female authors into their resulting recommendations, although they differ in both the strength of this propagation and the variance in the gender balance of the recommendation lists they produce. The data, experimental design, and statistical methods are designed to be reusable for studying potentially discriminatory social dimensions of recommendations in other domains and settings as well. © 2021, Springer Nature B.V."
"Ding K.; Chin M.; Zhao Y.; Huang W.; Mai B.K.; Wang H.; Liu P.; Yang Y.; Luo Y.","Ding, Kerr (58290068800); Chin, Michael (57414207100); Zhao, Yunlong (58497254600); Huang, Wei (59240166300); Mai, Binh Khanh (57200220618); Wang, Huanan (59239990900); Liu, Peng (57202809452); Yang, Yang (56316427800); Luo, Yunan (57201793688)","58290068800; 57414207100; 58497254600; 59240166300; 57200220618; 59239990900; 57202809452; 56316427800; 57201793688","Machine learning-guided co-optimization of fitness and diversity facilitates combinatorial library design in enzyme engineering","2024","Nature Communications","10.1038/s41467-024-50698-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199981329&doi=10.1038%2fs41467-024-50698-y&partnerID=40&md5=326d730eddebcb8b6d2bdad5498db21f","The effective design of combinatorial libraries to balance fitness and diversity facilitates the engineering of useful enzyme functions, particularly those that are poorly characterized or unknown in biology. We introduce MODIFY, a machine learning (ML) algorithm that learns from natural protein sequences to infer evolutionarily plausible mutations and predict enzyme fitness. MODIFY co-optimizes predicted fitness and sequence diversity of starting libraries, prioritizing high-fitness variants while ensuring broad sequence coverage. In silico evaluation shows that MODIFY outperforms state-of-the-art unsupervised methods in zero-shot fitness prediction and enables ML-guided directed evolution with enhanced efficiency. Using MODIFY, we engineer generalist biocatalysts derived from a thermostable cytochrome c to achieve enantioselective C-B and C-Si bond formation via a new-to-nature carbene transfer mechanism, leading to biocatalysts six mutations away from previously developed enzymes while exhibiting superior or comparable activities. These results demonstrate MODIFY’s potential in solving challenging enzyme engineering problems beyond the reach of classic directed evolution. © The Author(s) 2024."
"Coppock H.; Jones L.; Kiskin I.; Schuller B.","Coppock, Harry (57222152484); Jones, Lyn (7403623582); Kiskin, Ivan (57203321835); Schuller, Björn (6603767415)","57222152484; 7403623582; 57203321835; 6603767415","Bias and privacy in AI's cough-based COVID-19 recognition – Authors' reply","2021","The Lancet Digital Health","10.1016/S2589-7500(21)00233-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119513443&doi=10.1016%2fS2589-7500%2821%2900233-8&partnerID=40&md5=c8094ee357e804fb25d2a61eb8d094f9","[No abstract available]"
"Smart N.","Smart, Ninian (24313515300)","24313515300","I Recommend You to Read: XIII. Recent Books on the Comparative Study of Religion","1968","The Expository Times","10.1177/001452466807900702","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34447479187&doi=10.1177%2f001452466807900702&partnerID=40&md5=dda0a039ce1cf018e67d2eeb137b4019","[No abstract available]"
"Sharifzadeh R.","Sharifzadeh, Rahman (34974829000)","34974829000","ChatGPT as Co-Author? AI and Research Ethics","2024","Ethics in Progress","10.14746/eip.2024.1.8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199256352&doi=10.14746%2feip.2024.1.8&partnerID=40&md5=5f025b9e2e12e5f5cf27f538a75ad3db","Should ChatGPT be viewed merely as a supportive tool for writers, or does it qualify as a co-author? As ChatGPT and similar language models are likely to become more prevalent in assisting with academic writing and research, it seems that we will face with two possibilities: an increase in ghostwriting that could finally undermine the integrity of the knowledge system, or the need to theoretical preparation to recognize the role of non-human contributors. Drawing on Actor-Network Theory, this article examines the question of whether this Chatbot meets, in principle, the requirements for co-authorship. Answering this question in affirmative, it delves into philosophical discussions concerning the agency, moral agency, and moral accountability of such technological entities. © 2024, Adam Mickiewicz University, Faculty of Philosophy. All rights reserved."
"Shepperd M.; Hall T.; Bowes D.","Shepperd, Martin (55909730400); Hall, Tracy (56220907900); Bowes, David (25929085600)","55909730400; 56220907900; 25929085600","Authors' reply to 'comments on 'researcher bias: The use of machine learning in software defect prediction''","2018","IEEE Transactions on Software Engineering","10.1109/TSE.2017.2731308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028922080&doi=10.1109%2fTSE.2017.2731308&partnerID=40&md5=7d3c7542dd61f132b7e7e29a83c2ff42","In 2014 we published a meta-analysis of software defect prediction studies [1] . This suggested that the most important factor in determining results was Research Group, i.e., who conducts the experiment is more important than the classifier algorithms being investigated. A recent re-analysis [2] sought to argue that the effect is less strong than originally claimed since there is a relationship between Research Group and Dataset. In this response we show (i) the re-analysis is based on a small (21 percent) subset of our original data, (ii) using the same re-analysis approach with a larger subset shows that Research Group is more important than type of Classifier and (iii) however the data are analysed there is compelling evidence that who conducts the research has an effect on the results. This means that the problem of researcher bias remains. Addressing it should be seen as a matter of priority amongst those of us who conduct and publish experiments comparing the performance of competing software defect prediction systems. © 1976-2012 IEEE."
"Saxena S.; Jain S.","Saxena, Shrikant (57226826177); Jain, Shweta (57199045752)","57226826177; 57199045752","Exploring and mitigating gender bias in book recommender systems with explicit feedback","2024","Journal of Intelligent Information Systems","10.1007/s10844-023-00827-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188446080&doi=10.1007%2fs10844-023-00827-8&partnerID=40&md5=cb331d7edaab35b9237edb4b854f3506","Recommender systems are indispensable because they influence our day-to-day behavior and decisions by giving us personalized suggestions. Services like Kindle, YouTube, and Netflix depend heavily on the performance of their recommender systems to ensure that their users have a good experience and to increase revenues. Despite their popularity, it has been shown that recommender systems reproduce and amplify the bias present in the real world. The resulting feedback creates a self-perpetuating loop that deteriorates the user experience and results in homogenizing recommendations over time. Further, biased recommendations can also reinforce stereotypes based on gender or ethnicity, thus reinforcing the filter bubbles that we live in. In this paper, we address the problem of gender bias in recommender systems with explicit feedback. We propose a model to quantify the gender bias present in book rating datasets and in the recommendations produced by the recommender systems. Our main contribution is to provide a principled approach to mitigate the bias being produced in the recommendations. We theoretically show that the proposed approach provides unbiased recommendations despite biased data. Through empirical evaluation of publicly available book rating datasets, we further show that the proposed model can significantly reduce bias without significant impact on accuracy and outperforms the existing model in terms of bias. Our method is model-agnostic and can be applied to any recommender system. To demonstrate the performance of our model, we present the results on four recommender algorithms, two from the K-nearest neighbors family, UserKNN and ItemKNN, and the other two from the matrix factorization family, Alternating Least Square and Singular Value Decomposition. The extensive simulations of various recommender algorithms show the generality of the proposed approach. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024."
"Akbulut S.; Sahin T.T.","Akbulut, Sami (25959851900); Sahin, Tevfik Tolga (17435600600)","25959851900; 17435600600","Recommendations for the ethical guidelines for publication of scientific studies: The responsibilities of editors, reviewers and the authors","2021","Annals of Medicine and Surgery","10.1016/j.amsu.2021.103047","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119080099&doi=10.1016%2fj.amsu.2021.103047&partnerID=40&md5=0c270e5b96ef17b427db4abf4a9151e4","Objective: We aimed to evaluate the role of anesthesiologist in the management of hydatid disease from the perspective of the editors, reviewers and the authors. Methods: We searched the PubMed/Medline database using the following keywords: (hydatid* OR echinococc*) AND (disease OR cyst) AND (anesthesiology). We have evaluated the authors, their institutions and department, and the aim of the studies. We also evaluated the studies published by anesthesiologists in terms of content. Results: The literature search showed 6344 articles published between February 2010 to 2021. Sixty-three had at least one anesthesiologist in the author list. Anesthesiologists were leading authors in 35 studies; and in 19 of them, all the authors were anesthesiologist. Sixteen (84.2%) of these articles defined the outcomes of surgical therapy and there was no information regarding anesthesia technique. Conclusion: The results of our study emphasize an important controversy regarding jurisdiction of different departments in terms of scientific research ethics. We believe that different disciplines can work together to evaluate a scientific problem and can publish a study in collaboration. But collaboration is very important and violating the subject of another field without collaboration is a deontological problem. © 2021"
"Bubinger H.; Dinneen J.D.","Bubinger, Helen (57226267698); Dinneen, Jesse David (55885209300)","57226267698; 55885209300","Actionable Approaches to Promote Ethical AI in Libraries","2021","Proceedings of the Association for Information Science and Technology","10.1002/pra2.528","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139980635&doi=10.1002%2fpra2.528&partnerID=40&md5=89bbdb8bb5d8983cf55d3b2c66682337","The widespread use of artificial intelligence (AI) in many domains has revealed numerous ethical issues from data and design to deployment. In response, countless broad principles and guidelines for ethical AI have been published, and following those, specific approaches have been proposed for how to encourage ethical outcomes of AI. Meanwhile, library and information services too are seeing an increase in the use of AI-powered and machine learning-powered information systems, but no practical guidance currently exists for libraries to plan for, evaluate, or audit the ethics of intended or deployed AI. We therefore report on several promising approaches for promoting ethical AI that can be adapted from other contexts to AI-powered information services and in different stages of the software lifecycle.  Annual Meeting of the Association for Information Science & Technology | Oct. 29 – Nov. 3, 2021 | Salt Lake City, UT. Author(s) retain copyright, but ASIS&T receives an exclusive publication license."
"Kuldeep J.; Chaturvedi N.; Gupta D.","Kuldeep, Jitendra (57063420100); Chaturvedi, Neeraj (57751725400); Gupta, Dinesh (57203635807)","57063420100; 57751725400; 57203635807","Novel molecular inhibitor design for Plasmodium falciparum Lactate dehydrogenase enzyme using machine learning generated library of diverse compounds","2024","Molecular Diversity","10.1007/s11030-024-10960-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201644438&doi=10.1007%2fs11030-024-10960-3&partnerID=40&md5=6a73dbdf178004b99bf18cfdc0211729","Generative machine learning models offer a novel strategy for chemogenomics and de novo drug design, allowing researchers to streamline their exploration of the chemical space and concentrate on specific regions of interest. In cases with limited inhibitor data available for the target of interest, de novo drug design plays a crucial role. In this study, we utilized a package called 'mollib,' trained on ChEMBL data containing approximately 365,000 bioactive molecules. By leveraging transfer learning techniques with this package, we generated a series of compounds, starting from five initial compounds, which are potential Plasmodium falciparum (Pf) Lactate dehydrogenase inhibitors. The resulting compounds exhibit structural diversity and hold promise as potential novel Pf Lactate dehydrogenase inhibitors. Graphical Abstract: (Figure presented.). © The Author(s), under exclusive licence to Springer Nature Switzerland AG 2024."
"Jones B.E.","Jones, Bernard E. (57189419137)","57189419137","I Recommend you to Read: III. Books on Philosophy of Religion (1951-1966)","1967","The Expository Times","10.1177/001452466707800402","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970699879&doi=10.1177%2f001452466707800402&partnerID=40&md5=78ac08e690a81c2295972dea12077a11","[No abstract available]"
"Li L.; Gupta E.; Spaeth J.; Shing L.; Jaimes R.; Engelhart E.; Lopez R.; Caceres R.S.; Bepler T.; Walsh M.E.","Li, Lin (57207133427); Gupta, Esther (57928911300); Spaeth, John (57928724000); Shing, Leslie (57205700290); Jaimes, Rafael (57880402200); Engelhart, Emily (58817669700); Lopez, Randolph (57944958800); Caceres, Rajmonda S. (55002731100); Bepler, Tristan (56523363100); Walsh, Matthew E. (57943737800)","57207133427; 57928911300; 57928724000; 57205700290; 57880402200; 58817669700; 57944958800; 55002731100; 56523363100; 57943737800","Machine learning optimization of candidate antibody yields highly diverse sub-nanomolar affinity antibody libraries","2023","Nature Communications","10.1038/s41467-023-39022-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161922820&doi=10.1038%2fs41467-023-39022-2&partnerID=40&md5=2589aac293c08cc18014db0f3568ed21","Therapeutic antibodies are an important and rapidly growing drug modality. However, the design and discovery of early-stage antibody therapeutics remain a time and cost-intensive endeavor. Here we present an end-to-end Bayesian, language model-based method for designing large and diverse libraries of high-affinity single-chain variable fragments (scFvs) that are then empirically measured. In a head-to-head comparison with a directed evolution approach, we show that the best scFv generated from our method represents a 28.7-fold improvement in binding over the best scFv from the directed evolution. Additionally, 99% of designed scFvs in our most successful library are improvements over the initial candidate scFv. By comparing a library’s predicted success to actual measurements, we demonstrate our method’s ability to explore tradeoffs between library success and diversity. Results of our work highlight the significant impact machine learning models can have on scFv development. We expect our method to be broadly applicable and provide value to other protein engineering tasks. © 2023, The Author(s)."
"Bubinger H.; Dinneen J.D.","Bubinger, Helen (57226267698); Dinneen, Jesse David (55885209300)","57226267698; 55885209300","“What could go wrong?”: An evaluation of ethical foresight analysis as a tool to identify problems of AI in libraries","2024","Journal of Academic Librarianship","10.1016/j.acalib.2024.102943","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201900173&doi=10.1016%2fj.acalib.2024.102943&partnerID=40&md5=5767da29ced175a74cf75f28f65c0d8e","Artificial intelligence (AI) has entered libraries in various ways and raised concern about its potential ethical consequences therein. A number of approaches have been developed to encourage ethical AI and audit the ethics of specific AI applications, but very few approaches have been applied or tested, especially in a library setting, and so it remains unclear which, if any approaches are suitable or useful for encouraging ethical AI in libraries. We applied Ethical Foresight Analysis as an approach to identify possible ethical risks of an AI project for (semi-)automated subject indexing in a large research library. Specifically, to identify risks we conducted a two-round ethical Delphi study wherein experts on AI development, library practices, and AI ethics sought consensus on potential risks and their relative importance. The experts' post-test reflections on the procedure were then collected to inform an evaluation of the approach's feasibility. A variety of ethical risks of the specific project and of general AI indexing were indeed identified, most notably discrimination and under-representation stemming from attributes of the bibliographic training data provided by the library (e.g. varied historical contexts and gaps left by unindexed items). However, we identified some drawbacks of the approach tested: (1) it is time-consuming, which is likely prohibitive for many libraries, and (2) the identified risks were mainly well-known issues of AI and its training data rather than the subtle, application-specific, and human-centred issues that ethical foresight analysis might be employed to identify. Thus, although libraries should continue to model ethical AI through careful planning and auditing, alternative development and auditing approaches may be more practical to undertake and more effective at identifying novel or application-specific issues. © 2024 Elsevier Inc."
"Korosec M.R.","Korosec, Mojca Rupar (57580556400)","57580556400","Libraries and artificial intelligence: The power of enhancing data ethics","2021","Handbook of Research on Knowledge and Organization Systems in Library and Information Science","10.4018/978-1-7998-7258-0.ch023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128438888&doi=10.4018%2f978-1-7998-7258-0.ch023&partnerID=40&md5=5c56c52856b21582737306bca2fa59dd","Libraries are increasingly entering the digital age, and demands on them to offer more digital services are widening, with user expectations of ""remote or distant access,"" ""distant learning,"" and the use of other modern internet technologies. To this end, libraries must accelerate their use of technologies like AI, ""data mining,"" ""machine-readable data,"" ""machine-generated classification,"" ""semantic ontologies,"" and internet accessible catalogs and content because their aim should always be user benefit, user convenience, and user satisfaction. In this chapter, the author examines ways in which technologies and libraries are trying to fulfill their modern role and expectations of the modern user. Additionally, the author will examine how to strengthen data ethics in those particular fields of library use that most endanger the user's intellectual freedom on one side and his right to privacy on the other. One of the essential roles of modern libraries, in their new ""informational"" identity, will be as ""guardians of data ethics and intellectual freedom."" © 2021, IGI Global."
"Sboev A.; Moloshnikov I.; Gudovskikh D.; Rybka R.","Sboev, Aleksandr (57194755264); Moloshnikov, Ivan (57188749063); Gudovskikh, Dmitry (57188749022); Rybka, Roman (55696423700)","57194755264; 57188749063; 57188749022; 55696423700","A gender identification of Russian text author on base of multigenre data-driven approach using machine learning models","2018","International Conference on Multidisciplinary Research","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113839710&partnerID=40&md5=f3bb370c1ed30334cfa2c96735a77689","In this work data-driven approaches to identify the gender of author of Russian text are investigated with the purpose to clarify, to what extent the machine learning models trained on texts of a certain genre could give accurate results on texts of other genre. The set of data corpora includes: one collected by a crowdsourcing platform, essays of Russian students (RusPersonality), Gender Imitation corpus, and the corpora used at Forum for Information Retrieval Evaluation 2017 (FIRE), containing texts from Facebook, Twitter and Reviews. We present the analysis of numerical experiments based on different features(morphological data, vector of character n-gram frequencies, LIWC and others) of input texts along with various machine learning models (neural networks, gradient boosting methods, CNN, LSTM, SVM, Logistic Regression, Random Forest). Results of these experiments are compared with the results of FIRE competition to evaluate effects of multi-genre training. The presented results, obtained on a wide set of data-driven models, establish the accuracy level for the task to identify gender of an author of a Russian text in the multi-genre case. As shown, an average loss in F1 because of training on a set of genre other than the one used to test is about 11.7%. © International Conference on Multidisciplinary Research.All right reserved."
"Preston C.R.H.","Preston, Canon Ronald H. (57189562891)","57189562891","I Recommend You to Read: XI. Recent Books on Christian Ethics","1968","The Expository Times","10.1177/001452466807900502","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976926222&doi=10.1177%2f001452466807900502&partnerID=40&md5=25dc1e57bf30fdc9fbe46c680ed9ad69","[No abstract available]"
"Daniil S.","Daniil, Savvina (57872100800)","57872100800","Ethical Recommenders in the Public Library Sector","2022","AIES 2022 - Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society","10.1145/3514094.3539536","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137157847&doi=10.1145%2f3514094.3539536&partnerID=40&md5=2ac320ac8aa9313226af62b3ab7a5afb","Recommender Systems as an algorithmic class hide lurking risks despite their prevalence in academic and commercial circles. My specific research revolves around tracking and mitigating potential risks specifically in the Public Library domain. In collaboration with the National Library of The Netherlands, I am working on investigating whether the incorporation of Recommenders in a library's loaning system serves their social responsibility and purpose, with securing inclusivity being the main point of interest.  © 2022 Owner/Author."
"Ray P.P.; Majumder P.","Ray, Partha Pratim (56577228400); Majumder, Poulami (57201538175)","56577228400; 57201538175","Re: Comments on “The Potential of ChatGPT to Transform Healthcare and Address Ethical Challenges in Artificial Intelligence-Driven Medicine”: Author Response","2024","Journal of Clinical Neurology (Korea)","10.3988/jcn.2023.0338","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182469310&doi=10.3988%2fjcn.2023.0338&partnerID=40&md5=01ee2a6436842b208279ba8f2364a06c","[No abstract available]"
"Jang Y.; Choi S.; Kim H.","Jang, Yeonju (57224970016); Choi, Seongyune (58886095800); Kim, Hyeoncheol (55810210600)","57224970016; 58886095800; 55810210600","Author Correction: Development and validation of an instrument to measure undergraduate students’ attitudes toward the ethics of artificial intelligence (AT-EAI) and analysis of its difference by gender and experience of AI education (Education and Information Technologies, (2022), 27, 8, (11635-11667), 10.1007/s10639-022-11086-5)","2022","Education and Information Technologies","10.1007/s10639-022-11164-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132283702&doi=10.1007%2fs10639-022-11164-8&partnerID=40&md5=b6f14247ac1e847a7d9d67a8f92685dd","Corrections are needed to the original publication. In the 2nd paragraph of page 9, the Korean sentences should have been translated to English. The original article has been corrected. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2022."
"Thornley C.; Bustillo M.; Supprian C.S.","Thornley, Clare (22036720400); Bustillo, Marta (57224726435); Supprian, Christoph Schmidt (58040339500)","22036720400; 57224726435; 58040339500","The Ethics of Classifying the World: From Library Catalogues to AI","2022","Proceedings of the European Conference on Knowledge Management, ECKM","10.34190/eckm.23.2.514","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145439516&doi=10.34190%2feckm.23.2.514&partnerID=40&md5=8915459878ac69ac6eb09b5cbf2afc3b","This paper reports on an initial exploration of knowledge classification ethics: What are the important ethical issues in how we classify knowledge and what kind of cognitive, cultural and social impacts may they have? An important part of Knowledge Management is the classification and organisation of knowledge to make it findable and reveal connections in related subjects. Discussion on the ethical aspects of this issue have recently been brought to the fore in both Library and Information Studies (LIS), in terms of objections to Library classification terms, and also in AI which can classify data using data sets which themselves reflect existing injustices and bias. The ethical implications of both types of knowledge classification can be better understood when the classification ethics debate in LIS and AI are used to inform each other. Findings include that AI provides clarity on measuring adverse outcomes whilst LIS provides nuance on the potential cultural and psychological harm of inappropriate terminology and inaccurate positioning within ‘worlds of knowledge’. © 2022, Academic Conferences and Publishing International Limited. All rights reserved."
"Collins A.; Tkaczyk D.; Aizawa A.; Beel J.","Collins, Andrew (57201352640); Tkaczyk, Dominika (55247189800); Aizawa, Akiko (6701312731); Beel, Joeran (36695913300)","57201352640; 55247189800; 6701312731; 36695913300","Position bias in recommender systems for digital libraries","2018","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10.1007/978-3-319-78105-1_37","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044426402&doi=10.1007%2f978-3-319-78105-1_37&partnerID=40&md5=d27cebecd9eb33a958f1cfe5bd3c82a9","“Position bias” describes the tendency of users to interact with items on top of a list with higher probability than with items at a lower position in the list, regardless of the items’ actual relevance. In the domain of recommender systems, particularly recommender systems in digital libraries, position bias has received little attention. We conduct a study in a real-world recommender system that delivered ten million related-article recommendations to the users of the digital library Sowiport, and the reference manager JabRef. Recommendations were randomly chosen to be shuffled or non-shuffled, and we compared click-through rate (CTR) for each rank of the recommendations. According to our analysis, the CTR for the highest rank in the case of Sowiport is 53% higher than expected in a hypothetical non-biased situation (0.189% vs. 0.123%). Similarly, in the case of Jabref the highest rank received a CTR of 1.276%, which is 87% higher than expected (0.683%). A chi-squared test confirms the strong relationship between the rank of the recommendation shown to the user and whether the user decided to click it (p < 0.01 for both Jabref and Sowiport). Our study confirms the findings from other domains, that recommendations in the top positions are more often clicked, regardless of their actual relevance. © Springer International Publishing AG, part of Springer Nature 2018."
"Ingram E.; Cahill M.","Ingram, Erin (57219916285); Cahill, Maria (55545273000)","57219916285; 55545273000","Depictions of Diversity in Books Recommended for Storytime: A Cautionary Tale","2022","Libri","10.1515/libri-2021-0126","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133845740&doi=10.1515%2flibri-2021-0126&partnerID=40&md5=0b088f80d128d7d6b290df90a4f489e3","Elements of equity, diversity, and inclusion (EDI) in diverse books support children's intellectual, social, and emotional development. Public library storytime programs serve as venues to showcase books with characters of varied backgrounds, identities, and experiences who may or may not reflect those of the communities the libraries serve. Because storytime providers often rely on online resources to plan their programs, it is important to investigate the presence and quality of EDI elements in books recommended for storytimes by these resources. The present study analyzed the text, illustrations, and WorldCat metadata for a random sample of 481 children's books recommended by six popular online resources for storytime planning. Results revealed an overall lack of EDI in the recommended books with few characters representing parallel cultures, living with a disability or chronic illness, practicing a religion other than Christianity, or communicating in a language other than English. The paper includes implications for storytime providers and library administrators in the areas of program planning, professional development, and program assessment. © 2022 Walter de Gruyter GmbH, Berlin/Boston."
"Brown L.M.","Brown, Laila M. (57291869400)","57291869400","Gendered Artificial Intelligence in Libraries: Opportunities to Deconstruct Sexism and Gender Binarism","2022","Journal of Library Administration","10.1080/01930826.2021.2006979","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120702212&doi=10.1080%2f01930826.2021.2006979&partnerID=40&md5=34afcee8cf27acb57b99f84c5899da83","Historically, the majority of digital assistants, including chatbots, have been assigned names, voices, visual representations, and even “personalities” that are stereotypically feminine and reflect patriarchal ideology. This cross-sectional descriptive study of chatbots associated with large academic libraries in the United States found that there are few extant library chatbots, and in a major departure from trends, there are even fewer that are gendered. This is promising, in that it signals—whether intentionally or not—that the practices of creators and adopters are countering entrenched tendencies to typecast digital assistants as women, which may signal more feminist and gender-inclusive technology design to come. © 2021 The Author(s). Published with license by Taylor & Francis Group, LLC."
"Shen L.; Jiang L.","Shen, Lijuan (58983625400); Jiang, Liping (58983958400)","58983625400; 58983958400","Eliminating bias: enhancing children’s book recommendation using a hybrid model of graph convolutional networks and neural matrix factorization","2024","PeerJ Computer Science","10.7717/peerj-cs.1858","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190275288&doi=10.7717%2fpeerj-cs.1858&partnerID=40&md5=5d0f6d16bef32eae8f732485e1e4b578","Managing user bias in large-scale user review data is a significant challenge in optimizing children’s book recommendation systems. To tackle this issue, this study introduces a novel hybrid model that combines graph convolutional networks (GCN) based on bipartite graphs and neural matrix factorization (NMF). This model aims to enhance the precision and efficiency of children’s book recommendations by accurately capturing user biases. In this model, the complex interactions between users and books are modeled as a bipartite graph, with the users’ book ratings serving as the weights of the edges. Through GCN and NMF, we can delve into the structure of the graph and the behavioral patterns of users, more accurately identify and address user biases, and predict their future behaviors. Compared to traditional recommendation systems, our hybrid model excels in handling large-scale user review data. Experimental results confirm that our model has significantly improved in terms of recommendation accuracy and scalability, positively contributing to the advancement of children’s book recommendation systems. © 2024 Shen and Jian"
"Tizpaz-Niari S.; Kumar A.; Tan G.; Trivedi A.","Tizpaz-Niari, Saeid (57193916304); Kumar, Ashish (57208058157); Tan, Gang (57192503632); Trivedi, Ashutosh (7006248965)","57193916304; 57208058157; 57192503632; 7006248965","Fairness-aware Configuration of Machine Learning Libraries","2022","Proceedings - International Conference on Software Engineering","10.1145/3510003.3510202","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131378824&doi=10.1145%2f3510003.3510202&partnerID=40&md5=d581225a80d3c8bd9ceeb99e8b568dbd","This paper investigates the parameter space of machine learning (ML) algorithms in aggravating or mitigating fairness bugs. Data-driven software is increasingly applied in social-critical applications where ensuring fairness is of paramount importance. The existing approaches focus on addressing fairness bugs by either modifying the input dataset or modifying the learning algorithms. On the other hand, the selection of hyperparameters, which provide finer controls of ML algorithms, may enable a less intrusive approach to influence the fairness. Can hyperparameters amplify or suppress discrimination present in the input dataset? How can we help programmers in detecting, understanding, and exploiting the role of hyperparameters to improve the fairness? We design three search-based software testing algorithms to un-cover the precision-fairness frontier of the hyperparameter space. We complement these algorithms with statistical debugging to explain the role of these parameters in improving fairness. We implement the proposed approaches in the tool Parfait-ML (PARameter FAIrness Testing for ML Libraries) and show its effectiveness and utility over five mature ML algorithms as used in six social-critical applications. In these applications, our approach successfully iden-tified hyperparameters that significantly improve (vis-a-vis the state-of-the-art techniques) the fairness without sacrificing precision. Surprisingly, for some algorithms (e.g., random forest), our approach showed that certain configuration of hyperparameters (e.g., restricting the search space of attributes) can amplify biases across applications. Upon further investigation, we found intuitive explanations of these phenomena, and the results corroborate simi-lar observations from the literature. © 2022 ACM."
"Sboev A.; Moloshnikov I.; Gudovskikh D.; Selivanov A.; Rybka R.; Litvinova T.","Sboev, Alexander (57194755264); Moloshnikov, Ivan (57188749063); Gudovskikh, Dmitry (57188749022); Selivanov, Anton (55183531800); Rybka, Roman (55696423700); Litvinova, Tatiana (56638057700)","57194755264; 57188749063; 57188749022; 55183531800; 55696423700; 56638057700","Deep learning neural nets versus traditional machine learning in gender identification of authors of rusprofiling texts","2018","Procedia Computer Science","10.1016/j.procs.2018.01.065","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045647592&doi=10.1016%2fj.procs.2018.01.065&partnerID=40&md5=044c64bedd5d079559d7a39402278936","In this paper we compare accuracies of solving the task of gender identification of RusPro-filing texts without gender deception on base of two types of data-driven modeling approaches: On the one hand, well-known conventional machine learning algorithms, such as Support Vec-tor machine, Gradient Boosting; and, on the other hand, the set of Deep Learning neuronets, such as neuronet topologies with convolution, fully-connected, and Long Short-Term Memory layers, etc. The dependence of effectiveness of these models on the feature selection and on their representation is investigated. The obtained F1-score of 88% establishes the state of the art in the gender identification task with the RusProfiling corpus. © 2018 The Authors."
"Sboev A.; Moloshnikov I.; Gudovskikh D.; Selivanov A.; Rybka R.; Litvinova T.","Sboev, Alexander (57194755264); Moloshnikov, Ivan (57188749063); Gudovskikh, Dmitry (57188749022); Selivanov, Anton (55183531800); Rybka, Roman (55696423700); Litvinova, Tatiana (56638057700)","57194755264; 57188749063; 57188749022; 55183531800; 55696423700; 56638057700","Automatic gender identification of author of Russian text by machine learning and neural net algorithms in case of gender deception","2018","Procedia Computer Science","10.1016/j.procs.2018.01.064","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045661273&doi=10.1016%2fj.procs.2018.01.064&partnerID=40&md5=8c621c77c36dedba24eb0284d752568d","We present the analysis of approaches to solve an author gender identification task for Russian-language texts with gender deception, using different Data-Driven models based on conventional machine learning (Support Vector Classifier, Decision Tree, Gradient Boosting) and neuronet algorithms (convolutional layers, long short-term memory layers, etc.) The source of training and testing data are collections of texts from the Gender Imitation corpus, expanded by crowd-sourcing and supplemented with files of RusProfiling and RusPersonality corpora. The reached accuracy of this task milestone is presented and discussed. © 2018 The Authors."
"Wiens J.; Saria S.; Sendak M.; Ghassemi M.; Liu V.X.; Doshi-Velez F.; Jung K.; Heller K.; Kale D.; Saeed M.; Ossorio P.N.; Thadaney-Israni S.; Goldenberg A.","Wiens, Jenna (37110475500); Saria, Suchi (56014917500); Sendak, Mark (57192239737); Ghassemi, Marzyeh (56305414400); Liu, Vincent X. (35558866700); Doshi-Velez, Finale (34874672900); Jung, Kenneth (13607618300); Heller, Katherine (12140502600); Kale, David (34872150800); Saeed, Mohammed (7202098304); Ossorio, Pilar N. (58205858900); Thadaney-Israni, Sonoo (57208575489); Goldenberg, Anna (57209785076)","37110475500; 56014917500; 57192239737; 56305414400; 35558866700; 34874672900; 13607618300; 12140502600; 34872150800; 7202098304; 58205858900; 57208575489; 57209785076","Author Correction: Do no harm: a roadmap for responsible machine learning for health care (Nature Medicine, (2019), 25, 9, (1337-1340), 10.1038/s41591-019-0548-6)","2019","Nature Medicine","10.1038/s41591-019-0609-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073082435&doi=10.1038%2fs41591-019-0609-x&partnerID=40&md5=bde3a7496c8d435a50322f3b1306d528","In the version of this article initially published, an affiliation was missing for author Anna Goldenberg: Child and Brain Development Program, CIFAR, Toronto, Ontario, Canada. The error has been corrected in the HTML and PDF versions of the article. © 2019, Springer Nature America, Inc."
"Kovacs E.-R.; Cotfas L.-A.; Delcea C.","Kovacs, Erik-Robert (57940068700); Cotfas, Liviu-Adrian (36090880700); Delcea, Camelia (34871785800)","57940068700; 36090880700; 34871785800","Measuring Gender: A Machine Learning Approach to Social Media Demographics and Author Profiling","2023","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10.1007/978-3-031-41456-5_26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172416915&doi=10.1007%2f978-3-031-41456-5_26&partnerID=40&md5=064c6bff1f2ba6d34bf2627000a6bc0d","Social media has become a preeminent medium of communication during the early 21st century, facilitating dialogue between the political sphere, businesses, scientific experts, and everyday people. Researchers in the social sciences are focusing their attention on social media as a central site of social discourse, but such approaches are hampered by the lack of demographic data that could help them connect phenomena originating in social media spaces to their larger social context. Computational social science methods which use machine learning and deep learning natural language processing (NLP) tools for the task of author profiling (AP) can serve as an essential complement to such research. One of the major demographic categories of interest concerning social media is the gender distribution of users. We propose an ensemble of multiple machine learning classifiers able to distinguish whether a user is anonymous with an F1 score of 90.24%, then predict the gender of the user based on their name, obtaining an F1 score of 89.22%. We apply the classification pipeline to a set of approximately 44,000,000 posts related to COVID-19 extracted from the social media platform Twitter, comparing our results to a benchmark classifier trained on the PAN18 Author Profiling dataset, showing the validity of the proposed approach. An n-gram analysis on the text of the tweets to further compare the two methods has been performed. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG."
"Kavak A.","Kavak, Ali (58642103000)","58642103000","Ethical considerations and privacy concerns in AI-enabled libraries","2024","Applications of Artificial Intelligence in Libraries","10.4018/979-8-3693-1573-6.ch003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194748305&doi=10.4018%2f979-8-3693-1573-6.ch003&partnerID=40&md5=3e757f73a4d50c08f60493f4ca47b0bf","The primary aim of this chapter is to discuss the ethical dilemmas and privacy concerns that the adoption of artificial intelligence technologies in libraries may bring.In particular, it addresses how artificial intelligence can be used in library services and the associated risks, such as bias, discrimination, lack of transparency, and violations of data privacy. Also explores how artificial intelligence systems can impact human-machine interaction and the potential for replacing library staff. © 2024 by IGI Global. All rights reserved."
"Bradley F.","Bradley, Fiona (25642672500)","25642672500","Representation of Libraries in Artificial Intelligence Regulations and Implications for Ethics and Practice","2022","Journal of the Australian Library and Information Association","10.1080/24750158.2022.2101911","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135832248&doi=10.1080%2f24750158.2022.2101911&partnerID=40&md5=1ff33093412d54d1b2d582fce4f4fe00","We are already living in an algorithmic society. AI policies and regulations are now emerging at the same time as more is learned about the implications of bias in machine learning sets, the surveillance risks of smart cities and facial recognition, and automated decision-making by government, among many other applications of AI and machine learning. Each of these issues raises concerns around ethics, privacy, and data protection. This paper introduces some of the key AI regulatory developments to date and engagement by libraries in these processes. While many AI applications are largely emergent and hypothetical in libraries, some mature examples can be identified in research literature searching, language tools for textual analysis, and access to collection data. The paper presents a summary of how library activities such as these are represented in national AI plans and ways that libraries have engaged with other aspects of AI regulation including the development of ethical frameworks. Based on the sector's expertise in related regulatory issues including copyright and data protection, the paper suggests further opportunities to contribute to the future of ethical, trustworthy, and transparent AI. © 2022 Fiona Bradley."
"Ishag M.I.M.; Park K.H.; Lee J.Y.; Ryu K.H.","Ishag, Musa Ibrahim Musa (55322249500); Park, Kwang Ho (57194613010); Lee, Jong Yun (55818539100); Ryu, Keun Ho (7202685903)","55322249500; 57194613010; 55818539100; 7202685903","A Pattern-Based Academic Reviewer Recommendation Combining Author-Paper and Diversity Metrics","2019","IEEE Access","10.1109/ACCESS.2019.2894680","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061698863&doi=10.1109%2fACCESS.2019.2894680&partnerID=40&md5=7fa7b75038dc7022b47bb62edd75346a","With the rapid increase of publishable research articles and manuscripts, the pressure to find reviewers often overwhelms the journal editors. This paper incorporates the major entity level metrics found in the heterogeneous publication networks into a pattern mining process in order to recommend academic reviewers and potential research collaborators. In essence, the paper integrates authors' h-index and papers' citation count and proposes a quantification to account for the author diversity into one formula duped impact to measure the real influence of a scientific paper. Thereafter, this paper formulates two kinds of target patterns and mines them harnessing the high-utility itemset mining (HUIM) framework. The first pattern, researcher-general topic patterns (RGP), is a pattern that includes only researchers; whereas, the researcher-specific topic patterns (RSP) is comprised of combinations of researchers and keywords that summarize their niche of expertise. The HUI algorithms of Two Phase, IHUP, UP-Growth, FHM, FHN, HUINIV-Mine, D2HUP, and EFIM were compared on two real-world citation datasets related to Deep Learning and HUIM, in addition to the open source mushroom dataset. The EFIM algorithm showed good performance in terms of run time and memory usage. Consequently, it was then used to mine the patterns within the proposed framework. The discovered patterns of RGP and RSP showed high coverage, proving the efficiency of the proposed framework. © 2019 IEEE."
"Baxevanakis S.; Gavras S.; Mouratidis D.; Kermanidis K.L.","Baxevanakis, Spiros (57218222981); Gavras, Stelios (57216974284); Mouratidis, Despoina (57205544531); Kermanidis, Katia Lida (23090984000)","57218222981; 57216974284; 57205544531; 23090984000","A machine learning approach for gender identification of Greek tweet authors","2020","ACM International Conference Proceeding Series","10.1145/3389189.3397992","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088371912&doi=10.1145%2f3389189.3397992&partnerID=40&md5=dfb7be61c16b0abdb84d3de8b3d5cb3c","Digital communities and social media are widely used and produce a huge amount of information every second. Text analysis has been widely used by researchers and machine learning (ML) engineers for automating the author profiling task. Author profiling can be used in marketing and business intelligence frameworks but also remains a strong factor in crime investigations gaining more insight regarding the suspect. In this paper we describe the process we used in obtaining a new Twitter corpus and propose an ML approach to determine the gender of Greek author's tweets. The best result (0.7 accuracy) was obtained using SVMs and TF-IDF encoding. © 2020 ACM."
"Macgregor R.","Macgregor, Rachel (58600120800)","58600120800","Responsible Operations: Data Science, Machine Learning, and AI in Libraries","2020","American Archivist","10.17723/0360-9081-83.2.483","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161958180&doi=10.17723%2f0360-9081-83.2.483&partnerID=40&md5=004340fbe235dde0173019150a011403","[No abstract available]"
"Ekstrand M.D.; Tian M.; Imran Kazi M.R.; Mehrpouyan H.; Kluver D.","Ekstrand, Michael D. (35302511500); Tian, Mucun (57204708398); Imran Kazi, Mohammed R. (57204712789); Mehrpouyan, Hoda (55221145400); Kluver, Daniel (55386812200)","35302511500; 57204708398; 57204712789; 55221145400; 55386812200","Exploring author gender in book rating and recommendation","2018","RecSys 2018 - 12th ACM Conference on Recommender Systems","10.1145/3240323.3240373","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056759148&doi=10.1145%2f3240323.3240373&partnerID=40&md5=5b586000fb0b71495751135c85ffdb85","Collaborative filtering algorithms find useful patterns in rating and consumption data and exploit these patterns to guide users to good items. Many of the patterns in rating datasets reflect important real-world differences between the various users and items in the data; other patterns may be irrelevant or possibly undesirable for social or ethical reasons, particularly if they reflect undesired discrimination, such as gender or ethnic discrimination in publishing. In this work, we examine the response of collaborative filtering recommender algorithms to the distribution of their input data with respect to a dimension of social concern, namely content creator gender. Using publicly-available book ratings data, we measure the distribution of the genders of the authors of books in user rating profiles and recommendation lists produced from this data. We find that common collaborative filtering algorithms differ in the gender distribution of their recommendation lists, and in the relationship of that output distribution to user profile distribution. © 2018 Copyright held by the owner/author(s)."
"Kim S.-J.","Kim, Sang-Jun (57218797073)","57218797073","Research ethics and issues regarding the use of ChatGPT-like artificial intelligence platforms by authors and reviewers: a narrative review","2024","Science Editing","10.6087/kcse.343","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201892827&doi=10.6087%2fkcse.343&partnerID=40&md5=14db9fe258c8832cdf7b5783da45428a","While generative artificial intelligence (AI) technology has become increasingly competitive since OpenAI introduced ChatGPT, its widespread use poses significant ethical challenges in research. Excessive reliance on tools like ChatGPT may intensify ethical concerns in scholarly articles. Therefore, this article aims to provide a comprehensive narrative review of the ethical issues associated with using AI in academic writing and to inform researchers of current trends. Our methodology involved a detailed examination of literature on ChatGPT and related research trends. We conducted searches in major databases to identify additional relevant articles and cited literature, from which we collected and analyzed papers. We identified major issues from the literature, categorized into problems faced by authors using nonacademic AI platforms in writing and challenges related to the detection and acceptance of AI-generated content by reviewers and editors. We explored eight specific ethical problems highlighted by authors and reviewers and conducted a thorough review of five key topics in research ethics. Given that nonacademic AI platforms like ChatGPT often do not disclose their training data sources, there is a substantial risk of unattributed content and plagiarism. Therefore, researchers must verify the accuracy and authenticity of AI-generated content before incorporating it into their article, ensuring adherence to principles of research integrity and ethics, including avoidance of fabrication, falsification, and plagiarism. Copyright © 2024 Korean Council of Science Editors"
"Sboev A.; Litvinova T.; Gudovskikh D.; Rybka R.; Moloshnikov I.","Sboev, Aleksandr (57194755264); Litvinova, Tatiana (56638057700); Gudovskikh, Dmitry (57188749022); Rybka, Roman (55696423700); Moloshnikov, Ivan (57188749063)","57194755264; 56638057700; 57188749022; 55696423700; 57188749063","Machine Learning Models of Text Categorization by Author Gender Using Topic-independent Features","2016","Procedia Computer Science","10.1016/j.procs.2016.11.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008262516&doi=10.1016%2fj.procs.2016.11.017&partnerID=40&md5=d3a9c446a06ab83f4d4beb563a05ee01","In the present article, we address the problem of automatic text classification according to the author's gender. We used a preexisting corpus of Russian-language texts RusPersonality labeled with information on their authors (gender, age, psychological testing and so on). We performed the comparative study of machine learning techniques for gender attribution in Russian-language texts after deliberately removing gender bias in topics and genre. The obtained models of classifying Russian texts by their authors' gender demonstrate accuracy close to the state-of-the-art and even higher (up to 0.86 +/-0.03 in Accuracy, 86% in F1-score). © 2016 The Authors. Published by Elsevier B.V."
"Saeidnia H.R.","Saeidnia, Hamid Reza (57221740381)","57221740381","Ethical artificial intelligence (AI): confronting bias and discrimination in the library and information industry","2023","Library Hi Tech News","10.1108/LHTN-10-2023-0182","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174622130&doi=10.1108%2fLHTN-10-2023-0182&partnerID=40&md5=77f9407e58067392f54c2cfd52c9fe22","Purpose: The purpose of this study is to raise awareness about the ethical implications of artificial intelligence (AI) in the library and information industry, specifically focusing on bias and discrimination. It aims to highlight the need for proactive measures to mitigate these issues and ensure that AI technology is developed and implemented in an ethical and unbiased manner. Design/methodology/approach: This viewpoint paper presents a critical analysis of the ethical implications of bias and discrimination in the library and information industry with respect to AI. It explores current practices and challenges in AI implementation and proposes strategies to address bias and discrimination in AI systems. Findings: The findings of this study reveal that bias and discrimination are significant concerns in AI systems used in the library and information industry. These biases can perpetuate existing inequalities, hinder access to information and reinforce discriminatory practices. This study identifies key strategies such as data collection and representation, algorithmic transparency and inclusive design to address these issues. Originality/value: This study contributes to the existing literature by examining the specific challenges of bias and discrimination in AI implementation within the library and information industry. It provides valuable insights into the ethical implications of AI technology and offers practical recommendations for professionals to confront and mitigate bias and discrimination in AI systems, ensuring equitable access to information for all users. © 2023, Emerald Publishing Limited."
"Vysotska V.; Chyrun L.; Chyrun S.; Soltys M.","Vysotska, Victoria (24484045400); Chyrun, Lyubomyr (55225672300); Chyrun, Sofia (57211622785); Soltys, Mariia (59224982400)","24484045400; 55225672300; 57211622785; 59224982400","Information technology for textual content author's gender and age determination based on machine learning","2024","CEUR Workshop Proceedings","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198914736&partnerID=40&md5=2dafaf779a1e321a1e6299357f429998","In the process of implementing this project, namely the project on determining the author's age and gender based on his text, a model was developed that determines these biological data of the author based on his text. Before starting work, similar studies on a similar topic are reviewed to find out what has already been researched and tested, and what is still worth investigating. Also, from these studies, it was possible to find many clues about which implementation methods and tools are better to choose, and which work better for this task. The project work is carefully planned using process diagrams and data flows. The best methods and tools for the implementation of this project were studied, and simple classification and regression models of Random Forest became such tools. Such models were chosen, because they cope with the task quite well, and are much less resource-intensive than the same large language models, in addition, they are very easy to use and configure. Two datasets were selected, a dataset with blogs and a dataset with books. The dataset with blogs was used the most because it contains both the age and gender of the blog author. The prediction accuracy of the ""book"" model is 0.8, and with blogs - 0.6. Before use, the data was analysed and cleaned, later transformed into embeddings and sent for model training. The results of the model are studied and analysed in detail. Many useful features are extracted that are responsible for classifying the age or gender of the author in the texts. In addition, many interesting regularities were observed in the process of analysing the results. Additionally, a test case is implemented that allows the user to easily interact with my model. © 2024 Copyright for this paper by its authors."
"Syu J.-F.; Lew-Ting C.-Y.; Yen M.-Y.; Peing W.-C.","Syu, Jia-Fang (55211277600); Lew-Ting, Chin-Yin (6603107589); Yen, Muh-Yong (57139774100); Peing, Wie-Chu (55210905200)","55211277600; 6603107589; 57139774100; 55210905200","Author's respone to commentry: Risky behaviours of young female Sex workers and policy recommendations for the prevention of sexually transmitted infections in Taiwan","2012","Taiwan Journal of Public Health","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860762523&partnerID=40&md5=0810aca67a6092a9362456d91aef7ed6","[No abstract available]"
"Sboev A.; Gudovskikh D.; Moloshnikov I.; Rybka R.","Sboev, Aleksandr (57194755264); Gudovskikh, Dmitry (57188749022); Moloshnikov, Ivan (57188749063); Rybka, Roman (55696423700)","57194755264; 57188749022; 57188749063; 55696423700","A gender identification of text author in mixture of Russian multi-genre texts with distortions on base of data-driven approach using machine learning models","2019","AIP Conference Proceedings","10.1063/1.5114280","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069962400&doi=10.1063%2f1.5114280&partnerID=40&md5=2a10f51dd15177a0aa56ed150ad628f2","In this work we investigate a wide set of machine learning models of data-driven approaches (Long Short-Term Memory networks, Convolutional neural networks, multilayer perceptrons, Random Forest Classifiers, Logistic Regression and Gradient Boosting Classifiers with different sets of features) to identify the gender of author in Russian multi-genre texts in the case of existing style distortions and gender deceptions in training and testing sets. We consider and evaluate accuracy for the following situations: the influence of style distortions and gender deceptions in training texts for different genre, and the case when such deception is present only in test results. A comparison with known literature data is presented. The set of data corpora includes: one collected by a crowdsourcing platform, essays of Russian students (RusPersonality), Gender Imitation corpus, and the corpora used at Forum for Information Retrieval Evaluation 2017 (FIRE), containing texts from Facebook, Twitter and Reviews. We present the analysis of numerical experiments based on different features (morphological data, vector of character n-gram frequencies, LIWC and others) of input texts along with various machine learning models. The presented results, obtained on a wide set of data-driven models, establish the accuracy level for the task to identify gender of an author of a Russian text in the multi-genre case and analyzed the effect of the presence of deception in the test and training sets. © 2019 Author(s)."
"Rajkumar N.; Viji C.; Mohanraj A.; Senthilkumar K.R.; Jagajeevan R.; Kovilpillai J.A.","Rajkumar, N. (57027609100); Viji, C. (56607327700); Mohanraj, A. (58312948000); Senthilkumar, K.R. (58995607300); Jagajeevan, R. (58499960500); Kovilpillai, Judeson Antony (57216287065)","57027609100; 56607327700; 58312948000; 58995607300; 58499960500; 57216287065","Ethical considerations of AI implementation in the library era","2024","Improving Library Systems with AI: Applications, Approaches, and Bibliometric Insights","10.4018/9798369355930.ch007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195741950&doi=10.4018%2f9798369355930.ch007&partnerID=40&md5=3b3e21bbce042efa379f560b026ca563","As the mixture of artificial intelligence (AI) continues to permeate several sectors, ethical considerations have ended up a focus in ensuring responsible and sustainable AI deployment. This virtual library explores the multifaceted moral dimensions related to AI implementation. The gathering of scholarly articles and studies papers delves into key moral problems, spanning troubles which includes bias and fairness, transparency, responsibility, privacy, and societal impact. The number one section of the virtual library addresses the undertaking of algorithmic bias and fairness, reading how biases in AI systems can perpetuate societal inequalities. Various methods to mitigating bias and selling fairness in AI algorithms are explored, providing insights into the improvement of more equitable AI programs. Transparency and duty are the focal factors of the second one segment, emphasizing the need for clean conversation of AI decision-making techniques and mechanisms for holding AI systems answerable for their movements © 2024, IGI Global. All rights reserved."
"Habgood J.S.","Habgood, John S. (6603744867)","6603744867","I Recommend You to Read: XV. Some Recent Books on Science and Religion","1968","The Expository Times","10.1177/001452466807901203","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976922408&doi=10.1177%2f001452466807901203&partnerID=40&md5=982f79a67099ea42b1bc0502b499f1d4","[No abstract available]"
"Nguyen P.T.; Rubei R.; Di Rocco J.; Di Sipio C.; Di Ruscio D.; Di Penta M.","Nguyen, Phuong T. (57209915714); Rubei, Riccardo (57204794283); Di Rocco, Juri (55877197500); Di Sipio, Claudio (57215525221); Di Ruscio, Davide (57201633392); Di Penta, Massimiliano (6602794138)","57209915714; 57204794283; 55877197500; 57215525221; 57201633392; 6602794138","Dealing with Popularity Bias in Recommender Systems for Third-party Libraries: How far Are We?","2023","Proceedings - 2023 IEEE/ACM 20th International Conference on Mining Software Repositories, MSR 2023","10.1109/MSR59073.2023.00016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166303384&doi=10.1109%2fMSR59073.2023.00016&partnerID=40&md5=0434bc58e58bc13c8f491a92d7dec41a","Recommender systems for software engineering (RSSEs) assist software engineers in dealing with a growing information overload when discerning alternative development solutions. While RSSEs are becoming more and more effective in suggesting handy recommendations, they tend to suffer from popularity bias, i.e., favoring items that are relevant mainly because several developers are using them. While this rewards artifacts that are likely more reliable and well-documented, it would also mean that missing artifacts are rarely used because they are very specific or more recent. This paper studies popularity bias in Third-Party Library (TPL) RSSEs. First, we investigate whether state-of-the-art research in RSSEs has already tackled the issue of popularity bias. Then, we quantitatively assess four existing TPL RSSEs, exploring their capability to deal with the recommendation of popular items. Finally, we propose a mechanism to defuse popularity bias in the recommendation list. The empirical study reveals that the issue of dealing with popularity in TPL RSSEs has not received adequate attention from the software engineering community. Among the surveyed work, only one starts investigating the issue, albeit getting a low prediction performance.  © 2023 IEEE."
"Kim J.; Kim J.; Owen-Smith J.","Kim, Jinseok (56042325900); Kim, Jenna (57203213277); Owen-Smith, Jason (6602306116)","56042325900; 57203213277; 6602306116","Ethnicity-based name partitioning for author name disambiguation using supervised machine learning","2021","Journal of the Association for Information Science and Technology","10.1002/asi.24459","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101234924&doi=10.1002%2fasi.24459&partnerID=40&md5=5b3e288004b26bf4c56dcb4efdba6cdb","In several author name disambiguation studies, some ethnic name groups such as East Asian names are reported to be more difficult to disambiguate than others. This implies that disambiguation approaches might be improved if ethnic name groups are distinguished before disambiguation. We explore the potential of ethnic name partitioning by comparing performance of four machine learning algorithms trained and tested on the entire data or specifically on individual name groups. Results show that ethnicity-based name partitioning can substantially improve disambiguation performance because the individual models are better suited for their respective name group. The improvements occur across all ethnic name groups with different magnitudes. Performance gains in predicting matched name pairs outweigh losses in predicting nonmatched pairs. Feature (e.g., coauthor name) similarities of name pairs vary across ethnic name groups. Such differences may enable the development of ethnicity-specific feature weights to improve prediction for specific ethic name categories. These findings are observed for three labeled data with a natural distribution of problem sizes as well as one in which all ethnic name groups are controlled for the same sizes of ambiguous names. This study is expected to motive scholars to group author names based on ethnicity prior to disambiguation. © 2021 The Authors. Journal of the Association for Information Science and Technology published by Wiley Periodicals LLC on behalf of Association for Information Science and Technology."
"","","","Check List for Class Bias and Some Recommended Books","1982","English in Education","10.1111/j.1754-8845.1982.tb00451.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890930197&doi=10.1111%2fj.1754-8845.1982.tb00451.x&partnerID=40&md5=77f7085cb8d0426e6e699a00f161556e","[No abstract available]"
"Campos-Arceiz A.; Primack R.B.; Koh L.P.","Campos-Arceiz, Ahimsa (23491348000); Primack, Richard B. (7004665056); Koh, Lian Pin (7004786474)","23491348000; 7004665056; 7004786474","Reviewer recommendations and editors' decisions for a conservation journal: Is it just a crapshoot? And do Chinese authors get a fair shot?","2015","Biological Conservation","10.1016/j.biocon.2015.02.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924954578&doi=10.1016%2fj.biocon.2015.02.025&partnerID=40&md5=f49872d228e6328ef9c521501920f865","An important topic in the scientific publication process is how well reviewers evaluate the quality of papers and how their recommendations influence editors' decisions to accept or reject papers. Additionally, a particular concern for researchers from China and other countries with rapidly developing scientific communities is whether there are potential biases affecting their manuscripts in the review process. To address these topics, we examined 4575 manuscripts submitted to the journal Biological Conservation. For the 2093 papers sent out for review, reviewer recommendations strongly influenced the outcome of the review process. Reviewer recommendations of accept and minor revision were similar in their positive effects on editor decisions, while papers receiving at least one recommendation of reject (""the kiss of death"") were almost always rejected. Papers with more consistent reviews (e.g. both reviewers recommending a major revision) had a greater chance of acceptance than did papers with more variation (e.g. minor revision and reject). We found no evidence of editor bias against papers from China; however, reviewer recommendation for papers from China had a greater degree of agreement than did reviewers of papers from English-speaking countries (e.g. intra-class correlation of 0.25 vs. 0.55), due to reviewers of papers from China often agreeing that papers should be rejected or require major revision. Reviewers from China judged papers from China more harshly than did reviewers from other countries. Our results demonstrate that the review process is not a crapshoot; reviewers are providing useful information and editors are using this information to make reasonable decisions. © 2015 Elsevier Ltd."
"Oduoye M.O.; Javed B.; Gupta N.; Valentina Sih C.M.","Oduoye, Malik Olatunde (57859598500); Javed, Binish (57375717300); Gupta, Nikhil (22984732400); Valentina Sih, Che Mbali (58658500800)","57859598500; 57375717300; 22984732400; 58658500800","Algorithmic bias and research integrity; the role of nonhuman authors in shaping scientific knowledge with respect to artificial intelligence: a perspective","2023","International journal of surgery (London, England)","10.1097/JS9.0000000000000552","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173984430&doi=10.1097%2fJS9.0000000000000552&partnerID=40&md5=4d5c1553add644527ae9237dfccee98b","Artificial intelligence technologies were developed to assist authors in bettering the organization and caliber of their published papers, which are both growing in quantity and sophistication. Even though the usage of artificial intelligence tools in particular ChatGPT's natural language processing systems has been shown to be beneficial in research, there are still concerns about accuracy, responsibility, and transparency when it comes to the norms regarding authorship credit and contributions. Genomic algorithms quickly examine large amounts of genetic data to identify potential disease-causing mutations. By analyzing millions of medications for potential therapeutic benefits, they can quickly and relatively economically find novel approaches to treatment. Researchers from several fields can collaborate on difficult tasks with the assistance of nonhuman writers, promoting interdisciplinary research. Sadly, there are a number of significant disadvantages associated with employing nonhuman authors, including the potential for algorithmic prejudice. Biased data may be reinforced by the algorithm since machine learning algorithms can only be as objective as the data they are trained on. It is overdue that scholars bring forth basic moral concerns in the fight against algorithmic prejudice. Overall, even if the use of nonhuman authors has the potential to significantly improve scientific research, it is crucial for scientists to be aware of these drawbacks and take precautions to avoid bias and limits. To provide accurate and objective results, algorithms must be carefully designed and implemented, and researchers need to be mindful of the larger ethical ramifications of their usage. Copyright © 2023 The Author(s). Published by Wolters Kluwer Health, Inc."
"Miao Z.","Miao, Zeyi (57211554721)","57211554721","Investigation on human rights ethics in artificial intelligence researches with library literature analysis method","2019","Electronic Library","10.1108/EL-04-2019-0089","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074440092&doi=10.1108%2fEL-04-2019-0089&partnerID=40&md5=1423956d9453b51fa2a869d719c8399d","Purpose: The purpose of this paper was to identify whether artificial intelligence (AI) products can possess human rights, how to define their rights and obligations and what ethical standards they should follow. In this study, the human rights ethical dilemma encountered in the application and development of AI technology has been focused on and analyzed in detail in the light of the existing research status of AI ethics. Design/methodology/approach: In this study, first of all, the development and application of AI technology, as well as the concept and characteristics of human rights ethics, are introduced. Second, the human rights ethics of AI technology are introduced in detail, including the human rights endowment of AI machines, the fault liability of AI machines and the moral orientation of AI machines. Finally, the approaches to human rights ethics are proposed to ensure that AI technology serves human beings. Every link of its research, production and application should be strictly managed and supervised. Findings: The results show that the research in this study can provide help for the related problems encountered in AI practice. Intelligent library integrates human rights protection organically so that readers or users can experience more intimate service in this system. It is a kind of library operation mode with more efficient and convenient characteristics, which is based on digital, networked and intelligent information science. It aims at using the greenest way and digital means to realize the reading and research of human rights protection literature in the literature analysis method. Originality/value: Intelligent library is the future development mode of new libraries, which can realize broad interconnection and sharing. It is people-oriented and can make intelligent management and service and establish the importance of the principle of human rights protection and the specific idea of the principle. The development of science and technology brings not only convenience to people's social life but also questions to be thought. People should reduce its potential harm, so as to make AI technology continue to benefit humankind. © 2019, Emerald Publishing Limited."
"Zainab Z.; Al-Obeidat F.; Moreira F.; Gul H.; Amin A.","Zainab, Zarah (58304551800); Al-Obeidat, Feras (35785711700); Moreira, Fernando (8649758400); Gul, Haji (57218363906); Amin, Adnan (56435401800)","58304551800; 35785711700; 8649758400; 57218363906; 56435401800","Comparative Analysis of Machine Learning Algorithms for Author Age and Gender Identification","2023","Lecture Notes in Networks and Systems","10.1007/978-981-19-9331-2_11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161242726&doi=10.1007%2f978-981-19-9331-2_11&partnerID=40&md5=7f8dd91ae28f235daa9143e2f7169f0f","Author profiling is part of information retrieval in which different perspectives of the author are observed by considering various characteristics like native language, gender, and age. Different techniques are used to extract the required information using text analysis, like author identification on social media and for Short Text Message Service. Author profiling helps in security and blogs for identification purposes while capturing authors’ writing behaviors through messages, posts, comments, blogs, comments, and chat logs. Most of the work in this area has been done in English and other native languages. On the other hand, Roman Urdu is also getting attention for the author profiling task, but it needs to convert Roman-Urdu to English to extract important features like Named Entity Recognition (NER) and other linguistic features. The conversion may lose important information while having limitations in converting one language to another language. This research explores machine learning techniques that can be used for all languages to overcome the conversion limitation. The Vector Space Model (VSM) and Query Likelihood (Q.L.) are used to identify the author’s age and gender. Experimental results revealed that Q.L. produces better results in terms of accuracy. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd."
"Land K.","Land, Kaylin (57221416234)","57221416234","Predicting author gender using machine learning algorithms: Looking beyond the binary","2020","Digital Studies/ Le Champ Numerique","10.16995/DSCN.362","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099109192&doi=10.16995%2fDSCN.362&partnerID=40&md5=256c2a24a6e8683a08d6aaad28322901","This paper explores the relationship between digital humanities studies that utilize computer algorithms to identify author gender and feminist and queer literary theory. I argue that utilizing computer algorithms to sort literature into the categories ""authored by a male""or ""authored by a female""is too reductive in its treatment of gender as binary. However, I suggest computer algorithms could be utilized to explore the performative aspects of author gender and to ask larger questions about algorithmic criticism, the author as a subject, and the relationship between morphological and cultural properties of texts. © 2020 The Author(s)."
"Huang K.; Xu X.; Li A.; Xu F.","Huang, Kun (56251424300); Xu, Xiaoting (57216126767); Li, Anrunze (57219743912); Xu, Feng (57215764427)","56251424300; 57216126767; 57219743912; 57215764427","Study of the Literature of Artificial Intelligence Ethics in Library and Information from 2015—2019; [近缘年图情杂杂悦陨期刊人工智能 伦理研究文献分析与启示]","2021","Journal of Modern Information","10.3969/j.issn.1008-0821.2021.06.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115776481&doi=10.3969%2fj.issn.1008-0821.2021.06.015&partnerID=40&md5=efe785df6879d460152ec7c7320b357a","[Purpose/Significance] This paper aims to explore the research status of artificial intelligence ethics in lihrary and information science, and promote the healthy development of information management technology in the synchronous development of ethical research. [Method/Process] 39 academic papers discussing the ethics of artificial intelligence were collected under the discipline category of library and information in the core collection of Web of Science in the past five years. The content analysis method was used to analyze from the perspectives of problem levels, application fields and solutions. [ Result/Conclusion] The findings indicated that the papers published in library and information science journals studied similar issues as the whole field of artificial ethics. The research perspective covered both humanism and technicism. The research content covered data, algorithm and artificial intelligence system at different levels, involving medical and health, political and military fields. In addition, the research discussed the solutions from the social and technical perspectives. The future research can further focus on the information life cycle, strengthen the diversity of the level and field ol ethical issues, and promote the research ol artificial intelligence ethical norms and guidelines. © 2021 Editorial Board of Journal of Modern Information. All rights reserved."
"Izquierdo J.L.; Soriano J.B.","Izquierdo, Jose Luis (7102685483); Soriano, Joan B (7101973935)","7102685483; 7101973935","Authors' reply to: Minimizing selection and classification biases comment on ""clinical characteristics and prognostic factors for intensive care unit admission of patients with COVID-19: Retrospective study using machine learning and natural language processing""","2021","Journal of Medical Internet Research","10.2196/29405","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106917555&doi=10.2196%2f29405&partnerID=40&md5=c25f3b21ee8460fce18a8928a6bbd24f","[No abstract available]"
"Hamid A.R.A.H.","Hamid, Agus Rizal Ardy Hariandy (57202054669)","57202054669","How artificial intelligence chatbots becomes author’s true friend in medical writing without risking ethical violations","2024","Medical Journal of Indonesia","10.13181/mji.ed.247530","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194358145&doi=10.13181%2fmji.ed.247530&partnerID=40&md5=b8fe50302c26a9d0f4e7cfac8c4c4f12","[No abstract available]"
"Lin H.-W.","Lin, Huey-Wen (7405571889)","7405571889","Is there any gender/race bias in hep-lat primary publication? Machine-Learning Evaluation of Author Ethnicity and Gender","2022","Proceedings of Science","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134429742&partnerID=40&md5=10806827741100a29e0160ffaabe8fcf","In this work, we analyze papers that are classified as primary hep-lat to study whether there is any race or gender bias in the journal-publication process. We implement machine learning to predict the race and gender of authors based on their names and look for measurable differences between publication outcomes based on author classification. We would like to invite discussion on how journals can make improvements in their editorial process and how institutions or grant offices should account for these publication differences in gender and race. © Copyright owned by the author(s) under the terms of the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License (CC BY-NC-ND 4.0)"
"Barcot O.; Ivanda M.; Buljan I.; Pieper D.; Puljak L.","Barcot, Ognjen (57204475843); Ivanda, Matej (57224633636); Buljan, Ivan (57193889320); Pieper, Dawid (53871825400); Puljak, Livia (23668498800)","57204475843; 57224633636; 57193889320; 53871825400; 23668498800","Enhanced access to recommendations from the Cochrane Handbook for improving authors' judgments about risk of bias: A randomized controlled trial","2021","Research Synthesis Methods","10.1002/jrsm.1499","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108084971&doi=10.1002%2fjrsm.1499&partnerID=40&md5=a2051e22589d452bf6bcdd4b76236fc9","This randomized controlled trial (RCT) aimed to test the efficacy of enhanced access to Cochrane Handbook (Handbook) recommendations for judging the 2011 Cochrane risk of bias (RoB) domains for improving the adequacy of RoB judgments. Parallel-group RCT with a 1:1 allocation ratio (N = 2271 per group) was conducted. Eligible participants were corresponding authors of all published Cochrane reviews and protocols. After allocation by a random number generator, participants received 20 scenarios for assessing RoB. The intervention group was shown tables from the Handbook with instructions for assessing 2011 RoB tool together with scenarios they were supposed to assess—enhanced access to the Handbook. The control group was shown only a general link to the Handbook. The primary outcome was the proportion of participants that made an adequate judgment of RoB scenarios for analyzed domains. There were 240 responses out of 2020 delivered e-mail invitations in the intervention and 197/2254 in the control group. Only five participants from the intervention group judged RoB adequately in all the 20 scenarios and no one in the control group. The proportion of participants who adequately assessed all the scenarios within a domain was significantly higher in the intervention than in the control group. The frequency of adequate RoB judgments was 7.1% (95% CI: 5.0–9.3%, p < 0.001) higher in the intervention group (76.2%) than in the control group (69.0%). The enhanced access yields more adequate RoB assessments and could be incorporated in software supporting the RoB tool. © 2021 John Wiley & Sons Ltd."
"Moffatt B.; Hall A.","Moffatt, Barton (56266323900); Hall, Alicia (56090965500)","56266323900; 56090965500","Is AI my co-author? The ethics of using artificial intelligence in scientific publishing","2024","Accountability in Research","10.1080/08989621.2024.2386285","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200789044&doi=10.1080%2f08989621.2024.2386285&partnerID=40&md5=bc0f14408d445e893e656d2af2fdb4bd","The recent emergence of Large Language Models (LLMs) and other forms of Artificial Intelligence (AI) has led people to wonder whether they could act as an author on a scientific paper. This paper argues that AI systems should not be included on the author by-line. We agree with current commentators that LLMs are incapable of taking responsibility for their work and thus do not meet current authorship guidelines. We identify other problems with responsibility and authorship. In addition, the problems go deeper as AI tools also do not write in a meaningful sense nor do they have persistent identities. From a broader publication ethics perspective, adopting AI authorship would have detrimental effects on an already overly competitive and stressed publishing ecosystem. Deterrence is possible as backward-looking tools will likely be able to identify past AI usage. Finally, we question the value of using AI to produce more research simply for publication’s sake. © 2024 Informa UK Limited, trading as Taylor & Francis Group."
"Sysoyev P.V.","Sysoyev, Pavel V. (8419258800)","8419258800","Ethics and AI-Plagiarism in an Academic Environment: Students’ Understanding of Compliance with Author’s Ethics and the Problem of Plagiarism in the Process of Interaction with Generative Artificial Intelligence; [Этика и ИИ-плагиат в академической среде: понимание студентами вопросов соблюдения авторской этики и проблемы плагиата в процессе взаимодействия с генеративным искусственным интеллектом]","2024","Vysshee Obrazovanie v Rossii","10.31992/0869-3617-2024-33-2-31-53","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188590640&doi=10.31992%2f0869-3617-2024-33-2-31-53&partnerID=40&md5=28c2ea8362e30d4387838fbff310a072","Everyday, artificial intelligence (AI) is being increasingly integrated into the teaching and learning process at Russian universities. The high level of quality of feedback from AI tools leads to the spread of AI plagiarism – unauthorized borrowing of generative AI materials – among students. The purpose of this study is to: a) highlight aspects that determine students’ understanding of the issues of compliance with author’s ethics and the problem of plagiarism when interacting with generative AI; b) develop a questionnaire to determine students’ understanding of the issues of compliance with author’s ethics and the problem of AI plagiarism; c) conduct an online survey of university students, analyze and discuss the results obtained. The paper highlights five aspects that determine students’ understanding of the issues of compliance with author’s ethics and the problem of AI plagiarism when completing educational assignments and preparing research texts: a) students’ general understanding of the issues of compliance with author’s ethics and the problem of plagiarism in an academic environment; b) students’ experience of AI tools for educational purposes; c) students’ understanding of the problem of AI plagiarism and attitude towards borrowing materials from generative AI; d) teachers’ actions to prevent AI plagiarism among students; e) the policy of educational organizations regarding student compliance with ethics and AI plagiarism. An online questionnaire was developed to determine the degree to which students understand the issues of compliance with copyright ethics and the problem of AI plagiarism. 1,599 students from 29 universities of the Russian Federation took part in the survey. The results showed that in general, in the Russian student community, plagiarism is a widespread social phenomenon, many types of which are perceived by young people as a norm of academic behavior. Despite the relatively high awareness of students in the field of AI technologies, the extremely rare use by teachers of specialized subject disciplines of AI tools in the educational process I’d the reason for the current low level of spread of AI plagiarism in the academic environment. At the same time, it is necessary to state that students lack a systematic understanding of exactly how they can “legally” use generative AI materials and what exactly will be considered AI plagiarism. According to students, the importance of understanding the issues of compliance with author ethics and the problem of AI plagiarism will depend, on the one hand, on the actions of teachers to explain to students the rules for using generative AI materials, and on the other hand, the presence in universities of a regulatory framework regulating the field and the extent to which students use AI in the educational process. © 2024 Moscow Polytechnic University. All rights reserved."
"KELLY G.","KELLY, G. (35469863100)","35469863100","Medical ethics books; some recommendations for doctors.","1951","The Linacre quarterly","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-76949117889&partnerID=40&md5=4a16b9d229e445c93f27f1b76f9e9598","[No abstract available]"
"Baptiste H.P.; Townsend K.","Baptiste, H. Prentice (8303922300); Townsend, Katie (58343943700)","8303922300; 58343943700","Examining the presidential libraries: Students find biases and recommend a multicultural perspective","2008","Multicultural Education","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-58049214862&partnerID=40&md5=929c380613d6842abd27235e8067bdd3","[No abstract available]"
