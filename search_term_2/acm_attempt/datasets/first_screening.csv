Title,Relevant,Authors,Link,Abstract,Venue,Year,Type
Towards Green Recommender Systems: Investigating the Impact of Data Reduction on Carbon Footprint and Algorithm Performances,Keep,"['Giuseppe Spillo', 'Allegra De Filippo', 'Cataldo Musto', 'Michela Milano', 'Giovanni Semeraro']",https://doi.org/10.1145/3640457.3688160,"This work investigates the path toward green recommender systems by examining the impact of data reduction on both model performance and carbon footprint. In the pursuit of developing energy-efficient recommender systems, we investigated whether and how reducing the training data impacts the performances of several representative recommendation models. In order to obtain a fair comparison, all the models were run based on the implementations available in a popular recommendation library, i.e., RecBole, and used the same experimental settings. Results indicate that: (a) data reduction can be a promising strategy to make recommender systems more sustainable, at the cost of a lower accuracy; (b) training recommender systems with less data makes the suggestions more diverse and less biased. Overall, this study contributes to the ongoing discourse on the development of recommendation models that meet the principles of SDGs, laying the groundwork for the adoption of more sustainable practices in the field.",Proceedings of the 18th ACM Conference on Recommender Systems,2024,Short
Towards Sustainability-aware Recommender Systems: Analyzing the Trade-off Between Algorithms Performance and Carbon Footprint,Keep,"['Giuseppe Spillo', 'Allegra De Filippo', 'Cataldo Musto', 'Michela Milano', 'Giovanni Semeraro']",https://doi.org/10.1145/3604915.3608840,"In this paper, we present a comparative analysis of the trade-off between the performance of state-of-the-art recommendation algorithms and their environmental impact. In particular, we compared 18 popular recommendation algorithms in terms of both performance metrics (i.e., accuracy and diversity of the recommendations) as well as in terms of energy consumption and carbon footprint on three different datasets. In order to obtain a fair comparison, all the algorithms were run based on the implementations available in a popular recommendation library, i.e., RecBole, and used the same experimental settings. The outcomes of the experiments showed that the choice of the optimal recommendation algorithm requires a thorough analysis, since more sophisticated algorithms often led to tiny improvements at the cost of an exponential increase of carbon emissions. Through this paper, we aim to shed light on the problem of carbon footprint and energy consumption of recommender systems, and we make the first step towards the development of sustainability-aware recommendation algorithms.",Proceedings of the 17th ACM Conference on Recommender Systems,2023,Short
Promoting Two-sided Fairness with Adaptive Weights for Providers and Customers in Recommendation,Yes,"['Lanling Xu', 'Zihan Lin', 'Jinpeng Wang', 'Sheng Chen', 'Wayne Zhao', 'Ji-Rong Wen']",https://doi.org/10.1145/3640457.3688169,"At present, most recommender systems involve two stakeholders, providers and customers. Apart from maximizing the recommendation accuracy, the fairness issue for both sides should also be considered. Most of previous studies try to improve two-sided fairness with post-processing algorithms or fairness-aware loss constraints, which are highly dependent on the heuristic adjustments without respect to the optimization goal of accuracy. In contrast, we propose a novel training framework, adaptive weighting towards two-sided fairness-aware recommendation&nbsp;(named Ada2Fair), which lies in the extension of the accuracy-focused objective to a controllable preference learning loss over the interaction data. Specifically, we adjust the optimization scale of an interaction sample with an adaptive weight generator, and estimate the two-sided fairness-aware weights within model training. During the training process, the recommender is trained with two-sided fairness-aware weights to boost the utility of niche providers and inactive customers in a unified way. Extensive experiments on three public datasets verify the effectiveness of&nbsp;Ada2Fair, which can achieve Pareto efficiency in two-sided fairness-aware recommendation.",Proceedings of the 18th ACM Conference on Recommender Systems,2024,Short
Topic-Level Bayesian Surprise and Serendipity for Recommender Systems,No,"['Tonmoy Hasan', 'Razvan Bunescu']",https://doi.org/10.1145/3604915.3608851,"A recommender system that optimizes its recommendations solely to fit a user’s history of ratings for consumed items can create a filter bubble, wherein the user does not get to experience items from novel, unseen categories. One approach to mitigate this undesired behavior is to recommend items with high potential for serendipity, namely surprising items that are likely to be highly rated. In this paper, we propose a content-based formulation of serendipity that is rooted in Bayesian surprise and use it to measure the serendipity of items after they are consumed and rated by the user. When coupled with a collaborative-filtering component that identifies similar users, this enables recommending items with high potential for serendipity. To facilitate the evaluation of topic-level models for surprise and serendipity, we introduce a dataset of book reading histories extracted from Goodreads, containing over 26 thousand users and close to 1.3 million books, where we manually annotate 449 books read by 4 users in terms of their time-dependent, topic-level surprise. Experimental evaluations show that models that use Bayesian surprise correlate much better with the manual annotations of topic-level surprise than distance-based heuristics, and also obtain better serendipitous item recommendation performance.",Proceedings of the 17th ACM Conference on Recommender Systems,2023,Short
RecRec: Algorithmic Recourse for Recommender Systems,No,"['Sahil Verma', 'Ashudeep Singh', 'Varich Boonsanong', 'John Dickerson', 'Chirag Shah']",https://doi.org/10.1145/3583780.3615181,"Recommender systems play an essential role in the choices people make in domains such as entertainment, shopping, food, news, employment, and education. The machine learning models underlying these recommender systems are often enormously large and black-box in nature for users, content providers, and system developers alike. It is often crucial for all stakeholders to understand the model's rationale behind making certain predictions and recommendations. This is especially true for the content providers whose livelihoods depend on the recommender system. Drawing motivation from the practitioners' need, in this work, we propose a recourse framework for recommender systems, targeted towards the content providers. Algorithmic recourse in the recommendation setting is a set of actions that, if executed, would modify the recommendations (or ranking) of an item in the desired manner. A recourse suggests actions of the form: ''if a feature changes X to Y, then the ranking of that item for a set of users will change to X.'' Furthermore, we demonstrate that RecRec is highly effective in generating valid, sparse, and actionable recourses through an empirical evaluation of recommender systems trained on three real-world datasets. To the best of our knowledge, this work is the first to conceptualize and empirically test a generalized framework for generating recourses for recommender systems.",Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,2023,Short
The Effect of Feedback Granularity on Recommender Systems Performance,Keep,"['Ladislav Peska', 'Stepan Balcar']",https://doi.org/10.1145/3523227.3551479,"The main source of knowledge utilized in recommender systems (RS) is users’ feedback. While the usage of implicit feedback (i.e. user’s behavior statistics) is gaining in prominence, the explicit feedback (i.e. user’s ratings) remain an important data source. This is true especially for domains, where evaluation of an object does not require an extensive usage and users are well motivated to do so (e.g., video-on-demand services or library archives). So far, numerous rating schemes for explicit feedback have been proposed, ranging both in granularity and presentation style. There are several works studying the effect of rating’s scale and presentation on user’s rating behavior, e.g. willingness to provide feedback or various biases in rating behavior. Nonetheless, the effect of ratings granularity on RS performance remain largely under-researched. In this paper, we studied the combined effect of ratings granularity and supposed probability of feedback existence on various performance statistics of recommender systems. Results indicate that decreasing feedback granularity may lead to changes in RS’s performance w.r.t. nDCG for some recommending algorithms. Nonetheless, in most cases the effect of feedback granularity is surpassed by even a small decrease in feedback’s quantity. Therefore, our results corroborate the policy of many major real-world applications, i.e. preference of simpler rating schemes with the higher chance of feedback reception instead of finer-grained rating scenarios.",Proceedings of the 16th ACM Conference on Recommender Systems,2022,Short
Evaluation and simplification of text difficulty using LLMs in the context of recommending texts in French to facilitate language learning,No,"['Henri Jamet', 'Maxime Manderlier', 'Yash Shrestha', 'Michalis Vlachos']",https://doi.org/10.1145/3640457.3688181,"Learning a new language can be challenging. To help learners, we built a recommendation system that suggests texts and videos based on the learners’ skill level of the language and topic interests. Our system analyzes content to determine its difficulty and topic, and, if needed, can simplify complex texts while maintaining semantics. Our work explores the holistic use of Large Language Models (LLMs) for the various sub-tasks involved for accurate recommendations: difficulty estimation and simplification, graph recommender engine, topic estimation. We present a comprehensive evaluation comparing zero-shot and fine-tuned LLMs, demonstrating significant improvements in French content difficulty prediction (18-56%), topic prediction accuracy (27%), and recommendation relevance (up to 18% NDCG increase).",Proceedings of the 18th ACM Conference on Recommender Systems,2024,Short
Deep Stacked Ensemble Recommender,No,"['Rasaq Otunba', 'Raimi Rufai', 'Jessica Lin']",https://doi.org/10.1145/3335783.3335809,"Collaborative filtering techniques remain a staple in recommender systems research and applications. With the plethora of research done in recommender systems, some more recent works applied deep learning with great success. We stack a deep neural network recommender onto a shallow one for item recommendations in this work. Our experiments with popular datasets indicate that the proposed technique outperforms other state-of-the art techniques and baselines in key performance metrics.",Proceedings of the 31st International Conference on Scientific and Statistical Database Management,2019,Short
Scalable Approximate NonSymmetric Autoencoder for Collaborative Filtering,No,"[""Martin Spi\\v{s}\\'{a}k"", 'Radek Bartyzal', ""Anton\\'{\\i}n Hoskovec"", 'Ladislav Peska', 'Miroslav T\\r{u}ma']",https://doi.org/10.1145/3604915.3608827,"In the&nbsp;field of recommender systems, shallow autoencoders have recently gained significant attention. One of the&nbsp;most highly acclaimed shallow autoencoders is easer, favored for its competitive recommendation accuracy and simultaneous simplicity. However, the&nbsp;poor scalability of easer (both in time and especially in memory) severely restricts its use in production environments with vast item sets. In this paper, we propose a&nbsp;hyperefficient factorization technique for sparse approximate inversion of the&nbsp;data-Gram matrix used in easer. The&nbsp;resulting autoencoder, sansa, is an&nbsp;end-to-end sparse solution with prescribable density and almost arbitrarily low memory requirements — even for training. As such, sansa allows us to effortlessly scale the&nbsp;concept of easer to millions of items and beyond.",Proceedings of the 17th ACM Conference on Recommender Systems,2023,Short
Large Language Model Augmented Narrative Driven Recommendations,No,"['Sheshera Mysore', 'Andrew Mccallum', 'Hamed Zamani']",https://doi.org/10.1145/3604915.3608829,"Narrative-driven recommendation (NDR) presents an information access problem where users solicit recommendations with verbose descriptions of their preferences and context, for example, travelers soliciting recommendations for points of interest while describing their likes/dislikes and travel circumstances. These requests are increasingly important with the rise of natural language-based conversational interfaces for search and recommendation systems. However, NDR lacks abundant training data for models, and current platforms commonly do not support these requests. Fortunately, classical user-item interaction datasets contain rich textual data, e.g., reviews, which often describe user preferences and context – this may be used to bootstrap training for NDR models. In this work, we explore using large language models (LLMs) for data augmentation to train NDR models. We use LLMs for authoring synthetic narrative queries from user-item interactions with few-shot prompting and train retrieval models for NDR on synthetic queries and user-item interaction data. Our experiments demonstrate that this is an effective strategy for training small-parameter retrieval models that outperform other retrieval and LLM baselines for narrative-driven recommendation.",Proceedings of the 17th ACM Conference on Recommender Systems,2023,Short
Cross-Batch Negative Sampling for Training Two-Tower Recommenders,No,"['Jinpeng Wang', 'Jieming Zhu', 'Xiuqiang He']",https://doi.org/10.1145/3404835.3463032,"The two-tower architecture has been widely applied for learning item and user representations, which is important for large-scale recommender systems. Many two-tower models are trained using various in-batch negative sampling strategies, where the effects of such strategies inherently rely on the size of mini-batches. However, training two-tower models with a large batch size is inefficient, as it demands a large volume of memory for item and user contents and consumes a lot of time for feature encoding. Interestingly, we find that neural encoders can output relatively stable features for the same input after warming up in the training process. Based on such facts, we propose a simple yet effective sampling strategy called Cross-Batch Negative Sampling (CBNS), which takes advantage of the encoded item embeddings from recent mini-batches to boost the model training. Both theoretical analysis and empirical evaluations demonstrate the effectiveness and the efficiency of CBNS.",Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval,2021,Short
Generalized Negative Sampling for Implicit Feedback in Recommendation,No,"['Yuki Yamanaka', 'Kazunari Sugiyama']",https://doi.org/10.1145/3486622.3493998,"In a typical model-based collaborative filtering with implicit feedback, negative sampling is getting more and more popular to obtain negative labeled inputs from massive unobserved data. However, this approach wrongly samples false negatives, resulting in unacceptable recommender model. In this work, we first identify a situation where false negatives are problematic and estimate their impact on a model accuracy. Then, we take our negative sampling as a classification task and demonstrate that a recommender model and a negative sampling method actually share the same goal: identification of false negatives from other unobserved data. We also estimate the actual upper bound of the accuracy improvements with a feasible negative sampling. Lastly, we propose a generalized negative sampling that can alleviate the impact of false negatives by introducing two robustness against false negatives: self-sampling and dynamic sub-sampling. In user-item interaction matrix, experimental results on publicly available datasets show that our approach outperforms some state-of-the-arts with statistical significance.",IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology,2022,Short
A Study of Priors for Relevance-Based Language Modelling of Recommender Systems,No,"['Daniel Valcarce', 'Javier Parapar', 'Alvaro Barreiro']",https://doi.org/10.1145/2792838.2799677,"Probabilistic modelling of recommender systems naturally introduces the concept of prior probability into the recommendation task. Relevance-Based Language Models, a principled probabilistic query expansion technique in Information Retrieval, has been recently adapted to the item recommendation task with success. In this paper, we study the effect of the item and user prior probabilities under that framework. We adapt two priors from the document retrieval field and then we propose other two new probabilistic priors. Evidence gathered from experimentation indicates that a linear prior for the neighbour and a probabilistic prior based on Dirichlet smoothing for the items improve the quality of the item recommendation ranking.",Proceedings of the 9th ACM Conference on Recommender Systems,2015,Short
DSKReG: Differentiable Sampling on Knowledge Graph for Recommendation with Relational GNN,No,"['Yu Wang', 'Zhiwei Liu', 'Ziwei Fan', 'Lichao Sun', 'Philip Yu']",https://doi.org/10.1145/3459637.3482092,"In the information explosion era, recommender systems (RSs) are widely studied and applied to discover user-preferred information. A RS performs poorly when suffering from the cold-start issue, which can be alleviated if incorporating Knowledge Graphs (KGs) as side information. However, most existing works neglect the facts that node degrees in KGs are skewed and massive amount of interactions in KGs are recommendation-irrelevant. To address these problems, in this paper, we propose Differentiable Sampling on Knowledge Graph for Recommendation with Relational GNN (DSKReG) that learns the relevance distribution of connected items from KGs and samples suitable items for recommendation following this distribution. We devise a differentiable sampling strategy, which enables the selection of relevant items to be jointly optimized with the model training procedure. The experimental results demonstrate that our model outperforms state-of-the-art KG-based recommender systems. The code is available online at https://github.com/YuWang-1024/DSKReG.",Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,2021,Short
Injecting Semantic Diversity in Top-N Recommender Systems Using Determinantal Point Processes and Curated Lists,No,"['Surya Kallumadi', 'Gabriel Necoechea']",https://doi.org/10.1145/3213586.3226223,"Top-N Recommender Systems usually suffer from intra-list diversity as they are tailored for relevance and predicted rating accuracy. This problem is magnified in the case of cold start setting - resulting in users being restricted to popular set of items and can result in a ""rich getting richer eco-system"". As a result, in recent years, more attention is being paid to improving the diversity of recommender system results. List creation has become a popular way for users to express preferences over items on online platforms such as imdb.com and goodreads.com. These user curated lists tend to contain a coherent semantic representation of the domain the list of items belong to. List curation can be seen as a way to capture fine grained topic-specific item-lists by users. Understanding and modeling user preferences expressed in these curated lists can help with diverse set of applications such as recommendations, user modeling, session understanding etc. In this paper, we propose an approach to improve the diversity of results generated by Top-N recommender systems, by using Determinantal Point Processes (DPPs) over user curated lists in the movie domain and incorporating them to rerank the Top-N recommender systems. For this work, we use the user curated lists in the imdb.com domain. We evaluate our approach over the Movielens 1-Million dataset and compare the results with other baseline approaches. Our early results show that incorporating semantic similarity expressed in user lists as a diversity proxy results in a more diverse set of recommendations.","Adjunct Publication of the 26th Conference on User Modeling, Adaptation and Personalization",2018,Short
Sequential Recommendation for Cold-start Users with Meta Transitional Learning,No,"['Jianling Wang', 'Kaize Ding', 'James Caverlee']",https://doi.org/10.1145/3404835.3463089,"A fundamental challenge for sequential recommenders is to capture the sequential patterns of users toward modeling how users transit among items. In many practical scenarios, however, there are a great number of cold-start users with only minimal logged interactions. As a result, existing sequential recommendation models will lose their predictive power due to the difficulties in learning sequential patterns over users with only limited interactions. In this work, we aim to improve sequential recommendation for cold-start users with a novel framework named MetaTL, which learns to model the transition patterns of users through meta-learning. Specifically, the proposed MetaTL: (i) formulates sequential recommendation for cold-start users as a few-shot learning problem; (ii) extracts the dynamic transition patterns among users with a translation-based architecture; and (iii) adopts meta transitional learning to enable fast learning for cold-start users with only limited interactions, leading to accurate inference of sequential interactions.",Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval,2021,Short
Integrating trust and similarity to ameliorate the data sparsity and cold start for recommender systems,No,['Guibing Guo'],https://doi.org/10.1145/2507157.2508071,"Our research aims to tackle the problems of data sparsity and cold start of traditional recommender systems. Insufficient ratings often result in poor quality of recommendations in terms of accuracy and coverage. To address these issues, we propose three different approaches from the perspective of preference modelling. Firstly, we propose to merge the ratings of trusted neighbors and thus form a new rating profile for the active users, based on which better recommendations can be generated. Secondly, we aim to make better use of user ratings and introduce a novel Bayesian similarity measure by taking into account both the direction and length of rating vectors. Thirdly, we propose a new information source called prior ratings based on virtual product experience in virtual reality environments, in order to inherently resolve the concerned problems.",Proceedings of the 7th ACM Conference on Recommender Systems,2013,Short
Item Recommendation by Combining Relative and Absolute Feedback Data,No,"['Saikishore Kalloori', 'Tianyu Li', 'Francesco Ricci']",https://doi.org/10.1145/3331184.3331295,"User preferences in the form of absolute feedback, s.a., ratings, are widely exploited in Recommender Systems (RSs). Recent research has explored the usage of preferences expressed with pairwise comparisons, which signal relative feedback. It has been shown that pairwise comparisons can be effectively combined with ratings, but, it is important to fine tune the technique that leverages both types of feedback. Previous approaches train a single model by converting ratings into pairwise comparisons, and then use only that type of data. However, we claim that these two types of preferences reveal different information about users interests and should be exploited differently. Hence, in this work, we develop a ranking technique that separately exploits absolute and relative preferences in a hybrid model. In particular, we propose a joint loss function which is computed on both absolute and relative preferences of users. Our proposed ranking model uses pairwise comparisons data to predict the user's preference order between pairs of items and uses ratings to push high rated (relevant) items to the top of the ranking. Experimental results on three different data sets demonstrate that the proposed technique outperforms competitive baseline algorithms on popular ranking-oriented evaluation metrics.",Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval,2019,Short
Improving Collaborative Metric Learning with Efficient Negative Sampling,Keep,"['Viet-Anh Tran', 'Romain Hennequin', 'Jimena Royo-Letelier', 'Manuel Moussallam']",https://doi.org/10.1145/3331184.3331337,"Distance metric learning based on triplet loss has been applied with success in a wide range of applications such as face recognition, image retrieval, speaker change detection and recently recommendation with the Collaborative Metric Learning (CML) model. However, as we show in this article, CML requires large batches to work reasonably well because of a too simplistic uniform negative sampling strategy for selecting triplets. Due to memory limitations, this makes it difficult to scale in high-dimensional scenarios. To alleviate this problem, we propose here a 2-stage negative sampling strategy which finds triplets that are highly informative for learning. Our strategy allows CML to work effectively in terms of accuracy and popularity bias, even when the batch size is an order of magnitude smaller than what would be needed with the default uniform sampling. We demonstrate the suitability of the proposed strategy for recommendation and exhibit consistent positive results across various datasets.",Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval,2019,Short
Causally Attentive Collaborative Filtering,No,"['Jingsen Zhang', 'Xu Chen', 'Wayne Zhao']",https://doi.org/10.1145/3459637.3482070,"Attention-based recommender models hold the promise of improving performance by learning to discriminate different user/item feature importances. However, due to the existence of the latent confounders, the correlations captured by attention mechanisms may fail to reflect the true influence of the features on the targets (i.e., spurious correlation). In this paper, we propose to empower attention mechanism by the causal inference, which is a powerful tool to identify the real causal effects. Our model is based on the potential outcome framework, where the item features are regarded as the treatment and the outcome is the predicted user preference. In specific, the causal relation of each feature on the outcome is measured by the individual treatment effect (ITE). In order to distill the causal information into the attention learning process, we minimize the distance between the traditional attention weights and the normalized ITE. With such causal regularization, the learned attention weights can capture the real causal effects, which are expected to correct the feature importances for improving performance. We conduct extensive experiments based on three real-world datasets to demonstrate the effectiveness.",Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,2021,Short
CF4CF: recommending collaborative filtering algorithms using collaborative filtering,No,"['Tiago Cunha', 'Carlos Soares', ""Andr\\'{e} Carvalho""]",https://doi.org/10.1145/3240323.3240378,"As Collaborative Filtering becomes increasingly important in both academia and industry recommendation solutions, it also becomes imperative to study the algorithm selection task in this domain. This problem aims at finding automatic solutions which enable the selection of the best algorithms for a new problem, without performing full-fledged training and validation procedures. Existing work in this area includes several approaches using Metalearning, which relate the characteristics of the problem domain with the performance of the algorithms. This study explores an alternative approach to deal with this problem. Since, in essence, the algorithm selection problem is a recommendation problem, we investigate the use of Collaborative Filtering algorithms to select Collaborative Filtering algorithms. The proposed approach integrates subsampling landmarkers, a data characterization approach commonly used in Metalearning, with a Collaborative Filtering methodology, named CF4CF. The predictive performance obtained by CF4CF using benchmark recommendation datasets was similar or superior to that obtained with Metalearning.",Proceedings of the 12th ACM Conference on Recommender Systems,2018,Short
Convex AUC optimization for top-N recommendation with implicit feedback,No,['Fabio Aiolli'],https://doi.org/10.1145/2645710.2645770,"In this paper, an effective collaborative filtering algorithm for top-N item recommendation with implicit feedback is proposed. The task of top-N item recommendation is to predict a ranking of items (movies, books, songs, or products in general) that can be of interest for a user based on earlier preferences of the user. We focus on implicit feedback where preferences are given in the form of binary events/ratings. Differently from state-of-the-art methods, the method proposed is designed to optimize the AUC directly within a margin maximization paradigm. Specifically, this turns out in a simple constrained quadratic optimization problem, one for each user. Experiments performed on several benchmarks show that our method significantly outperforms state-of-the-art matrix factorization methods in terms of AUC of the obtained predictions.",Proceedings of the 8th ACM Conference on Recommender Systems,2014,Short
A Hierarchical User Behavior Modeling Framework for Cross-Domain Click-Through Rate Prediction,No,"['Hai Li', 'Xin Dong', 'Lei Cheng', 'Linjian Mo']",https://doi.org/10.1145/3511808.3557531,"Click-through rate (CTR) prediction is a long-standing problem in advertising systems. Existing single-domain CTR prediction methods suffer from the data sparsity problem since few users can click advertisements on many items. Recently, cross-domain CTR prediction leverages the relatively richer information from a source domain to improve the performance on a target domain with sparser information, but it cannot explicitly capture users' diverse interests in different domains. In this paper, we propose a novel hierarchical user behavior modeling framework for cross-domain CTR prediction, named HBMNet. HBMNet contains two main components: an element-wise behavior transfer(EWBT) layer and a user representation layer. EWBT layer transfers the information collected from one domain by element-level masks to dynamically highlight the informative elements in another domain. The user representation layer performs behavior-level attention between these behavior representations and the ranking item representation. Extensive experimental results on two cross-domain datasets show that the proposed HBMNet outperforms SOTA models.",Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,2022,Short
'Free lunch' enhancement for collaborative filtering with factorization machines,No,"['Babak Loni', 'Alan Said', 'Martha Larson', 'Alan Hanjalic']",https://doi.org/10.1145/2645710.2645771,"The advantage of Factorization Machines over other factorization models is their ability to easily integrate and efficiently exploit auxiliary information to improve Collaborative Filtering. Until now, this auxiliary information has been drawn from external knowledge sources beyond the user-item matrix. In this paper, we demonstrate that Factorization Machines can exploit additional representations of information inherent in the user-item matrix to improve recommendation performance. We refer to our approach as 'Free Lunch' enhancement since it leverages clusters that are based on information that is present in the user-item matrix, but not otherwise directly exploited during matrix factorization. Borrowing clustering concepts from codebook sharing, our approach can also make use of 'Free Lunch' information inherent in a user-item matrix from a auxiliary domain that is different from the target domain of the recommender. Our approach improves performance both in the joint case, in which the auxiliary and target domains share users, and in the disjoint case, in which they do not. Although 'Free Lunch' enhancement does not apply equally well to any given domain or domain combination, our overall conclusion is that Factorization Machines present an opportunity to exploit information that is ubiquitously present, but commonly under-appreciated by Collaborative Filtering algorithms.",Proceedings of the 8th ACM Conference on Recommender Systems,2014,Short
Multi-Interest Refinement by Collaborative Attributes Modeling for Click-Through Rate Prediction,No,"['Huachi Zhou', 'Jiaqi Fan', 'Xiao Huang', 'Ka Li', 'Zhenyu Tang', 'Dahai Yu']",https://doi.org/10.1145/3511808.3557652,"Learning interest representation plays a core role in click-through rate prediction task. Existing Transformer-based approaches learn multi-interests from a sequence of interacted items with rich attributes. The attention weights explain how relevant an item's specific attribute sequence is to the user's interest. However, it implicitly assumes the independence of attributes regarding the same item, which may not always hold in practice. Empirically, the user places varied emphasis on different attributes to consider whether interacting with one item, which is unobserved. Independently modeling each attribute may allow attention to assign probability mass to some unimportant attributes. Collaborative attributes of varied emphasis can be incorporated to help the model more reasonably approximate attributes' relevance to others and generate refined interest representations.To this end, we novelly propose to integrate a dynamic collaborative attribute routing module into Transformer. The module assigns collaborative scores to each attribute of clicked items and induces the extended Transformer to prioritize the influential attributes. To learn collaborative scores without labels, we design a diversity loss to facilitate score differentiation. The comparison with baselines on two real-world benchmark datasets and one industrial dataset validates the effectiveness of the framework.",Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,2022,Short
Using Sentiment Analysis for Pseudo-Relevance Feedback in Social Book Search,No,"['Amal Htait', ""S\\'{e}bastien Fournier"", 'Patrice Bellot', 'Leif Azzopardi', 'Gabriella Pasi']",https://doi.org/10.1145/3409256.3409847,"Book search is a challenging task due to discrepancies between the content and description of books, on one side, and the ways in which people query for books, on the other. However, online reviewers provide an opinionated description of the book, with alternative features that describe the emotional and experiential aspects of the book. Therefore, locating emotional sentences within reviews, could provide a rich alternative source of evidence to help improve book recommendations. Specifically, sentiment analysis (SA) could be employed to identify salient emotional terms, which could then be used for query expansion? This paper explores the employment ofSA based query expansion, in the book search domain. We introduce a sentiment-oriented method for the selection of sentences from the reviews of top rated book. From these sentences, we extract the terms to be employed in the query formulation. The sentence selection process is based on a semi-supervised SA method, which makes use of adapted word embeddings and lexicon seed-words.Using the CLEF 2016 Social Book Search (SBS) Suggestion TrackCollection, an exploratory comparison between standard pseudo-relevance feedback and the proposed sentiment-based approach is performed. The experiments show that the proposed approach obtains 24%-57% improvement over the baselines, whilst the classic technique actually degrades the performance by 14%-51%.",Proceedings of the 2020 ACM SIGIR on International Conference on Theory of Information Retrieval,2020,Short
KGrEaT: A Framework to Evaluate Knowledge Graphs via Downstream Tasks,No,"['Nicolas Heist', 'Sven Hertling', 'Heiko Paulheim']",https://doi.org/10.1145/3583780.3615241,"In recent years, countless research papers have addressed the topics of knowledge graph creation, extension, or completion in order to create knowledge graphs that are larger, more correct, or more diverse. This research is typically motivated by the argumentation that using such enhanced knowledge graphs to solve downstream tasks will improve performance. Nonetheless, this is hardly ever evaluated. Instead, the predominant evaluation metrics - aiming at correctness and completeness - are undoubtedly valuable but fail to capture the complete picture, i.e., how useful the created or enhanced knowledge graph actually is. Further, the accessibility of such a knowledge graph is rarely considered (e.g., whether it contains expressive labels, descriptions, and sufficient context information to link textual mentions to the entities of the knowledge graph). To better judge how well knowledge graphs perform on actual tasks, we present KGrEaT - a framework to estimate the quality of knowledge graphs via actual downstream tasks like classification, clustering, or recommendation. Instead of comparing different methods of processing knowledge graphs with respect to a single task, the purpose of KGrEaT is to compare various knowledge graphs as such by evaluating them on a fixed task setup. The framework takes a knowledge graph as input, automatically maps it to the datasets to be evaluated on, and computes performance metrics for the defined tasks. It is built in a modular way to be easily extendable with additional tasks and datasets.",Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,2023,Short
Mining cross-domain rating datasets from structured data on twitter,No,"['Simon Dooms', 'Toon De Pessemier', 'Luc Martens']",https://doi.org/10.1145/2567948.2579232,"While rating data is essential for all recommender systems research, there are only a few public rating datasets available, most of them years old and limited to the movie domain. With this work, we aim to end the lack of rating data by illustrating how vast amounts of ratings can be unambiguously collected from Twitter. We validate our approach by mining ratings from four major online websites focusing on movies, books, music and video clips. In a short mining period of 2 weeks, close to 3 million ratings were collected. Since some users turned up in more than one dataset, we believe this work to be amongst the first to provide a true cross-domain rating dataset.",Proceedings of the 23rd International Conference on World Wide Web,2014,Short
Modeling the uniqueness of the user preferences for recommendation systems,Keep,"['Haggai Roitman', 'David Carmel', 'Yosi Mass', 'Iris Eiron']",https://doi.org/10.1145/2484028.2484102,"In this paper we propose a novel framework for modeling the uniqueness of the user preferences for recommendation systems. User uniqueness is determined by learning to what extent the user's item preferences deviate from those of an ""average user"" in the system. Based on this framework, we suggest three different recommendation strategies that trade between uniqueness and conformity. Using two real item datasets, we demonstrate the effectiveness of our uniqueness based recommendation framework.",Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval,2013,Short
A Complete &amp; Comprehensive Movie Review Dataset (CCMR),No,"['Xuezhi Cao', 'Weiyue Huang', 'Yong Yu']",https://doi.org/10.1145/2911451.2914669,"Online review sites are widely used for various domains including movies and restaurants. These sites now have strong influences towards users during purchasing processes. There exist plenty of research works for review sites on various aspects, including item recommendation, user behavior analysis, etc. However, due to the lack of complete and comprehensive dataset, there are still problems that remain to be solved. Therefore, in this paper we assemble and publish such dataset (CCMR) for the community. CCMR outruns existing datasets in terms of completeness, comprehensiveness and scale. Besides describing the dataset and its collecting methodology, we also propose several potential research topics that are made possible by having this dataset. Such topics include: (i) a statistical approach to reduce the impacts from fake reviews and (ii) analyzing and modeling the influences of public opinions towards users during rating actions. We further conduct preliminary analysis and experiments for both directions to show that they are promising.",Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval,2016,Short
Adaptive User Engagement Evaluation via Multi-task Learning,No,"['Hamed Zamani', 'Pooya Moradi', 'Azadeh Shakery']",https://doi.org/10.1145/2766462.2767785,"User engagement evaluation task in social networks has recently attracted considerable attention due to its applications in recommender systems. In this task, the posts containing users' opinions about items, e.g., the tweets containing the users' ratings about movies in the IMDb website, are studied. In this paper, we try to make use of tweets from different web applications to improve the user engagement evaluation performance. To this aim, we propose an adaptive method based on multi-task learning. Since in this paper we study the problem of detecting tweets with positive engagement which is a highly imbalanced classification problem, we modify the loss function of multi-task learning algorithms to cope with the imbalanced data. Our evaluations over a dataset including the tweets of four diverse and popular data sources, i.e., IMDb, YouTube, Goodreads, and Pandora, demonstrate the effectiveness of the proposed method. Our findings suggest that transferring knowledge between data sources can improve the user engagement evaluation performance.",Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval,2015,Short
"Mapping Cultural Representations of Machine Vision: Developing Methods to Analyse Games, Art and Narratives",No,"['Jill Rettberg', 'Marianne Gunderson', 'Linda Kronman', 'Ragnhild Solberg', 'Linn Stokkedal']",https://doi.org/10.1145/3342220.3343647,"Machine vision technologies are increasingly ubiquitous in society and have become part of everyday life. However, the rapid adoption has led to ethical concerns relating to privacy, agency, bias and accuracy. This paper presents the methodology and preliminary results from a digital humanities project that maps and categorises references to and uses of machine vision in digital art, narratives and games in order to find patterns to help us analyse broader cultural understandings of machine vision in society. Understanding the cultural significance and valence of machine vision is crucial for developers of machine vision technologies, so that new technologies are designed to meet general needs and ethical concerns, and ultimately contribute to a better, more just society.",Proceedings of the 30th ACM Conference on Hypertext and Social Media,2019,Short
Personalized Entity Search by Sparse and Scrutable User Profiles,No,"['Ghazaleh Torbati', 'Andrew Yates', 'Gerhard Weikum']",https://doi.org/10.1145/3343413.3378011,"Prior work on personalizing web search results has focused on considering query-and-click logs to capture users' individual interests. For product search, extensive user histories about purchases and ratings have been exploited. However, for general entity search, such as for books on specific topics or travel destinations with certain features, personalization is largely underexplored. In this paper, we address personalization of book search, as an exemplary case of entity search, by exploiting sparse user profiles obtained through online questionnaires. We devise and compare a variety of re-ranking methods based on language models or neural learning. Our experiments show that even very sparse information about individuals can enhance the effectiveness of the search results.",Proceedings of the 2020 Conference on Human Information Interaction and Retrieval,2020,Short
Novel Views on Novels:Embedding Multiple Facets of Long Texts,No,"['Lasse Kohlmeyer', 'Tim Repke', 'Ralf Krestel']",https://doi.org/10.1145/3486622.3494006,"Novels are one of the longest document types and thus one of the most complex types of texts. Many NLP tasks utilize document embeddings as machine-understandable semantic representations of documents. However, such document embeddings are optimized for short texts, such as sentences or paragraphs. When faced with longer texts, these models either truncate the long text or split it sequentially into smaller chunks. We show that when applied to a fictional novel, these traditional document embeddings fail to capture all its facets. Complex information, such as time, place, atmosphere, style, and plot is typically not represented adequately. To this end, we propose lib2vec which computes and combines multiple embedding vectors based on various facets. Instead of splitting the text sequentially, lib2vec splits the text semantically based on domain-specific facets. We evaluate the semantic expressiveness using human-assessed book comparisons as well as content-based information retrieval tasks. The results show that our approach outperforms state-of-the-art document embeddings for long texts.",IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology,2022,Short
Reproducing Popularity Bias in Recommendation: The Effect of Evaluation Strategies,Yes,"['Savvina Daniil', 'Mirjam Cuper', 'Cynthia Liem', 'Jacco Ossenbruggen', 'Laura Hollink']",https://doi.org/10.1145/3637066,"The extent to which popularity bias is propagated by media recommender systems is a current topic within the community, as is the uneven propagation among users with varying interests for niche items. Recent work focused on exactly this topic, with movies being the domain of interest. Later on, two different research teams reproduced the methodology in the domains of music and books, respectively. The results across the different domains diverge. In this paper, we reproduce the three studies and identify four aspects that are relevant in investigating the differences in results: data, algorithms, division of users in groups and evaluation strategy. We run a set of experiments in which we measure general popularity bias propagation and unfair treatment of certain users with various combinations of these aspects. We conclude that all aspects account to some degree for the divergence in results, and should be carefully considered in future studies. Further, we find that the divergence in findings can be in large part attributed to the choice of evaluation strategy.",missing,2024,Research
Toward Bias-Agnostic Recommender Systems: A Universal Generative Framework,Yes,"['Zhidan Wang', 'Lixin Zou', 'Chenliang Li', 'Shuaiqiang Wang', 'Xu Chen', 'Dawei Yin', 'Weidong Liu']",https://doi.org/10.1145/3655617,"User behavior data, such as ratings and clicks, has been widely used to build personalizing models for recommender systems. However, many unflattering factors&nbsp;(e.g., popularity, ranking position, users’ selection) significantly affect the performance of the learned recommendation model. Most existing work on unbiased recommendation addressed these biases from sample granularity&nbsp;(e.g., sample reweighting, data augmentation) or from the perspective of representation learning&nbsp;(e.g., bias-modeling). However, these methods are usually designed for a specific bias, lacking the universal capability to handle complex situations where multiple biases co-exist. Besides, rare work frees itself from laborious and sophisticated debiasing configurations&nbsp;(e.g., propensity scores, imputed values, or user behavior-generating process).Towards this research gap, in this article, we propose a universal Generative framework for Bias Disentanglement termed as GBD, constantly generating calibration perturbations for the intermediate representations during training to keep them from being affected by the bias. Specifically, a bias-identifier that tries to retrieve the bias-related information from the representations is first introduced. Subsequently, the calibration perturbations are generated to significantly deteriorate the bias-identifier’s performance, making the bias gradually disentangled from the calibrated representations. Therefore, without relying on notorious debiasing configurations, a bias-agnostic model is obtained under the guidance of the bias identifier. We further present its universality by subsuming the representative biases and their mixture under the proposed framework. Finally, extensive experiments on the real-world, synthetic, and semi-synthetic datasets have demonstrated the superiority of the proposed approach against a wide range of recommendation debiasing methods. The code is available at .",missing,2024,Research
Evaluating the performance and privacy of a token-based collaborative recommender,No,"['Ville Ollikainen', 'Valtteri Niemi']",https://doi.org/10.1145/3106426.3109434,"The rapid expansion of available online services has raised concerns about user privacy. In the online world, only a minority of users is actually aware where their data is stored and the policies, how the data may be eventually used. However, at the same time consumers expect more quality from online services, demanding personalized services that fit their individual needs, preferences and values. One approach for service personalization is to use collaborative recommenders. From the privacy perspective, mainstream collaborative recommenders present an inherent security risk, since they are based on memorizing user-item transactions. In this paper, we will study a recently developed token-based method (sometimes referred as an acronym ""upcv"") which creates privacy-protecting abstraction that is based on collections of randomly generated tokens. These collections are capable of providing information for collaborative recommendations without maintaining any transactional history. This paper presents quality evaluation of item-to-item recommendations using the token-based collaborative recommender, utilizing ISBN agencies of Book-Crossing dataset (BX) books at the data set. This paper will also discuss challenges related to BX. Privacy issues are evaluated with a specific emphasis on the concept of deniability.",Proceedings of the International Conference on Web Intelligence,2017,Research
What We Evaluate When We Evaluate Recommender Systems: Understanding Recommender Systems’ Performance using Item Response Theory,Yes,"['Yang Liu', 'Alan Medlar', 'Dorota Glowacka']",https://doi.org/10.1145/3604915.3608809,"Current practices in offline evaluation use rank-based metrics to measure the quality of top-n recommendation lists. This approach has practical benefits as it centres assessment on the output of the recommender system and, therefore, measures performance from the perspective of end-users. However, this methodology neglects how recommender systems more broadly model user preferences, which is not captured by only considering the top-n recommendations. In this article, we use item response theory (IRT), a family of latent variable models used in psychometric assessment, to gain a comprehensive understanding of offline evaluation. We use IRT to jointly estimate the latent abilities of 51 recommendation algorithms and the characteristics of 3 commonly used benchmark data sets. For all data sets, the latent abilities estimated by IRT suggest that higher scores from traditional rank-based metrics do not reflect improvements in modeling user preferences. Furthermore, we show that the top-n recommendations with the most discriminatory power are biased towards lower difficulty items, leaving much room for improvement. Lastly, we highlight the role of popularity in evaluation by investigating how user engagement and item popularity influence recommendation difficulty.",Proceedings of the 17th ACM Conference on Recommender Systems,2023,Research
A Personalized Framework for Consumer and Producer Group Fairness Optimization in Recommender Systems,Yes,"['Hossein Rahmani', 'Mohammadmehdi Naghiaei', 'Yashar Deldjoo']",https://doi.org/10.1145/3651167,"In recent years, there has been an increasing recognition that when machine learning (ML) algorithms are used to automate decisions, they may mistreat individuals or groups, with legal, ethical, or economic implications. Recommender systems are prominent examples of these ML systems that aid users in making decisions. The majority of past literature research on recommender systems fairness treats user and item fairness concerns independently, ignoring the fact that recommender systems function in a two-sided marketplace. In this article, we propose CP-FairRank, an optimization-based re-ranking algorithm that seamlessly integrates fairness constraints from both the consumer and producer side in a joint objective framework. The framework is generalizable and may take into account varied fairness settings based on group segmentation, recommendation model selection, and domain, which is one of its key characteristics. For instance, we demonstrate that the system may jointly increase consumer and producer fairness when (un)protected consumer groups are defined on the basis of their&nbsp;activity level and&nbsp;main-streamness, while producer groups are defined according to their popularity level. For empirical validation, through large-scale on eight datasets and four mainstream collaborative filtering recommendation models, we demonstrate that our proposed strategy is able to improve both consumer and producer fairness without compromising or very little overall recommendation quality, demonstrating the role algorithms may play in avoiding data biases. Our results on different group segmentation also indicate that the amount of improvement can vary and is dependent on group segmentation, indicating that the amount of bias produced and how much the algorithm can improve it depend on the protected group definition, a factor that, to our knowledge, has not been examined in great depth in previous studies but rather is highlighted by the results discovered in this study.",missing,2024,Research
Navigating Serendipity - An Experimental User Study On The Interplay of Trust and Serendipity In Recommender Systems,Keep,"['Irina Nalis', 'Tobias Sippl', 'Thomas Kolb', 'Julia Neidhardt']",https://doi.org/10.1145/3631700.3664901,"Recommender systems play a crucial role in our daily lives, constantly evolving to meet the diverse needs of users. As the pursuit of improved user experiences continues, metrics such as serendipity have emerged within the realm of beyond-accuracy paradigms. However, integrating serendipitous recommendations presents complex challenges, necessitating a delicate balance between novelty, relevance, and user engagement. In this interdisciplinary experimental user study, we address these challenges within the context of a book recommender system. By investigating the impact of interface design changes on user trust, a key determinant of satisfaction with serendipitous recommendations, we measured trust levels for both individual recommended items and the recommender system as a whole. Our findings indicate that while interface enhancements did not yield significant increases in trust, they did notably elevate serendipity ratings for previously unknown books. These results highlight the intricate interplay between technical and psychological factors in the design of recommender systems, emphasizing the importance of human-centered approaches in the creation of more responsible AI applications. This research contributes to ongoing discussions surrounding user-centric recommendation systems and aligns with broader themes of digital humanism and responsible AI.","Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization",2024,Research
Exploring the Landscape of Recommender Systems Evaluation: Practices and Perspectives,Keep,"['Christine Bauer', 'Eva Zangerle', 'Alan Said']",https://doi.org/10.1145/3629170,"Recommender systems research and practice are fast-developing topics with growing adoption in a wide variety of information access scenarios. In this article, we present an overview of research specifically focused on the evaluation of recommender systems. We perform a systematic literature review, in which we analyze 57 papers spanning six years (2017–2022). Focusing on the processes surrounding evaluation, we dial in on the methods applied, the datasets utilized, and the metrics used. Our study shows that the predominant experiment type in research on the evaluation of recommender systems is offline experimentation and that online evaluations are primarily used in combination with other experimentation methods, e.g., an offline experiment. Furthermore, we find that only a few datasets (MovieLens, Amazon review dataset) are widely used, while many datasets are used in only a few papers each. We observe a similar scenario when analyzing the employed performance metrics—a few metrics are widely used (precision, normalized Discounted Cumulative Gain, and Recall), while many others are used in only a few papers. Overall, our review indicates that beyond-accuracy qualities are rarely assessed. Our analysis shows that the research community working on evaluation has focused on the development of evaluation in a rather narrow scope, with the majority of experiments focusing on a few metrics, datasets, and methods.",missing,2024,Research
Biased User History Synthesis for Personalized Long-Tail Item Recommendation,Yes,"['Keshav Balasubramanian', 'Abdulla Alshabanah', 'Elan Markowitz', 'Greg Ver Steeg', 'Murali Annavaram']",https://doi.org/10.1145/3640457.3688141,"Recommendation systems connect users to items and create value chains in the internet economy. Recommendation systems learn from past user-item interaction histories. As such, items that have short interaction histories, either because they are new or not popular, have been shown to be disproportionately under-recommended. This long-tail item problem can exacerbate model bias, and reinforce poor recommendation of tail items. In this paper, we propose biased user history synthesis, to not only address this problem but also achieve better personalization in recommendation systems. As a result, we concurrently improve tail and head item recommendation performance. Our approach is built on a tail item biased User Interaction History (UIH) sampling strategy and a synthesis model that produces an augmented user representation from the sampled user history. We provide a theoretical justification for our approach using information theory and demonstrate through extensive experimentation, that our model outperforms state-of-the-art baselines on tail, head, and overall recommendation. The source code is available at https://github.com/lkp411/BiasedUserHistorySynthesis.",Proceedings of the 18th ACM Conference on Recommender Systems,2024,Research
User Cold-Start Learning in Recommender Systems using Monte Carlo Tree Search,No,"['Dilina Rajapakse', 'Douglas Leith']",https://doi.org/10.1145/3618002,"We consider the cold-start task for new users of a recommender system, whereby a new user is asked to rate a few items with the aim of quickly discovering the user’s preferences. This is a combinatorial stochastic learning task, and so it is difficult in general. In this paper we study the use of Monte Carlo Tree Search (MCTS) to dynamically select the sequence of items presented to a new user. We find that the MCTS-based cold-start approach is able to consistently quickly identify the preferences of a user with significantly higher accuracy than with either a decision tree or a state-of-the-art bandit-based approach without incurring higher regret, i.e., the learning performance is fundamentally superior to that of the state of the art. This boost in recommender accuracy is achieved in a computationally lightweight fashion. The MCTS approach is flexible in the sense that it can be readily extended to incorporate different types of user feedback including explicit ratings, ranked comparisons and missing not at random data.",missing,2024,Research
Countering Popularity Bias by Regularizing Score Differences,Yes,"['Wondo Rhee', 'Sung Cho', 'Bongwon Suh']",https://doi.org/10.1145/3523227.3546757,"Recommendation system often suffers from popularity bias. Often the training data inherently exhibits long-tail distribution in item popularity (data bias). Moreover, the recommendation systems could give unfairly higher recommendation scores to popular items even among items a user equally liked, resulting in over-recommendation of popular items (model bias). In this study we propose a novel method to reduce the model bias while maintaining accuracy by directly regularizing the recommendation scores to be equal across items a user preferred. Akin to contrastive learning, we extend the widely used pairwise loss (BPR loss) which maximizes the score differences between preferred and unpreferred items, with a regularization term that minimizes the score differences within preferred and unpreferred items, respectively, thereby achieving both high debias and high accuracy performance with no additional training. To test the effectiveness of the proposed method, we design an experiment using a synthetic dataset which induces model bias with baseline training; we showed applying the proposed method resulted in drastic reduction of model bias while maintaining accuracy. Comprehensive comparison with earlier debias methods showed the proposed method had advantages in terms of computational validity and efficiency. Further empirical experiments utilizing four benchmark datasets and four recommendation models indicated the proposed method showed general improvements over performances of earlier debias methods. We hope that our method could help users enjoy diverse recommendations promoting serendipitous findings. Code available at https://github.com/stillpsy/popbias.",Proceedings of the 16th ACM Conference on Recommender Systems,2022,Research
Rethinking Multi-Interest Learning for Candidate Matching in Recommender Systems,Keep,"['Yueqi Xie', 'Jingqi Gao', 'Peilin Zhou', 'Qichen Ye', 'Yining Hua', 'Jae Kim', 'Fangzhao Wu', 'Sunghun Kim']",https://doi.org/10.1145/3604915.3608766,"Existing research efforts for multi-interest candidate matching in recommender systems mainly focus on improving model architecture or incorporating additional information, neglecting the importance of training schemes. This work revisits the training framework and uncovers two major problems hindering the expressiveness of learned multi-interest representations. First, the current training objective (i.e., uniformly sampled softmax) fails to effectively train discriminative representations in a multi-interest learning scenario due to the severe increase in easy negative samples. Second, a routing collapse problem is observed where each learned interest may collapse to express information only from a single item, resulting in information loss. To address these issues, we propose the REMI framework, consisting of an Interest-aware Hard Negative mining strategy (IHN) and a Routing Regularization (RR) method. IHN emphasizes interest-aware hard negatives by proposing an ideal sampling distribution and developing a Monte-Carlo strategy for efficient approximation. RR prevents routing collapse by introducing a novel regularization term on the item-to-interest routing matrices. These two components enhance the learned multi-interest representations from both the optimization objective and the composition information. REMI is a general framework that can be readily applied to various existing multi-interest candidate matching methods. Experiments on three real-world datasets show our method can significantly improve state-of-the-art methods with easy implementation and negligible computational overhead. The source code is available at https://github.com/Tokkiu/REMI.",Proceedings of the 17th ACM Conference on Recommender Systems,2023,Research
Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models,No,"['Yunjia Xi', 'Weiwen Liu', 'Jianghao Lin', 'Xiaoling Cai', 'Hong Zhu', 'Jieming Zhu', 'Bo Chen', 'Ruiming Tang', 'Weinan Zhang', 'Yong Yu']",https://doi.org/10.1145/3640457.3688104,"Recommender system plays a vital role in various online services. However, its insulated nature of training and deploying separately within a specific closed domain limits its access to open-world knowledge. Recently, the emergence of large language models (LLMs) has shown promise in bridging this gap by encoding extensive world knowledge and demonstrating reasoning capabilities. Nevertheless, previous attempts to directly use LLMs as recommenders cannot meet the inference latency demand of industrial recommender systems. In this work, we propose an Open-World Knowledge Augmented Recommendation Framework with Large Language Models, dubbed KAR, to acquire two types of external knowledge from LLMs — the reasoning knowledge on user preferences and the factual knowledge on items. We introduce factorization prompting to elicit accurate reasoning on user preferences. The generated reasoning and factual knowledge are effectively transformed and condensed into augmented vectors by a hybrid-expert adaptor in order to be compatible with the recommendation task. The obtained vectors can then be directly used to enhance the performance of any recommendation model. We also ensure efficient inference by preprocessing and prestoring the knowledge from the LLM. Extensive experiments show that KAR significantly outperforms the state-of-the-art baselines and is compatible with a wide range of recommendation algorithms. We deploy KAR to Huawei’s news and music recommendation platforms and gain a 7% and 1.7% improvement in the online A/B test, respectively.",Proceedings of the 18th ACM Conference on Recommender Systems,2024,Research
On the Effectiveness of Sampled Softmax Loss for Item Recommendation,Keep,"['Jiancan Wu', 'Xiang Wang', 'Xingyu Gao', 'Jiawei Chen', 'Hongcheng Fu', 'Tianyu Qiu']",https://doi.org/10.1145/3637061,"The learning objective plays a fundamental role to build a recommender system. Most methods routinely adopt either pointwise (e.g., binary cross-entropy) or pairwise (e.g., BPR) loss to train the model parameters, while rarely pay attention to softmax loss, which assumes the probabilities of all classes sum up to 1, due to its computational complexity when scaling up to large datasets or intractability for streaming data where the complete item space is not always available. The sampled softmax (SSM) loss emerges as an efficient substitute for softmax loss. Its special case, InfoNCE loss, has been widely used in self-supervised learning and exhibited remarkable performance for contrastive learning. Nonetheless, limited recommendation work uses the SSM loss as the learning objective. Worse still, none of them explores its properties thoroughly and answers “Does SSM loss suit for item recommendation?” and “What are the conceptual advantages of SSM loss, as compared with the prevalent losses?”, to the best of our knowledge.In this work, we aim at offering a better understanding of SSM for item recommendation. Specifically, we first theoretically reveal three model-agnostic advantages: (1) mitigating popularity bias, which is beneficial to long-tail recommendation; (2) mining hard negative samples, which offers informative gradients to optimize model parameters; and (3) maximizing the ranking metric, which facilitates top-K performance. However, based on our empirical studies, we recognize that the default choice of cosine similarity function in SSM limits its ability in learning the magnitudes of representation vectors. As such, the combinations of SSM with the models that also fall short in adjusting magnitudes (e.g., matrix factorization) may result in poor representations. One step further, we provide mathematical proof that message passing schemes in graph convolution networks can adjust representation magnitude according to node degree, which naturally compensates for the shortcoming of SSM. Extensive experiments on four benchmark datasets justify our analyses, demonstrating the superiority of SSM for item recommendation. Our implementations are available in both TensorFlow1 and PyTorch.2",missing,2024,Research
A Survey on Recommender Systems using Graph Neural Network,Keep,"['Vineeta Anand', 'Ashish Maurya']",https://doi.org/10.1145/3694784,"The expansion of the Internet has resulted in a change in the flow of information. With the vast amount of digital information generated online, it is easy for users to feel overwhelmed. Finding the specific information can be a challenge, and it can be difficult to distinguish credible sources from unreliable ones. This has made recommender system (RS) an integral part of the information services framework. These systems alleviate users from information overload by analyzing users’ past preferences and directing only desirable information toward users. Traditional RSs use approaches like collaborative and content-based filtering to generate recommendations. Recently, these systems have evolved to a whole new level, intuitively optimizing recommendations using deep network models. Graph Neural Networks (GNNs) have become one of the most widely used approaches in RSs, capturing complex relationships between users and items using graphs. In this survey, we provide a literature review of the latest research efforts done on GNN-based RSs. We present an overview of RS, discuss its generalized pipeline and evolution with changing learning approaches. Furthermore, we explore basic GNN architecture and its variants used in RSs, their applications, and some critical challenges for future research.",missing,2024,Research
User Perceptions of Diversity in Recommender Systems,Yes,"['Patrik Dokoupil', 'Ludovico Boratto', 'Ladislav Peska']",https://doi.org/10.1145/3627043.3659555,"In the context of recommender systems (RS), the concept of diversity is probably the most studied perspective beyond mere accuracy. Despite the extensive development of diversity measures and enhancement methods, the understanding of how users perceive diversity in recommendations remains limited. This gap hinders progress in multi-objective RS, as it challenges the alignment of algorithmic advancements with genuine user needs. Addressing this, our study delves into two key aspects of diversity perception in RS. We investigate user responses to recommendation lists generated using varied diversity metrics but identical diversification thresholds, and lists created with the same metrics but differing thresholds. Our findings reveal a user preference for metadata and content-based diversity metrics over collaborative ones. Interestingly, while users typically recognize more diversified lists as being more diverse in scenarios with significant diversification differences, this perception is not consistently linear and quickly diminishes when the diversification variance between lists is less pronounced. This study sheds light on the nuanced user perceptions of diversity in RS, providing valuable insights for the development of more user-centric recommendation algorithms. Study data and analysis scripts are available from https://osf.io/9y8gx/.","Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization",2024,Research
Towards a More User-Friendly and Easy-to-Use Benchmark Library for Recommender Systems,No,"['Lanling Xu', 'Zhen Tian', 'Gaowei Zhang', 'Junjie Zhang', 'Lei Wang', 'Bowen Zheng', 'Yifan Li', 'Jiakai Tang', 'Zeyu Zhang', 'Yupeng Hou', 'Xingyu Pan', 'Wayne Zhao', 'Xu Chen', 'Ji-Rong Wen']",https://doi.org/10.1145/3539618.3591889,"In recent years, the reproducibility of recommendation models has become a severe concern in recommender systems. In light of this challenge, we have previously released a unified, comprehensive and efficient recommendation library called RecBole, attracting much attention from the research community. With the increasing number of users, we have received a number of suggestions and update requests. This motivates us to make further improvements on our library, so as to meet the user requirements and contribute to the research community. In this paper, we present a significant update of RecBole, making it more user-friendly and easy-to-use as a comprehensive benchmark library for recommendation. More specifically, the highlights of this update are summarized as: (1) we include more benchmark models and datasets, improve the benchmark framework in terms of data processing, training and evaluation, and release reproducible configurations to benchmark the recommendation models; (2) we upgrade the user friendliness of our library by providing more detailed documentation and well-organized frequently asked questions, and (3) we propose several development guidelines for the open-source library developers. These extensions make it much easier to reproduce the benchmark results and stay up-to-date with the recent advances on recommender systems. Our update is released at the link: https://github.com/RUCAIBox/RecBole.",Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval,2023,Research
AMBAR: A dataset for Assessing Multiple Beyond-Accuracy Recommenders,No,"[""Elizabeth G\\'{o}mez"", 'David Contreras', 'Ludovico Boratto', 'Maria Salamo']",https://doi.org/10.1145/3640457.3688067,"Nowadays a recommendation model should exploit additional information from both the user and item perspectives, in addition to utilizing user-item interaction data. Datasets are central in offering the required information for evaluating new models or algorithms. Although there are many datasets in the literature with user and item properties, there are several issues not covered yet: (i) it is difficult to perform cross-analysis of properties at user and item level as they are not related in most cases; and (ii) on top of that, in many occasions datasets do not allow analysis at different granularity levels. In this paper, we propose a new dataset in the music domain, named AMBAR, that tackles the above-mentioned issues. Besides detailing in depth the structure of the new dataset, we also show its application in contexts (i.e., multi-objective, fair, and calibrated recommendations) where both the effectiveness and the beyond-accuracy perspectives of recommendation are assessed.",Proceedings of the 18th ACM Conference on Recommender Systems,2024,Research
AutoML for Deep Recommender Systems: A Survey,No,"['Ruiqi Zheng', 'Liang Qu', 'Bin Cui', 'Yuhui Shi', 'Hongzhi Yin']",https://doi.org/10.1145/3579355,"Recommender systems play a significant role in information filtering and have been utilized in different scenarios, such as e-commerce and social media. With the prosperity of deep learning, deep recommender systems show superior performance by capturing non-linear information and item-user relationships. However, the design of deep recommender systems heavily relies on human experiences and expert knowledge. To tackle this problem, Automated Machine Learning (AutoML) is introduced to automatically search for the proper candidates for different parts of deep recommender systems. This survey performs a comprehensive review of the literature in this field. First, we propose an abstract concept for AutoML for deep recommender systems (AutoRecSys) that describes its building blocks and distinguishes it from conventional AutoML techniques and recommender systems. Second, we present a taxonomy as a classification framework containing feature selection search, embedding dimension search, feature interaction search, model architecture search, and other components search. Furthermore, we put a particular emphasis on the search space and search strategy, as they are the common thread to connect all methods within each category and enable practitioners to analyze and compare various approaches. Finally, we propose four future promising research directions that will lead this line of research.",missing,2023,Research
On the Opportunities and Challenges of Offline Reinforcement Learning for Recommender Systems,No,"['Xiaocong Chen', 'Siyu Wang', 'Julian Mcauley', 'Dietmar Jannach', 'Lina Yao']",https://doi.org/10.1145/3661996,"Reinforcement learning serves as a potent tool for modeling dynamic user interests within recommender systems, garnering increasing research attention of late. However, a significant drawback persists: its poor data efficiency, stemming from its interactive nature. The training of reinforcement learning-based recommender systems demands expensive online interactions to amass adequate trajectories, essential for agents to learn user preferences. This inefficiency renders reinforcement learning-based recommender systems a formidable undertaking, necessitating the exploration of potential solutions. Recent strides in offline reinforcement learning present a new perspective. Offline reinforcement learning empowers agents to glean insights from offline datasets and deploy learned policies in online settings. Given that recommender systems possess extensive offline datasets, the framework of offline reinforcement learning aligns seamlessly. Despite being a burgeoning field, works centered on recommender systems utilizing offline reinforcement learning remain limited. This survey aims to introduce and delve into offline reinforcement learning within recommender systems, offering an inclusive review of existing literature in this domain. Furthermore, we strive to underscore prevalent challenges, opportunities, and future pathways, poised to propel research in this evolving field.",missing,2024,Research
Knowledge-based Multiple Adaptive Spaces Fusion for Recommendation,No,"['Meng Yuan', 'Fuzhen Zhuang', 'Zhao Zhang', 'Deqing Wang', 'Jin Dong']",https://doi.org/10.1145/3604915.3608787,"Since Knowledge Graphs (KGs) contain rich semantic information, recently there has been an influx of KG-enhanced recommendation methods. Most of existing methods are entirely designed based on euclidean space without considering curvature. However, recent studies have revealed that a tremendous graph-structured data exhibits highly non-euclidean properties. Motivated by these observations, in this work, we propose a knowledge-based multiple adaptive spaces fusion method for recommendation, namely MCKG. Unlike existing methods that solely adopt a specific manifold, we introduce the unified space that is compatible with hyperbolic, euclidean and spherical spaces. Furthermore, we fuse the multiple unified spaces in an attention manner to obtain the high-quality embeddings for better knowledge propagation. In addition, we propose a geometry-aware optimization strategy which enables the pull and push processes benefited from both hyperbolic and spherical spaces. Specifically, in hyperbolic space, we set smaller margins in the area near to the origin, which is conducive to distinguishing between highly similar positive items and negative ones. At the same time, we set larger margins in the area far from the origin to ensure the model has sufficient error tolerance. The similar manner also applies to spherical spaces. Extensive experiments on three real-world datasets demonstrate that the MCKG has a significant improvement over state-of-the-art recommendation methods. Further ablation experiments verify the importance of multi-space fusion and geometry-aware optimization strategy, justifying the rationality and effectiveness of MCKG.",Proceedings of the 17th ACM Conference on Recommender Systems,2023,Research
Comprehensive Fair Meta-learned Recommender System,Yes,"['Tianxin Wei', 'Jingrui He']",https://doi.org/10.1145/3534678.3539269,"In recommender systems, one common challenge is the cold-start problem, where interactions are very limited for fresh users in the systems. To address this challenge, recently, many works introduce the meta-optimization idea into the recommendation scenarios, i.e. learning to learn the user preference by only a few past interaction items. The core idea is to learn global shared meta-initialization parameters for all users and rapidly adapt them into local parameters for each user respectively. They aim at deriving general knowledge across preference learning of various users, so as to rapidly adapt to the future new user with the learned prior and a small amount of training data. However, previous works have shown that recommender systems are generally vulnerable to bias and unfairness. Despite the success of meta-learning at improving the recommendation performance with cold-start, the fairness issues are largely overlooked.In this paper, we propose a comprehensive fair meta-learning framework, named CLOVER, for ensuring the fairness of meta-learned recommendation models. We systematically study three kinds of fairness - individual fairness, counterfactual fairness, and group fairness in the recommender systems, and propose to satisfy all three kinds via a multi-task adversarial learning scheme. Our framework offers a generic training paradigm that is applicable to different meta-learned recommender systems. We demonstrate the effectiveness of CLOVER on the representative meta-learned user preference estimator on three real-world data sets. Empirical results show that CLOVER achieves comprehensive fairness without deteriorating the overall cold-start recommendation performance.",Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,2022,Research
Collaboration-Aware Graph Convolutional Network for Recommender Systems,No,"['Yu Wang', 'Yuying Zhao', 'Yi Zhang', 'Tyler Derr']",https://doi.org/10.1145/3543507.3583229,"Graph Neural Networks (GNNs) have been successfully adopted in recommender systems by virtue of the message-passing that implicitly captures collaborative effect. Nevertheless, most of the existing message-passing mechanisms for recommendation are directly inherited from GNNs without scrutinizing whether the captured collaborative effect would benefit the prediction of user preferences. In this paper, we first analyze how message-passing captures the collaborative effect and propose a recommendation-oriented topological metric, Common Interacted Ratio (CIR), which measures the level of interaction between a specific neighbor of a node with the rest of its neighbors. After demonstrating the benefits of leveraging collaborations from neighbors with higher CIR, we propose a recommendation-tailored GNN, Collaboration-Aware Graph Convolutional Network (CAGCN), that goes beyond 1-Weisfeiler-Lehman(1-WL) test in distinguishing non-bipartite-subgraph-isomorphic graphs. Experiments on six benchmark datasets show that the best CAGCN variant outperforms the most representative GNN-based recommendation model, LightGCN, by nearly 10% in Recall@20 and also achieves around 80% speedup. Our code/supplementary is at https://github.com/YuWVandy/CAGCN.",Proceedings of the ACM Web Conference 2023,2023,Research
Expressive Latent Feature Modelling for Explainable Matrix Factorisation-based Recommender Systems,No,"['Abdullah Alhejaili', 'Shaheen Fatima']",https://doi.org/10.1145/3530299,"The traditional matrix factorisation (MF)-based recommender system methods, despite their success in making the recommendation, lack explainable recommendations as the produced latent features are meaningless and cannot explain the recommendation. This article introduces an MF-based explainable recommender system framework that utilises the user-item rating data and the available item information to model meaningful user and item latent features. These features are exploited to enhance the rating prediction accuracy and the recommendation explainability. Our proposed feature-based explainable recommender system framework utilises these meaningful user and item latent features to explain the recommendation without relying on private or outer data. The recommendations are explained to the user using text message and bar chart. Our proposed model has been evaluated in terms of the rating prediction accuracy and the reasonableness of the explanation using six real-world benchmark datasets for movies, books, video games, and fashion recommendation systems. The results show that the proposed model can produce accurate explainable recommendations.",missing,2022,Research
Using Neural and Graph Neural Recommender Systems to Overcome Choice Overload: Evidence From a Music Education Platform,No,"[""H\\'{e}di Razgallah"", 'Michalis Vlachos', 'Ahmad Ajalloeian', 'Ninghao Liu', 'Johannes Schneider', 'Alexis Steinmann']",https://doi.org/10.1145/3637873,"The application of recommendation technologies has been crucial in the promotion of physical and digital content across numerous global platforms such as Amazon, Apple, and Netflix. Our study aims to investigate the advantages of employing recommendation technologies on educational platforms, with a particular focus on an educational platform for learning and practicing music. Our research is based on data from Tomplay, a music platform that offers sheet music with professional audio recordings, enabling users to discover and practice music content at varying levels of difficulty. Through our analysis, we emphasize the distinct interaction patterns on educational platforms like Tomplay, which we compare with other commonly used recommendation datasets. We find that interactions are comparatively sparse on educational platforms, with users often focusing on specific content as they learn, rather than interacting with a broader range of material. Therefore, our primary goal is to address the issue of data sparsity. We achieve this through entity resolution principles and propose a neural network (NN)-based recommendation model. Further, we improve this model by utilizing graph neural networks (GNNs), which provide superior predictive accuracy compared to NNs. Notably, our study demonstrates that GNNs are highly effective even for users with little or no historical preferences (cold-start problem). Our cold-start experiments also provide valuable insights into an independent issue, namely, the number of historical interactions needed by a recommendation model to gain a comprehensive understanding of a user. Our findings demonstrate that a platform acquires a solid knowledge of a user’s general preferences and characteristics with 50 past interactions. Overall, our study makes significant contributions to information systems research on business analytics and prescriptive analytics. Moreover, our framework and evaluation results offer implications for various stakeholders, including online educational institutions, education policymakers, and learning platform users.",missing,2024,Research
Top-Personalized-K Recommendation,No,"['Wonbin Kweon', 'SeongKu Kang', 'Sanghwan Jang', 'Hwanjo Yu']",https://doi.org/10.1145/3589334.3645417,"The conventional top-K recommendation, which presents the top-K items with the highest ranking scores, is a common practice for generating personalized ranking lists. However, is this fixed-size top-K recommendation the optimal approach for every user's satisfaction? Not necessarily. We point out that providing fixed-size recommendations without taking into account user utility can be suboptimal, as it may unavoidably include irrelevant items or limit the exposure to relevant ones. To address this issue, we introduce Top-Personalized-K Recommendation, a new recommendation task aimed at generating a personalized-sized ranking list to maximize individual user satisfaction. As a solution to the proposed task, we develop a model-agnostic framework named PerK. PerK estimates the expected user utility by leveraging calibrated interaction probabilities, subsequently selecting the recommendation size that maximizes this expected utility. Through extensive experiments on real-world datasets, we demonstrate the superiority of PerK in Top-Personalized-K recommendation task. We expect that Top-Personalized-K recommendation has the potential to offer enhanced solutions for various real-world recommendation scenarios, based on its great compatibility with existing models.",Proceedings of the ACM Web Conference 2024,2024,Research
Active learning in multi-domain collaborative filtering recommender systems,No,"['Xin Guan', 'Chang-Tsun Li', 'Yu Guan']",https://doi.org/10.1145/3167132.3167277,"The lack of information is an acute challenge in most recommender systems, especially for the collaborative filtering algorithms which utilize user-item rating matrix as the only source of information. Active learning can be used to remedy this problem by querying users to give ratings to some items. Apart from the active learning algorithms, cross-domain recommender system techniques try to alleviate the sparsity problem by exploiting knowledge from auxiliary (source) domains. A special case of cross-domain recommendation is multi-domain recommendation that utilizes the shared knowledge across multiple domains to alleviate the data sparsity in all domains. In this paper, we propose a novel multi-domain active learning framework by incorporating active learning techniques with cross-domain collaborative filtering algorithms in the multi-domain scenarios. Specifically, our proposed active learning elicits all the ratings simultaneously based on the criteria with regard to both items and users, for the purpose of improving the performance of the whole system. We evaluate a variety of active learning strategies in the proposed framework on different multi-domain recommendation tasks based on three popular datasets: Movielens, Netflix and Book-Crossing. The results show that the system performance can be improved further when combining cross-domain collaborative filtering with active learning algorithms.",Proceedings of the 33rd Annual ACM Symposium on Applied Computing,2018,Research
Experiments on Generalizability of User-Oriented Fairness in Recommender Systems,Yes,"['Hossein Rahmani', 'Mohammadmehdi Naghiaei', 'Mahdi Dehghan', 'Mohammad Aliannejadi']",https://doi.org/10.1145/3477495.3531718,"Recent work in recommender systems mainly focuses on fairness in recommendations as an important aspect of measuring recommendations quality. A fairness-aware recommender system aims to treat different user groups similarly. Relevant work on user-oriented fairness highlights the discriminant behavior of fairness-unaware recommendation algorithms towards a certain user group, defined based on users' activity level. Typical solutions include proposing a user-centered fairness re-ranking framework applied on top of a base ranking model to mitigate its unfair behavior towards a certain user group i.e., disadvantaged group. In this paper, we re-produce a user-oriented fairness study and provide extensive experiments to analyze the dependency of their proposed method on various fairness and recommendation aspects, including the recommendation domain, nature of the base ranking model, and user grouping method. Moreover, we evaluate the final recommendations provided by the re-ranking framework from both user- (e.g., NDCG, user-fairness) and item-side (e.g., novelty, item-fairness) metrics. We discover interesting trends and trade-offs between the model's performance in terms of different evaluation metrics. For instance, we see that the definition of the advantaged/disadvantaged user groups plays a crucial role in the effectiveness of the fairness algorithm and how it improves the performance of specific base ranking models. Finally, we highlight some important open challenges and future directions in this field. We release the data, evaluation pipeline, and the trained models publicly on https://github.com/rahmanidashti/FairRecSys.",Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval,2022,Research
Co-refining user and item representations with feature-level self-attention for enhanced recommendation,No,"['Zikai Guo', 'Deqing Yang', 'Baichuan Liu', 'Lyuxin Xue', 'Yanghua Xiao']",https://doi.org/10.1109/ASONAM49781.2020.9381303,"Self-attention mechanism is primarily designed to capture the correlation (interaction) between any two objects in a sequence. Inspired by self-attention's success in many NLP tasks, some researchers have employed self-attention in sequential recommendation to refine user representations by capturing the correlations between the historical interacted items of a user. However, the user representations in previous self-attention based models are not flexible enough since the self-attention is only applied on user side, restricting performance improvement. In this paper, we propose a deep recommendation model with feature-level self-attention, namely SAFrec, which exhibits enhanced recommendation performance mainly due to its two advantages. The first one is that SAFrec employs self-attention mechanism on user side and item side simultaneously, to co-refine user representations and item representations. The second one is that, SAFrec leverages item features distilled from open knowledge graphs or websites, to represent users and items on fine-grained level (feature-level). Thus the correlations between users and items are discovered sufficiently. The extensive experiments conducted over two real datasets (NetEase music and Book-Crossing) not only demonstrate SAFrec's superiority on top-n recommendation over the state-of-the-art deep recommendation models, but also validate the significance of incorporating self-attention mechanism and feature-level representations.",Proceedings of the 12th IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,2021,Research
User Behavior Enriched Temporal Knowledge Graphs for Sequential Recommendation,No,"['Hengchang Hu', 'Wei Guo', 'Xu Liu', 'Yong Liu', 'Ruiming Tang', 'Rui Zhang', 'Min-Yen Kan']",https://doi.org/10.1145/3616855.3635762,"Knowledge Graphs (KGs) enhance recommendations by providing external connectivity between items. However, there is limited research on distilling relevant knowledge in sequential recommendation, where item connections can change over time. To address this, we introduce the Temporal Knowledge Graph (TKG), which incorporates such dynamic features of user behaviors into the original KG while emphasizing sequential relationships. The TKG captures both patterns of entity dynamics (nodes) and structural dynamics (edges). Considering real-world applications with large-scale and rapidly evolving user behavior patterns, we propose an efficient two-phase framework called TKG-SRec, which strengthens Sequential Recommendation with Temporal KGs. In the first phase, we learn dynamic entity embeddings using our novel Knowledge Evolution Network (KEN) that brings together pretrained static knowledge with evolving temporal knowledge. In the second stage, downstream sequential recommender models utilize these time-specific dynamic entity embeddings with compatible neural backbones like GRUs, Transformers, and MLPs. From our extensive experiments over four datasets, TKG-SRec outperforms the current state-of-the-art by a statistically significant 5% on average. Detailed analysis validates that such filtered temporal knowledge better adapts entity embedding for sequential recommendation. In summary, TKG-SRec provides an effective and efficient approach.",Proceedings of the 17th ACM International Conference on Web Search and Data Mining,2024,Research
Measuring Commonality in Recommendation of Cultural Content to Strengthen Cultural Citizenship,Yes,"['Andres Ferraro', 'Gustavo Ferreira', 'Fernando Diaz', 'Georgina Born']",https://doi.org/10.1145/3643138,"Recommender systems have become the dominant means of curating cultural content, significantly influencing the nature of individual cultural experience. While the majority of academic and industrial research on recommender systems optimizes for personalized user experience, this paradigm does not capture the ways that recommender systems impact cultural experience in the aggregate, across populations of users. Although existing novelty, diversity, and fairness studies probe how recommender systems relate to the broader social role of cultural content, they do not adequately center culture as a core concept and challenge. In this work, we introduce commonality as a new measure of recommender systems that reflects the degree to which recommendations familiarize a given user population with specified categories of cultural content. Our proposed commonality metric responds to a set of arguments developed through an interdisciplinary dialogue between researchers in computer science and the social sciences and humanities. With reference to principles underpinning public service media (PSM) systems in democratic societies, we identify universality of address and content diversity in the service of strengthening cultural citizenship as particularly relevant goals for recommender systems delivering cultural content. We develop commonality as a measure of recommender system alignment with the promotion of a shared cultural experience of, and exposure to, diverse cultural content across a population of users. Moreover, we advocate for the involvement of human editors accountable to a larger value community as a fundamental part of defining categories in the service of cultural citizenship. We empirically compare the performance of recommendation algorithms using commonality with existing utility, diversity, novelty, and fairness metrics using three different domains. Our results demonstrate that commonality captures a property of system behavior complementary to existing metrics and suggests the need for alternative, non-personalized interventions in recommender systems oriented to strengthening cultural citizenship across populations of users. Moreover, commonality demonstrates both consistent results under different editorial policies and robustness to missing labels and users. Alongside existing fairness and diversity metrics, commonality contributes to a growing body of scholarship developing “public good” rationales for digital media and machine learning systems.",missing,2024,Research
Fair Projections as a Means Towards Balanced Recommendations,Yes,"['Aris Anagnostopoulos', 'Luca Becchetti', 'Matteo B\\""{o}hm', 'Adriano Fazzone', 'Stefano Leonardi', 'Cristina Menghini', 'Chris Schwiegelshohn']",https://doi.org/10.1145/3664929,"The goal of recommender systems is to provide to users suggestions that match their interests, with the eventual goal of increasing their satisfaction, as measured by the number of transactions (clicks, purchases, etc.). Often, this leads to providing recommendations that are of a particular type. For some contexts (e.g., browsing videos for information) this may be undesirable, as it may enforce the creation of filter bubbles. This is because of the existence of underlying bias in the input data of prior user actions.Reducing hidden bias in the data and ensuring fairness in algorithmic data analysis has recently received significant attention. In this paper, we consider both the densest subgraph and the (k) -clustering problem, two primitives that are being used by some recommender systems. We are given a coloring on the nodes, respectively the points, and aim to compute a fair solution (S) , consisting of a subgraph or a clustering, such that none of the colors is disparately impacted by the solution.Unfortunately, introducing fair solutions typically makes these problems substantially more difficult. Unlike the unconstrained densest subgraph problem, which is solvable in polynomial time, the fair densest subgraph problem is NP-hard even to approximate. For (k) -clustering, the fairness constraints make the problem very similar to capacitated clustering, which is a notoriously hard problem to even approximate.Despite such negative premises, we are able to provide positive results in important use cases. In particular, we are able to prove that a suitable spectral embedding allows recovery of an almost optimal, fair, dense subgraph hidden in the input data, whenever one is present, a result that is further supported by experimental evidence.We also show a polynomial-time, (2) -approximation algorithm to the problem of fair densest subgraph, assuming that there exist only two colors and both colors occur equally often in the graph. This result turns out to be optimal assuming the small set expansion hypothesis. For fair (k) -clustering, we show that we can recover high quality fair clusterings effectively and efficiently. For the special case of (k) -median and (k) -center, we offer additional, fast and simple approximation algorithms as well as new hardness results.The above theoretical findings drive the design of heuristics, which we experimentally evaluate on a scenario based on real data, in which our aim is to strike a good balance between diversity and highly correlated items from Amazon co-purchasing graphs and facebook contacts. We additionally evaluated our algorithmic solutions for the fair (k) -median problem through experiments on various real-world datasets.",missing,2024,Research
Modeling User Repeat Consumption Behavior for Online Novel Recommendation,Keep,"['Yuncong Li', 'Cunxiang Yin', 'yancheng he', 'Guoqiang Xu', 'Jing Cai', 'leeven luo', 'Sheng-hua Zhong']",https://doi.org/10.1145/3523227.3546762,"Given a user’s historical interaction sequence, online novel recommendation suggests the next novel the user may be interested in. Online novel recommendation is important but underexplored. In this paper, we concentrate on recommending online novels to new users of an online novel reading platform, whose first visits to the platform occurred in the last seven days. We have two observations about online novel recommendation for new users. First, repeat novel consumption of new users is a common phenomenon. Second, interactions between users and novels are informative. To accurately predict whether a user will reconsume a novel, it is crucial to characterize each interaction at a fine-grained level. Based on these two observations, we propose a neural network for online novel recommendation, called NovelNet. NovelNet can recommend the next novel from both the user’s consumed novels and new novels simultaneously. Specifically, an interaction encoder is used to obtain accurate interaction representation considering fine-grained attributes of interaction, and a pointer network with a pointwise loss is incorporated into NovelNet to recommend previously-consumed novels. Moreover, an online novel recommendation dataset is built from a well-known online novel reading platform and is released for public use as a benchmark. Experimental results on the dataset demonstrate the effectiveness of NovelNet 1.",Proceedings of the 16th ACM Conference on Recommender Systems,2022,Research
Decomposed Collaborative Filtering: Modeling Explicit and Implicit Factors For Recommender Systems,No,"['Hao Chen', 'Xin Xin', 'Dong Wang', 'Yue Ding']",https://doi.org/10.1145/3437963.3441826,"Representation learning is the keystone for collaborative filtering. The learned representations should reflect both explicit factors that are revealed by extrinsic attributes such as movies' genres, books' authors, and implicit factors that are implicated in the collaborative signal. Existing methods fail to decompose these two types of factors, making it difficult to infer the deep motivations behind user behaviors, and thus suffer from sub-optimal solutions. In this paper, we propose Decomposed Collaborative Filtering (DCF) to address the above problems. For the explicit representation learning, we devise a user-specific relation aggregator to aggregate the most important attributes. For the implicit part, we propose Decomposed Graph Convolutional Network (DGCN), which decomposes users and items into multiple factor-level representations, then utilizes factor-level attention and attentive relation aggregation to model implicit factors behind collaborative signals in fine-grained level. Moreover, to reflect more diverse implicit factors, we augment the model with disagreement regularization. We conduct experiments on three public accessible datasets and the results demonstrate the significant improvement of our method over several state-of-the-art baselines. Further studies verify the efficacy and interpretability benefits bought from the fine-grained implicit relation modeling. Our Code is available on https://github.com/cmaxhao/DCF.",Proceedings of the 14th ACM International Conference on Web Search and Data Mining,2021,Research
Not All Embeddings are Created Equal: Towards Robust Cross-domain Recommendation via Contrastive Learning,Yes,"['Wenhao Yang', 'Yingchun Jian', 'Yibo Wang', 'Shiyin Lu', 'Lei Shen', 'Bing Wang', 'Haihong Tang', 'Lijun Zhang']",https://doi.org/10.1145/3589334.3645357,"Cross-domain recommendation (CDR) aims to leverage the rich information from the source domain to enhance recommendation performance in the target domain. However, the data imbalance problem inherent across different domains compromises the effectiveness of CDR approaches, posing a significant challenge to CDR. Most current CDR methodologies focus on creating better user embeddings for the target domain, yet usually neglect the inconsistency in user activities due to data imbalance. As a result, the process of creating user embeddings tends to prioritize users with more frequent interactions and leave less active users underserved, leading these CDR methods to struggle in making accurate recommendations for those with fewer interactions. Such bias in creating embeddings reveals the fact that ''not all embeddings are created equal'' in CDR, which serves as the primary motivation of this study. Inspired by the recent development of contrastive learning, this paper proposes User-aware Contrastive Learning for Robust cross-domain recommendation (UCLR), enhancing the robustness of cross-domain recommendation. Specifically, our proposed method consists of two sub-modules: (i) pretrained global embedding, where the global user embeddings are pretrained across all the domains; (ii) contrastive dual-stream collaborative autoencoder, where more equal user embeddings are generated by optimizing contrastive loss with individualized temperatures. To further improve the performance of our method in each domain, we finetune the whole framework of UCLR based on Low-Rank Adaptation (LoRA). Theoretically, our method is equipped with a provable convergence guarantee during the contrastive learning stage. Furthermore, we also conduct comprehensive experiments on real-world datasets to validate the effectiveness of our proposed method.",Proceedings of the ACM Web Conference 2024,2024,Research
CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems,Yes,"['Mohammadmehdi Naghiaei', 'Hossein Rahmani', 'Yashar Deldjoo']",https://doi.org/10.1145/3477495.3531959,"Recently, there has been a rising awareness that when machine learning (ML) algorithms are used to automate choices, they may treat/affect individuals unfairly, with legal, ethical, or economic consequences. Recommender systems are prominent examples of such ML systems that assist users in making high-stakes judgments. A common trend in the previous literature research on fairness in recommender systems is that the majority of works treat user and item fairness concerns separately, ignoring the fact that recommender systems operate in a two-sided marketplace. In this work, we present an optimization-based re-ranking approach that seamlessly integrates fairness constraints from both the consumer and producer-side in a joint objective framework. We demonstrate through large-scale experiments on 8 datasets that our proposed method is capable of improving both consumer and producer fairness without reducing overall recommendation quality, demonstrating the role algorithms may play in minimizing data biases.",Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval,2022,Research
Interactive Recommender System via Knowledge Graph-enhanced Reinforcement Learning,No,"['Sijin Zhou', 'Xinyi Dai', 'Haokun Chen', 'Weinan Zhang', 'Kan Ren', 'Ruiming Tang', 'Xiuqiang He', 'Yong Yu']",https://doi.org/10.1145/3397271.3401174,"Interactive recommender system (IRS) has drawn huge attention because of its flexible recommendation strategy and the consideration of optimal long-term user experiences. To deal with the dynamic user preference and optimize accumulative utilities, researchers have introduced reinforcement learning (RL) into IRS. However, RL methods share a common issue of sample efficiency, i.e., huge amount of interaction data is required to train an effective recommendation policy, which is caused by the sparse user responses and the large action space consisting of a large number of candidate items. Moreover, it is infeasible to collect much data with explorative policies in online environments, which will probably harm user experience. In this work, we investigate the potential of leveraging knowledge graph (KG) in dealing with these issues of RL methods for IRS, which provides rich side information for recommendation decision making. Instead of learning RL policies from scratch, we make use of the prior knowledge of the item correlation learned from KG to (i) guide the candidate selection for better candidate item retrieval, (ii) enrich the representation of items and user states, and (iii) propagate user preferences among the correlated items over KG to deal with the sparsity of user feedback. Comprehensive experiments have been conducted on two real-world datasets, which demonstrate the superiority of our approach with significant improvements against state-of-the-arts.",Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval,2020,Research
Mixed-Curvature Manifolds Interaction Learning for Knowledge Graph-aware Recommendation,No,"['Jihu Wang', 'Yuliang Shi', 'Han Yu', 'Xinjun Wang', 'Zhongmin Yan', 'Fanyu Kong']",https://doi.org/10.1145/3539618.3591730,"As auxiliary collaborative signals, the entity connectivity and relation semanticity beneath knowledge graph (KG) triples can alleviate the data sparsity and cold-start issues of recommendation tasks. Thus many works consider obtaining user and item representations via information aggregation on graph-structured data within Euclidean space. However, the scale-free graphs (e.g., KGs) inherently exhibit non-Euclidean geometric topologies, such as tree-like and circle-like structures. The existing recommendation models built in a single type of embedding space do not have enough capacity to embrace various geometric patterns, consequently, resulting in suboptimal performance. To address this limitation, we propose a KG-aware recommendation model with mixed-curvature manifolds interaction learning, namely CurvRec. On the one hand, it aims to preserve various global geometric structures in KG with mixed-curvature manifold spaces as the backbone. On the other hand, we integrate Ricci curvature into graph convolutional networks (GCNs) to capture local geometric structural properties when aggregating neighbor nodes. Besides, to exploit the expressive spatial features in KG, we incorporate interaction learning to ensure the geometric message passing between curved manifolds. Specifically, we adopt curvature-aware geodesic distance metrics to maximize the mutual information between Euclidean space and non-Euclidean spaces. Through extensive experiments, we demonstrate that the proposed CurvRec outperforms state-of-the-art baselines.",Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval,2023,Research
A Survey on Stream-Based Recommender Systems,Keep,"['Marie Al-Ghossein', 'Talel Abdessalem', ""Anthony BARR\\'{E}""]",https://doi.org/10.1145/3453443,"Recommender Systems (RS) have proven to be effective tools to help users overcome information overload, and significant advances have been made in the field over the past two decades. Although addressing the recommendation problem required first a formulation that could be easily studied and evaluated, there currently exists a gap between research contributions and industrial applications where RS are actually deployed. In particular, most RS are meant to function in batch: they rely on a large static dataset and build a recommendation model that is only periodically updated. This functioning introduces several limitations in various settings, leading to considering more realistic settings where RS learn from continuous streams of interactions. Such RS are framed as Stream-Based Recommender Systems (SBRS).In this article, we review SBRS, underline their relation with time-aware RS and online adaptive learning, and present and categorize existing work that tackle the corresponding problem and its multiple facets. We discuss the methodologies used to evaluate SBRS and the adapted datasets that can be used, and finally we outline open challenges in the area.",missing,2021,Research
Graph Masked Autoencoder for Sequential Recommendation,Keep,"['Yaowen Ye', 'Lianghao Xia', 'Chao Huang']",https://doi.org/10.1145/3539618.3591692,"While some powerful neural network architectures (e.g., Transformer, Graph Neural Networks) have achieved improved performance in sequential recommendation with high-order item dependency modeling, they may suffer from poor representation capability in label scarcity scenarios. To address the issue of insufficient labels, Contrastive Learning (CL) has attracted much attention in recent methods to perform data augmentation through embedding contrasting for self-supervision. However, due to the hand-crafted property of their contrastive view generation strategies, existing CL-enhanced models i) can hardly yield consistent performance on diverse sequential recommendation tasks; ii) may not be immune to user behavior data noise. In light of this, we propose a simple yet effective Graph Masked AutoEncoder-enhanced sequential Recommender system (MAERec) that adaptively and dynamically distills global item transitional information for self-supervised augmentation. It naturally avoids the above issue of heavy reliance on constructing high-quality embedding contrastive views. Instead, an adaptive data reconstruction paradigm is designed to be integrated with the long-range item dependency modeling, for informative augmentation in sequential recommendation. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baseline models and can learn more accurate representations against data noise and sparsity. Our implemented model code is available at https://github.com/HKUDS/MAERec.",Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval,2023,Research
ReuseKNN: Neighborhood Reuse for Differentially Private KNN-Based Recommendations,Keep,"['Peter M\\""{u}llner', 'Elisabeth Lex', 'Markus Schedl', 'Dominik Kowald']",https://doi.org/10.1145/3608481,"User-based KNN recommender systems (UserKNN) utilize the rating data of a target user’s k nearest neighbors in the recommendation process. This, however, increases the privacy risk of the neighbors, since the recommendations could expose the neighbors’ rating data to other users or malicious parties. To reduce this risk, existing work applies differential privacy by adding randomness to the neighbors’ ratings, which unfortunately reduces the accuracy of UserKNN. In this work, we introduce ReuseKNN, a novel differentially private KNN-based recommender system. The main idea is to identify small but highly reusable neighborhoods so that (i) only a minimal set of users requires protection with differential privacy and (ii) most users do not need to be protected with differential privacy since they are only rarely exploited as neighbors. In our experiments on five diverse datasets, we make two key observations. Firstly, ReuseKNN requires significantly smaller neighborhoods and, thus, fewer neighbors need to be protected with differential privacy compared with traditional UserKNN. Secondly, despite the small neighborhoods, ReuseKNN outperforms UserKNN and a fully differentially private approach in terms of accuracy. Overall, ReuseKNN leads to significantly less privacy risk for users than in the case of UserKNN.",missing,2023,Research
Calibration in Collaborative Filtering Recommender Systems: a User-Centered Analysis,Yes,"['Kun Lin', 'Nasim Sonboli', 'Bamshad Mobasher', 'Robin Burke']",https://doi.org/10.1145/3372923.3404793,"Recommender systems learn from past user preferences in order to predict future user interests and provide users with personalized suggestions. Previous research has demonstrated that biases in user profiles in the aggregate can influence the recommendations to users who do not share the majority preference. One consequence of this bias propagation effect is miscalibration, a mismatch between the types or categories of items that a user prefers and the items provided in recommendations. In this paper, we conduct a systematic analysis aimed at identifying key characteristics in user profiles that might lead to miscalibrated recommendations. We consider several categories of profile characteristics, including similarity to the average user, propensity towards popularity, profile diversity, and preference intensity. We develop predictive models of miscalibration and use these models to identify the most important features correlated with miscalibration, given different algorithms and dataset characteristics. Our analysis is intended to help system designers predict miscalibration effects and to develop recommendation algorithms with improved calibration properties.",Proceedings of the 31st ACM Conference on Hypertext and Social Media,2020,Research
Deployable and Continuable Meta-learning-Based Recommender System with Fast User-Incremental Updates,No,"['Renchu Guan', 'Haoyu Pang', 'Fausto Giunchiglia', 'Ximing Li', 'Xuefeng Yang', 'Xiaoyue Feng']",https://doi.org/10.1145/3477495.3531964,"User cold-start is a major challenge in building personalized recommender systems. Due to the lack of sufficient interactions, it is difficult to effectively model new users. One of the main solutions is to obtain an initial model through meta-learning (mainly gradient-based methods) and adapt it to new users with a few steps of gradient descent. Although these methods have achieved remarkable performance, they are still far from being usable in real-world applications due to their high-demand data processing, heavy computational burden, and inability to perform effective user-incremental update. In this paper, we propose a d eployable and c ontinuable m eta-learning-based r ecommendation (DCMR) approach, which can achieve fast user-incremental updating with task replay and first-order gradient descent. Specifically, we introduce a dual-constrained task sampler, distillation-based loss functions, and an adaptive controller in this framework to balance the trade-off between stability and plasticity in updating. In summary, DCMR can be updated while serving new users; in other words, it learns continuously and rapidly from a sequential user stream and is able to make recommendations at any time. The extensive experiments conducted on three benchmark datasets illustrate the superiority of our model.",Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval,2022,Research
Knowledge Graph Enhanced Contextualized Attention-Based Network for Responsible User-Specific Recommendation,Yes,"['Ehsan Elahi', 'Sajid Anwar', 'Babar Shah', 'Zahid Halim', 'Abrar Ullah', 'Imad Rida', 'Muhammad Waqas']",https://doi.org/10.1145/3641288,"With ever-increasing dataset size and data storage capacity, there is a strong need to build systems that can effectively utilize these vast datasets to extract valuable information. Large datasets often exhibit sparsity and pose cold start problems, necessitating the development of responsible recommender systems. Knowledge graphs have utility in responsibly representing information related to recommendation scenarios. However, many studies overlook explicitly encoding contextual information, which is crucial for reducing the bias of multi-layer propagation. Additionally, existing methods stack multiple layers to encode high-order neighbor information while disregarding the relational information between items and entities. This oversight hampers their ability to capture the collaborative signal latent in user-item interactions. This is particularly important in health informatics, where knowledge graphs consist of various entities connected to items through different relations. Ignoring the relational information renders them insufficient for modeling user preferences. This work presents an end-to-end recommendation framework named KGCAN (Knowledge Graph Enhanced Contextualized Attention-Based Network), which explicitly encodes both relational and contextual information of entities to preserve the original entity information. Furthermore, a user-specific attention mechanism is employed to capture personalized recommendations. The proposed model is validated on three benchmark datasets through extensive experiments. The experimental results demonstrate that KGCAN outperforms existing knowledge graph based recommendation models. Additionally, a case study from the healthcare domain is discussed, highlighting the importance of attention mechanisms and high-order connectivity in the responsible recommendation system for health informatics.",missing,2024,Research
Causality-driven User Modeling for Sequential Recommendations over Time,Keep,"['Xingming Chen', 'Qing Li']",https://doi.org/10.1145/3589335.3651896,"Contemporary sequential recommendation systems predominantly leverage statistical correlations derived from user interaction histories to predict future preferences. However, these correlations often mask implicit challenges. On the one hand, user data is frequently plagued by implicit, noisy feedback, misdirecting users towards items that fail to align with their actual interests, which is magnified in sequential recommendation contexts. On the other hand, prevalent methods tend to over-rely on similarity-based attention mechanisms across item pairs, which are prone to utilizing heuristic shortcuts, thereby leading to suboptimal recommendation.To tackle these issues, we put forward a causality-driven user modeling approach for sequential recommendation, which pivots towards a causal perspective. Specifically, we involves the application of a causal graph to identify confounding factors that give rise to spurious correlations and to isolate conceptual variables that causally encapsulate user preferences. By learning the representation of these disentangled causal variables at the conceptual level, we can distinguish between causal and non-causal associations while preserving the inherent sequential nature of user behaviors. This enables us to ascertain which elements are critical and which may induce unintended biases. The framework of our method can be compatible with various mainstream sequential models, which offers a robust foundation for reconstructing more accurate and meaningful user and item representations driven by causality.",Companion Proceedings of the ACM Web Conference 2024,2024,Research
RetaGNN: Relational Temporal Attentive Graph Neural Networks for Holistic Sequential Recommendation,No,"['Cheng Hsu', 'Cheng-Te Li']",https://doi.org/10.1145/3442381.3449957,"Sequential recommendation (SR) is to accurately recommend a list of items for a user based on her current accessed ones. While new-coming users continuously arrive in the real world, one crucial task is to have inductive SR that can produce embeddings of users and items without re-training. Given user-item interactions can be extremely sparse, another critical task is to have transferable SR that can transfer the knowledge derived from one domain with rich data to another domain. In this work, we aim to present the holistic SR that simultaneously accommodates conventional, inductive, and transferable settings. We propose a novel deep learning-based model, Relational Temporal Attentive Graph Neural Networks (RetaGNN), for holistic SR. The main idea of RetaGNN is three-fold. First, to have inductive and transferable capabilities, we train a relational attentive GNN on the local subgraph extracted from a user-item pair, in which the learnable weight matrices are on various relations among users, items, and attributes, rather than nodes or edges. Second, long-term and short-term temporal patterns of user preferences are encoded by a proposed sequential self-attention mechanism. Third, a relation-aware regularization term is devised for better training of RetaGNN. Experiments conducted on MovieLens, Instagram, and Book-Crossing datasets exhibit that RetaGNN can outperform state-of-the-art methods under conventional, inductive, and transferable settings. The derived attention weights also bring model explainability.",Proceedings of the Web Conference 2021,2021,Research
Decentralized Graph Neural Network for Privacy-Preserving Recommendation,No,"['Xiaolin Zheng', 'Zhongyu Wang', 'Chaochao Chen', 'Jiashu Qian', 'Yao Yang']",https://doi.org/10.1145/3583780.3614834,"Building a graph neural network (GNN)-based recommender system without violating user privacy proves challenging. Existing methods can be divided into federated GNNs and decentralized GNNs. But both methods have undesirable effects, i.e., low communication efficiency and privacy leakage. This paper proposes DGREC, a novel decentralized GNN for privacy-preserving recommendations, where users can choose to publicize their interactions. It includes three stages, i.e., graph construction, local gradient calculation, and global gradient passing. The first stage builds a local inner-item hypergraph for each user and a global inter-user graph. The second stage models user preference and calculates gradients on each local device. The third stage designs a local differential privacy mechanism named secure gradient-sharing, which proves strong privacy-preserving of users' private data. We conduct extensive experiments on three public datasets to validate the consistent superiority of our framework.",Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,2023,Research
Mutual Information-based Preference Disentangling and Transferring for Non-overlapped Multi-target Cross-domain Recommendations,No,"['Zhi Li', 'Daichi Amagata', 'Yihong Zhang', 'Takahiro Hara', 'Shuichiro Haruta', 'Kei Yonekawa', 'Mori Kurokawa']",https://doi.org/10.1145/3626772.3657780,"Building high-quality recommender systems is challenging for new services and small companies, because of their sparse interactions. Cross-domain recommendations (CDRs) alleviate this issue by transferring knowledge from data in external domains. However, most existing CDRs leverage data from only a single external domain and serve only two domains. CDRs serving multiple domains require domain-shared entities (i.e., users and items) to transfer knowledge, which significantly limits their applications due to the hardness and privacy concerns of finding such entities. We therefore focus on a more general scenario, non-overlapped multi-target CDRs (NO-MTCDRs), which require no domain-shared entities and serve multiple domains. Existing methods require domain-shared users to learn user preferences and cannot work on NO-MTCDRs. We hence propose MITrans, a novel mutual information-based (MI-based) preference disentangling and transferring framework to improve recommendations for all domains. MITrans effectively leverages knowledge from multiple domains as well as learning both domain-shared and domain-specific preferences without using domain-shared users. In MITrans, we devise two novel MI constraints to disentangle domain-shared and domain-specific preferences. Moreover, we introduce a module that fuses domain-shared preferences in different domains and combines them with domain-specific preferences to improve recommendations. Our experimental results on two real-world datasets demonstrate the superiority of MITrans in terms of recommendation quality and application range against state-of-the-art overlapped and non-overlapped CDRs.",Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval,2024,Research
Knowledge Graph Convolutional Networks for Recommender Systems,No,"['Hongwei Wang', 'Miao Zhao', 'Xing Xie', 'Wenjie Li', 'Minyi Guo']",https://doi.org/10.1145/3308558.3313417,"To alleviate sparsity and cold start problem of collaborative filtering based recommender systems, researchers and engineers usually collect attributes of users and items, and design delicate algorithms to exploit these additional information. In general, the attributes are not isolated but connected with each other, which forms a knowledge graph (KG). In this paper, we propose Knowledge Graph Convolutional Networks (KGCN), an end-to-end framework that captures inter-item relatedness effectively by mining their associated attributes on the KG. To automatically discover both high-order structure information and semantic information of the KG, we sample from the neighbors for each entity in the KG as their receptive field, then combine neighborhood information with bias when calculating the representation of a given entity. The receptive field can be extended to multiple hops away to model high-order proximity information and capture users' potential long-distance interests. Moreover, we implement the proposed KGCN in a minibatch fashion, which enables our model to operate on large datasets and KGs. We apply the proposed model to three datasets about movie, book, and music recommendation, and experiment results demonstrate that our approach outperforms strong recommender baselines.",The World Wide Web Conference,2019,Research
Batch-Mix Negative Sampling for Learning Recommendation Retrievers,Keep,"['Yongfu Fan', 'Jin Chen', 'Yongquan Jiang', 'Defu Lian', 'Fangda Guo', 'Kai Zheng']",https://doi.org/10.1145/3583780.3614789,"Recommendation retrievers commonly retrieve user potentially preferred items from numerous items, where the query and item representation are learned according to the dual encoders with the log-softmax loss. Under real scenarios, the number of items becomes considerably large, making it exceedingly difficult to calculate the partition function with the whole item corpus. Negative sampling, which samples a subset from the item corpus, is widely used to accelerate the model training. Among different samplers, the in-batch sampling is commonly adopted for online recommendation retrievers, which regards the other items within the mini-batch as the negative samples for the given query, owing to its time and memory efficiency. However, the sample selection bias occurs due to the skewed feedback, harming the retrieval quality. In this paper, we propose a negative sampling approach named Batch-Mix Negative Sampling (BMNS), which adopts batch mixing operation to generate additional negatives for model training. Concretely, BMNS first generates new negative items with the sampled mix coefficient from the Beta distribution, after which a tailored correct strategy guided by frequency is designed to match the sampled softmax loss. In this way, the effort of re-encoding items out of the mini-batch is reduced while also improving the representation space of the negative set. The empirical experiments on four real-world datasets demonstrate BMNS is superior to the competitive negative inbatch sampling method.",Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,2023,Research
Improving the Estimation of Tail Ratings in Recommender System with Multi-Latent Representations,Yes,"['Xing Zhao', 'Ziwei Zhu', 'Yin Zhang', 'James Caverlee']",https://doi.org/10.1145/3336191.3371810,"The importance of the distribution of ratings on recommender systems (RS) is well-recognized. And yet, recommendation approaches based on latent factor models and recently introduced neural variants (e.g., NCF) optimize for the head of these distributions, potentially leading to large estimation errors for tail ratings. These errors in tail ratings that are far from the mean predicted rating fall out of a uni-modal assumption underlying these popular models, as we show in this paper. We propose to improve the estimation of tail ratings by extending traditional single latent representations (e.g., an item is represented by a single latent vector) with new multi-latent representations for better modeling these tail ratings. We show how to incorporate these multi-latent representations in an end-to-end neural prediction model that is designed to better reflect the underlying ratings distributions of items. Through experiments over six datasets, we find the proposed model leads to a significant improvement in RMSE versus a suite of benchmark methods. We also find that the predictions for the most polarized items are improved by more than 15%.",Proceedings of the 13th International Conference on Web Search and Data Mining,2020,Research
CROLoss: Towards a Customizable Loss for Retrieval Models in Recommender Systems,No,"['Yongxiang Tang', 'Wentao Bai', 'Guilin Li', 'Xialong Liu', 'Yu Zhang']",https://doi.org/10.1145/3511808.3557274,"In large-scale recommender systems, retrieving top N relevant candidates accurately with resource constrain is crucial. To evaluate the performance of such retrieval models, Recall@N, the frequency of positive samples being retrieved in the top N ranking, is widely used. However, most of the conventional loss functions for retrieval models such as softmax cross-entropy and pairwise comparison methods do not directly optimize Recall@N. Moreover, those conventional loss functions cannot be customized for the specific retrieval size N required by each application and thus may lead to sub-optimal performance. In this paper, we proposed the Customizable Recall@N Optimization Loss (CROLoss), a loss function that can directly optimize the Recall@N metrics and is customizable for different choices of N. This proposed CROLoss formulation defines a more generalized loss function space, covering most of the conventional loss functions as special cases. Furthermore, we develop the Lambda method, a gradient-based method that invites more flexibility and can further boost the system performance. We evaluate the proposed CROLoss on two public benchmark datasets. The results show that CROLoss achieves SOTA results over conventional loss functions for both datasets with various choices of retrieval size N. CROLoss has been deployed onto our online E-commerce advertising platform, where a fourteen-day online A/B test demonstrated that CROLoss contributes to a significant business revenue growth of 4.75%.",Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,2022,Research
Distributional Fairness-aware Recommendation,Yes,"['Hao Yang', 'Xian Wu', 'Zhaopeng Qiu', 'Yefeng Zheng', 'Xu Chen']",https://doi.org/10.1145/3652854,"Fairness has been gradually recognized as a significant problem in the recommendation domain. Previous models usually achieve fairness by reducing the average performance gap between different user groups. However, the average performance may not sufficiently represent all the characteristics of the performances in a user group. Thus, equivalent average performance may not mean the recommender model is fair, for example, the variance of the performances can be different. To alleviate this problem, in this article, we define a novel type of fairness, where we require that the performance distributions across different user groups should be similar. We prove that with the same performance distribution, the numerical characteristics of the group performance, including the expectation, variance, and any higher-order moment, are also the same. To achieve distributional fairness, we propose a generative and adversarial training framework. Specifically, we regard the recommender model as the generator to compute the performance for each user in different groups, and then we deploy a discriminator to judge which group the performance is drawn from. By iteratively optimizing the generator and the discriminator, we can theoretically prove that the optimal generator (the recommender model) can indeed lead to the equivalent performance distributions. To smooth the adversarial training process, we propose a novel dual curriculum learning strategy for optimal scheduling of training samples. Additionally, we tailor our framework to better suit top-N recommendation tasks by incorporating softened ranking metrics as measures of performance discrepancies. We conduct extensive experiments based on real-world datasets to demonstrate the effectiveness of our model.",missing,2024,Research
Critique on Natural Noise in Recommender Systems,Keep,"['Wissam Jurdi', 'Jacques Abdo', 'Jacques Demerjian', 'Abdallah Makhoul']",https://doi.org/10.1145/3447780,"Recommender systems have been upgraded, tested, and applied in many, often incomparable ways. In attempts to diligently understand user behavior in certain environments, those systems have been frequently utilized in domains like e-commerce, e-learning, and tourism. Their increasing need and popularity have allowed the existence of numerous research paths on major issues like data sparsity, cold start, malicious noise, and natural noise, which immensely limit their performance. It is typical that the quality of the data that fuel those systems should be extremely reliable. Inconsistent user information in datasets can alter the performance of recommenders, albeit running advanced personalizing algorithms. The consequences of this can be costly as such systems are employed in abundant online businesses. Successfully managing these inconsistencies results in more personalized user experiences. In this article, the previous works conducted on natural noise management in recommender datasets are thoroughly analyzed. We adequately explore the ways in which the proposed methods measure improved performances and touch on the different natural noise management techniques and the attributes of the solutions. Additionally, we test the evaluation methods employed to assess the approaches and discuss several key gaps and other improvements the field should realize in the future. Our work considers the likelihood of a modern research branch on natural noise management and recommender assessment.",missing,2021,Research
User Cold-start Problem in Multi-armed Bandits: When the First Recommendations Guide the User’s Experience,Keep,"['Nicollas Silva', 'Thiago Silva', 'Heitor Werneck', 'Leonardo Rocha', 'Adriano Pereira']",https://doi.org/10.1145/3554819,"Nowadays, Recommender Systems have played a crucial role in several entertainment scenarios by making personalised recommendations and guiding the entire users’ journey from their first interaction. Recent works have addressed it as a Contextual Bandit by providing a sequential decision model to explore items not tried yet (or not tried enough) or exploit the best options learned so far. However, this work noticed these current algorithms are limited to naive non-personalised approaches in the first interactions of a new user, offering random or most popular items. Through experiments in three domains, we identify a negative impact of these first choices. Our study indicates that the bandit performance is directly related to the choices made in the first trials. Then, we propose a new approach to balance exploration and exploitation in the first interactions and handle these drawbacks. This approach is based on the Active Learning theory to catch more information about the new users and improve their long-term experience. Our idea is to explore the potential information gain of items that can also please the user’s taste. This method is named Warm-Starting Contextual Bandits, and it statistically outperforms 10 benchmarks in the literature in the long run.",missing,2023,Research
Optimizing Neighborhoods for Fair Top-N Recommendation,Yes,"['Stavroula Eleftherakis', 'Georgia Koutrika', 'Sihem Amer-Yahia']",https://doi.org/10.1145/3627043.3659539,"We address demographic bias in neighborhood-learning models for collaborative filtering recommendations. Despite their superior ranking performance, these methods can learn neighborhoods that inadvertently foster discriminatory patterns. Little work exists in this area, highlighting an important research gap. A notable yet solitary effort, Balanced Neighborhood Sparse LInear Method (BNSLIM) aims at balancing neighborhood influence across different demographic groups. Yet, BNSLIM is hampered by computational inefficiency, and its rigid balancing approach often impacts accuracy. In that vein, we introduce two novel algorithms. The first, an enhancement of BNSLIM, incorporates the Alternating Direction Method of Multipliers (ADMM) to optimize all similarities concurrently, greatly reducing training time. The second, Fairly Sparse Linear Regression (FSLR), induces controlled sparsity in neighborhoods to reveal correlations among different demographic groups, achieving comparable efficiency while being more accurate. Their performance is evaluated using standard exposure metrics alongside a new metric for user coverage disparities. Our experiments cover various applications, including a novel exploration of bias in course recommendations by teachers’ country development status. Our results show the effectiveness of our algorithms in imposing fairness compared to BNSLIM and other well-known fairness approaches.","Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization",2024,Research
Shopping Trajectory Representation Learning with Pre-training for E-commerce Customer Understanding and Recommendation,No,"['Yankai Chen', 'Quoc-Tuan Truong', 'Xin Shen', 'Jin Li', 'Irwin King']",https://doi.org/10.1145/3637528.3671747,"Understanding customer behavior is crucial for improving service quality in large-scale E-commerce. This paper proposes C-STAR, a new framework that learns compact representations from customer shopping journeys, with good versatility to fuel multiple downstream customer-centric tasks. We define the notion of shopping trajectory that encompasses customer interactions at the level of product categories, capturing the overall flow of their browsing and purchase activities. C-STAR excels at modeling both inter-trajectory distribution similarity-the structural similarities between different trajectories, and intra-trajectory semantic correlation-the semantic relationships within individual ones. This coarse-to-fine approach ensures informative trajectory embeddings for representing customers. To enhance embedding quality, we introduce a pre-training strategy that captures two intrinsic properties within the pre-training data. Extensive evaluation on large-scale industrial and public datasets demonstrates the effectiveness of C-STAR across three diverse customer-centric tasks. These tasks empower customer profiling and recommendation services for enhancing personalized shopping experiences on our E-commerce platform.",Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,2024,Research
Multimodal Pre-training for Sequential Recommendation via Contrastive Learning,No,"['Lingzi Zhang', 'Xin Zhou', 'Zhiwei Zeng', 'Zhiqi Shen']",https://doi.org/10.1145/3682075,"Sequential recommendation systems often suffer from data sparsity, leading to suboptimal performance. While multimodal content, such as images and text, has been utilized to mitigate this issue, its integration within sequential recommendation frameworks remains challenging. Current multimodal sequential recommendation models are often unable to effectively explore and capture correlations among behavior sequences of users and items across different modalities, either neglecting correlations among sequence representations or inadequately capturing associations between multimodal data and sequence data in their representations. To address this problem, we explore multimodal pre-training in the context of sequential recommendation, with the aim of enhancing fusion and utilization of multimodal information. We propose a novel Multimodal Pre-training for Sequential Recommendation (MP4SR) framework, which utilizes contrastive losses to capture the correlation among different modality sequences of users, as well as the correlation among different modality sequences of users and items. MP4SR consists of three key components: 1) multimodal feature extraction, 2) a backbone network, Multimodal Mixup Sequence Encoder (M2SE), and 3) pre-training tasks. After utilizing pre-trained encoders to generate initial multimodal features of items, M2SE adopts a complementary sequence mixup strategy to fuse different modality sequences, and leverages contrastive learning to capture modality interactions at the sequence-to-sequence and sequence-to-item levels. Extensive experiments on four real-world datasets demonstrate that MP4SR outperforms state-of-the-art approaches in both normal and cold-start settings. We further highlight the efficacy of incorporating multimodal pre-training in sequential recommendation representation learning, serving as an effective regularizer and optimizing the parameter space for the recommendation task.",missing,2024,Research
On the instability of embeddings for recommender systems: the case of matrix factorization,Keep,"['Giovanni Gabbolini', ""Edoardo D'Amico"", 'Cesare Bernardis', 'Paolo Cremonesi']",https://doi.org/10.1145/3412841.3442011,"Most state-of-the-art top-N collaborative recommender systems work by learning embeddings to jointly represent users and items. Learned embeddings are considered to be effective to solve a variety of tasks. Among others, providing and explaining recommendations. In this paper we question the reliability of the embeddings learned by Matrix Factorization (MF). We empirically demonstrate that, by simply changing the initial values assigned to the latent factors, the same MF method generates very different embeddings of items and users, and we highlight that this effect is stronger for less popular items. To overcome these drawbacks, we present a generalization of MF, called Nearest Neighbors Matrix Factorization (NNMF). The new method propagates the information about items and users to their neighbors, speeding up the training procedure and extending the amount of information that supports recommendations and representations. We describe the NNMF variants of three common MF approaches, and with extensive experiments on five different datasets we show that they strongly mitigate the instability issues of the original MF versions and they improve the accuracy of recommendations on the long-tail.",Proceedings of the 36th Annual ACM Symposium on Applied Computing,2021,Research
Knowledge-aware Graph Neural Networks with Label Smoothness Regularization for Recommender Systems,No,"['Hongwei Wang', 'Fuzheng Zhang', 'Mengdi Zhang', 'Jure Leskovec', 'Miao Zhao', 'Wenjie Li', 'Zhongyuan Wang']",https://doi.org/10.1145/3292500.3330836,"Knowledge graphs capture structured information and relations between a set of entities or items. As such knowledge graphs represent an attractive source of information that could help improve recommender systems. However, existing approaches in this domain rely on manual feature engineering and do not allow for an end-to-end training. Here we propose Knowledge-aware Graph Neural Networks with Label Smoothness regularization (KGNN-LS) to provide better recommendations. Conceptually, our approach computes user-specific item embeddings by first applying a trainable function that identifies important knowledge graph relationships for a given user. This way we transform the knowledge graph into a user-specific weighted graph and then apply a graph neural network to compute personalized item embeddings. To provide better inductive bias, we rely on label smoothness assumption, which posits that adjacent items in the knowledge graph are likely to have similar user relevance labels/scores. Label smoothness provides regularization over the edge weights and we prove that it is equivalent to a label propagation scheme on a graph. We also develop an efficient implementation that shows strong scalability with respect to the knowledge graph size. Experiments on four datasets show that our method outperforms state of the art baselines. KGNN-LS also achieves strong performance in cold-start scenarios where user-item interactions are sparse.",Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,2019,Research
TPUF: Enhancing Cross-domain Sequential Recommendation via Transferring Pre-trained User Features,No,"['Yujia Ding', 'Huan Li', 'Ke Chen', 'Lidan Shou']",https://doi.org/10.1145/3583780.3615094,"Sequential recommendation has long been challenged by data sparsity issues. Most recently, cross-domain sequential recommendation (CDSR) techniques have been proposed to leverage sequential interaction data from other domains. However, accessing raw data from source domains is often restricted due to privacy concerns. To tackle this issue, we introduce TPUF, a novel CDSR model that transfers pre-trained latent user features from the source domain (UFS) instead of the original interaction data. By doing so, TPUF improves recommendation effectiveness while maintaining practicality. TPUF has three functional characteristics: (1) It is a feature mapping-and-aggregation framework that does not impose specific constraints on the nature of pre-trained UFS. (2) It incorporates a temporal feature mapping unit to effectively extract domain-shared information from UFS with temporal information recovered. (3) It additionally employs an adversarial feature alignment unit to align features across domains to combat feature transfer bias. Experimental results on real-world datasets demonstrate that TPUF outperforms other state-of-the-art cross-domain recommendation models and is compatible with multiple UFS types.",Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,2023,Research
"A Survey on Cross-domain Recommendation: Taxonomies, Methods, and Future Directions",Keep,"['Tianzi Zang', 'Yanmin Zhu', 'Haobing Liu', 'Ruohan Zhang', 'Jiadi Yu']",https://doi.org/10.1145/3548455,"Traditional recommendation systems are faced with two long-standing obstacles, namely data sparsity and cold-start problems, which promote the emergence and development of Cross-Domain Recommendation (CDR). The core idea of CDR is to leverage information collected from other domains to alleviate the two problems in one domain. Since the early 2010s, many efforts have been engaged for cross-domain recommendation. Recently, with the development of deep learning and neural networks, a large number of methods have emerged. However, there is a limited number of systematic surveys on CDR, especially regarding the latest proposed methods as well as the recommendation scenarios and recommendation tasks they address. In this survey article, we first proposed a two-level taxonomy of cross-domain recommendation that classifies different recommendation scenarios and recommendation tasks. We then introduce and summarize existing cross-domain recommendation approaches under different recommendation scenarios in a structured manner. We also organize datasets commonly used. We conclude this survey by providing several potential research directions about this field.",missing,2022,Research
Inductive Modeling for Realtime Cold Start Recommendations,Keep,"['Chandler Zuo', 'Jonathan Castaldo', 'Hanqing Zhu', 'Haoyu Zhang', 'Ji Liu', 'Yangpeng Ou', 'Xiao Kong']",https://doi.org/10.1145/3637528.3671588,"In recommendation systems, the timely delivery of new content to their relevant audiences is critical for generating a growing and high quality collection of content for all users. The nature of this problem requires retrieval models to be able to make inferences in real time and with high relevance. There are two specific challenges for cold start contents. First, the information loss problem in a standard Two Tower model, due to the limited feature interactions between the user and item towers, is exacerbated for cold start items due to training data sparsity. Second, the huge volume of user-generated content in industry applications today poses a big bottleneck in the end-to-end latency of recommending new content. To overcome the two challenges, we propose a novel architecture, the Item History Model (IHM). IHM directly injects user-interaction information into the item tower to overcome information loss. In addition, IHM incorporates an inductive structure using attention-based pooling to eliminate the need for recurring training, a key bottleneck for the real-timeness. On both public and industry datasets, we demonstrate that IHM can not only outperform baselines in recommending cold start contents, but also achieves SoTA real-timeness in industry applications.",Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,2024,Research
Exploiting Performance Estimates for Augmenting Recommendation Ensembles,No,"['Gustavo Penha', 'Rodrygo Santos']",https://doi.org/10.1145/3383313.3412264,"Ensembling multiple recommender systems via stacking has shown to be effective at improving collaborative recommendation. Recent work extends stacking to use additional user performance predictors (e.g., the total number of ratings made by the user) to help determine how much each base recommender should contribute to the ensemble. Nonetheless, despite the cost of handcrafting discriminative predictors, which typically requires deep knowledge of the strengths and weaknesses of each recommender in the ensemble, only minor improvements have been observed. To overcome this limitation, instead of engineering complex features to predict the performance of different recommenders for a given user, we propose to directly estimate these performances by leveraging the user’s own historical ratings. Experiments on real-world datasets from multiple domains demonstrate that using performance estimates as additional features can significantly improve the accuracy of state-of-the-art ensemblers, achieving nDCG@20 improvements by an average of 23% over not using them.",Proceedings of the 14th ACM Conference on Recommender Systems,2020,Research
Exploring High-Order User Preference on the Knowledge Graph for Recommender Systems,No,"['Hongwei Wang', 'Fuzheng Zhang', 'Jialin Wang', 'Miao Zhao', 'Wenjie Li', 'Xing Xie', 'Minyi Guo']",https://doi.org/10.1145/3312738,"To address the sparsity and cold-start problem of collaborative filtering, researchers usually make use of side information, such as social networks or item attributes, to improve the performance of recommendation. In this article, we consider the knowledge graph (KG) as the source of side information. To address the limitations of existing embedding-based and path-based methods for KG-aware recommendation, we propose RippleNet, an end-to-end framework that naturally incorporates the KG into recommender systems. RippleNet has two versions: (1) The outward propagation version, which is analogous to the actual ripples on water, stimulates the propagation of user preferences over the set of knowledge entities by automatically and iteratively extending a user’s potential interests along links in the KG. The multiple “ripples” activated by a user’s historically clicked items are thus superposed to form the preference distribution of the user with respect to a candidate item. (2) The inward aggregation version aggregates and incorporates the neighborhood information biasedly when computing the representation of a given entity. The neighborhood can be extended to multiple hops away to model high-order proximity and capture users’ long-distance interests. In addition, we intuitively demonstrate how a KG assists with recommender systems in RippleNet, and we also find that RippleNet provides a new perspective of explainability for the recommended results in terms of the KG. Through extensive experiments on real-world datasets, we demonstrate that both versions of RippleNet achieve substantial gains in a variety of scenarios, including movie, book, and news recommendations, over several state-of-the-art baselines.",missing,2019,Research
Preference-aware Graph Attention Networks for Cross-Domain Recommendations with Collaborative Knowledge Graph,No,"['Yakun Li', 'Lei Hou', 'Juanzi Li']",https://doi.org/10.1145/3576921,"Knowledge graphs (KGs) can provide users with semantic information and relations among numerous entities and nodes, which can greatly facilitate the performance of recommender systems. However, existing KG-based approaches still suffer from severe data sparsity and may not be effective in capturing the preference features of similar entities across domains. Therefore, in this article, we propose a Preference-aware Graph Attention network model with Collaborative Knowledge Graph (PGACKG) for cross-domain recommendations. Preference-aware entity embeddings with some collaborative signals are first obtained by exploiting the graph-embedding model, which can transform entities and items in the collaborative knowledge graph into semantic preference spaces. To better learn user preference features, we devise a preference-aware graph attention network framework that aggregates the preference features of similar entities within domains and across domains. In this framework, multi-hop reasoning is employed to assist in the generation of preference features within domains, and the node random walk based on frequency visits is proposed to gather similar preferences across domains for target entities. Then, the final preference features of entities are fused, while a novel Cross-domain Bayesian Personalized Ranking (CBPR) is proposed to improve cross-domain recommendation accuracy. Extensive empirical experiments on four real-world datasets demonstrate that our proposed approach consistently outperforms state-of-the-art baselines. Furthermore, our PGACKG achieves strong performance in different ablation scenarios, and the interaction sparsity experiments also demonstrate that our proposed approach can significantly alleviate the data sparsity issue.",missing,2023,Research
Task-Difficulty-Aware Meta-Learning with Adaptive Update Strategies for User Cold-Start Recommendation,No,"['Xuhao Zhao', 'Yanmin Zhu', 'Chunyang Wang', 'Mengyuan Jing', 'Jiadi Yu', 'Feilong Tang']",https://doi.org/10.1145/3583780.3615074,"User cold-start recommendation is one of the most challenging problems that limit the effectiveness of recommender systems. Meta-learning-based methods are introduced to address this problem by learning initialization parameters for cold-start tasks. Recent studies attempt to enhance the initialization methods. They first represent each task by the cold-start user and interacted items. Then they distinguish tasks based on the task relevance to learn adaptive initialization. However, this manner is based on the assumption that user preferences can be reflected by the interacted items saliently, which is not always true in reality. In addition, we argue that previous approaches suffer from their adaptive framework (e.g., adaptive initialization), which reduces the adaptability in the process of transferring meta-knowledge to personalized RSs. In response to the issues, we propose a task-difficulty-aware meta-learning with adaptive update strategies (TDAS) for user cold-start recommendation. First, we design a task difficulty encoder, which can represent user preference salience, task relevance, and other task characteristics by modeling task difficulty information. Second, we adopt a novel framework with task-adaptive local update strategies by optimizing the initialization parameters with task-adaptive per-step and per-layer hyperparameters. Extensive experiments based on three real-world datasets demonstrate that our TDAS outperforms the state-of-the-art methods. The source code is available at https://github.com/XuHao-bit/TDAS.",Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,2023,Research
MUKG: Unifying Multi-Task and Knowledge Graph Method for Recommender System,No,"['Jingyu Sun', 'MD BILLA SHAGAR']",https://doi.org/10.1145/3421558.3421561,"Recommendation systems (RS) are automated mechanisms designed exclusively to prescribe desired products scientifically based on the preferences of the consumer. The users' interest would be either implied or precisely defined by the processes. Implicit meta-data collections merely provide all the possible detection of usage profiles. Recommendations may produce predominantly based on consumer anticipations, item features, user-interactions among other contextual factors. In popular RS techniques, collaborative filtering stoically endures from sparsity as well as cold start problems. To adequately address the key issues, many academic studies subtly manipulate feature learning to positively enhance the exceptional performance of RS. This paper ponders the Knowledge Graph to serve as the source of heterogeneous information. We introduce the MUKG a unifying framework based on multi-task feature learning and Knowledge graph to improve tremendously the recommendation. The MUKG represents a deep succeeding framework that appropriates the knowledge graph representation task to support the recommendation task. We develop a Mapping Layer Network and two inter-link tasks that learn precisely higher-order interactions between specific items and entities. We convincingly demonstrate MUKG represents a comprehensive framework incorporating many representative methods of RS along with multi-task learning. Through extensive experiments on four pragmatic datasets, we profusely illustrate that the potency of the MUKG over different newfangled touchstone. Precisely, our developed model properly obtains average Accuracy accumulations of 11.6%, 11.5%, 12.7%, and 8.7% in movies, books, music and news recommendation, individually.",Proceedings of the 2020 2nd International Conference on Image Processing and Machine Vision,2020,Research
Privacy-preserving Multi-source Cross-domain Recommendation Based on Knowledge Graph,No,"['Jing Liu', 'Litao Shang', 'Yuting Su', 'Weizhi Nie', 'Xin Wen', 'Anan Liu']",https://doi.org/10.1145/3639706,"The cross-domain recommender systems aim to alleviate the data sparsity problem in the target domain by transferring knowledge from the auxiliary domain. However, existing works ignore the fact that the data sparsity problem may also exist in the single auxiliary domain, and sharing user behavior data is restricted by the privacy policy. In addition, their cross-domain models lack interpretability. To address these concerns, we propose a novel multi-source cross-domain model based on knowledge graph. Specifically, to avoid the insufficiency of single auxiliary domain, we construct a knowledge graph comprehensively leveraging items from multiple auxiliary domains. To avoid the leakage of user privacy when user information is transferred to multiple domains, we construct graph for information transfer between items to effectively avoid the propagation of users’ private information between different domains. We implicitly integrate the user–item interaction by transferring the learned item embeddings. To improve the interpretability of cross-domain knowledge transfer, we propose a knowledge graph-based retrieval and fusion method to transfer knowledge derived from multiple auxiliary domains. An attention-based fusion network is designed to enhance the representation of the targeted user and items with the transferred item embedding. We perform extensive experiments on three real-world datasets, demonstrating that our model outperforms the states of the art.",missing,2024,Research
Multilingual Review-aware Deep Recommender System via Aspect-based Sentiment Analysis,No,"['Peng Liu', 'Lemei Zhang', 'Jon Gulla']",https://doi.org/10.1145/3432049,"With the dramatic expansion of international markets, consumers write reviews in different languages, which poses a new challenge for Recommender Systems (RSs) dealing with this increasing amount of multilingual information. Recent studies that leverage deep-learning techniques for review-aware RSs have demonstrated their effectiveness in modelling fine-grained user-item interactions through the aspects of reviews. However, most of these models can neither take full advantage of the contextual information from multilingual reviews nor discriminate the inherent ambiguity of words originated from the user’s different tendency in writing. To this end, we propose a novel Multilingual Review-aware Deep Recommendation Model (MrRec) for rating prediction tasks. MrRec mainly consists of two parts: (1) Multilingual aspect-based sentiment analysis module (MABSA), which aims to jointly extract aligned aspects and their associated sentiments in different languages simultaneously with only requiring overall review ratings. (2) Multilingual recommendation module that learns aspect importances of both the user and item with considering different contributions of multiple languages and estimates aspect utility via a dual interactive attention mechanism integrated with aspect-specific sentiments from MABSA. Finally, overall ratings can be inferred by a prediction layer adopting the aspect utility value and aspect importance as inputs. Extensive experimental results on nine real-world datasets demonstrate the superior performance and interpretability of our model.",missing,2021,Research
Reconciling the Accuracy-Diversity Trade-off in Recommendations,Yes,"['Kenny Peng', 'Manish Raghavan', 'Emma Pierson', 'Jon Kleinberg', 'Nikhil Garg']",https://doi.org/10.1145/3589334.3645625,"When making recommendations, there is an apparent trade-off between the goals of accuracy (to recommend items a user is most likely to want) and diversity (to recommend items representing a range of categories). As such, real-world recommender systems often explicitly incorporate diversity into recommendations, at the cost of accuracy.We study the accuracy-diversity trade-off by bringing in a third concept: user utility. We argue that accuracy is misaligned with user utility because it fails to incorporate a user's consumption constraints: at any given time, users can typically only use at most a few recommended items (e.g., dine at one restaurant, or watch a couple of movies). In a theoretical model, we show that utility-maximizing recommendations---when accounting for consumption constraints---are naturally diverse due to diminishing returns of recommending similar items. Therefore, while increasing diversity may come at the cost of accuracy, it can also help align accuracy-based recommendations toward the more fundamental objective of user utility. Our theoretical results yield practical guidance into how recommendations should incorporate diversity to serve user ends.",Proceedings of the ACM Web Conference 2024,2024,Research
Spiral of Silence in Recommender Systems,Yes,"['Dugang Liu', 'Chen Lin', 'Zhilin Zhang', 'Yanghua Xiao', 'Hanghang Tong']",https://doi.org/10.1145/3289600.3291003,"It has been established that, ratings are missing not at random in recommender systems. However, little research has been done to reveal how the ratings are missing. In this paper we present one possible explanation of the missing not at random phenomenon. We verify that, using a variety of different real-life datasets, there is a spiral process for a silent minority in recommender systems where (1) people whose opinions fall into the minority are less likely to give ratings than majority opinion holders; (2) as the majority opinion becomes more dominant, the rating possibility of a majority opinion holder is intensifying but the rating possibility of a minority opinion holder is shrinking; (3) only hardcore users remain to rate for minority opinions when the spiral achieves its steady state. Our empirical findings are beneficial for future recommendation models. To demonstrate the impact of our empirical findings, we present a probabilistic model that mimics the generation process of spiral of silence. We experimentally show that, the presented model offers more accurate recommendations, compared with state-of-the-art recommendation models.",Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining,2019,Research
PROPN: Personalized Probabilistic Strategic Parameter Optimization in Recommendations,No,"['Pengfei He', 'Haochen Liu', 'Xiangyu Zhao', 'Hui Liu', 'Jiliang Tang']",https://doi.org/10.1145/3511808.3557130,"Real-world recommender systems usually consist of two phases. Predictive models in Phase I provide accurate predictions of users' actions on items, and Phase II is to aggregate the predictions withstrategic parameters to make final recommendations, which aim to meet multiple business goals, such as maximizing users' like rate and average engagement time. Though it is important to generate accurate predictions in Phase I, it is also crucial to optimize the strategic parameters in Phase II. Conventional solutions include manually tunning, Bayesian optimization, contextual multi-armed bandit optimization, etc. However, these methods either produce universal strategic parameters for all the users or focus on a deterministic solution, which leads to an undesirable performance. In this paper, we propose a personalized probabilistic solution for strategic parameter optimization. We first formulate the personalized probabilistic optimizing problem and compare its solution with deterministic and context-free solutions theoretically to show its superiority. We then introduce a novel Personalized pRObabilistic strategic parameter optimizing Policy Network (PROPN) to solve the problem. PROPN follows reinforcement learning architecture where a neural network serves as an agent that dynamically adjusts the distributions of strategic parameters for each user. We evaluate our model under the streaming recommendation setting on two public real-world datasets. The results show that our framework outperforms representative baseline methods.",Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,2022,Research
CoRec: An Efficient Internet Behavior-based Recommendation Framework with Edge-cloud Collaboration on Deep Convolution Neural Networks,No,"['Yangfan Li', 'Kenli Li', 'Wei Wei', 'Tianyi Zhou', 'Cen Chen']",https://doi.org/10.1145/3526191,"Both accurate and fast mobile recommendation systems based on click behaviors analysis are crucial in e-business. Deep learning has achieved state-of-the-art accuracy and the traditional wisdom often hosts these computation-intensive models in powerful cloud centers. However, the cloud-only approaches put significant computational pressure on cloud servers and increase the latency in heavy-load scenarios. Moreover, existing work often adopts RNN structures to model behaviors that suffer from low processing speed for under-utilization of parallel devices such as GPUs. In this work, we propose an efficient internet behavior-based recommendation framework with edge-cloud collaboration on deep CNNs (CoRec) to improve both the accuracy and speed for mobile recommendation. A novel convolutional interest network (CIN) improves the accuracy by modeling the long- and short-term interests and accelerates the prediction through parallel-friendly convolutions. To further improve the serving throughput and latency, a novel device-cloud collaboration strategy reduces workloads by pre-computing and caching long-term interests in the cloud offline and real-time computation of short-term interests in devices. Extensive experiments on real-world datasets show that CoRec significantly outperforms the state-of-the-art methods in accuracy and has achieved at least an order of magnitude improvement in latency and throughput compared to cloud-only RNN-based approaches for long behaviors.",missing,2022,Research
Heterogeneous Side Information-based Iterative Guidance Model for Recommendation,No,"['Feifei Dai', 'Xiaoyan Gu', 'Zhuo Wang', 'Mingda Qian', 'Bo Li', 'Weiping Wang']",https://doi.org/10.1145/3460426.3463631,"Heterogeneous side information has been widely used in recommender systems to alleviate the data sparsity problem. However, the heterogeneous side information in existing methods provides insufficient guidance for predicting user preferences as its effect is inevitably weakened during utilization. Furthermore, most existing methods cannot effectively utilize the heterogeneous side information to understand users and items. They often neglect the interrelation among various types of heterogeneous side information of a user or an item. As a result, it is difficult for existing methods to comprehensively understand users and items so that the recommender system recommends inappropriate items to users. To overcome the above drawbacks, we propose an interrelation learning-based recommendation method with iterative heterogeneous side information guidance (ILIG). ILIG includes two modules: 1) Iterative Heterogeneous Side Information Guidance Module. It uses heterogeneous side information to iteratively guide the prediction of user preferences, which effectively enhances the effect of the heterogeneous side information. 2) Interrelation Learning-based Portrait Construction Module. It captures the interrelation among various types of heterogeneous side information to comprehensively learn the representations of users and items. To demonstrate the effectiveness of ILIG, we conduct extensive experiments on Movielens-100K, Movielens-1M, and BookCrossing datasets. The experimental results show that ILIG outperforms the state-of-the-art recommender systems.",Proceedings of the 2021 International Conference on Multimedia Retrieval,2021,Research
Are We Evaluating Rigorously? Benchmarking Recommendation for Reproducible Evaluation and Fair Comparison,No,"['Zhu Sun', 'Di Yu', 'Hui Fang', 'Jie Yang', 'Xinghua Qu', 'Jie Zhang', 'Cong Geng']",https://doi.org/10.1145/3383313.3412489,"With tremendous amount of recommendation algorithms proposed every year, one critical issue has attracted a considerable amount of attention: there are no effective benchmarks for evaluation, which leads to two major concerns, i.e., unreproducible evaluation and unfair comparison. This paper aims to conduct rigorous (i.e., reproducible and fair) evaluation for implicit-feedback based top-N recommendation algorithms. We first systematically review 85 recommendation papers published at eight top-tier conferences (e.g., RecSys, SIGIR) to summarize important evaluation factors, e.g., data splitting and parameter tuning strategies, etc. Through a holistic empirical study, the impacts of different factors on recommendation performance are then analyzed in-depth. Following that, we create benchmarks with standardized procedures and provide the performance of seven well-tuned state-of-the-arts across six metrics on six widely-used datasets as a reference for later study. Additionally, we release a user-friendly Python toolkit, which differs from existing ones in addressing the broad scope of rigorous evaluation for recommendation. Overall, our work sheds light on the issues in recommendation evaluation and lays the foundation for further investigation. Our code and datasets are available at GitHub (https://github.com/AmazingDD/daisyRec).",Proceedings of the 14th ACM Conference on Recommender Systems,2020,Research
Modeling Scale-free Graphs with Hyperbolic Geometry for Knowledge-aware Recommendation,No,"['Yankai Chen', 'Menglin Yang', 'Yingxue Zhang', 'Mengchen Zhao', 'Ziqiao Meng', 'Jianye Hao', 'Irwin King']",https://doi.org/10.1145/3488560.3498419,"Aiming to alleviate data sparsity and cold-start problems of tradi- tional recommender systems, incorporating knowledge graphs (KGs) to supplement auxiliary information has recently gained considerable attention. Via unifying the KG with user-item interactions into a tripartite graph, recent works explore the graph topologies to learn the low-dimensional representations of users and items with rich semantics. These real-world tripartite graphs are usually scale-free, however, the intrinsic hierarchical graph structures of which are underemphasized in existing works, consequently, leading to suboptimal recommendation performance. To address this issue and provide more accurate recommendation, we propose a knowledge-aware recommendation method with Lorentz model of the hyperbolic geometry, namely Lorentzian Knowledge-enhanced Graph convolutional networks for Recommendation (LKGR). LKGR facilitates better modeling of scale-free tripartite graphs after the data unification. Specifically, we employ different information propagation strategies in the hyperbolic space to explicitly encode heterogeneous information from historical interactions and KGs. Additionally, our proposed knowledge-aware attention mechanism enables the model to automatically measure the information contribution, producing the coherent information aggregation in the hyperbolic space. Extensive experiments on three real-world benchmarks demonstrate that LKGR outperforms state-of-the-art methods by 3.6-15.3% of Recall@20 on Top-K recommendation.",Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining,2022,Research
Post-hoc Selection of Pareto-Optimal Solutions in Search and Recommendation,Keep,"['Vincenzo Paparella', 'Vito Anelli', 'Franco Nardini', 'Raffaele Perego', 'Tommaso Di Noia']",https://doi.org/10.1145/3583780.3615010,"Information Retrieval (IR) and Recommender Systems (RSs) tasks are moving from computing a ranking of final results based on a single metric to multi-objective problems. Solving these problems leads to a set of Pareto-optimal solutions, known as Pareto frontier, in which no objective can be further improved without hurting the others. In principle, all the points on the Pareto frontier are potential candidates to represent the best model selected with respect to the combination of two, or more, metrics. To our knowledge, there are no well-recognized strategies to decide which point should be selected on the frontier in IR and RSs. In this paper, we propose a novel, post-hoc, theoretically-justified technique, named ""Population Distance from Utopia"" (PDU), to identify and select the one-best Pareto-optimal solution. PDU considers fine-grained utopia points, and measures how far each point is from its utopia point, allowing to select solutions tailored to user preferences, a novel feature we call ""calibration"". We compare PDU against state-of-the-art strategies through extensive experiments on tasks from both IR and RS, showing that PDU combined with calibration notably impacts the solution selection.",Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,2023,Research
Disentangled Representation for Diversified Recommendations,Keep,"['Xiaoying Zhang', 'Hongning Wang', 'Hang Li']",https://doi.org/10.1145/3539597.3570389,"Accuracy and diversity have long been considered to be two conflicting goals for recommendations. We point out, however, that as the diversity is typically measured by certain pre-selected item attributes, e.g., category as the most popularly employed one, improved diversity can be achieved without sacrificing recommendation accuracy, as long as the diversification respects the user's preference about the pre-selected attributes. This calls for a fine-grained understanding of a user's preferences over items, where one needs to recognize the user's choice is driven by the quality of the item itself, or the pre-selected attributes of the item.In this work, we focus on diversity defined on item categories. We propose a general diversification framework agnostic to the choice of recommendation algorithm. Our solution disentangles the learnt user representation in the recommendation module into category- independent and category-dependent components to differentiate a user's preference over items from two orthogonal perspectives. Experimental results on three benchmark datasets and online A/B test demonstrate the effectiveness of our solution in improving both recommendation accuracy and diversity. In-depth analysis suggests that the improvement is due to our improved modeling of users' categorical preferences and refined ranking within item categories.",Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining,2023,Research
Bidirectional Knowledge-Aware Attention Network over Knowledge Graph for Explainable Recommendation,No,"['Yanxia Lyu', 'Guorui Su', 'Jianghan Wang', 'Ye Xing']",https://doi.org/10.1145/3578741.3578776,"Now recommendation systems are introduced into various online applications to help users find the content they want from massive data. Although the recommendation method based on collaborative filtering can adapt to the change of recommendation scenarios, the recommendation heavily depends on interaction data, so the recommendations are seriously affected by data sparsity. To alleviate the above problem researchers introduce knowledge graph as side information into the recommendation system. By exploring the rich entity information and relation information in knowledge graph, we can enrich the representations of user and item and enhance interpretability of recommendation system. However, some recommendation methods only carry out unidirectional knowledge propagation when mining knowledge information, which makes it difficult to capture higher-order knowledge information when the knowledge graph is sparse. Meanwhile, most recommendation models do not make full use of the relations between users, items and entities to enhance the interpretability of recommendations. Based on the reasons above, we design a novel bidirectional knowledge-aware attention network framework for explainable recommendation named BKANE, which integrates interaction information and high-order knowledge information, completing the recommendation in an end-to-end manner. The experimental results on three real datasets show that BKANE is significantly better than the state-of-the-art baselines in terms of recommendation performance. Also, the graphical explanation form can provide developers and users with a reasonable explanation of the model and recommendations.",Proceedings of the 2022 5th International Conference on Machine Learning and Natural Language Processing,2023,Research
Cracking the Code of Negative Transfer: A Cooperative Game Theoretic Approach for Cross-Domain Sequential Recommendation,No,"['Chung Park', 'Taesan Kim', 'Taekyoon Choi', 'Junui Hong', 'Yelim Yu', 'Mincheol Cho', 'Kyunam Lee', 'Sungil Ryu', 'Hyungjun Yoon', 'Minsung Choi', 'Jaegul Choo']",https://doi.org/10.1145/3583780.3614828,"This paper investigates Cross-Domain Sequential Recommendation (CDSR), a promising method that uses information from multiple domains (more than three) to generate accurate and diverse recommendations, and takes into account the sequential nature of user interactions. The effectiveness of these systems often depends on the complex interplay among the multiple domains. In this dynamic landscape, the problem of negative transfer arises, where heterogeneous knowledge between dissimilar domains leads to performance degradation due to differences in user preferences across these domains. As a remedy, we propose a new CDSR framework that addresses the problem of negative transfer by assessing the extent of negative transfer from one domain to another and adaptively assigning low weight values to the corresponding prediction losses. To this end, the amount of negative transfer is estimated by measuring the marginal contribution of each domain to model performance based on a cooperative game theory. In addition, a hierarchical contrastive learning approach that incorporates information from the sequence of coarse-level categories into that of fine-level categories (e.g., item level) when implementing contrastive learning was developed to mitigate negative transfer. Despite the potentially low relevance between domains at the fine-level, there may be higher relevance at the category level due to its generalised and broader preferences. We show that our model is superior to prior works in terms of model performance on two real-world datasets across ten different domains.",Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,2023,Research
Dual-Side Adversarial Learning Based Fair Recommendation for Sensitive Attribute Filtering,Yes,"['Shenghao Liu', 'Yu Zhang', 'Lingzhi Yi', 'Xianjun Deng', 'Laurence Yang', 'Bang Wang']",https://doi.org/10.1145/3648683,"With the development of recommendation algorithms, researchers are paying increasing attention to fairness issues such as user discrimination in recommendations. To address these issues, existing works often filter users’ sensitive information that may cause discrimination during the process of learning user representations. However, these approaches overlook the latent relationship between items’ content attributes and users’ sensitive information. In this article, we propose DALFRec, a fairness-aware recommendation algorithm based on user-side and item-side adversarial learning to mitigate the effects of sensitive information on both sides of the recommendation process. First, we conduct a statistical analysis to demonstrate the latent relationship between items’ information and users’ sensitive attributes. Then, we design a dual-side adversarial learning network that simultaneously filters out users’ sensitive information on the user and item side. Additionally, we propose a new evaluation strategy that leverages the latent relationship between items’ content attributes and users’ sensitive attributes to better assess the algorithm’s ability to reduce discrimination. Our experiments on three real datasets demonstrate the superiority of our proposed algorithm over state-of-the-art methods.",missing,2024,Research
HRS: Hybrid Recommendation System based on Attention Mechanism and Knowledge Graph Embedding,No,"['Chunfang Dong', 'Xuchan Ju', 'Yue Ma']",https://doi.org/10.1145/3498851.3498987,"Traditional recommendation methods often have sparsity and cold start problems in real applications. Researchers found that introducing knowledge graphs into recommender systems as a kind of auxiliary information can alleviate these problems and improve the performance of the recommender systems. This paper put forward a Hybrid Recommendation System based on Attention Mechanism and Knowledge Graph Embedding (HRS). It uses crosscompress unit and preference propagation respectively to enrich the features of items and users. In this process, we use the attention mechanism and knowledge graph embedding to enhance the recommender system. After obtaining the user vector representation and the item vector representation, we can predict the probability of the user clicking on the item. The experiments on three datasets derived from the actual scenes demonstrate the competitiveness of HRS, compared with several state-of-the-art baselines in the recommendation.",IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology,2022,Research
PNMTA: A Pretrained Network Modulation and Task Adaptation Approach for User Cold-Start Recommendation,No,"['Haoyu Pang', 'Fausto Giunchiglia', 'Ximing Li', 'Renchu Guan', 'Xiaoyue Feng']",https://doi.org/10.1145/3485447.3511963,"User cold-start recommendation is a serious problem that limits the performance of recommender systems (RSs). Recent studies have focused on treating this issue as a few-shot problem and seeking solutions with model-agnostic meta-learning (MAML). Such methods regard making recommendations for one user as a task and adapt to new users with a few steps of gradient updates on the meta-model. However, none of those methods consider the limitation of user representation learning imposed by the special task setting of MAML-based RSs. And they learn a common meta-model for all users while ignoring the implicit grouping distribution induced by the correlation differences among users. In response to the above problems, we propose a pretrained network modulation and task adaptation approach (PNMTA) for user cold-start recommendation. In the pretraining stage, a pretrained model is obtained with non-meta-learning methods to achieve better user representation and generalization, which can also transfer the learned knowledge to the meta-learning stage for modulation. During the meta-learning stage, an encoder modulator is utilized to realize the memorization and correction of prior parameters for the meta-learning task, and a predictor modulator is introduced to condition the model initialization on the task identity for adaptation steps. In addition, PNMTA can also make use of the existing non-cold-start users for pretraining. Comprehensive experiments on two benchmark datasets demonstrate that our model can achieve significant and consistent improvements against other state-of-the-art methods.",Proceedings of the ACM Web Conference 2022,2022,Research
CKAN: Collaborative Knowledge-aware Attentive Network for Recommender Systems,No,"['Ze Wang', 'Guangyan Lin', 'Huobin Tan', 'Qinghong Chen', 'Xiyang Liu']",https://doi.org/10.1145/3397271.3401141,"Since it can effectively address the problem of sparsity and cold start of collaborative filtering, knowledge graph (KG) is widely studied and employed as side information in the field of recommender systems. However, most of existing KG-based recommendation methods mainly focus on how to effectively encode the knowledge associations in KG, without highlighting the crucial collaborative signals which are latent in user-item interactions. As such, the learned embeddings underutilize the two kinds of pivotal information and are insufficient to effectively represent the latent semantics of users and items in vector space.In this paper, we propose a novel method named Collaborative Knowledge-aware Attentive Network (CKAN) which explicitly encodes the collaborative signals by collaboration propagation and proposes a natural way of combining collaborative signals with knowledge associations together. Specifically, CKAN employs a heterogeneous propagation strategy to explicitly encode both kinds of information, and applies a knowledge-aware attention mechanism to discriminate the contribution of different knowledge-based neighbors. Compared with other KG-based methods, CKAN provides a brand-new idea of combining collaborative information with knowledge information together. We apply the proposed model on four real-world datasets, and the empirical results demonstrate that CKAN significantly outperforms several compelling state-of-the-art baselines.",Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval,2020,Research
Is Rank Aggregation Effective in Recommender Systems? An Experimental Analysis,No,"['Samuel Oliveira', 'Victor Diniz', 'Anisio Lacerda', 'Luiz Merschmanm', 'Gisele Pappa']",https://doi.org/10.1145/3365375,"Recommender Systems are tools designed to help users find relevant information from the myriad of content available online. They work by actively suggesting items that are relevant to users according to their historical preferences or observed actions. Among recommender systems, top-N recommenders work by suggesting a ranking of N items that can be of interest to a user. Although a significant number of top-N recommenders have been proposed in the literature, they often disagree in their returned rankings, offering an opportunity for improving the final recommendation ranking by aggregating the outputs of different algorithms.Rank aggregation was successfully used in a significant number of areas, but only a few rank aggregation methods have been proposed in the recommender systems literature. Furthermore, there is a lack of studies regarding rankings’ characteristics and their possible impacts on the improvements achieved through rank aggregation. This work presents an extensive two-phase experimental analysis of rank aggregation in recommender systems. In the first phase, we investigate the characteristics of rankings recommended by 15 different top-N recommender algorithms regarding agreement and diversity. In the second phase, we look at the results of 19 rank aggregation methods and identify different scenarios where they perform best or worst according to the input rankings’ characteristics.Our results show that supervised rank aggregation methods provide improvements in the results of the recommended rankings in six out of seven datasets. These methods provide robustness even in the presence of a big set of weak recommendation rankings. However, in cases where there was a set of non-diverse high-quality input rankings, supervised and unsupervised algorithms produced similar results. In these cases, we can avoid the cost of the former in favor of the latter.",missing,2020,Research
A Recommendation Algorithm Incorporating Self-Attention Mechanism and Knowledge Graph,No,"['Jingjing Hou', 'Yuchen Jin', 'Yiwen Liu', 'Zhenhua Zhang', 'Qinghua Zhao']",https://doi.org/10.1145/3581807.3581858,"To address the problems of sparse data, low recommendation accuracy and poor recommendation effect in recommendation systems. In this paper, we propose a recommendation algorithm that fuses the self-attention mechanism and knowledge graph. The algorithm mainly includes recommendation module, knowledge graph feature learning, and self-attention. In this algorithm recommendation system module, a user and an item are input, and the input item vector and entity vector are embedded in the self-attention module, so that the feature representation of these two vectors is enhanced. The knowledge graph feature representation module maps the head entities and relations in the triad into a continuous vector space, and calculates the corresponding values through the score function. The recommendation module and the knowledge graph representation model are connected through the cross-compression unit embedded in the self-attentive mechanism. Finally, the loss of each module is calculated by a loss function. Experiments on three different publicly available datasets show that: the embedded attention mechanism module introduced can well solve the accuracy problem of the recommendation system; Secondly, the embedded attention mechanism cross-compression unit module enhances the recommendation system in which vectors are compressed in horizontal and vertical directions. Finally, through experiments comparing other algorithms, the proposed method improves the recommendation accuracy and effectiveness in the recommendation system.",Proceedings of the 2022 11th International Conference on Computing and Pattern Recognition,2023,Research
Learning Recommenders for Implicit Feedback with Importance Resampling,No,"['Jin Chen', 'Defu Lian', 'Binbin Jin', 'Kai Zheng', 'Enhong Chen']",https://doi.org/10.1145/3485447.3512075,"Recommendation is prevalently studied for implicit feedback recently, but it seriously suffers from the lack of negative samples, which has a significant impact on the training of recommendation models. Existing negative sampling is based on the static or adaptive probability distributions. Sampling from the adaptive probability receives more attention, since it tends to generate more hard examples, to make recommender training faster to converge. However, item sampling becomes much more time-consuming particularly for complex recommendation models. In this paper, we propose an Adaptive Sampling method based on Importance Resampling (AdaSIR for short), which is not only almost equally efficient and accurate for any recommender models, but also can robustly accommodate arbitrary proposal distributions. More concretely, AdaSIR maintains a contextualized sample pool of fixed-size with importance resampling, from which items are only uniformly sampled. Such a simple sampling method can be proved to provide approximately accurate adaptive sampling under some conditions. The sample pool plays two extra important roles in (1) reusing historical hard samples with certain probabilities; (2) estimating the rank of positive samples for weighting, such that recommender training can concentrate more on difficult positive samples. Extensive empirical experiments demonstrate that AdaSIR outperforms state-of-the-art methods in terms of sampling efficiency and effectiveness.",Proceedings of the ACM Web Conference 2022,2022,Research
Self-Supervised Bot Play for Transcript-Free Conversational Critiquing with Rationales,No,"['Shuyang Li', 'Bodhisattwa Prasad Majumder', 'Julian McAuley']",https://doi.org/10.1145/3665502,"Conversational critiquing in recommender systems offers a way for users to engage in multi-turn conversations to find items they enjoy. For users to trust an agent and give effective feedback, the recommender system must be able to explain its suggestions and rationales. We develop a two-part framework for training multi-turn conversational critiquing in recommender systems that provide recommendation rationales that users can effectively interact with to receive better recommendations. First, we train a recommender system to jointly suggest items and explain its reasoning via subjective rationales. We then fine-tune this model to incorporate iterative user feedback via self-supervised bot-play. Experiments on three real-world datasets demonstrate that our system can be applied to different recommendation models across diverse domains to achieve state-of-the-art performance in multi-turn recommendation. Human studies show that systems trained with our framework provide more useful, helpful, and knowledgeable suggestions in warm- and cold-start settings. Our framework allows us to use only product reviews during training, avoiding the need for expensive dialog transcript datasets that limit the applicability of previous conversational recommender agents.",missing,2024,Research
Meta Graph Learning for Long-tail Recommendation,Yes,"['Chunyu Wei', 'Jian Liang', 'Di Liu', 'Zehui Dai', 'Mang Li', 'Fei Wang']",https://doi.org/10.1145/3580305.3599428,"Highly skewed long-tail item distribution commonly hurts model performance on tail items in recommendation systems, especially for graph-based recommendation models. We propose a novel idea to learn relations among items as an auxiliary graph to enhance the graph-based representation learning and make recommendations collectively in a coupled framework. This raises two challenges, 1) the long-tail downstream information may also bias the auxiliary graph learning, and 2) the learned auxiliary graph may cause negative transfer to the original user-item bipartite graph. We innovatively propose a novel Meta Graph Learning framework for long-tail recommendation (MGL) for solving both challenges. The meta-learning strategy is introduced to the learning of an edge generator, which is first tuned to reconstruct a debiased item co-occurrence matrix, and then virtually evaluated on generating item relations for recommendation. Moreover, we propose a popularity-aware contrastive learning strategy to prevent negative transfer by aligning the confident head item representations with those of the learned auxiliary graph. Experiments on public datasets demonstrate that our proposed model significantly outperforms strong baselines for tail items without compromising the overall performance.",Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,2023,Research
CauseRec: Counterfactual User Sequence Synthesis for Sequential Recommendation,Keep,"['Shengyu Zhang', 'Dong Yao', 'Zhou Zhao', 'Tat-Seng Chua', 'Fei Wu']",https://doi.org/10.1145/3404835.3462908,"Learning user representations based on historical behaviors lies at the core of modern recommender systems. Recent advances in sequential recommenders have convincingly demonstrated high capability in extracting effective user representations from the given behavior sequences. Despite significant progress, we argue that solely modeling the observational behaviors sequences may end up with a brittle and unstable system due to the noisy and sparse nature of user interactions logged. In this paper, we propose to learn accurate and robust user representations, which are required to be less sensitive to (attack on) noisy behaviors and trust more on the indispensable ones, by modeling counterfactual data distribution. Specifically, given an observed behavior sequence, the proposed CauseRec framework identifies dispensable and indispensable concepts at both the fine-grained item level and the abstract interest level. CauseRec conditionally samples user concept sequences from the counterfactual data distributions by replacing dispensable and indispensable concepts within the original concept sequence. With user representations obtained from the synthesized user sequences, CauseRec performs contrastive user representation learning by contrasting the counterfactual with the observational. We conduct extensive experiments on real-world public recommendation benchmarks and justify the effectiveness of CauseRec with multi-aspects model analysis. The results demonstrate that the proposed CauseRec outperforms state-of-the-art sequential recommenders by learning accurate and robust user representations.",Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval,2021,Research
Exploring Scenarios of Uncertainty about the Users' Preferences in Interactive Recommendation Systems,Yes,"[""N\\'{\\i}collas Silva"", 'Thiago Silva', 'Henrique Hott', 'Yan Ribeiro', 'Adriano Pereira', 'Leonardo Rocha']",https://doi.org/10.1145/3539618.3591684,"Interactive Recommender Systems have played a crucial role in distinct entertainment domains through a Contextual Bandit model. Despite the current advances, their personalisation level is still directly related to the information previously available about the users. However, there are at least two scenarios of uncertainty about the users' preferences over their journey: (1) when the user joins for the first time and (2) when the system continually makes wrong recommendations because of prior misleading assumptions. In this work, we introduce concepts from the Active Learning theory to mitigate the impact of such scenarios. We modify three traditional bandits to recommend items with a higher potential to get more user information without decreasing the model's accuracy when an uncertain scenario is observed. Our experiments show that the modified models outperform all baselines by increasing the cumulative reward in the long run. Moreover, a counterfactual evaluation validates that such improvements were not simply achieved due to the bias of offline datasets.",Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval,2023,Research
FairSR: Fairness-aware Sequential Recommendation through Multi-Task Learning with Preference Graph Embeddings,Yes,"['Cheng-Te Li', 'Cheng Hsu', 'Yang Zhang']",https://doi.org/10.1145/3495163,"Sequential recommendation (SR) learns from the temporal dynamics of user-item interactions to predict the next ones. Fairness-aware recommendation mitigates a variety of algorithmic biases in the learning of user preferences. This article aims at bringing a marriage between SR and algorithmic fairness. We propose a novel fairness-aware sequential recommendation task, in which a new metric, interaction fairness, is defined to estimate how recommended items are fairly interacted by users with different protected attribute groups. We propose a multi-task learning-based deep end-to-end model, FairSR, which consists of two parts. One is to learn and distill personalized sequential features from the given user and her item sequence for SR. The other is fairness-aware preference graph embedding (FPGE). The aim of FPGE is two-fold: incorporating the knowledge of users’ and items’ attributes and their correlation into entity representations, and alleviating the unfair distributions of user attributes on items. Extensive experiments conducted on three datasets show FairSR can outperform state-of-the-art SR models in recommendation performance. In addition, the recommended items by FairSR also exhibit promising interaction fairness.",missing,2022,Research
Using Stable Matching to Optimize the Balance between Accuracy and Diversity in Recommendation,Yes,"['Farzad Eskandanian', 'Bamshad Mobasher']",https://doi.org/10.1145/3340631.3394858,"Increasing aggregate diversity (or catalog coverage) is an important system-level objective in many recommendation domains where it may be desirable to mitigate the popularity bias and to improve the coverage of long-tail items in recommendations given to users. This is especially important in multistakeholder recommendation scenarios where it may be important to optimize utilities not just for the end user, but also for other stakeholders such as item sellers or producers who desire a fair representation of their items across recommendation lists produced by the system. Unfortunately, attempts to increase aggregate diversity often result in lower recommendation accuracy for end users. Thus, addressing this problem requires an approach that can effectively manage the trade-offs between accuracy and aggregate diversity. In this work, we propose a two-sided post-processing approach in which both user and item utilities are considered. Our goal is to maximize aggregate diversity while minimizing loss in recommendation accuracy. Our solution is a generalization of the Deferred Acceptance algorithm which was proposed as an efficient algorithm to solve the well-known stable matching problem. We prove that our algorithm results in a unique user-optimal stable match between items and users. Using three recommendation datasets, we empirically demonstrate the effectiveness of our approach in comparison to several baselines. In particular, our results show that the proposed solution is quite effective in increasing aggregate diversity and item-side utility while optimizing recommendation accuracy for end users.","Proceedings of the 28th ACM Conference on User Modeling, Adaptation and Personalization",2020,Research
Flatter Is Better: Percentile Transformations for Recommender Systems,Yes,"['Masoud Mansoury', 'Robin Burke', 'Bamshad Mobasher']",https://doi.org/10.1145/3437910,"It is well known that explicit user ratings in recommender systems are biased toward high ratings and that users differ significantly in their usage of the rating scale. Implementers usually compensate for these issues through rating normalization or the inclusion of a user bias term in factorization models. However, these methods adjust only for the central tendency of users’ distributions. In this work, we demonstrate that a lack of flatness in rating distributions is negatively correlated with recommendation performance. We propose a rating transformation model that compensates for skew in the rating distribution as well as its central tendency by converting ratings into percentile values as a pre-processing step before recommendation generation. This transformation flattens the rating distribution, better compensates for differences in rating distributions, and improves recommendation performance. We also show that a smoothed version of this transformation can yield more intuitive results for users with very narrow rating distributions. A comprehensive set of experiments, with state-of-the-art recommendation algorithms in four real-world datasets, show improved ranking performance for these percentile transformations.",missing,2021,Research
White Box: On the Prediction of Collaborative Filtering Recommendation Systems’ Performance,No,"['Iulia Paun', 'Yashar Moshfeghi', 'Nikos Ntarmos']",https://doi.org/10.1145/3554979,"Collaborative Filtering (CF) recommendation algorithms are a popular solution to the information overload problem, aiding users in the item selection process. Relevant research has long focused on refining and improving these models to produce better (more effective) recommendations, and has converged on a methodology to predict their effectiveness on target datasets by evaluating them on random samples of the latter. However, predicting the efficiency of the solutions—especially with regard to their time- and resource-hungry training phase, whose requirements dwarf those of the prediction/recommendation phase—has received little to no attention in the literature. This article addresses this gap for a number of representative and highly popular CF models, including algorithms based on matrix factorization, k-nearest neighbors, co-clustering, and slope one schemes. To this end, we first study the computational complexity of the training phase of said CF models and derive time and space complexity equations. Then, using characteristics of the input and the aforementioned equations, we contribute a methodology for predicting the processing time and memory usage of their training phase. Our contributions further include an adaptive sampling strategy, to address the tradeoff between resource usage costs and prediction accuracy, and a framework that quantifies both the efficiency and effectiveness of CF. Finally, a systematic experimental evaluation demonstrates that our method outperforms state-of-the-art regression schemes by a considerable margin, with an overhead that is a small fraction of the overall requirements of CF training.",missing,2023,Research
Dual Learning for Explainable Recommendation: Towards Unifying User Preference Prediction and Review Generation,No,"['Peijie Sun', 'Le Wu', 'Kun Zhang', 'Yanjie Fu', 'Richang Hong', 'Meng Wang']",https://doi.org/10.1145/3366423.3380164,"In many recommender systems, users express item opinions through two kinds of behaviors: giving preferences and writing detailed reviews. As both kinds of behaviors reflect users’ assessment of items, review enhanced recommender systems leverage these two kinds of user behaviors to boost recommendation performance. On the one hand, researchers proposed to better model the user and item embeddings with additional review information for enhancing preference prediction accuracy. On the other hand, some recent works focused on automatically generating item reviews for recommendation explanations with related user and item embeddings. We argue that, while the task of preference prediction with the accuracy goal is well recognized in the community, the task of generating reviews for explainable recommendation is also important to gain user trust and increase conversion rate. Some preliminary attempts have considered jointly modeling these two tasks, with the user and item embeddings are shared. These studies empirically showed that these two tasks are correlated, and jointly modeling them would benefit the performance of both tasks. In this paper, we make a further study of unifying these two tasks for explainable recommendation. Instead of simply correlating these two tasks with shared user and item embeddings, we argue that these two tasks are presented in dual forms. In other words, the input of the primal preference prediction task is exactly the output of the dual review generation task , with and denote the preference value space and review space. Therefore, we could explicitly model the probabilistic correlation between these two dual tasks with . We design a unified dual framework of how to inject the probabilistic duality of the two tasks in the training stage. Furthermore, as the detailed preference and review information are not available for each user-item pair in the test stage, we propose a transfer learning based model for preference prediction and review generation. Finally, extensive experimental results on two real-world datasets clearly show the effectiveness of our proposed model for both user preference prediction and review generation.",Proceedings of The Web Conference 2020,2020,Research
Knowledge-Aware Cross-Semantic Alignment for Domain-Level Zero-Shot Recommendation,No,"['Junji Jiang', 'Hongke Zhao', 'Ming He', 'Likang Wu', 'Kai Zhang', 'Jianping Fan']",https://doi.org/10.1145/3583780.3614945,"Recommendation systems have attracted attention from academia and industry due to their wide range of application scenarios. However, cold start remains a challenging problem limited by sparse user interactions. Some scholars propose to transfer the dense information from the source domain to the target domain through cross-domain recommendation, but most of the work assumes that there is a small amount of historical interaction in the target domain. However, this approach essentially presupposes the existence of at least some historical interaction within the target domain. In this paper, we focus on the domain-level zero-shot recommendation (DZSR) problem. To address the above challenges, we propose a knowledge-aware cross-semantic alignment (K-CSA) framework to learn transferable source domain semantic information. The motivation is to establish stable alignments of interests in different domains through class semantic descriptions (CSDs). Specifically, due to the lack of effective information in the target domain, we learn semantic representations of source and target domain items based on knowledge graphs. Moreover, we conduct multi-view K-means to extract item CSDs from the learned semantic representations. Further, K-CSA learns universal user CSDs through the designed multi-head self-attention. To facilitate the transference of user interest from the source domain to the target domain, we devise a cross-semantic contrastive learning strategy, grounded in the prototype distribution matrix. We conduct extensive experiments on several real-world cross-domain datasets, and the experimental results clearly demonstrate the superiority of our proposed K-CSA compared with other baselines.",Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,2023,Research
A Case Study in Educational Recommenders: Recommending Music Partitures at Tomplay,No,"['Ahmad Ajalloeian', 'Michalis Vlachos', 'Johannes Schneider', 'Alexis Steinmann']",https://doi.org/10.1145/3511808.3557111,"Recommendation technologies have been playing an instrumental role for promoting both physical and digital content across several global platforms (Amazon, Apple, Netflix). Here we provide a study on the benefits of recommendation technologies in an educational platform with a focus on music learning. There are several characteristics present in this educational platform that make this recommendation problem particularly interesting, namely: a) the few but highly repetitive interactions, b) the existence of multiple versions of the same content across many difficulty levels, orchestrations, and musical instruments, and c) the user's expertise in a musical instrument which is essential for making appropriate recommendations. We highlight the unique dataset characteristics and compare them to those of other widely-used recommendation datasets. To alleviate the very high data sparsity due to the multi-instantiation of songs, we use entity resolution principles to embed songs in a new space. Using this lightweight entity resolution step on song data, in combination with neural recommendation architectures, we can double the predictive accuracy compared to techniques based on matrix factorization.",Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,2022,Research
Path-based Deep Network for Candidate Item Matching in Recommenders,No,"['Houyi Li', 'Zhihong Chen', 'Chenliang Li', 'Rong Xiao', 'Hongbo Deng', 'Peng Zhang', 'Yongchao Liu', 'Haihong Tang']",https://doi.org/10.1145/3404835.3462878,"The large-scale recommender system mainly consists of two stages: matching and ranking. The matching stage (also known as the retrieval step) identifies a small fraction of relevant items from billion-scale item corpus in low latency and computational cost. Item-to-item collaborative filtering (item-based CF) and embedding-based retrieval (EBR) have been long used in the industrial matching stage owing to its efficiency. However, item-based CF is hard to meet personalization, while EBR has difficulty in satisfying diversity. In this paper, we propose a novel matching architecture, Path-based Deep Network (named PDN), through incorporating both personalization and diversity to enhance matching performance. Specifically, PDN is comprised of two modules: Trigger Net and Similarity Net. PDN utilizes Trigger Net to capture the user's interest in each of his/her interacted item. Similarity Net is devised to evaluate the similarity between each interacted item and the target item based on these items' profile and CF information. The final relevance between the user and the target item is calculated by explicitly considering user's diverse interests, ie aggregating the relevance weights of the related two-hop paths (one hop of a path corresponds to user-item interaction and the other to item-item relevance). Furthermore, we describe the architecture design of the proposed PDN in a leading real-world E-Commerce service (Mobile Taobao App). Based on offline evaluations and online A/B test, we show that PDN outperforms the existing solutions for the same task. The online results also demonstrate that PDN can retrieve more personalized and more diverse items to significantly improve user engagement. Currently, PDN system has been successfully deployed at Mobile Taobao App and handling major online traffic.",Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval,2021,Research
The Datasets Dilemma: How Much Do We Really Know About Recommendation Datasets?,Yes,"['Jin Chin', 'Yile Chen', 'Gao Cong']",https://doi.org/10.1145/3488560.3498519,"There has been sustained interest from both academia and industry throughout the years due to the importance and practicability of recommendation systems. However, several recent papers have pointed out critical issues with the evaluation process in recommender systems. Likewise, this paper takes an in-depth look at a fundamental but often neglected aspect of the evaluation procedure, i.e. the datasets themselves. To do so, we adopt a systematic and comprehensive approach to understand the datasets used for implicit feedback based top-K recommendation. We start by examining recent papers from top-tier conferences to find out how different datasets have been utilised thus far. Next, we look at the characteristics of these datasets to understand their similarities and differences. Finally, we conduct an empirical study to determine whether the choice of datasets used for evaluation can influence the observations and/or conclusions obtained. Our findings suggest that greater attention needs to be paid to the selection process of datasets used for evaluating recommender systems in order to improve the robustness of the obtained results.",Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining,2022,Research
ELIXIR: Learning from User Feedback on Explanations to&nbsp;Improve&nbsp;Recommender Models,No,"['Azin Ghazimatin', 'Soumajit Pramanik', 'Rishiraj Saha Roy', 'Gerhard Weikum']",https://doi.org/10.1145/3442381.3449848,"System-provided explanations for recommendations are an important component towards transparent and trustworthy AI. In state-of-the-art research, this is a one-way signal, though, to improve user acceptance. In this paper, we turn the role of explanations around and investigate how they can contribute to enhancing the quality of generated recommendations themselves. We devise a human-in-the-loop framework, called Elixir, where user feedback on explanations is leveraged for pairwise learning of user preferences. Elixir leverages feedback on pairs of recommendations and explanations to learn user-specific latent preference vectors, overcoming sparseness by label propagation with item-similarity-based neighborhoods. Our framework is instantiated using generalized graph recommendation via Random Walk with Restart. Insightful experiments with a real user study show significant improvements in movie and book recommendations over item-level feedback.",Proceedings of the Web Conference 2021,2021,Research
CADPP: An Effective Approach to Recommend Attentive and Diverse Long-tail Items,Yes,"['Shuai Tang', 'Xiaofeng Zhang']",https://doi.org/10.1145/3486622.3493961,"As the long-tail items are widely seen in various recommendation related applications, e.g., E-commerce and music recommendation, the long-tail recommendation consequently becomes an important research issue attracting both academic and industrial attentions. Apparently, it is a very challenging practical issue and the corresponding key challenges to address this task is to find the long-tail items which best match users’ preferences but are sufficiently diverse to avoid recommending similar long-tail items. To address this issue, this paper proposes a novel long-tail item recommendation approach which is based on the multi-pointer co-attention mechanism and the determinant point process (abbreviated as CADPP). Specifically, we design the multi-pointer co-attention mechanism for extracting important feature embeddings to capture the common characteristics of multiple items clicked by the users. We also employ the determinant point process (DPP) to allow diverse long-tail items but are relevant to the target items. To evaluate the model performance, extensive experiments have been performed on two real-world datasets. The promising results have demonstrated that the proposed CADPP is superior to both baseline and the state-of-the-art approaches with respect to the widely adopted evaluation metrics.",IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology,2022,Research
Empowering Long-tail Item Recommendation through Cross Decoupling Network (CDN),Yes,"['Yin Zhang', 'Ruoxi Wang', 'Derek Cheng', 'Tiansheng Yao', 'Xinyang Yi', 'Lichan Hong', 'James Caverlee', 'Ed Chi']",https://doi.org/10.1145/3580305.3599814,"Industry recommender systems usually suffer from highly-skewed long-tail item distributions where a small fraction of the items receives most of the user feedback. This skew hurts recommender quality especially for the item slices without much user feedback. While there have been many research advances made in academia, deploying these methods in production is very difficult and very few improvements have been made in industry. One challenge is that these methods often hurt overall performance; additionally, they could be complex and expensive to train and serve.In this work, we aim to improve tail item recommendations while maintaining the overall performance with less training and serving cost. We first find that the predictions of user preferences are biased under long-tail distributions. The bias comes from the differences between training and serving data in two perspectives: 1) the item distributions, and 2) user's preference given an item. Most existing methods mainly attempt to reduce the bias from the item distribution perspective, ignoring the discrepancy from user preference given an item. This leads to a severe forgetting issue and results in sub-optimal performance.To address the problem, we design a novel Cross Decoupling Network (CDN) to reduce the two differences. Specifically, CDN (i) decouples the learning process of memorization and generalization on the item side through a mixture-of-expert architecture; (ii) decouples the user samples from different distributions through a regularized bilateral branch network. Finally, a new adapter is introduced to aggregate the decoupled vectors, and softly shift the training attention to tail items. Extensive experimental results show that CDN significantly outperforms state-of-the-art approaches on popular benchmark datasets. We also demonstrate its effectiveness by a case study of CDN in a large-scale recommendation system at Google.",Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,2023,Research
Tiger: Transferable Interest Graph Embedding for Domain-Level Zero-Shot Recommendation,No,"['Jianhuan Zhuo', 'Jianxun Lian', 'Lanling Xu', 'Ming Gong', 'Linjun Shou', 'Daxin Jiang', 'Xing Xie', 'Yinliang Yue']",https://doi.org/10.1145/3511808.3557472,"Recommender systems play a significant role in online services and have attracted wide attention from both academia and industry. In this paper, we focus on an important, practical, but often overlooked task: domain-level zero-shot recommendation (DZSR). The challenge of DZSR mainly lies in the absence of collaborative behaviors in the target domain, which may be caused by various reasons, such as the domain being newly launched without existing user-item interactions, or users' behaviors being too sensitive to collect for training. To address this challenge, we propose a Transferable Interest Graph Embedding technique for Recommendations (Tiger). The key idea is to connect isolated collaborative filtering datasets with a knowledge graph tailored to recommendations, then propagate collaborative signals from public domains to the zero-shot target domain. The backbone of Tiger is the transferable interest extractor, which is a simple yet effective graph convolutional network (GCN) aggregating multiple hops of neighbors on a shared interest graph. We find that the bottom layers of GCN preserve more domain-specific information while the upper layers represent universal interest better. Thus, in Tiger, we discard the bottom layers of GCN to reconstruct user interest so that collaborative signals can be successfully propagated to other domains, and retain the bottom layers of GCN to include domain-specific information for items. Extensive experiments with four public datasets demonstrate that Tiger can effectively make recommendations for a zero-shot domain and outperform several alternative baselines.",Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,2022,Research
User-Oriented Objective Prioritization for Meta-Featured Multi-Objective Recommender Systems,No,"['Reinaldo Fortes', 'Anisio Lacerda', 'Alan Freitas', 'Carlos Bruckner', 'Dayanne Coelho', 'Marcos Gon\\c{c}alves']",https://doi.org/10.1145/3213586.3225243,"Multi-Objective Recommender Systems (MO-RS) consider several objectives to produce useful recommendations. Besides accuracy, other important quality metrics include novelty and diversity of recommended lists of items. Previous research up to this point focused on naive combinations of objectives. In this paper, we present a new and adaptable strategy for prioritizing objectives focused on users' preferences. Our proposed strategy is based on meta-features, i.e., characteristics of the input data that are influential in the final recommendation. We conducted a series of experiments on three real-world datasets, from which we show that: (i) the use of meta-features leads to the improvement of the Pareto solution set in the search process; (ii) the strategy is effective at making choices according to the specificities of the users' preferences; and (iii) our approach outperforms state-of-the-art methods in MO-RS.","Adjunct Publication of the 26th Conference on User Modeling, Adaptation and Personalization",2018,Research
Counterfactual Data-Augmented Sequential Recommendation,No,"['Zhenlei Wang', 'Jingsen Zhang', 'Hongteng Xu', 'Xu Chen', 'Yongfeng Zhang', 'Wayne Zhao', 'Ji-Rong Wen']",https://doi.org/10.1145/3404835.3462855,"Sequential recommendation aims at predicting users' preferences based on their historical behaviors. However, this recommendation strategy may not perform well in practice due to the sparsity of the real-world data. In this paper, we propose a novel counterfactual data augmentation framework to mitigate the impact of the imperfect training data and empower sequential recommendation models. Our framework is composed of a sampler model and an anchor model. The sampler model aims to generate new user behavior sequences based on the observed ones, while the anchor model is leveraged to provide the final recommendation list, which is trained based on both observed and generated sequences. We design the sampler model to answer the key counterfactual question: ""what would a user like to buy if her previously purchased items had been different?"". Beyond heuristic intervention methods, we leverage two learning-based methods to implement the sampler model, and thus, improve the quality of the generated sequences when training the anchor model. Additionally, we analyze the influence of the generated sequences on the anchor model in theory and achieve a trade-off between the information and the noise introduced by the generated sequences. Experiments on nine real-world datasets demonstrate our framework's effectiveness and generality.",Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval,2021,Research
Knowledge Graph-Based Convolutional Network Coupled With Sentiment Analysis Towards Enhanced Drug Recommendation,No,"['Hajira Saadat', 'Babar Shah', 'Zahid Halim', 'Sajid Anwar']",https://doi.org/10.1109/TCBB.2022.3225234,"Recommending appropriate drugs to patients based on their history and symptoms is a complex real-world problem. Knowing whether a drug is useful without its consumption by a variety of people followed by proper evaluation is a challenge. Modern-day recommender systems can assist in this provided they receive large data to learn. Public reviews on various drugs are available for knowledge sharing. These reviews assist in recommending the best and most appropriate option to the user. The explicit feedback underpins the entire recommender system. This work develops a novel knowledge graph-based convolutional network for recommending drugs. The knowledge graph is coupled with sentiment analysis extracted from the public reviews on drugs to enhance drug recommendations. For each drug that has been used previously, sentiments have been analyzed to determine which one has the most effective reviews. The knowledge graph effectively captures user-item relatedness by mining its associated attributes. Experiments are performed on public benchmarks and a comparison is made with closely related state-of-the-art works. Based on the obtained results, the current work performs better than the past contributions by achieving up to 98.7% Area Under Curve (AUC) score.",missing,2022,Research
Challenging the Myth of Graph Collaborative Filtering: a Reasoned and Reproducibility-driven Analysis,Keep,"['Vito Anelli', 'Daniele Malitesta', 'Claudio Pomo', 'Alejandro Bellogin', 'Eugenio Di Sciascio', 'Tommaso Di Noia']",https://doi.org/10.1145/3604915.3609489,"The success of graph neural network-based models (GNNs) has significantly advanced recommender systems by effectively modeling users and items as a bipartite, undirected graph. However, many original graph-based works often adopt results from baseline papers without verifying their validity for the specific configuration under analysis. Our work addresses this issue by focusing on the replicability of results. We present a code that successfully replicates results from six popular and recent graph recommendation models (NGCF, DGCF, LightGCN, SGL, UltraGCN, and GFCF) on three common benchmark datasets (Gowalla, Yelp 2018, and Amazon Book). Additionally, we compare these graph models with traditional collaborative filtering models that historically performed well in offline evaluations. Furthermore, we extend our study to two new datasets (Allrecipes and BookCrossing) that lack established setups in existing literature. As the performance on these datasets differs from the previous benchmarks, we analyze the impact of specific dataset characteristics on recommendation accuracy. By investigating the information flow from users’ neighborhoods, we aim to identify which models are influenced by intrinsic features in the dataset structure. The code to reproduce our experiments is available at:&nbsp;https://github.com/sisinflab/Graph-RSs-Reproducibility.",Proceedings of the 17th ACM Conference on Recommender Systems,2023,Research
Learning to Embed Categorical Features without Embedding Tables for Recommendation,No,"['Wang-Cheng Kang', 'Derek Cheng', 'Tiansheng Yao', 'Xinyang Yi', 'Ting Chen', 'Lichan Hong', 'Ed Chi']",https://doi.org/10.1145/3447548.3467304,"Embedding learning of categorical features (e.g. user/item IDs) is at the core of various recommendation models. The standard approach creates an embedding table where each row represents a dedicated embedding vector for every unique feature value. However, this method fails to efficiently handle high-cardinality features and unseen feature values (e.g. new video ID) that are prevalent in real-world recommendation systems. In this paper, we propose an alternative embedding framework Deep Hash Embedding (DHE), replacing embedding tables by a deep embedding network to compute embeddings on the fly. DHE first encodes the feature value to a unique identifier vector with multiple hashing functions and transformations, and then applies a DNN to convert the identifier vector to an embedding. The encoding module is deterministic, non-learnable, and free of storage, while the embedding network is updated during the training time to learn embedding generation. Empirical results show that DHE achieves comparable AUC against the standard one-hot full embedding, with smaller model sizes. Our work sheds light on the design of DNN-based alternative embedding schemes for categorical features without using embedding table lookup.",Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining,2021,Research
Exploring author gender in book rating and recommendation,Yes,"['Michael Ekstrand', 'Mucun Tian', 'Mohammed Kazi', 'Hoda Mehrpouyan', 'Daniel Kluver']",https://doi.org/10.1145/3240323.3240373,"Collaborative filtering algorithms find useful patterns in rating and consumption data and exploit these patterns to guide users to good items. Many of the patterns in rating datasets reflect important real-world differences between the various users and items in the data; other patterns may be irrelevant or possibly undesirable for social or ethical reasons, particularly if they reflect undesired discrimination, such as gender or ethnic discrimination in publishing. In this work, we examine the response of collaborative filtering recommender algorithms to the distribution of their input data with respect to a dimension of social concern, namely content creator gender. Using publicly-available book ratings data, we measure the distribution of the genders of the authors of books in user rating profiles and recommendation lists produced from this data. We find that common collaborative filtering algorithms differ in the gender distribution of their recommendation lists, and in the relationship of that output distribution to user profile distribution.",Proceedings of the 12th ACM Conference on Recommender Systems,2018,Research
ColdNAS: Search to Modulate for User Cold-Start Recommendation,No,"['Shiguang Wu', 'Yaqing Wang', 'Qinghe Jing', 'Daxiang Dong', 'Dejing Dou', 'Quanming Yao']",https://doi.org/10.1145/3543507.3583344,"Making personalized recommendation for cold-start users, who only have a few interaction histories, is a challenging problem in recommendation systems. Recent works leverage hypernetworks to directly map user interaction histories to user-specific parameters, which are then used to modulate predictor by feature-wise linear modulation function. These works obtain the state-of-the-art performance. However, the physical meaning of scaling and shifting in recommendation data is unclear. Instead of using a fixed modulation function and deciding modulation position by expertise, we propose a modulation framework called ColdNAS for user cold-start problem, where we look for proper modulation structure, including function and position, via neural architecture search. We design a search space which covers broad models and theoretically prove that this search space can be transformed to a much smaller space, enabling an efficient and robust one-shot search algorithm. Extensive experimental results on benchmark datasets show that ColdNAS consistently performs the best. We observe that different modulation functions lead to the best performance on different datasets, which validates the necessity of designing a searching-based method. Codes are available at https://github.com/LARS-research/ColdNAS.",Proceedings of the ACM Web Conference 2023,2023,Research
Revisiting Neural Retrieval on Accelerators,Keep,"['Jiaqi Zhai', 'Zhaojie Gong', 'Yueming Wang', 'Xiao Sun', 'Zheng Yan', 'Fu Li', 'Xing Liu']",https://doi.org/10.1145/3580305.3599897,"Retrieval finds a small number of relevant candidates from a large corpus for information retrieval and recommendation applications. A key component of retrieval is to model (user, item) similarity, which is commonly represented as the dot product of two learned embeddings. This formulation permits efficient inference, commonly known as Maximum Inner Product Search (MIPS). Despite its popularity, dot products cannot capture complex user-item interactions, which are multifaceted and likely high rank. We hence examine non-dot-product retrieval settings on accelerators, and propose mixture of logits (MoL), which models (user, item) similarity as an adaptive composition of elementary similarity functions. This new formulation is expressive, capable of modeling high rank (user, item) interactions, and further generalizes to the long tail. When combined with a hierarchical retrieval strategy, h-indexer, we are able to scale up MoL to 100M corpus on a single GPU with latency comparable to MIPS baselines. On public datasets, our approach leads to uplifts of up to 77.3% in hit rate (HR). Experiments on a large recommendation surface at Meta showed strong metric gains and reduced popularity bias, validating the proposed approach's performance and improved generalization.",Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,2023,Research
MAMO: Memory-Augmented Meta-Optimization for Cold-start Recommendation,No,"['Manqing Dong', 'Feng Yuan', 'Lina Yao', 'Xiwei Xu', 'Liming Zhu']",https://doi.org/10.1145/3394486.3403113,"A common challenge for most current recommender systems is the cold-start problem. Due to the lack of user-item interactions, the fine-tuned recommender systems are unable to handle situations with new users or new items. Recently, some works introduce the meta-optimization idea into the recommendation scenarios, i.e. predicting the user preference by only a few of past interacted items. The core idea is learning a global sharing initialization parameter for all users and then learning the local parameters for each user separately. However, most meta-learning based recommendation approaches adopt model-agnostic meta-learning for parameter initialization, where the global sharing parameter may lead the model into local optima for some users. In this paper, we design two memory matrices that can store task-specific memories and feature-specific memories. Specifically, the feature-specific memories are used to guide the model with personalized parameter initialization, while the task-specific memories are used to guide the model fast predicting the user preference. And we adopt a meta-optimization approach for optimizing the proposed method. We test the model on two widely used recommendation datasets and consider four cold-start situations. The experimental results show the effectiveness of the proposed methods.",Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,2020,Research
Reconsidering Learning Objectives in Unbiased Recommendation: A Distribution Shift Perspective,Yes,"['Teng Xiao', 'Zhengyu Chen', 'Suhang Wang']",https://doi.org/10.1145/3580305.3599487,"This work studies the problem of learning unbiased algorithms from biased feedback for recommendation. We address this problem from a novel distribution shift perspective. Recent works in unbiased recommendation have advanced the state-of-the-art with various techniques such as re-weighting, multi-task learning, and meta-learning. Despite their empirical successes, most of them lack theoretical guarantees, forming non-negligible gaps between theories and recent algorithms. In this paper, we propose a theoretical understanding of why existing unbiased learning objectives work for unbiased recommendation. We establish a close connection between unbiased recommendation and distribution shift, which shows that existing unbiased learning objectives implicitly align biased training and unbiased test distributions. Built upon this connection, we develop two generalization bounds for existing unbiased learning methods and analyze their learning behavior. Besides, as a result of the distribution shift, we further propose a principled framework, Adversarial Self-Training (AST), for unbiased recommendation. Extensive experiments on real-world and semi-synthetic datasets demonstrate the effectiveness of AST.",Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,2023,Research
Understanding and improving relational matrix factorization in recommender systems,No,"['Li Pu', 'Boi Faltings']",https://doi.org/10.1145/2507157.2507178,"Matrix factorization techniques such as the singular value decomposition (SVD) have had great success in recommender systems. We present a new perspective of SVD for constructing a latent space from the training data, which is justified by the theory of hypergraph model. We show that the vectors representing the items in the latent space can be grouped into (approximately) orthogonal clusters which correspond to the vertex clusters in the co-rating hypergraph, and the lengths of the vectors are indicators of the representativeness of the items. These properties are used for making top-$N$ recommendations in a two-phase algorithm. In this work, we provide a new explanation for the significantly better performance of the asymmetric SVD approaches and a novel algorithm for better diversity in top-N recommendations.",Proceedings of the 7th ACM Conference on Recommender Systems,2013,Research
Multi-Task Feature Learning for Knowledge Graph Enhanced Recommendation,No,"['Hongwei Wang', 'Fuzheng Zhang', 'Miao Zhao', 'Wenjie Li', 'Xing Xie', 'Minyi Guo']",https://doi.org/10.1145/3308558.3313411,"Collaborative filtering often suffers from sparsity and cold start problems in real recommendation scenarios, therefore, researchers and engineers usually use side information to address the issues and improve the performance of recommender systems. In this paper, we consider knowledge graphs as the source of side information. We propose MKR, a Multi-task feature learning approach for Knowledge graph enhanced Recommendation. MKR is a deep end-to-end framework that utilizes knowledge graph embedding task to assist recommendation task. The two tasks are associated by crosscompress units, which automatically share latent features and learn high-order interactions between items in recommender systems and entities in the knowledge graph. We prove that crosscompress units have sufficient capability of polynomial approximation, and show that MKR is a generalized framework over several representative methods of recommender systems and multi-task learning. Through extensive experiments on real-world datasets, we demonstrate that MKR achieves substantial gains in movie, book, music, and news recommendation, over state-of-the-art baselines. MKR is also shown to be able to maintain satisfactory performance even if user-item interactions are sparse.",The World Wide Web Conference,2019,Research
Scalable Hierarchical Recommendations Using Spatial Autocorrelation,No,"['Ayushi Dalmia', 'Joydeep Das', 'Prosenjit Gupta', 'Subhashis Majumder', 'Debarshi Dutta']",https://doi.org/10.1145/2640087.2644165,"Collaborative Filtering (CF) is one of the most successful and widely used approaches behind Recommendation Algorithms. CF algorithms use the known preferences of a group of users to make recommendations or predictions of the unknown preferences for other users. In this paper, we deal with the Scalability issue which is one of the main challenges to the CF algorithms. In Collaborative Filtering, finding similarity amongst N users is an O(N2) process. If N is large then similarity computation becomes very expensive. In this work, we propose a Quadtree based user partitioning technique that partitions the entire users' space into regions based on the location. We develop a Spatially Aware Recommendation Algorithm, where the Recommendation Algorithm is applied separately to each region and therefore allows us to reduce the quadratic complexity associated with the CF process. The proposed work tries to measure the Spatial Autocorrelation indices, such as Geary's index in the regions or cells formed by the Quadtree decomposition. One of the main objectives of our work is to reduce the running time as well as maintain a good quality of recommendation. This approach of recommendation using the decomposition method makes our algorithm feasible to work with large datasets. We have tested our algorithms on the MovieLens and the Book-Crossing datasets.",Proceedings of the 2014 International Conference on Big Data Science and Computing,2014,Research
Power of the Few: Analyzing the Impact of Influential Users in Collaborative Recommender Systems,Yes,"['Farzad Eskandanian', 'Nasim Sonboli', 'Bamshad Mobasher']",https://doi.org/10.1145/3320435.3320464,"Like other social systems, in collaborative filtering a small number of ""influential"" users may have a large impact on the recommendations of other users, thus affecting the overall behavior of the system. Identifying influential users and studying their impact on other users is an important problem because it provides insight into how small groups can inadvertently or intentionally affect the behavior of the system as a whole. Modeling these influences can also shed light on patterns and relationships that would otherwise be difficult to discern, hopefully leading to more transparency in how the system generates personalized content. In this work we first formalize the notion of ""influence"" in collaborative filtering using an Influence Discrimination Model. We then empirically identify and characterize influential users and analyze their impact on the system under different underlying recommendation algorithms and across three different recommendation domains: job, movie and book recommendations. Insights from these experiments can help in designing systems that are not only optimized for accuracy, but are also tuned to mitigate the impact of influential users when it might lead to potential imbalance or unfairness in the system's outcomes.","Proceedings of the 27th ACM Conference on User Modeling, Adaptation and Personalization",2019,Research
Gated Attentive-Autoencoder for Content-Aware Recommendation,No,"['Chen Ma', 'Peng Kang', 'Bin Wu', 'Qinglong Wang', 'Xue Liu']",https://doi.org/10.1145/3289600.3290977,"The rapid growth of Internet services and mobile devices provides an excellent opportunity to satisfy the strong demand for the personalized item or product recommendation. However, with the tremendous increase of users and items, personalized recommender systems still face several challenging problems: (1) the hardness of exploiting sparse implicit feedback; (2) the difficulty of combining heterogeneous data. To cope with these challenges, we propose a gated attentive-autoencoder (GATE) model, which is capable of learning fused hidden representations of items' contents and binary ratings, through a neural gating structure. Based on the fused representations, our model exploits neighboring relations between items to help infer users' preferences. In particular, a word-level and a neighbor-level attention module are integrated with the autoencoder. The word-level attention learns the item hidden representations from items' word sequences, while favoring informative words by assigning larger attention weights. The neighbor-level attention learns the hidden representation of an item's neighborhood by considering its neighbors in a weighted manner. We extensively evaluate our model with several state-of-the-art methods and different validation metrics on four real-world datasets. The experimental results not only demonstrate the effectiveness of our model on top-N recommendation but also provide interpretable results attributed to the attention modules.",Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining,2019,Research
On Unexpectedness in Recommender Systems: Or How to Better Expect the Unexpected,No,"['Panagiotis Adamopoulos', 'Alexander Tuzhilin']",https://doi.org/10.1145/2559952,"Although the broad social and business success of recommender systems has been achieved across several domains, there is still a long way to go in terms of user satisfaction. One of the key dimensions for significant improvement is the concept of unexpectedness. In this article, we propose a method to improve user satisfaction by generating unexpected recommendations based on the utility theory of economics. In particular, we propose a new concept of unexpectedness as recommending to users those items that depart from what they would expect from the system - the consideration set of each user. We define and formalize the concept of unexpectedness and discuss how it differs from the related notions of novelty, serendipity, and diversity. In addition, we suggest several mechanisms for specifying the users’ expectations and propose specific performance metrics to measure the unexpectedness of recommendation lists. We also take into consideration the quality of recommendations using certain utility functions and present an algorithm for providing users with unexpected recommendations of high quality that are hard to discover but fairly match their interests. Finally, we conduct several experiments on “real-world” datasets and compare our recommendation results with other methods. The proposed approach outperforms these baseline methods in terms of unexpectedness and other important metrics, such as coverage, aggregate diversity and dispersion, while avoiding any accuracy loss.",missing,2014,Research
Personalized recommendation algorithm of books based on the diffusion of reader's interest,Keep,['Lei Min'],https://doi.org/10.1145/3573428.3573733,"The ever-growing books help readers acquire knowledge faster than ever before. But the huge scale of these resources also easily makes people fall into the dilemma of ""Information-Explosion"", which prevents the reader from easily locating the books that are really suitable for them. To alleviate this dilemma, we analyzes the principle of the ""Networks-Based-Inference"" algorithm (NBI), which is a classical heuristic algorithm for recommendation. We also proposes an improved algorithm—NBI algorithm using Interest Diffusion (NBI-ID), that derives from this classical algorithm. This improved algorithm inherits the advantages of NBI method in simplicity and effectiveness, and optimizes the allocation of initial information in the process of information diffusion with an interest related indicator. Thus increasing the efficiency of the recommendation results. Experiments on the GoodBooks dataset show that the proposed algorithm improves in accuracy, recall and diversity compared to the classic NBI, CF (Collaborative Filtering) and GRM (Global Ranking Method) algorithms.",Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering,2023,Research
A contextual approach to improve the user's experience in interactive recommendation systems,Keep,"[""N\\'{\\i}collas Silva"", 'Heitor Werneck', 'Thiago Silva', 'Adriano Pereira', 'Leonardo Rocha']",https://doi.org/10.1145/3470482.3479621,"Recommendation Systems have concerned about the online environment of real-world scenarios where the system should continually learn and predict new recommendations. Current works have handled it as a Multi-Armed Bandit (MAB) problem by proposing parametric bandit models based on the main recommendation concepts to handle the exploitation and exploration dilemma. However, recent works identified a new problem about the way these models handle the user cold-start. Due to the lack of information about the user, these models have intrinsically delivered naive non-personalized recommendations in their first recommendations until the system learns more about the user. The first recommendations of these bandit models are equivalent to a random selection around the items (i.e., a pure-exploration approach) or a biased selection by the most popular items in the system (i.e., a pure-exploitation approach). Thus, to mitigate this problem, we propose a new contextual approach to initialize the bandit models. This context is made by the information available about the items: their popularity and entropy. The idea is to address both exploration and exploitation goals since the first recommendations by mixing entropic and popular items. Indeed, this approach maximizes the user's satisfaction in the long-term run. By a strong experimental evaluation, comparing our proposal with seven state-of-the-art methods in three real datasets, we demonstrate this context achieves statistically significant improvements by outperforming all baselines.",Proceedings of the Brazilian Symposium on Multimedia and the Web,2021,Research
Modeling the Assimilation-Contrast Effects in Online Product Rating Systems: Debiasing and Recommendations,Keep,"['Xiaoying Zhang', 'Junzhou Zhao', 'John Lui']",https://doi.org/10.1145/3109859.3109885,"The unbiasedness of online product ratings, an important property to ensure that users' ratings indeed reflect their true evaluations to products, is vital both in shaping consumer purchase decisions and providing reliable recommendations. Recent experimental studies showed that distortions from historical ratings would ruin the unbiasedness of subsequent ratings. How to ""discover"" the distortions from historical ratings in each single rating (or at the micro-level), and perform the ""debiasing operations"" in real rating systems are the main objectives of this work.Using 42 million real customer ratings, we first show that users either ""assimilate"" or ""contrast"" to historical ratings under different scenarios: users conform to historical ratings if historical ratings are not far from the product quality (assimilation), while users deviate from historical ratings if historical ratings are significantly different from the product quality (contrast). This phenomenon can be explained by the well-known psychological argument: the ""Assimilate-Contrast"" theory. However, none of the existing works on modeling historical ratings' influence have taken this into account, and this motivates us to propose the Historical Influence Aware Latent Factor Model (HIALF), the first model for real rating systems to capture and mitigate historical distortions in each single rating. HIALF also allows us to study the influence patterns of historical ratings from a modeling perspective, and it perfectly matches the assimilation and contrast effects we previously observed. Also, HIALF achieves significant improvements in predicting subsequent ratings, and accurately predicts the relationships revealed in previous empirical measurements on real ratings. Finally, we show that HIALF can contribute to better recommendations by decoupling users' real preference from distorted ratings, and reveal the intrinsic product quality for wiser consumer purchase decisions.",Proceedings of the Eleventh ACM Conference on Recommender Systems,2017,Research
Alleviating Cold-Start Problems in Recommendation through Pseudo-Labelling over Knowledge Graph,Yes,"['Riku Togashi', 'Mayu Otani', ""Shin'ichi Satoh""]",https://doi.org/10.1145/3437963.3441773,"Solving cold-start problems is indispensable to provide meaningful recommendation results for new users and items. Under sparsely observed data, unobserved user-item pairs are also a vital source for distilling latent users' information needs. Most present works leverage unobserved samples for extracting negative signals. However, such an optimisation strategy can lead to biased results toward already popular items by frequently handling new items as negative instances. In this study, we tackle the cold-start problems for new users/items by appropriately leveraging unobserved samples. We propose a knowledge graph (KG)-aware recommender based on graph neural networks, which augments labelled samples through pseudo-labelling. Our approach aggressively employs unobserved samples as positive instances and brings new items into the spotlight. To avoid exhaustive label assignments to all possible pairs of users and items, we exploit a KG for selecting probably positive items for each user. We also utilise an improved negative sampling strategy and thereby suppress the exacerbation of popularity biases. Through experiments, we demonstrate that our approach achieves improvements over the state-of-the-art KG-aware recommenders in a variety of scenarios; in particular, our methodology successfully improves recommendation performance for cold-start users/items.",Proceedings of the 14th ACM International Conference on Web Search and Data Mining,2021,Research
Block-Aware Item Similarity Models for Top-N Recommendation,No,"['Yifan Chen', 'Yang Wang', 'Xiang Zhao', 'Jie Zou', 'Maarten Rijke']",https://doi.org/10.1145/3411754,"Top-N recommendations have been studied extensively. Promising results have been achieved by recent item-based collaborative filtering (ICF) methods. The key to ICF lies in the estimation of item similarities. Observing the block-diagonal structure of the item similarities in practice, we propose a block-diagonal regularization (BDR) over item similarities for ICF. The intuitions behind BDR are as follows: (1) with BDR, item clustering is embedded into the learning of ICF methods; (2) BDR induces sparsity of item similarities, which guarantees recommendation efficiency; and (3) BDR captures in-block transitivity to overcome rating sparsity. By regularizing the item similarity matrix of item similarity models with BDR, we obtain a block-aware item similarity model. Our experimental evaluations on a large number of datasets show that the block-diagonal structure is crucial to the performance of top-N recommendation.",missing,2020,Research
A Hybrid Recommendation Method with Multilayer Perception Applied on Real World Data,No,"['Liyang Bi', 'Yongji Wang', 'Dacheng Qu', 'Bei Guan']",https://doi.org/10.1145/3302425.3302470,"Collaborative filtering (CF) is an approach widely used in recommender systems (RS). Traditional CF-based methods simply utilize user-item rating matrix which implies interactions between users and items to make recommendation. However, rating matrix is often very sparse in real world, resulting in these methods a significant degradation in recommendation performance. Therefore, some employ side information of users and items to address the sparse problem. Nevertheless, when it comes to the interactions between user and item latent factors, they still utilize linear inner product. Neural Collaborative Filtering (NeuMF) is an appealing recent method employing Multilayer Perception (MLP) to learn interaction function between user and item latent factors. However, this method does not integrate side information of users and items. To tackle problems above, we generalize effective learning ability of multilayer perception and propose a hybrid recommendation method with multilayer perception which jointly learns deep representations of users and items from side information as well as rating matrix and interaction function between user and item latent factors. We also propose to add a data normalization layer after combining two vectors coming from different magnitudes. Extensive experiments on two real world datasets show that our model outperforms state-of-the-art algorithms.","Proceedings of the 2018 International Conference on Algorithms, Computing and Artificial Intelligence",2018,Research
Personalized privacy-preserving semi-centralized recommendation system in a social network,No,"['Carson Leung', 'Qi Wen']",https://doi.org/10.1145/3625007.3627338,"In the contemporary era of big data, recommendation systems play a crucial role in guiding our daily decision-making amidst an overwhelming array of choices. Personalized recommendations have become increasingly popular by tailoring suggestions to user profiles, preferences, and interests. While many existing systems rely on centralizing data for making recommendations, the revelation of sensitive information poses a significant privacy concern. Studies indicate the potential to de-identify anonymous users, exposing details such as political views or sexual orientations through seemingly innocuous data, like movie ratings. In this paper, we introduce a personalized privacy-preserving semi-centralized recommendation system in a social network known as trust-based social network (TSN) to address these privacy challenges. TSN addresses privacy concerns by semi-centralizing data, treating each node in the network as an independent social entities. Data are distributed to social entities within trusted social networks, and the recommendation service provider only collects obfuscated data from social entities through the adoption of a differential-privacy mechanism. Consequently, data within TSN are either protected within local trusted social networks or obfuscated outside of these networks. The final recommendation is generated by combining local suggestions from the trusted social network with obfuscated global suggestions from the service provider. The emphasis on local suggestions ensures highly personalized recommendations. Evaluation results demonstrate that TSN achieves high accuracy in recommendations while effectively safeguarding user privacy.",Proceedings of the 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,2024,Research
PRINCE: Provider-side Interpretability with Counterfactual Explanations in Recommender Systems,No,"['Azin Ghazimatin', 'Oana Balalau', 'Rishiraj Saha Roy', 'Gerhard Weikum']",https://doi.org/10.1145/3336191.3371824,"Interpretable explanations for recommender systems and other machine learning models are crucial to gain user trust. Prior works that have focused on paths connecting users and items in a heterogeneous network have several limitations, such as discovering relationships rather than true explanations, or disregarding other users' privacy. In this work, we take a fresh perspective, and present PRINCE: a provider-side mechanism to produce tangible explanations for end-users, where an explanation is defined to be a set of minimal actions performed by the user that, if removed, changes the recommendation to a different item. Given a recommendation, PRINCE uses a polynomial-time optimal algorithm for finding this minimal set of a user's actions from an exponential search space, based on random walks over dynamic graphs. Experiments on two real-world datasets show that PRINCE provides more compact explanations than intuitive baselines, and insights from a crowdsourced user-study demonstrate the viability of such action-based explanations. We thus posit that PRINCE produces scrutable, actionable, and concise explanations, owing to its use of counterfactual evidence, a user's own actions, and minimal sets, respectively.",Proceedings of the 13th International Conference on Web Search and Data Mining,2020,Research
Top-N Recommendation for Shared Accounts,No,"['Koen Verstrepen', 'Bart Goethals']",https://doi.org/10.1145/2792838.2800170,"Standard collaborative filtering recommender systems assume that every account in the training data represents a single user. However, multiple users often share a single account. A typical example is a single shopping account for the whole family. Traditional recommender systems fail in this situation. If contextual information is available, context aware recommender systems are the state-of-the-art solution. Yet, often no contextual information is available. Therefore, we introduce the challenge of recommending to shared accounts in the absence of contextual information. We propose a solution to this challenge for all cases in which the reference recommender system is an item-based top-N collaborative filtering recommender system, generating recommendations based on binary, positive-only feedback. We experimentally show the advantages of our proposed solution for tackling the problems that arise from the existence of shared accounts on multiple datasets.",Proceedings of the 9th ACM Conference on Recommender Systems,2015,Research
Toward identification and adoption of best practices in algorithmic recommender systems research,No,"['Joseph Konstan', 'Gediminas Adomavicius']",https://doi.org/10.1145/2532508.2532513,"One of the goals of data-intensive research, in any field of study, is to grow knowledge over time as additional studies contribute to collective knowledge and understanding. Two steps are critical to making such research cumulative -- the individual research results need to be documented thoroughly and conducted on data made available to others (to allow replication and meta-analysis), and the individual research needs to be carried out correctly, following standards and best practices for coding, missing data, algorithm choices, algorithm implementations, metrics, and statistics. This work aims to address a growing concern that the Recommender Systems research community (which is uniquely equipped to address many important challenges in electronic commerce, social networks, social media, and big data settings) is facing a crisis where a significant number of research papers lack the rigor and evaluation to be properly judged and, therefore, have little to contribute to collective knowledge. We advocate that this issue can be addressed through development and dissemination (to authors, reviewers, and editors) of best-practice research methodologies, resulting in specific guidelines and checklists, as well as through tool development to support effective research. We also plan to assess the impact on the field with an eye toward supporting such efforts in other data-intensive specialties.",Proceedings of the International Workshop on Reproducibility and Replication in Recommender Systems Evaluation,2013,Research
Hyperbolic Hypergraphs for Sequential Recommendation,No,"['Yicong Li', 'Hongxu Chen', 'Xiangguo Sun', 'Zhenchao Sun', 'Lin Li', 'Lizhen Cui', 'Philip Yu', 'Guandong Xu']",https://doi.org/10.1145/3459637.3482351,"Hypergraphs have been becoming a popular choice to model complex, non-pairwise, and higher-order interactions for recommender systems. However, compared with traditional graph-based methods, the constructed hypergraphs are usually much sparser, which leads to a dilemma when balancing the benefits of hypergraphs and the modelling difficulty. Moreover, existing sequential hypergraph recommendation overlooks the temporal modelling among user relationships, which neglects rich social signals from the recommendation data. To tackle the above shortcomings of the existing hypergraph-based sequential recommendations, we propose a novel architecture named Hyperbolic Hypergraph representation learning method for Sequential Recommendation (H2SeqRec) with the pre-training phase. Specifically, we design three self-supervised tasks to obtain the pre-training item embeddings to feed or fuse into the following recommendation architecture (with two ways to use the pre-trained embeddings). In the recommendation phase, we learn multi-scale item embeddings via a hierarchical structure to capture multiple time-span information. To alleviate the negative impact of sparse hypergraphs, we utilize a hyperbolic space-based hypergraph convolutional neural network to learn the dynamic item embeddings. Also, we design an item enhancement module to capture dynamic social information at each timestamp to improve effectiveness. Extensive experiments are conducted on two real-world datasets to prove the effectiveness and high performance of the model.",Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,2021,Research
AdaMCL: Adaptive Fusion Multi-View Contrastive Learning for Collaborative Filtering,No,"['Guanghui Zhu', 'Wang Lu', 'Chunfeng Yuan', 'Yihua Huang']",https://doi.org/10.1145/3539618.3591632,"Graph collaborative filtering has achieved great success in capturing users' preferences over items. Despite effectiveness, graph neural network (GNN)-based methods suffer from data sparsity in real scenarios. Recently, contrastive learning (CL) has been used to address the problem of data sparsity. However, most CL-based methods only leverage the original user-item interaction graph to construct the CL task, lacking the explicit exploitation of the higher-order information (i.e., user-user and item-item relationships). Even for the CL-based method that uses the higher-order information, the reception field of the higher-order information is fixed and regardless of the difference between nodes. In this paper, we propose a novel adaptive multi-view fusion contrastive learning framework, named AdaMCL, for graph collaborative filtering. To exploit the higher-order information more accurately, we propose an adaptive fusion strategy to fuse the embeddings learned from the user-item and user-user graphs. Moreover, we propose a multi-view fusion contrastive learning paradigm to construct effective CL tasks. Besides, to alleviate the noisy information caused by aggregating higher-order neighbors, we propose a layer-level CL task. Extensive experimental results reveal that AdaMCL is effective and outperforms existing collaborative filtering models significantly.",Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval,2023,Research
A Novel Evidence-Based Bayesian Similarity Measure for Recommender Systems,No,"['Guibing Guo', 'Jie Zhang', 'Neil Yorke-Smith']",https://doi.org/10.1145/2856037,"User-based collaborative filtering, a widely used nearest neighbour-based recommendation technique, predicts an item’s rating by aggregating its ratings from similar users. User similarity is traditionally calculated by cosine similarity or the Pearson correlation coefficient. However, both of these measures consider only the direction of rating vectors, and suffer from a range of drawbacks. To overcome these issues, we propose a novel Bayesian similarity measure based on the Dirichlet distribution, taking into consideration both the direction and length of rating vectors. We posit that not all the rating pairs should be equally counted in order to accurately model user correlation. Three different evidence factors are designed to compute the weights of rating pairs. Further, our principled method reduces correlation due to chance and potential system bias. Experimental results on six real-world datasets show that our method achieves superior accuracy in comparison with counterparts.",missing,2016,Research
Weighted Random Walk Sampling for Multi-Relational Recommendation,No,"['Fatemeh Vahedian', 'Robin Burke', 'Bamshad Mobasher']",https://doi.org/10.1145/3079628.3079685,"In the information overloaded web, personalized recommender systems are essential tools to help users find most relevant information. The most heavily-used recommendation frameworks assume user interactions that are characterized by a single relation. However, for many tasks, such as recommendation in social networks, user-item interactions must be modeled as a complex network of multiple relations, not only a single relation. Recently research on multi-relational factorization and hybrid recommender models has shown that using extended meta-paths to capture additional information about both users and items in the network can enhance the accuracy of recommendations in such networks. Most of this work is focused on unweighted heterogeneous networks, and to apply these techniques, weighted relations must be simplified into binary ones. However, information associated with weighted edges, such as user ratings, which may be crucial for recommendation, are lost in such binarization. In this paper, we explore a random walk sampling method in which the frequency of edge sampling is a function of edge weight, and apply this generate extended meta-paths in weighted heterogeneous networks. With this sampling technique, we demonstrate improved performance on multiple data sets both in terms of recommendation accuracy and model generation efficiency.","Proceedings of the 25th Conference on User Modeling, Adaptation and Personalization",2017,Research
GSL4Rec: Session-based Recommendations with Collective Graph Structure Learning and Next Interaction Prediction,No,"['Chunyu Wei', 'Bing Bai', 'Kun Bai', 'Fei Wang']",https://doi.org/10.1145/3485447.3512085,"Users’ social connections have recently shown significant benefits to session-based recommendations, and graph neural networks have demonstrated great success in learning the pattern of information flow among users. However, the current paradigm presumes a given social network, which is not necessarily consistent with the fast-evolving shared interests and is expensive to collect. We propose a novel idea to learn the graph structure among users and make recommendations collectively in a coupled framework. This idea raises two challenges, i.e., scalability and effectiveness. We introduce a novel graph-structure learning framework for session-based recommendations&nbsp;(GSL4Rec) for solving both challenges simultaneously. Our framework has a two-stage strategy, i.e., the coarse neighbor screening and the self-adaptive graph structure learning, to enable the exploration of potential links among all users while maintaining a tractable amount of computation for scalability. We also propose a phased heuristic learning strategy to sequentially and synergistically train the graph learning part and recommendation part of GSL4Rec, thus improving the effectiveness by making the model easier to achieve good local optima. Experiments on five public datasets demonstrate that our proposed model significantly outperforms strong baselines, including state-of-the-art social network-based methods.",Proceedings of the ACM Web Conference 2022,2022,Research
Modeling User Preferences in Recommender Systems: A Classification Framework for Explicit and Implicit User Feedback,No,"['Gawesh Jawaheer', 'Peter Weller', 'Patty Kostkova']",https://doi.org/10.1145/2512208,"Recommender systems are firmly established as a standard technology for assisting users with their choices; however, little attention has been paid to the application of the user model in recommender systems, particularly the variability and noise that are an intrinsic part of human behavior and activity. To enable recommender systems to suggest items that are useful to a particular user, it can be essential to understand the user and his or her interactions with the system. These interactions typically manifest themselves as explicit and implicit user feedback that provides the key indicators for modeling users’ preferences for items and essential information for personalizing recommendations. In this article, we propose a classification framework for the use of explicit and implicit user feedback in recommender systems based on a set of distinct properties that include Cognitive Effort, User Model, Scale of Measurement, and Domain Relevance. We develop a set of comparison criteria for explicit and implicit user feedback to emphasize the key properties. Using our framework, we provide a classification of recommender systems that have addressed questions about user feedback, and we review state-of-the-art techniques to improve such user feedback and thereby improve the performance of the recommender system. Finally, we formulate challenges for future research on improvement of user feedback.",missing,2014,Research
Bayesian Additive Matrix Approximation for Social Recommendation,No,"['Huafeng Liu', 'Liping Jing', 'Jingxuan Wen', 'Pengyu Xu', 'Jian Yu', 'Michael Ng']",https://doi.org/10.1145/3451391,"Social relations between users have been proven to be a good type of auxiliary information to improve the recommendation performance. However, it is a challenging issue to sufficiently exploit the social relations and correctly determine the user preference from both social and rating information. In this article, we propose a unified Bayesian Additive Matrix Approximation model (BAMA), which takes advantage of rating preference and social network to provide high-quality recommendation. The basic idea of BAMA is to extract social influence from social networks, integrate them to Bayesian additive co-clustering for effectively determining the user clusters and item clusters, and provide an accurate rating prediction. In addition, an efficient algorithm with collapsed Gibbs Sampling is designed to inference the proposed model. A series of experiments were conducted on six real-world social datasets. The results demonstrate the superiority of the proposed BAMA by comparing with the state-of-the-art methods from three views, all users, cold-start users, and users with few social relations. With the aid of social information, furthermore, BAMA has ability to provide the explainable recommendation.",missing,2021,Research
A Hierarchical Self-Attentive Model for Recommending User-Generated Item Lists,No,"['Yun He', 'Jianling Wang', 'Wei Niu', 'James Caverlee']",https://doi.org/10.1145/3357384.3358030,"User-generated item lists are a popular feature of many different platforms. Examples include lists of books on Goodreads, playlists on Spotify and YouTube, collections of images on Pinterest, and lists of answers on question-answer sites like Zhihu. Recommending item lists is critical for increasing user engagement and connecting users to new items, but many approaches are designed for the item-based recommendation, without careful consideration of the complex relationships between items and lists. Hence, in this paper, we propose a novel user-generated list recommendation model called AttList. Two unique features of AttList are careful modeling of (i) hierarchical user preference, which aggregates items to characterize the list that they belong to, and then aggregates these lists to estimate the user preference, naturally fitting into the hierarchical structure of item lists; and (ii) item and list consistency, through a novel self-attentive aggregation layer designed for capturing the consistency of neighboring items and lists to better model user preference. Through experiments over three real-world datasets reflecting different kinds of user-generated item lists, we find that AttList results in significant improvements in NDCG, Precision@k, and Recall@k versus a suite of state-of-the-art baselines. Furthermore, all code and data are available at https://github.com/heyunh2015/AttList.",Proceedings of the 28th ACM International Conference on Information and Knowledge Management,2019,Research
Personalized Bundle Recommendation in Online Games,No,"['Qilin Deng', 'Kai Wang', 'Minghao Zhao', 'Zhene Zou', 'Runze Wu', 'Jianrong Tao', 'Changjie Fan', 'Liang Chen']",https://doi.org/10.1145/3340531.3412734,"In business domains, bundling is one of the most important marketing strategies to conduct product promotions, which is commonly used in online e-commerce and offline retailers. Existing recommender systems mostly focus on recommending individual items that users may be interested in. In this paper, we target at a practical but less explored recommendation problem named bundle recommendation, which aims to offer a combination of items to users. To tackle this specific recommendation problem in the context of the virtual mall in online games, we formalize it as a link prediction problem on a user-item-bundle tripartite graph constructed from the historical interactions, and solve it with a neural network model that can learn directly on the graph-structure data. Extensive experiments on three public datasets and one industrial game dataset demonstrate the effectiveness of the proposed method. Further, the bundle recommendation model has been deployed in production for more than one year in a popular online game developed by Netease Games, and the launch of the model yields more than 60% improvement on conversion rate of bundles, and a relative improvement of more than 15% on gross merchandise volume (GMV).",Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,2020,Research
Item recommendation on monotonic behavior chains,No,"['Mengting Wan', 'Julian McAuley']",https://doi.org/10.1145/3240323.3240369,"'Explicit' and 'implicit' feedback in recommender systems have been studied for many years, as two relatively isolated areas. However many real-world systems involve a spectrum of both implicit and explicit signals, ranging from clicks and purchases, to ratings and reviews. A natural question is whether implicit signals (which are dense but noisy) might help to predict explicit signals (which are sparse but reliable), or vice versa. Thus in this paper, we propose an item recommendation framework which jointly models this full spectrum of interactions. Our main observation is that in many settings, feedback signals exhibit monotonic dependency structures, i.e., any signal necessarily implies the presence of a weaker (or more implicit) signal (a 'review' action implies a 'purchase' action, which implies a 'click' action, etc.). We refer to these structures as 'monotonic behavior chains,' for which we develop new algorithms that exploit these dependencies. Using several new and existing datasets that exhibit a variety of feedback types, we demonstrate the quantitative performance of our approaches. We also perform qualitative analysis to uncover the relationships between different stages of implicit vs. explicit signals.",Proceedings of the 12th ACM Conference on Recommender Systems,2018,Research
On the robustness and discriminative power of information retrieval metrics for top-N recommendation,No,"['Daniel Valcarce', ""Alejandro Bellog\\'{\\i}n"", 'Javier Parapar', 'Pablo Castells']",https://doi.org/10.1145/3240323.3240347,"The evaluation of Recommender Systems is still an open issue in the field. Despite its limitations, offline evaluation usually constitutes the first step in assessing recommendation methods due to its reduced costs and high reproducibility. Selecting the appropriate metric is a critical and ranking accuracy usually attracts the most attention nowadays. In this paper, we aim to shed light on the advantages of different ranking metrics which were previously used in Information Retrieval and are now used for assessing top-N recommenders. We propose methodologies for comparing the robustness and the discriminative power of different metrics. On the one hand, we study cut-offs and we find that deeper cut-offs offer greater robustness and discriminative power. On the other hand, we find that precision offers high robustness and Normalised Discounted Cumulative Gain provides the best discriminative power.",Proceedings of the 12th ACM Conference on Recommender Systems,2018,Research
Toward Structure Fairness in Dynamic Graph Embedding: A Trend-aware Dual Debiasing Approach,Yes,"['Yicong Li', 'Yu Yang', 'Jiannong Cao', 'Shuaiqi Liu', 'Haoran Tang', 'Guandong Xu']",https://doi.org/10.1145/3637528.3671848,"Recent studies successfully learned static graph embeddings that are structurally fair by preventing the effectiveness disparity of high- and low-degree vertex groups in downstream graph mining tasks. However, achieving structure fairness in dynamic graph embedding remains an open problem. Neglecting degree changes in dynamic graphs will significantly impair embedding effectiveness without notably improving structure fairness. This is because the embedding performance of high-degree and low-to-high-degree vertices will significantly drop close to the generally poorer embedding performance of most slightly changed vertices in the long-tail part of the power-law distribution. We first identify biased structural evolutions in a dynamic graph based on the evolving trend of vertex degree and then propose FairDGE, the first structurally Fair Dynamic Graph Embedding algorithm. FairDGE learns biased structural evolutions by jointly embedding the connection changes among vertices and the long-short-term evolutionary trend of vertex degrees. Furthermore, a novel dual debiasing approach is devised to encode fair embeddings contrastively, customizing debiasing strategies for different biased structural evolutions. This innovative debiasing strategy breaks the effectiveness bottleneck of embeddings without notable fairness loss. Extensive experiments demonstrate that FairDGE achieves simultaneous improvement in the effectiveness and fairness of embeddings.",Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,2024,Research
"Tags, Borders, and Catalogs: Social Re-Working of Genre on LibraryThing",No,"['Maria Antoniak', 'Melanie Walsh', 'David Mimno']",https://doi.org/10.1145/3449103,"Through a computational reading of the online book reviewing community LibraryThing, we examine the dynamics of a collaborative tagging system and learn how its users refine and redefine literary genres. LibraryThing tags are overlapping and multi-dimensional, created in a shared space by thousands of users, including readers, bookstore owners, and librarians. A common understanding of genre is that it relates to the content of books, but this resource allows us to view genre as an intersection of user communities and reader values and interests. We explore different methods of computational genre measurement within the open space of user-created tags. We measure overlap between books, tags, and users, and we also measure the homogeneity of communities associated with genre tags and correlate this homogeneity with reviewing behavior.Finally, by analyzing the text of reviews, we identify the thematic signatures of genres on LibraryThing, revealing similarities and differences between them. These measurements are intended to elucidate the genre conceptions of the users, not, as in prior work, to normalize the tags or enforce a hierarchy. We find that LibraryThing users make sense of genre through a variety of values and expectations, many of which fall outside common definitions and understandings of genre.",missing,2021,Research
SimpleX: A Simple and Strong Baseline for Collaborative Filtering,No,"['Kelong Mao', 'Jieming Zhu', 'Jinpeng Wang', 'Quanyu Dai', 'Zhenhua Dong', 'Xi Xiao', 'Xiuqiang He']",https://doi.org/10.1145/3459637.3482297,"Collaborative filtering (CF) is a widely studied research topic in recommender systems. The learning of a CF model generally depends on three major components, namely interaction encoder, loss function, and negative sampling. While many existing studies focus on the design of more powerful interaction encoders, the impacts of loss functions and negative sampling ratios have not yet been well explored. In this work, we show that the choice of loss function as well as negative sampling ratio is equivalently important. More specifically, we propose the cosine contrastive loss (CCL) and further incorporate it to a simple unified CF model, dubbed SimpleX. Extensive experiments have been conducted on 10 benchmark datasets and compared with 28 existing CF models in total. Surprisingly, the results show that, under our CCL loss and a large negative sampling ratio, SimpleX can surpass most sophisticated state-of-the-art models by a large margin (e.g., max 48.5% improvement in NDCG@20 over LightGCN). We believe that SimpleX could not only serve as a simple strong baseline to foster future research on CF, but also shed light on the potential research direction towards improving loss function and negative sampling.",Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,2021,Research
MCL: Mixed-Centric Loss for Collaborative Filtering,No,"['Zhaolin Gao', 'Zhaoyue Cheng', 'Felipe Perez', 'Jianing Sun', 'Maksims Volkovs']",https://doi.org/10.1145/3485447.3512106,"The majority of recent work in latent Collaborative Filtering (CF) has focused on developing new model architectures to learn accurate user and item representations. Typically, a standard pairwise loss function (BPR, Triplet, etc.) is used in these models, and little exploration is done on how to optimally extract signals from the available preference information. In the implicit setting, negative examples are sampled, and these losses allocate weights that solely depend on the difference in user distance between observed (positive) and negative item pairs. This can ignore valuable global information from other users and items, and lead to sub-optimal results. Motivated by this problem, we propose a novel loss which first leverages mining to select the most informative pairs, followed by a weighing process to allocate more weight to harder examples. Our weighting process consists of four different components, and incorporates distance information from other users, enabling the model to better position the learned representations. We conduct extensive experiments and demonstrate that our loss can be applied to different types of CF models leading to significant gains with each type. In particular, by applying our loss to the graph convolutional architecture, we achieve new state-of-the-art results on four different datasets. Further analysis shows that through our loss the model is able to learn better user-item representation space compared to other losses. Full code for this work is available here:&nbsp;https://github.com/layer6ai-labs/MCL.",Proceedings of the ACM Web Conference 2022,2022,Research
User Recommendation in Content Curation Platforms,No,"['Jianling Wang', 'Ziwei Zhu', 'James Caverlee']",https://doi.org/10.1145/3336191.3371822,"We propose a personalized user recommendation framework for content curation platforms that models preferences for both users and the items they engage with simultaneously. In this way, user preferences for specific item types (e.g., fantasy novels) can be balanced with user specialties (e.g., reviewing novels with strong female protagonists). In particular, the proposed model has three unique characteristics: (i) it simultaneously learns both user-item and user-user preferences through a multi-aspect autoencoder model; (ii) it fuses the latent representations of user preferences on users and items to construct shared factors through an adversarial framework; and (iii) it incorporates an attention layer to produce weighted aggregations of different latent representations, leading to improved personalized recommendation of users and items. Through experiments against state-of-the-art models, we find the proposed framework leads to a 18.43% (Goodreads) and 6.14% (Spotify) improvement in top-k user recommendation.",Proceedings of the 13th International Conference on Web Search and Data Mining,2020,Research
Unifying Explicit and Implicit Feedback for Rating Prediction and Ranking Recommendation Tasks,Keep,"['Amir Jadidinejad', 'Craig Macdonald', 'Iadh Ounis']",https://doi.org/10.1145/3341981.3344225,"The two main tasks addressed by collaborative filtering approaches are rating prediction and ranking. Rating prediction models leverage explicit feedback (e.g. ratings), and aim to estimate the rating a user would assign to an unseen item. In contrast, ranking models leverage implicit feedback (e.g. clicks) in order to provide the user with a personalized ranked list of recommended items. Several previous approaches have been proposed that learn from both explicit and implicit feedback to optimize the task of ranking or rating prediction at the level of recommendation algorithm. Yet we argue that these two tasks are not completely separate, but are part of a unified process: a user first interacts with a set of items and then might decide to provide explicit feedback on a subset of items. We propose to bridge the gap between the tasks of rating prediction and ranking through the use of a novel weak supervision approach that unifies both explicit and implicit feedback datasets. The key aspects of the proposed model is that (1) it is applied at the level of data pre-processing and (2) it increases the representation of less popular items in recommendations while maintaining reasonable recommendation performance. Our experimental results - on six datasets covering different types of heterogeneous user's interactions and using a wide range of evaluation metrics - show that, our proposed approach can effectively combine explicit and implicit feedback and improve the effectiveness of the baseline explicit model on the ranking task by covering a broader range of long-tail items.",Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval,2019,Research
Neural Graph Matching based Collaborative Filtering,No,"['Yixin Su', 'Rui Zhang', 'Sarah M. Erfani', 'Junhao Gan']",https://doi.org/10.1145/3404835.3462833,"User and item attributes are essential side-information; their interactions (i.e., their co-occurrence in the sample data) can significantly enhance prediction accuracy in various recommender systems. We identify two different types of attribute interactions, inner interactions and cross interactions: inner interactions are those between only user attributes or those between only item attributes; cross interactions are those between user attributes and item attributes. Existing models do not distinguish these two types of attribute interactions, which may not be the most effective way to exploit the information carried by the interactions. To address this drawback, we propose a neural Graph Matching based Collaborative Filtering model (GMCF), which effectively captures the two types of attribute interactions through modeling and aggregating attribute interactions in a graph matching structure for recommendation. In our model, the two essential recommendation procedures, characteristic learning and preference matching, are explicitly conducted through graph learning (based on inner interactions) and node matching (based on cross interactions), respectively. Experimental results show that our model outperforms state-of-the-art models. Further studies verify the effectiveness of GMCF in improving the accuracy of recommendation.",Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval,2021,Research
Are we there yet? Estimating Training Time for Recommendation Systems,No,"['Iulia Paun', 'Yashar Moshfeghi', 'Nikos Ntarmos']",https://doi.org/10.1145/3437984.3458832,"Recommendation systems (RS) are a key component of modern commercial platforms, with Collaborative Filtering (CF) based RSs being the centrepiece. Relevant research has long focused on measuring and improving the effectiveness of such CF systems, but alas their efficiency - especially with regards to their time- and resource-consuming training phase - has received little to no attention. This work is a first step in the direction of addressing this gap. To do so, we first perform a methodical study of the computational complexity of the training phase for a number of highly popular CF-based RSs, including approaches based on matrix factorisation, k-nearest neighbours, co-clustering, and slope one schemes. Based on this, we then build a simple yet effective predictor that, given a small sample of a dataset, is able to predict training times over the complete dataset. Our systematic experimental evaluation shows that our approach outperforms state-of-the-art regression schemes by a considerable margin.",Proceedings of the 1st Workshop on Machine Learning and Systems,2021,Research
BookCeption: A Proposed Framework for an Artificially Intelligent Recommendation Platform,No,"['Aniqa Khanom', 'Sheikh Farzana', 'Tahsinur Rahman', 'Iftekharul Mobin']",https://doi.org/10.1145/3316615.3316721,"BookCeption is a web-based book recommendation system that allows readers to browse and buy books across multiple platforms at the most affordable price. It fetches data from E-commerce sites like Barnes and Nobles, Amazon, eBay along with Facebook pages and retail bookstore websites. It is a unique book recommender that uses Machine Learning techniques to recommend books as well as offers from other platforms to the registered users. This paper introduces the architecture of the proposed framework, which integrates the book recommendation system with a platform for buying books. For the book recommender discussed here, four different recommendation techniques were used- SVD, Co-clustering, NMF and Deep Learning to determine the best one for the framework. In terms of computational training time, Co-clustering works best with a time of 5.21 minutes and RMSE value of 0.868. However, on the basis of RMSE value, Deep Learning Embedding Model works best with RMSE value of 0.7599 in 8.06 minutes when the number of epochs and the batch size are 20 and 200 respectively.",Proceedings of the 2019 8th International Conference on Software and Computer Applications,2019,Research
Key Opinion Leaders in Recommendation Systems: Opinion Elicitation and Diffusion,No,"['Jianling Wang', 'Kaize Ding', 'Ziwei Zhu', 'Yin Zhang', 'James Caverlee']",https://doi.org/10.1145/3336191.3371826,"Recommendation systems typically rely on the interactions between a crowd of ordinary users and items, ignoring the fact that many real-world communities are notably influenced by a small group of key opinion leaders, whose feedback on items wields outsize influence. With important positions in the community (e.g. have a large number of followers), their elite opinions are able to diffuse to the community and further impact what items we buy, what media we consume, and how we interact with online platforms. Hence, this paper investigates how to develop a novel recommendation system by explicitly capturing the influence from key opinion leaders to the whole community. Centering around opinion elicitation and diffusion, we propose an end-to-end Graph-based neural model - GoRec. Specifically, to preserve the multi-relations between key opinion leaders and items, GoRec elicits the opinions from key opinion leaders with a translation-based embedding method. Moreover, GoRec adopts the idea of Graph Neural Networks to model the elite opinion diffusion process for improved recommendation. Through experiments on Goodreads and Epinions, the proposed model outperforms state-of-the-art approaches by 10.75% and 9.28% on average in Top-K item recommendation.",Proceedings of the 13th International Conference on Web Search and Data Mining,2020,Research
The Performance Evaluation of Recommendation Algorithm Using Mahout Framework,No,"['ZiDong Yan', 'Qingchun Hu', 'Chengyu Tang', 'Kelang Yang', 'Hongyu Cai']",https://doi.org/10.1145/3403746.3403898,"In order to achieve a better recommendation effect, the optimization and improvement of the recommendation algorithm has been the research hotspot of the recommendation system. Similarity is the core problem of recommendation algorithm, so in this paper, a novel method of calculating similarity in collaborative filtering recommendation was proposed to make the recommendation better. We used the weighted average method to combine various similarity algorithms on the calculation of similarity, so as to improve the accuracy of recommend results and the stability of the algorithm. In order to test the weighted coefficient of similarity and tuning, the experiment is conducted on open source data sets and Mahout framework. Finally, an effective way to improve the collaborative filtering algorithm is presented.",Proceedings of the 3rd International Conference on Computer Science and Software Engineering,2020,Research
Travelers vs. Locals: The Effect of Cluster Analysis in Point-of-Interest Recommendation,No,"['Pablo Sanchez', 'Linus Dietz']",https://doi.org/10.1145/3503252.3531320,"The involvement of geographic information differentiates point-of-interest recommendation from traditional product recommendation. This geographic influence is usually manifested in the effect of users tending toward visiting nearby locations, but further mobility patterns can be used to model different groups of users. In this study, we characterize the check-in behavior of local and traveling users in a global Foursquare check-in data set. Based on the features that capture the mobility and preferences of the users, we obtain representative groups of travelers and locals through an independent cluster analysis. Interestingly, for locals, the mobility features analyzed in this work seem to aggravate the cluster quality, whereas these signals are fundamental in defining the traveler clusters. To measure the effect of such a cluster analysis when categorizing users, we compare the performance of a set of recommendation algorithms, first on all users together, and then on each user group separately in terms of ranking accuracy, novelty, and diversity. Our results on the Foursquare data set of 139,270 users in five cities show that locals, despite being the most numerous groups of users, tend to obtain lower values than the travelers in terms of ranking accuracy while these locals also seem to receive more novel and diverse POI recommendations. For travelers, we observe the advantages of popularity-based recommendation algorithms in terms of ranking accuracy, by recommending venues related to transportation and large commercial establishments. However, there are huge differences in the respective travelers groups, especially between predominantly domestic and international travelers. Due to the large influence of mobility on the recommendations, this article underlines the importance of analyzing user groups differently when making and evaluating personalized point-of-interest recommendations.","Proceedings of the 30th ACM Conference on User Modeling, Adaptation and Personalization",2022,Research
Embedding Knowledge Graphs for Semantics-aware Recommendations based on DBpedia,No,"['Cataldo Musto', 'Pierpaolo Basile', 'Giovanni Semeraro']",https://doi.org/10.1145/3314183.3324976,"In this paper we present a semantics-aware recommendation strategy that uses graph embedding techniques to learn a vector space reresentation of the items to be recommended. Such a representation relies on the tripartite graph which connects users, items and entities gathered from DBpedia, thus it encodes both collaborative and content-based information. These embeddings are then used to feed with positive and negative examples (the items the user liked and those she did not like) a classification model, which is finally exploited to classify new items as interesting or not interesting for the target user. In the experimental evaluation we evaluate the effectiveness of our method on varying of different graph embedding techniques and on several topologies of the graph. Results show that the embeddings learnt by combining collaborative data points with the information gathered from DBpedia led to the best results and also beat several state-of-the-art techniques.","Adjunct Publication of the 27th Conference on User Modeling, Adaptation and Personalization",2019,Research
Preference elicitation as an optimization problem,No,"['Anna Sepliarskaia', 'Julia Kiseleva', 'Filip Radlinski', 'Maarten Rijke']",https://doi.org/10.1145/3240323.3240352,"The new user coldstart problem arises when a recommender system does not yet have any information about a user. A common solution to it is to generate a profile by asking the user to rate a number of items. Which items are selected determines the quality of the recommendations made, and thus has been studied extensively. We propose a new elicitation method to generate a static preference questionnaire (SPQ) that poses relative preference questions to the user. Using a latent factor model, we show that SPQ improves personalized recommendations by choosing a minimal and diverse set of questions. We are the first to rigorously prove which optimization task should be solved to select each question in static questionnaires. Our theoretical results are confirmed by extensive experimentation. We test the performance of SPQ on two real-world datasets, under two experimental conditions: simulated, when users behave according to a latent factor model (LFM), and real, in which only real user judgments are revealed as the system asks questions. We show that SPQ reduces the necessary length of a questionnaire by up to a factor of three compared to state-of-the-art preference elicitation methods. Moreover, solving the right optimization task, SPQ also performs better than baselines with dynamically generated questions.",Proceedings of the 12th ACM Conference on Recommender Systems,2018,Research
Recurrent Recommendation with Local Coherence,No,"['Jianling Wang', 'James Caverlee']",https://doi.org/10.1145/3289600.3291024,"We propose a new time-dependent predictive model of user-item ratings centered around local coherence -- that is, while both users and items are constantly in flux, within a short-term sequence, the neighborhood of a particular user or item is likely to be coherent. Three unique characteristics of the framework are: (i) it incorporates both implicit and explicit feedbacks by extracting the local coherence hidden in the feedback sequences; (ii) it uses parallel recurrent neural networks to capture the evolution of users and items, resulting in a dual factor recommendation model; and (iii) it combines both coherence-enhanced consistent latent factors and dynamic latent factors to balance short-term changes with long-term trends for improved recommendation. Through experiments on Goodreads and Amazon, we find that the proposed model can outperform state-of-the-art models in predicting users' preferences.",Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining,2019,Research
Recommending user generated item lists,No,"['Yidan Liu', 'Min Xie', 'Laks Lakshmanan']",https://doi.org/10.1145/2645710.2645750,"Existing recommender systems mostly focus on recommending individual items which users may be interested in. User-generated item lists on the other hand have become a popular feature in many applications. E.g., Goodreads provides users with an interface for creating and sharing interesting book lists. These user-generated item lists complement the main functionality of the corresponding application, and intuitively become an alternative way for users to browse and discover interesting items to be consumed. Unfortunately, existing recommender systems are not designed for recommending user-generated item lists. In this work, we study properties of these user-generated item lists and propose a Bayesian ranking model, called LIRE for recommending them. The proposed model takes into consideration users' previous interactions with both item lists and with individual items. Furthermore, we propose in LIRE a novel way of weighting items within item lists based on both position of items, and personalized list consumption pattern. Through extensive experiments on a real item list dataset from Goodreads, we demonstrate the effectiveness of our proposed LIRE model.",Proceedings of the 8th ACM Conference on Recommender Systems,2014,Research
"Updatable, Accurate, Diverse, and Scalable Recommendations for Interactive Applications",Keep,"['Bibek Paudel', 'Fabian Christoffel', 'Chris Newell', 'Abraham Bernstein']",https://doi.org/10.1145/2955101,"Recommender systems form the backbone of many interactive systems. They incorporate user feedback to personalize the user experience typically via personalized recommendation lists. As users interact with a system, an increasing amount of data about a user’s preferences becomes available, which can be leveraged for improving the systems’ performance. Incorporating these new data into the underlying recommendation model is, however, not always straightforward. Many models used by recommender systems are computationally expensive and, therefore, have to perform offline computations to compile the recommendation lists. For interactive applications, it is desirable to be able to update the computed values as soon as new user interaction data is available: updating recommendations in interactive time using new feedback data leads to better accuracy and increases the attraction of the system to the users. Additionally, there is a growing consensus that accuracy alone is not enough and user satisfaction is also dependent on diverse recommendations.In this work, we tackle this problem of updating personalized recommendation lists for interactive applications in order to provide both accurate and diverse recommendations. To that end, we explore algorithms that exploit random walks as a sampling technique to obtain diverse recommendations without compromising on efficiency and accuracy. Specifically, we present a novel graph vertex ranking recommendation algorithm called RP3β that reranks items based on three-hop random walk transition probabilities. We show empirically that RP3β provides accurate recommendations with high long-tail item frequency at the top of the recommendation list. We also present approximate versions of RP3β and the two most accurate previously published vertex ranking algorithms based on random walk transition probabilities and show that these approximations converge with an increasing number of samples.To obtain interactively updatable recommendations, we additionally show how our algorithm can be extended for online updates at interactive speeds. The underlying random walk sampling technique makes it possible to perform the updates without having to recompute the values for the entire dataset.In an empirical evaluation with three real-world datasets, we show that RP3β provides highly accurate and diverse recommendations that can easily be updated with newly gathered information at interactive speeds (≪ 100ms).",missing,2016,Research
User-Specific Feature-Based Similarity Models for Top-n Recommendation of New Items,No,"['Asmaa Elbadrawy', 'George Karypis']",https://doi.org/10.1145/2700495,"Recommending new items for suitable users is an important yet challenging problem due to the lack of preference history for the new items. Noncollaborative user modeling techniques that rely on the item features can be used to recommend new items. However, they only use the past preferences of each user to provide recommendations for that user. They do not utilize information from the past preferences of other users, which can potentially be ignoring useful information. More recent factor models transfer knowledge across users using their preference information in order to provide more accurate recommendations. These methods learn a low-rank approximation for the preference matrix, which can lead to loss of information. Moreover, they might not be able to learn useful patterns given very sparse datasets. In this work, we present &lt;scp&gt;UFSM&lt;/scp&gt;, a method for top-&lt;i&gt;n&lt;/i&gt; recommendation of new items given binary user preferences. &lt;scp&gt;UFSM&lt;/scp&gt; learns &lt;b&gt;U&lt;/b&gt;ser-specific &lt;b&gt;F&lt;/b&gt;eature-based item-&lt;b&gt;S&lt;/b&gt;imilarity &lt;b&gt;M&lt;/b&gt;odels, and its strength lies in combining two points: (1)&nbsp;exploiting preference information across all users to learn multiple global item similarity functions and (2)&nbsp;learning user-specific weights that determine the contribution of each global similarity function in generating recommendations for each user. &lt;scp&gt;UFSM&lt;/scp&gt; can be considered as a sparse high-dimensional factor model where the previous preferences of each user are incorporated within his or her latent representation. This way, &lt;scp&gt;UFSM&lt;/scp&gt; combines the merits of item similarity models that capture local relations among items and factor models that learn global preference patterns. A comprehensive set of experiments was conduced to compare &lt;scp&gt;UFSM&lt;/scp&gt; against state-of-the-art collaborative factor models and noncollaborative user modeling techniques. Results show that &lt;scp&gt;UFSM&lt;/scp&gt; outperforms other techniques in terms of recommendation quality. &lt;scp&gt;UFSM&lt;/scp&gt; manages to yield better recommendations even with very sparse datasets. Results also show that &lt;scp&gt;UFSM&lt;/scp&gt; can efficiently handle high-dimensional as well as low-dimensional item feature spaces.",missing,2015,Research
Holistic Transfer to Rank for Top-N Recommendation,No,"['Wanqi Ma', 'Xiaoxiao Liao', 'Wei Dai', 'Weike Pan', 'Zhong Ming']",https://doi.org/10.1145/3434360,"Recommender systems have been a valuable component in various online services such as e-commerce and entertainment. To provide an accurate top-N recommendation list of items for each target user, we have to answer a very basic question of how to model users’ feedback effectively. In this article, we focus on studying users’ explicit feedback, which is usually assumed to contain more preference information than the counterpart, i.e., implicit feedback. In particular, we follow two very recent transfer to rank algorithms by converting the original feedback to three different but related views of examinations, scores, and purchases, and then propose a novel solution called holistic transfer to rank (HoToR), which is able to address the uncertainty challenge and the inconvenience challenge in the existing works. More specifically, we take the rating scores as a weighting strategy to alleviate the uncertainty of the examinations, and we design a holistic one-stage solution to address the inconvenience of the two/three-stage training and prediction procedures in previous works. We then conduct extensive empirical studies in a direct comparison with the two closely related transfer learning algorithms and some very competitive factorization- and neighborhood-based methods on three public datasets and find that our HoToR performs significantly better than the other methods in terms of several ranking-oriented evaluation metrics.",missing,2021,Research
From Variability to Stability: Advancing RecSys Benchmarking Practices,No,"['Valeriy Shevchenko', 'Nikita Belousov', 'Alexey Vasilev', 'Vladimir Zholobov', 'Artyom Sosedka', 'Natalia Semenova', 'Anna Volodkevich', 'Andrey Savchenko', 'Alexey Zaytsev']",https://doi.org/10.1145/3637528.3671655,"In the rapidly evolving domain of Recommender Systems (RecSys), new algorithms frequently claim state-of-the-art performance based on evaluations over a limited set of arbitrarily selected datasets. However, this approach may fail to holistically reflect their effectiveness due to the significant impact of dataset characteristics on algorithm performance. Addressing this deficiency, this paper introduces a novel benchmarking methodology to facilitate a fair and robust comparison of RecSys algorithms, thereby advancing evaluation practices. By utilizing a diverse set of 30 open datasets, including two introduced in this work, and evaluating 11 collaborative filtering algorithms across 9 metrics, we critically examine the influence of dataset characteristics on algorithm performance. We further investigate the feasibility of aggregating outcomes from multiple datasets into a unified ranking. Through rigorous experimental analysis, we validate the reliability of our methodology under the variability of datasets, offering a benchmarking strategy that balances quality and computational demands. This methodology enables a fair yet effective means of evaluating RecSys algorithms, providing valuable guidance for future research endeavors.",Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,2024,Research
Efficient Bayesian Methods for Graph-based Recommendation,No,"['Ramon Lopes', 'Renato Assun\\c{c}\\~{a}o', 'Rodrygo Santos']",https://doi.org/10.1145/2959100.2959132,"Short-length random walks on the bipartite user-item graph have recently been shown to provide accurate and diverse recommendations. Nonetheless, these approaches suffer from severe time and space requirements, which can be alleviated via random walk sampling, at the cost of reduced recommendation quality. In addition, these approaches ignore users' ratings, which further limits their expressiveness. In this paper, we introduce a computationally efficient graph-based approach for collaborative filtering based on short-path enumeration. Moreover, we propose three scoring functions based on the Bayesian paradigm that effectively exploit distributional aspects of the users' ratings. We experiment with seven publicly available datasets against state-of-the-art graph-based and matrix factorization approaches. Our empirical results demonstrate the effectiveness of the proposed approach, with significant improvements in most settings. Furthermore, analytical results demonstrate its efficiency compared to other graph-based approaches.",Proceedings of the 10th ACM Conference on Recommender Systems,2016,Research
Graph-based Recommendation Meets Bayes and Similarity Measures,No,"['Ramon Lopes', 'Renato Assun\\c{c}\\~{a}o', 'Rodrygo Santos']",https://doi.org/10.1145/3356882,"Graph-based approaches provide an effective memory-based alternative to latent factor models for collaborative recommendation. Modern approaches rely on either sampling short walks or enumerating short paths starting from the target user in a user-item bipartite graph. While the effectiveness of random walk sampling heavily depends on the underlying path sampling strategy, path enumeration is sensitive to the strategy adopted for scoring each individual path. In this article, we demonstrate how both strategies can be improved through Bayesian reasoning. In particular, we propose to improve random walk sampling by exploiting distributional aspects of items’ ratings on the sampled paths. Likewise, we extend existing path enumeration approaches to leverage categorical ratings and to scale the score of each path proportionally to the affinity of pairs of users and pairs of items on the path. Experiments on several publicly available datasets demonstrate the effectiveness of our proposed approaches compared to state-of-the-art graph-based recommenders.",missing,2019,Research
Improving Graph Collaborative Filtering with Directional Behavior Enhanced Contrastive Learning,Keep,"['Penghang Yu', 'Bing-Kun Bao', 'Zhiyi Tan', 'Guanming Lu']",https://doi.org/10.1145/3663574,"Graph Collaborative Filtering is a widely adopted approach for recommendation, which captures similar behavior features through Graph Neural Network (GNN). Recently, Contrastive Learning (CL) has been demonstrated as an effective method to enhance the performance of graph collaborative filtering. Typically, CL-based methods first perturb users’ history behavior data (e.g., drop clicked items), then construct a self-discriminating task for behavior representations under different random perturbations. However, for widely existing inactive users, random perturbation makes their sparse behavior information more incomplete, thereby harming the behavior feature extraction. To tackle the above issue, we design a novel directional perturbation-based CL method to improve the graph collaborative filtering performance. The idea is to perturb node representations through directionally enhancing behavior features. To do so, we propose a simple yet effective feedback mechanism, which fuses the representations of nodes based on behavior similarity. Then, to avoid irrelevant behavior preferences introduced by the feedback mechanism, we construct a behavior self-contrast task before and after feedback, to align the node representations between the final output and the first layer of GNN. Different from the widely adopted self-discriminating task, the behavior self-contrast task avoids complex message propagation on different perturbed graphs, which is more efficient than previous methods. Extensive experiments on three public datasets demonstrate that the proposed method has distinct advantages over other CL methods on recommendation accuracy.",missing,2024,Research
Incremental Graph Convolutional Network for Collaborative Filtering,No,"['Jiafeng Xia', 'Dongsheng Li', 'Hansu Gu', 'Tun Lu', 'Peng Zhang', 'Ning Gu']",https://doi.org/10.1145/3459637.3482354,"Graph neural networks (GNN) recently achieved huge success in collaborative filtering (CF) due to the useful graph structure information. However, users will continuously interact with items, which causes the user-item interaction graphs to change over time and well-trained GNN models to be out-of-date soon. Naive solutions such as periodic retraining lose important temporal information and are computationally expensive. Recent works that leverage recurrent neural networks to keep GNN up-to-date may suffer from the ""catastrophic forgetting'' issue, and experience a cold start with new users and items. To this end, we propose the incremental graph convolutional network (IGCN) --- a pure graph convolutional network (GCN) based method to update GNN models when new user-item interactions are available. IGCN consists of two main components: 1) a historical feature generation layer, which generates the initial user/item embedding via model agnostic meta-learning and ensures good initial states and fast model adaptation; 2) a temporal feature learning layer, which first aggregates the features from local neighborhood to update the embedding of each user/item within each subgraph via graph convolutional network and then fuses the user/item embeddings from last subgraph and current subgraph via incremental temporal convolutional network. Experimental studies on real-world datasets show that IGCN can outperform state-of-the-art CF algorithms in sequential recommendation tasks.",Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,2021,Research
"Blockbusters and Wallflowers: Accurate, Diverse, and Scalable Recommendations with Random Walks",,"['Fabian Christoffel', 'Bibek Paudel', 'Chris Newell', 'Abraham Bernstein']",https://doi.org/10.1145/2792838.2800180,"User satisfaction is often dependent on providing accurate and diverse recommendations. In this paper, we explore scalable algorithms that exploit random walks as a sampling technique to obtain diverse recommendations without compromising on accuracy. Specifically, we present a novel graph vertex ranking recommendation algorithm called RP^3_beta that re-ranks items based on 3-hop random walk transition probabilities. We show empirically, that RP^3_beta provides accurate recommendations with high long-tail item frequency at the top of the recommendation list. We also present scalable approximate versions of RP^3_beta and the two most accurate previously published vertex ranking algorithms based on random walk transition probabilities and show that these approximations converge with increasing number of samples.",Proceedings of the 9th ACM Conference on Recommender Systems,2015,Research
Triangle Graph Interest Network for Click-through Rate Prediction,,"['Wensen Jiang', 'Yizhu Jiao', 'Qingqin Wang', 'Chuanming Liang', 'Lijie Guo', 'Yao Zhang', 'Zhijun Sun', 'Yun Xiong', 'Yangyong Zhu']",https://doi.org/10.1145/3488560.3498458,"Click-through rate prediction is a critical task in online advertising. Currently, many existing methods attempt to extract user potential interests from historical click behavior sequences. However, it is difficult to handle sparse user behaviors or broaden interest exploration. Recently, some researchers incorporate the item-item co-occurrence graph as an auxiliary. Due to the elusiveness of user interests, those works still fail to determine the real motivation of user click behaviors. Besides, those works are more biased towards popular or similar commodities. They lack an effective mechanism to break the diversity restrictions. In this paper, we point out two special properties of triangles in the item-item graphs for recommendation systems: Intra-triangle homophily and Inter-triangle heterophiy. Based on this, we propose a novel and effective framework named Triangle Graph Interest Network (TGIN). For each clicked item in user behavior sequences, we introduce the triangles in its neighborhood of the item-item graphs as a supplement. TGIN regards these triangles as the basic units of user interests, which provide the clues to capture the real motivation for a user clicking an item. We characterize every click behavior by aggregating the information of several interest units to alleviate the elusive motivation problem. The attention mechanism determines users' preference for different interest units. By selecting diverse and relative triangles, short brings in novel and serendipitous items to expand exploration opportunities of user interests. Then, we aggregate the multi-level interests of historical behavior sequences to improve CTR prediction. Extensive experiments on both of public and industrial datasets clearly verify the effectiveness of our framework.",Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining,2022,Research
"Diversity, Serendipity, Novelty, and Coverage: A Survey and Empirical Analysis of Beyond-Accuracy Objectives in Recommender Systems",,"['Marius Kaminskas', 'Derek Bridge']",https://doi.org/10.1145/2926720,"What makes a good recommendation or good list of recommendations?Research into recommender systems has traditionally focused on accuracy, in particular how closely the recommender’s predicted ratings are to the users’ true ratings. However, it has been recognized that other recommendation qualities—such as whether the list of recommendations is diverse and whether it contains novel items—may have a significant impact on the overall quality of a recommender system. Consequently, in recent years, the focus of recommender systems research has shifted to include a wider range of “beyond accuracy” objectives.In this article, we present a survey of the most discussed beyond-accuracy objectives in recommender systems research: diversity, serendipity, novelty, and coverage. We review the definitions of these objectives and corresponding metrics found in the literature. We also review works that propose optimization strategies for these beyond-accuracy objectives. Since the majority of works focus on one specific objective, we find that it is not clear how the different objectives relate to each other.Hence, we conduct a set of offline experiments aimed at comparing the performance of different optimization approaches with a view to seeing how they affect objectives other than the ones they are optimizing. We use a set of state-of-the-art recommendation algorithms optimized for recall along with a number of reranking strategies for optimizing the diversity, novelty, and serendipity of the generated recommendations. For each reranking strategy, we measure the effects on the other beyond-accuracy objectives and demonstrate important insights into the correlations between the discussed objectives. For instance, we find that rating-based diversity is positively correlated with novelty, and we demonstrate the positive influence of novelty on recommendation coverage.",missing,2016,Research
MeLU: Meta-Learned User Preference Estimator for Cold-Start Recommendation,,"['Hoyeop Lee', 'Jinbae Im', 'Seongwon Jang', 'Hyunsouk Cho', 'Sehee Chung']",https://doi.org/10.1145/3292500.3330859,"This paper proposes a recommender system to alleviate the cold-start problem that can estimate user preferences based on only a small number of items. To identify a user's preference in the cold state, existing recommender systems, such as Netflix, initially provide items to a user; we call those items evidence candidates. Recommendations are then made based on the items selected by the user. Previous recommendation studies have two limitations: (1) the users who consumed a few items have poor recommendations and (2) inadequate evidence candidates are used to identify user preferences. We propose a meta-learning-based recommender system called MeLU to overcome these two limitations. From meta-learning, which can rapidly adopt new task with a few examples, MeLU can estimate new user's preferences with a few consumed items. In addition, we provide an evidence candidate selection strategy that determines distinguishing items for customized preference estimation. We validate MeLU with two benchmark datasets, and the proposed model reduces at least 5.92% mean absolute error than two comparative models on the datasets. We also conduct a user study experiment to verify the evidence selection strategy.",Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining,2019,Research
A Model of Two Tales: Dual Transfer Learning Framework for Improved Long-tail Item Recommendation,,"['Yin Zhang', 'Derek Cheng', 'Tiansheng Yao', 'Xinyang Yi', 'Lichan Hong', 'Ed Chi']",https://doi.org/10.1145/3442381.3450086,"Highly skewed long-tail item distribution is very common in recommendation systems. It significantly hurts model performance on tail items. To improve tail-item recommendation, we conduct research to transfer knowledge from head items to tail items, leveraging the rich user feedback in head items and the semantic connections between head and tail items. Specifically, we propose a novel dual transfer learning framework that jointly learns the knowledge transfer from both model-level and item-level: 1. The model-level knowledge transfer builds a generic meta-mapping of model parameters from few-shot to many-shot model. It captures the implicit data augmentation on the model-level to improve the representation learning of tail items. 2. The item-level transfer connects head and tail items through item-level features, to ensure a smooth transfer of meta-mapping from head items to tail items. The two types of transfers are incorporated to ensure the learned knowledge from head items can be well applied for tail item representation learning in the long-tail distribution settings. Through extensive experiments on two benchmark datasets, results show that our proposed dual transfer learning framework significantly outperforms other state-of-the-art methods for tail item recommendation in hit ratio and NDCG. It is also very encouraging that our framework further improves head items and overall performance on top of the gains on tail items.",Proceedings of the Web Conference 2021,2021,Research
A Novel Classification Framework for Evaluating Individual and Aggregate Diversity in Top-N Recommendations,,"['Jennifer Moody', 'David Glass']",https://doi.org/10.1145/2700491,"The primary goal of a recommender system is to generate high quality user-centred recommendations. However, the traditional evaluation methods and metrics were developed before researchers understood all the factors that increase user satisfaction. This study is an introduction to a novel user and item classification framework. It is proposed that this framework should be used during user-centred evaluation of recommender systems and the need for this framework is justified through experiments. User profiles are constructed and matched against other users’ profiles to formulate neighbourhoods and generate top-N recommendations. The recommendations are evaluated to measure the success of the process. In conjunction with the framework, a new diversity metric is presented and explained. The accuracy, coverage, and diversity of top-N recommendations is illustrated and discussed for groups of users. It is found that in contradiction to common assumptions, not all users suffer as expected from the data sparsity problem. In fact, the group of users that receive the most accurate recommendations do not belong to the least sparse area of the dataset.",missing,2016,Research
"Complexities associated with user-generated book reviews in digital libraries: temporal, cultural, and political case studies",,"['Yuerong Hu', 'Zoe LeBlanc', 'Jana Diesner', 'Ted Underwood', 'Glen Layne-Worthey', 'J. Downie']",https://doi.org/10.1145/3529372.3530930,"While digital libraries (DL) have made large-scale collections of digitized books increasingly available to researchers [31, 67], there remains a dearth of similar data provisions or infrastructure for computational studies of the consumption and reception of books. In the last two decades, user-generated book reviews on social media have opened up unprecedented research possibilities for humanities and social sciences (HSS) scholars who are interested in book reception. However, limitations and gaps have emerged from existing DH research which utilize social media data for answering HSS questions. To shed light on the under-investigated features of user-generated book reviews and the challenges they might pose to scholarly research, we conducted three exemplar cases studies: (1) a longitudinal analysis for profiling the temporal changes of ratings and popularity of 552 books across ten years; (2) a cross-cultural comparison of book ratings of the same 538 books across two platforms; and, (3) a classification experiment on 20,000 sponsored and non-sponsored books reviews. Correspondingly, our research reveals the real-world complexities and under-investigated features of user-generated book reviews in three dimensions: the transience of book ratings and popularity (temporal dimension), the cross-cultural differences in reading interests and book reception (cultural dimension), and the user power dynamics behind the publicly accessible reviews (""political"" dimension). Our case studies also demonstrate the challenges posed by user-generated book reviews' real-world complexities to their scholarly usage and propose solutions to these challenges. We conclude that DL stakeholders and scholars working with user-generated book reviews should look into these under-investigated features and real-world challenges to evaluate and improve the scholarly usability and interpretability of their data.",Proceedings of the 22nd ACM/IEEE Joint Conference on Digital Libraries,2022,Research
Matrix Factorization for Collaborative Filtering Is Just Solving an Adjoint Latent Dirichlet Allocation Model After All,,['Florian Wilhelm'],https://doi.org/10.1145/3460231.3474266,"Matrix factorization-based methods are among the most popular methods for collaborative filtering tasks with implicit feedback. The most effective of these methods do not apply sign constraints, such as non-negativity, to their factors. Despite their simplicity, the latent factors for users and items lack interpretability, which is becoming an increasingly important requirement. In this work, we provide a theoretical link between unconstrained and the interpretable non-negative matrix factorization in terms of the personalized ranking induced by these methods. We also introduce a novel, latent Dirichlet allocation-inspired model for recommenders and extend our theoretical link to also allow the interpretation of an unconstrained matrix factorization as an adjoint formulation of our new model. Our experiments indicate that this novel approach represents the unknown processes of implicit user-item interactions in the real world much better than unconstrained matrix factorization while being interpretable.",Proceedings of the 15th ACM Conference on Recommender Systems,2021,Research
Mining recommendations from the web,,"['Guy Shani', 'Max Chickering', 'Christopher Meek']",https://doi.org/10.1145/1454008.1454015,"In this paper we study the challenges and evaluate the effectiveness of data collected from the web for recommendations. We provide experimental results, including a user study, showing that our methods produce good recommendations in realistic applications. We propose a new evaluation metric, that takes into account the difficulty of prediction. We show that the new metric aligns well with the results from a user study.",Proceedings of the 2008 ACM Conference on Recommender Systems,2008,Research
Group Recommendations by Learning Rating Behavior,,['Dimitris Sacharidis'],https://doi.org/10.1145/3079628.3079691,"In many domains, it is often required to provide recommendations for groups, instead of individual users. Existing approaches try to compensate for the lack of group profiles, by either merging individual profiles, or treating users separately and then fusing the recommendations. Both paradigms thus fail to account for the different roles and behaviors people assume when making group decisions. In this work, we propose two novel group recommendation models that explicitly try to model the behavior of group members and distinguish it from that when they act alone. A detailed evaluation has shown that our models consistently provide significantly better recommendations. In addition, useful conclusions are drawn regarding the favorable settings of existing techniques.","Proceedings of the 25th Conference on User Modeling, Adaptation and Personalization",2017,Research
HybridSVD: when collaborative information is not enough,,"['Evgeny Frolov', 'Ivan Oseledets']",https://doi.org/10.1145/3298689.3347055,"We propose a new hybrid algorithm that allows incorporating both user and item side information within the standard collaborative filtering technique. One of its key features is that it naturally extends a simple PureSVD approach and inherits its unique advantages, such as highly efficient Lanczos-based optimization procedure, simplified hyper-parameter tuning and a quick folding-in computation for generating recommendations instantly even in highly dynamic online environments. The algorithm utilizes a generalized formulation of the singular value decomposition, which adds flexibility to the solution and allows imposing the desired structure on its latent space. Conveniently, the resulting model also admits an efficient and straightforward solution for the cold start scenario. We evaluate our approach on a diverse set of datasets and show its superiority over similar classes of hybrid models.",Proceedings of the 13th ACM Conference on Recommender Systems,2019,Research
CoNet: Collaborative Cross Networks for Cross-Domain Recommendation,,"['Guangneng Hu', 'Yu Zhang', 'Qiang Yang']",https://doi.org/10.1145/3269206.3271684,"The cross-domain recommendation technique is an effective way of alleviating the data sparse issue in recommender systems by leveraging the knowledge from relevant domains. Transfer learning is a class of algorithms underlying these techniques. In this paper, we propose a novel transfer learning approach for cross-domain recommendation by using neural networks as the base model. In contrast to the matrix factorization based cross-domain techniques, our method is deep transfer learning, which can learn complex user-item interaction relationships. We assume that hidden layers in two base networks are connected by cross mappings, leading to the collaborative cross networks (CoNet). CoNet enables dual knowledge transfer across domains by introducing cross connections from one base network to another and vice versa. CoNet is achieved in multi-layer feedforward networks by adding dual connections and joint loss functions, which can be trained efficiently by back-propagation. The proposed model is thoroughly evaluated on two large real-world datasets. It outperforms baselines by relative improvements of 7.84% in NDCG. We demonstrate the necessity of adaptively selecting representations to transfer. Our model can reduce tens of thousands training examples comparing with non-transfer methods and still has the competitive performance with them.",Proceedings of the 27th ACM International Conference on Information and Knowledge Management,2018,Research
Image-Based Recommendations on Styles and Substitutes,,"['Julian McAuley', 'Christopher Targett', 'Qinfeng Shi', 'Anton Hengel']",https://doi.org/10.1145/2766462.2767755,"Humans inevitably develop a sense of the relationships between objects, some of which are based on their appearance. Some pairs of objects might be seen as being alternatives to each other (such as two pairs of jeans), while others may be seen as being complementary (such as a pair of jeans and a matching shirt). This information guides many of the choices that people make, from buying clothes to their interactions with each other. We seek here to model this human sense of the relationships between objects based on their appearance. Our approach is not based on fine-grained modeling of user annotations but rather on capturing the largest dataset possible and developing a scalable method for uncovering human notions of the visual relationships within. We cast this as a network inference problem defined on graphs of related images, and provide a large-scale dataset for the training and evaluation of the same. The system we develop is capable of recommending which clothes and accessories will go well together (and which will not), amongst a host of other applications.",Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval,2015,Research
"Understanding Assimilation-contrast Effects in Online Rating Systems: Modelling, Debiasing, and Applications",,"['Xiaoying Zhang', 'Hong Xie', 'Junzhou Zhao', 'John Lui']",https://doi.org/10.1145/3362651,"“Unbiasedness,” which is an important property to ensure that users’ ratings indeed reflect their true evaluations of products, is vital both in shaping consumer purchase decisions and providing reliable recommendations in online rating systems. Recent experimental studies showed that distortions from historical ratings would ruin the unbiasedness of subsequent ratings. How to “discover” historical distortions in each single rating (or at the micro-level), and perform the “debiasing operations” are our main objective. Using 42M real customer ratings, we first show that users either “assimilate” or “contrast” to historical ratings under different scenarios, which can be further explained by a well-known psychological argument: the “Assimilate-Contrast” theory. This motivates us to propose the Historical Influence Aware Latent Factor Model (HIALF), the “first” model for real rating systems to capture and mitigate historical distortions in each single rating. HIALF allows us to study the influence patterns of historical ratings from a modelling perspective, which perfectly matches the assimilation and contrast effects observed in experiments. Moreover, HIALF achieves significant improvements in predicting subsequent ratings and characterizing relationships in ratings. It also contributes to better recommendations, wiser consumer purchase decisions, and deeper understanding of historical distortions in both honest rating and misbehaving rating settings.",missing,2019,Research
Hidden factors and hidden topics: understanding rating dimensions with review text,,"['Julian McAuley', 'Jure Leskovec']",https://doi.org/10.1145/2507157.2507163,"In order to recommend products to users we must ultimately predict how a user will respond to a new product. To do so we must uncover the implicit tastes of each user as well as the properties of each product. For example, in order to predict whether a user will enjoy Harry Potter, it helps to identify that the book is about wizards, as well as the user's level of interest in wizardry. User feedback is required to discover these latent product and user dimensions. Such feedback often comes in the form of a numeric rating accompanied by review text. However, traditional methods often discard review text, which makes user and product latent dimensions difficult to interpret, since they ignore the very text that justifies a user's rating. In this paper, we aim to combine latent rating dimensions (such as those of latent-factor recommender systems) with latent review topics (such as those learned by topic models like LDA). Our approach has several advantages. Firstly, we obtain highly interpretable textual labels for latent rating dimensions, which helps us to `justify' ratings with text. Secondly, our approach more accurately predicts product ratings by harnessing the information present in review text; this is especially true for new products and users, who may have too few ratings to model their latent factors, yet may still provide substantial information from the text of even a single review. Thirdly, our discovered topics can be used to facilitate other tasks such as automated genre discovery, and to identify useful and representative reviews.",Proceedings of the 7th ACM Conference on Recommender Systems,2013,Research
Towards Robust Neural Graph Collaborative Filtering via Structure Denoising and Embedding Perturbation,,"['Haibo Ye', 'Xinjie Li', 'Yuan Yao', 'Hanghang Tong']",https://doi.org/10.1145/3568396,"Neural graph collaborative filtering has received great recent attention due to its power of encoding the high-order neighborhood via the backbone graph neural networks. However, their robustness against noisy user-item interactions remains largely unexplored. Existing work on robust collaborative filtering mainly improves the robustness by denoising the graph structure, while recent progress in other fields has shown that directly adding adversarial perturbations in the embedding space can significantly improve the model robustness. In this work, we propose to improve the robustness of neural graph collaborative filtering via both denoising in the structure space and perturbing in the embedding space. Specifically, in the structure space, we measure the reliability of interactions and further use it to affect the message propagation process of the backbone graph neural networks; in the embedding space, we add in-distribution perturbations by mimicking the behavior of adversarial attacks and further combine it with contrastive learning to improve the performance. Extensive experiments have been conducted on four benchmark datasets to evaluate the effectiveness and efficiency of the proposed approach. The results demonstrate that the proposed approach outperforms the recent neural graph collaborative filtering methods especially when there are injected noisy interactions in the training data.",missing,2023,Research
Fast Variational AutoEncoder with Inverted Multi-Index for Collaborative Filtering,,"['Jin Chen', 'Defu Lian', 'Binbin Jin', 'Xu Huang', 'Kai Zheng', 'Enhong Chen']",https://doi.org/10.1145/3485447.3512068,"Variational AutoEncoder (VAE) has been extended as a representative nonlinear method for collaborative filtering. However, the bottleneck of VAE lies in the softmax computation over all items, such that it takes linear costs in the number of items to compute the loss and gradient for optimization. This hinders the practical use due to millions of items in real-world scenarios. Importance sampling is an effective approximation method, based on which the sampled softmax has been derived. However, existing methods usually exploit the uniform or popularity sampler as proposal distributions, leading to a large bias of gradient estimation. To this end, we propose to decompose the inner-product-based softmax probability based on the inverted multi-index, leading to sublinear-time and highly accurate sampling. Based on the proposed proposals, we develop a fast Variational AutoEncoder (FastVAE) for collaborative filtering. FastVAE can outperform the state-of-the-art baselines in terms of both sampling quality and efficiency according to the experiments on three real-world datasets.",Proceedings of the ACM Web Conference 2022,2022,Research
Recurrent Meta-Learning against Generalized Cold-start Problem in CTR Prediction,,"['Junyu Chen', 'Qianqian Xu', 'Zhiyong Yang', 'Ke Ma', 'Xiaochun Cao', 'Qingming Huang']",https://doi.org/10.1145/3503161.3548118,"During the last decades, great success has been witnessed along the course of accurate Click-Through-Rate (CTR) prediction models for online advertising. However, the cold-start problem, which refers to the issue that the standard models can hardly draw accurate inferences for unseen users/ads, is still yet to be fully understood. Most recently, some related studies have been proposed to tackle this problem with only the new users/ads being considered. We argue that such new users/ads are not the only sources for cold-start. From another perspective, since users might shift their interests over time, one's recent behaviors might vary greatly from the records long ago. In this sense, we believe that the cold-start problem should also exist along the temporal dimension. Motivated by this, a generalized definition of the cold-start problem is provided where both new users/ads and recent behavioral data from known users are considered. To attack this problem, we propose a recursive meta-learning model with the user's behavior sequence prediction as a separate training task. Specifically, a time-series CTR model with the MAML (Model-Agnostic Meta-Learning)-like meta-learning method is proposed to make our model adapt to new tasks rapidly. Besides, we propose a parallel structure for extracting the feature interactions to efficiently fuse attention mechanisms and the RNN layer. Finally, experiments on three public datasets demonstrate the effectiveness of the proposed approaches.",Proceedings of the 30th ACM International Conference on Multimedia,2022,Research
What to read next? making personalized book recommendations for K-12 users,,"['Maria Pera', 'Yiu-Kai Ng']",https://doi.org/10.1145/2507157.2507181,"Finding books that children/teenagers are interested in these days is a non-trivial task due to the diversity of topics covered in huge volumes of books with varied readability levels. Even though K-12 readers can turn to book recommenders to look for books, the recommended books may not satisfy their personal needs, since they could be beyond/below their readability levels or fail to match their topics of interest. To address these problems, we introduce BReK12, a book recommender that makes personalized suggestions tailored to each K-12 user U based on books available on a social book-marking site that (i) are similar in content to the ones that are known to be of interest to U, (ii) have been bookmarked by users with reading patterns similar to U's, and (iii) can be comprehended by U. BReK12 is an asset to its users, since it suggests books that are appealing to its users and at grade levels that they can cope with, which can increase their reading selection choices and motivate them to read. We have also developed ReLAT, the readability analysis tool employed by BReK12 to determine the grade level of books. ReLAT is novel, compared with existing readability formulas, since it can predict the grade level of a book even if an excerpt of the book is not available. We have conducted empirical studies which have verified the accuracy of ReLAT in predicting the grade level of a book and the effectiveness of BReK12 over existing baseline recommendation systems.",Proceedings of the 7th ACM Conference on Recommender Systems,2013,Research
"Fewer Flops at the Top: Accuracy, Diversity, and Regularization in Two-Class Collaborative Filtering",,"['Bibek Paudel', 'Thilo Haas', 'Abraham Bernstein']",https://doi.org/10.1145/3109859.3109916,"In most existing recommender systems, implicit or explicit interactions are treated as positive links and all unknown interactions are treated as negative links. The goal is to suggest new links that will be perceived as positive by users. However, as signed social networks and newer content services become common, it is important to distinguish between positive and negative preferences. Even in existing applications, the cost of a negative recommendation could be high when people are looking for new jobs, friends, or places to live.In this work, we develop novel probabilistic latent factor models to recommend positive links and compare them with existing methods on five different openly available datasets. Our models are able to produce better ranking lists and are effective in the task of ranking positive links at the top, with fewer negative links (flops). Moreover, we find that modeling signed social networks and user preferences this way has the advantage of increasing the diversity of recommendations. We also investigate the effect of regularization on the quality of recommendations, a matter that has not received enough attention in the literature. We find that regularization parameter heavily affects the quality of recommendations in terms of both accuracy and diversity.",Proceedings of the Eleventh ACM Conference on Recommender Systems,2017,Research
VizRec: Recommending Personalized Visualizations,,"['Belgin Mutlu', 'Eduardo Veas', 'Christoph Trattner']",https://doi.org/10.1145/2983923,"Visualizations have a distinctive advantage when dealing with the information overload problem: Because they are grounded in basic visual cognition, many people understand them. However, creating proper visualizations requires specific expertise of the domain and underlying data. Our quest in this article is to study methods to suggest appropriate visualizations autonomously. To be appropriate, a visualization has to follow known guidelines to find and distinguish patterns visually and encode data therein. A visualization tells a story of the underlying data; yet, to be appropriate, it has to clearly represent those aspects of the data the viewer is interested in. Which aspects of a visualization are important to the viewer? Can we capture and use those aspects to recommend visualizations? This article investigates strategies to recommend visualizations considering different aspects of user preferences. A multi-dimensional scale is used to estimate aspects of quality for visualizations for collaborative filtering. Alternatively, tag vectors describing visualizations are used to recommend potentially interesting visualizations based on content. Finally, a hybrid approach combines information on what a visualization is about (tags) and how good it is (ratings). We present the design principles behind VizRec, our visual recommender. We describe its architecture, the data acquisition approach with a crowd sourced study, and the analysis of strategies for visualization recommendation.",missing,2016,Research
Improving Latent Factor Models via Personalized Feature Projection for One Class Recommendation,,"['Tong Zhao', 'Julian McAuley', 'Irwin King']",https://doi.org/10.1145/2806416.2806511,"Latent Factor models, which transform both users and items into the same latent feature space, are one of the most successful and ubiquitous models in recommender systems. Most existing models in this paradigm define both users' and items' latent factors to be of the same size and use an inner product to represent a user's ""compatibility"" with an item. Intuitively, users' factors encode ""preferences"" while item factors encode ""properties"", so that the inner product encodes how well an item matches a user's preferences. However, a user's opinion of an item may be more complex, for example each dimension of each user's opinion may depend on a combination of multiple item factors simultaneously. Thus it may be better to view each dimension of a user's preference as a personalized projection of an item's properties so that the preference model can capture complex relationships between items' properties and users' preferences.Therefore, in this paper we propose a novel personalized feature projection method to model users' preferences over items. Specifically, for each user, we define a personalized projection matrix, which takes the place of user-specific factors from existing models. This matrix describes a mapping between items' factors and users' preferences in order to build personalized preference models for each user and item. The proposed personalized feature projection method is quite general and existing latent factor models, for example, can be cast as a special case. We present three objective functions to optimize predictions in the form of ranked lists of users' preferences over items, and demonstrate how each can be used to improve one-class recommendation performance. Experiments are conducted on four real-world datasets and our results show that our personalized feature projection method outperforms several state-of-the-art methods on various evaluation metrics.",Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,2015,Research
Personalized recommendations on books for K-12 readers,,"['Maria Pera', 'Yiu-Kai Ng']",https://doi.org/10.1145/2390116.2390124,"Learning to read efficiently and effectively is emphasized at the elementary and high school levels. Finding books that children/youth are interested in reading, however, is a non-trivial task due to the diversity of topics and different readability levels covered in the huge volume of books available these days. Ideally, K-12 students can turn to book recommenders which suggest books that match their interests. However, since the preferences and reading levels of these students vary from one grade to another, books suggested by existing recommenders, which ignore the literacy skills and the personal interests of their users, may be unsuitable for the targeted audience. In this paper, we present additional design issues that should be applied in developing a book recommender based on BReK12, our previously-proposed book recommender for K-12 users, to further enhance the quality of its recommendations. BReK12, which performs content and readability analysis to identify books potentially appealing to its users, is extended to incorporate (i) a multi-criteria analysis that studies its users' complex and diverse interests and (ii) an enhanced readability-detection tool that determines precisely the readability levels of books which match the literary skills of its users.",Proceedings of the Fifth ACM Workshop on Research Advances in Large Digital Book Repositories and Complementary Media,2012,Research
SPrank: Semantic Path-Based Ranking for Top-N Recommendations Using Linked Open Data,,"['Tommaso Noia', 'Vito Ostuni', 'Paolo Tomeo', 'Eugenio Sciascio']",https://doi.org/10.1145/2899005,"In most real-world scenarios, the ultimate goal of recommender system applications is to suggest a short ranked list of items, namely top-N recommendations, that will appeal to the end user. Often, the problem of computing top-N recommendations is mainly tackled with a two-step approach. The system focuses first on predicting the unknown ratings, which are eventually used to generate a ranked recommendation list. Actually, the top-N recommendation task can be directly seen as a ranking problem where the main goal is not to accurately predict ratings but to directly find the best-ranked list of items to recommend. In this article we present SPrank, a novel hybrid recommendation algorithm able to compute top-N recommendations exploiting freely available knowledge in the Web of Data. In particular, we employ DBpedia, a well-known encyclopedic knowledge base in the Linked Open Data cloud, to extract semantic path-based features and to eventually compute top-N recommendations in a learning-to-rank fashion. Experiments with three datasets related to different domains (books, music, and movies) prove the effectiveness of our approach compared to state-of-the-art recommendation algorithms.",missing,2016,Research
Social relations versus near neighbours: reliable recommenders in limited information social network collaborative filtering for online advertising,,"['Dionisis Margaris', 'Dimitris Spiliotopoulos', 'Costas Vassilakis']",https://doi.org/10.1145/3341161.3345620,"Online advertising benefits by recommender systems since the latter analyse reviews and rating of products, providing useful insight of the buyer perception of products and services. When traditional recommender system information is enriched with social network information, more successful recommendations are produced, since more users' aspects are taken into consideration. However, social network information may be unavailable since some users may not have social network accounts or may not consent to their use for recommendations, while rating data may be unavailable due to the cold start phenomenon. In this paper, we propose an algorithm that combines limited collaborative filtering information, comprised only of users' ratings on items, with limited social network information, comprised only of users' social relations, in order to improve (1) prediction accuracy and (2) prediction coverage in collaborative filtering recommender systems, at the same time. The proposed algorithm considerably improves rating prediction accuracy and coverage, while it can be easily integrated in recommender systems.",Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,2020,Research
Unsupervised Identification of Abnormal Nodes and Edges in Graphs,,"['Asara Senaratne', 'Peter Christen', 'Graham Williams', 'Pouya Omran']",https://doi.org/10.1145/3546912,"Much of today’s data are represented as graphs, ranging from social networks to bibliographic citations. Nodes in such graphs correspond to records that generally represent entities, while edges represent relationships between these entities. Both nodes and edges in a graph can have attributes that characterize the entities and their relationships. Relationships are either explicitly known (like friends in a social network), or they are inferred using link prediction (such as two babies are siblings because they have the same mother). Any graph representing real-world data likely contains nodes and edges that are abnormal, and identifying these can be important for outlier detection in applications ranging from crime and fraud detection to viral marketing. We propose a novel approach to the unsupervised detection of abnormal nodes and edges in graphs. We first characterize nodes and edges using a set of features, and then employ a one-class classifier to identify abnormal nodes and edges. We extract patterns of features from these abnormal nodes and edges, and apply clustering to identify groups of patterns with similar characteristics. We finally visualize these abnormal patterns to show co-occurrences of features and relationships between those features that mostly influence the abnormality of nodes and edges. We evaluate our approach on datasets from diverse domains, including historical birth certificates, COVID patient records, e-mails, books, and movies. This evaluation demonstrates that our approach is well suited to identify both abnormal nodes and edges in graphs in an unsupervised way, and it can outperform several baseline anomaly detection techniques.",missing,2022,Research
Exploring Missing Interactions: A Convolutional Generative Adversarial Network for Collaborative Filtering,,"['Feng Yuan', 'Lina Yao', 'Boualem Benatallah']",https://doi.org/10.1145/3340531.3411917,"Adversarial examples can be detrimental to a recommender,leading to a surging enthusiasm for applying adversarial learning to improve recommendation performance, e.g. raising model robustness, alleviating data sparsity, generating initial profiles for cold-start users or items, etc. Most existing adversarial example generation methods fall within three categories: attacking the user-item interactions or auxiliary contents, adding perturbations in latent space, sampling the latent space according to certain distribution. In this work, we focus on the semantic-rich user-item interactions in a recommender system and propose a novel generative adversarial network (GAN) named Convolutional Generative Collaborative Filtering (Conv-GCF). We develop an effective perturbation mechanism (adversarial noise layer) for convolutional neural networks (CNN), based on which we design a generator with residual blocks to synthesize user-item interactions. We empirically demonstrate that on Conv-GCF, the adversarial noise layer is superior to the conventional noise-adding approach. Moreover, we propose two types of discriminators: one using Bayes Personalized Ranking (BPR) and the other with binary classification. On four public datasets, we show that our approach achieves the state-of-the-art top-n recommendation performance among competitive baselines.",Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,2020,Research
NeuSE: A Neural Snapshot Ensemble Method for Collaborative Filtering,,"['Dongsheng Li', 'Haodong Liu', 'Chao Chen', 'Yingying Zhao', 'Stephen Chu', 'Bo Yang']",https://doi.org/10.1145/3450526,"In collaborative filtering (CF) algorithms, the optimal models are usually learned by globally minimizing the empirical risks averaged over all the observed data. However, the global models are often obtained via a performance tradeoff among users/items, i.e., not all users/items are perfectly fitted by the global models due to the hard non-convex optimization problems in CF algorithms. Ensemble learning can address this issue by learning multiple diverse models but usually suffer from efficiency issue on large datasets or complex algorithms. In this article, we keep the intermediate models obtained during global model learning as the snapshot models, and then adaptively combine the snapshot models for individual user-item pairs using a memory network-based method. Empirical studies on three real-world datasets show that the proposed method can extensively and significantly improve the accuracy (up to 15.9% relatively) when applied to a variety of existing collaborative filtering methods.",missing,2021,Research
Collaborative Preference Embedding against Sparse Labels,,"['Shilong Bao', 'Qianqian Xu', 'Ke Ma', 'Zhiyong Yang', 'Xiaochun Cao', 'Qingming Huang']",https://doi.org/10.1145/3343031.3350915,"Living in the era of the internet, we are now facing with a big bang of online information. As a consequence, we often find ourselves troubling with hundreds and thousands of options before making a decision. As a way to improve the quality of users' online experience, Recommendation System aims to facilitate personalized online decision making processes via predicting users' responses toward different options. However, the vast majority of the literature in the field merely focus on datasets with sufficient amount of samples. Different from the traditional methods, we propose a novel method named as Collaborative Preference Embedding (CPE) which directly deals with sparse and insufficient user preference information. Specifically, we represent the intrinsic pattern of users/items with a high dimensional embedding space. On top of this embedding space, we design two schemes specifically against the limited generalization ability in terms of sparse labels. On one hand, we construct a margin function which could indicate the consistency between the embedding space and the true user preference. From the margin theory point-of-view, we then propose a generalization enhancement scheme for sparse and insufficient labels via optimizing the margin distribution. On the other hand, regarding the embedding as a code for a user/item, we then improve the generalization ability from the coding point-of-view. Specifically, we leverage a compact embedding space by reducing the dependency across different dimensions of a code (embedding). Finally, extensive experiments on a number of real-world datasets demonstrate the superior generalization performance of the proposed algorithm.",Proceedings of the 27th ACM International Conference on Multimedia,2019,Research
On Sampling Collaborative Filtering Datasets,,"['Noveen Sachdeva', 'Carole-Jean Wu', 'Julian McAuley']",https://doi.org/10.1145/3488560.3498439,"We study the practical consequences of dataset sampling strategies on the ranking performance of recommendation algorithms. Recommender systems are generally trained and evaluated on samples of larger datasets. Samples are often taken in a naive or ad-hoc fashion: e.g. by sampling a dataset randomly or by selecting users or items with many interactions. As we demonstrate, commonly-used data sampling schemes can have significant consequences on algorithm performance. Following this observation, this paper makes three main contributions: (1) characterizing the effect of sampling on algorithm performance, in terms of algorithm and dataset characteristics (e.g. sparsity characteristics, sequential dynamics, etc.); (2) designing SVP-CF, which is a data-specific sampling strategy, that aims to preserve the relative performance of models after sampling, and is especially suited to long-tailed interaction data; and (3) developing an oracle, DATA-GENIE, which can suggest the sampling scheme that is most likely to preserve model performance for a given dataset. The main benefit of DATA-GENIE is that it will allow recommender system practitioners to quickly prototype and compare various approaches, while remaining confident that algorithm performance will be preserved, once the algorithm is retrained and deployed on the complete data. Detailed experiments show that using DATA-GENIE, we can discard upto 5x more data than any sampling strategy with the same level of performance.",Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining,2022,Research
The MovieLens Datasets: History and Context,,"['F. Harper', 'Joseph Konstan']",https://doi.org/10.1145/2827872,"The MovieLens datasets are widely used in education, research, and industry. They are downloaded hundreds of thousands of times each year, reflecting their use in popular press programming books, traditional and online courses, and software. These datasets are a product of member activity in the MovieLens movie recommendation system, an active research platform that has hosted many experiments since its launch in 1997. This article documents the history of MovieLens and the MovieLens datasets. We include a discussion of lessons learned from running a long-standing, live research platform from the perspective of a research organization. We document best practices and limitations of using the MovieLens datasets in new research.",missing,2015,Research
The task-dependent effect of tags and ratings on social media access,,"['Maarten Clements', 'Arjen De Vries', 'Marcel Reinders']",https://doi.org/10.1145/1852102.1852107,"Recently, online social networks have emerged that allow people to share their multimedia files, retrieve interesting content, and discover like-minded people. These systems often provide the possibility to annotate the content with tags and ratings.Using a random walk through the social annotation graph, we have combined these annotations into a retrieval model that effectively balances the personal preferences and opinions of like-minded users into a single relevance ranking for either content, tags, or people. We use this model to identify the influence of different annotation methods and system design aspects on common ranking tasks in social content systems.Our results show that a combination of rating and tagging information can improve tasks like search and recommendation. The optimal influence of both sources on the ranking is highly dependent on the retrieval task and system design. Results on content search and tag suggestion indicate that the profile created by a user's annotations can be used effectively to adapt the ranking to personal preferences. The random walk reduces sparsity problems by smoothly integrating indirectly related concepts in the relevance ranking, which is especially valuable for cold-start users or individual tagging systems like YouTube and Flickr.",missing,2010,Research
Exploring social influence via posterior effect of word-of-mouth recommendations,,"['Junming Huang', 'Xue-Qi Cheng', 'Hua-Wei Shen', 'Tao Zhou', 'Xiaolong Jin']",https://doi.org/10.1145/2124295.2124365,"Word-of-mouth has proven an effective strategy for promoting products through social relations. Particularly, existing studies have convincingly demonstrated that word-of-mouth recommendations can boost users' prior expectation and hence encourage them to adopt a certain innovation, such as buying a book or watching a movie. However, less attention has been paid to studying the posterior effect of word-of-mouth recommendations, i.e., whether or not word-of-mouth recommendations can influence users' posterior evaluation on the products or services recommended to them, the answer to which is critical to estimating user satisfaction when proposing a word-of-mouth marketing strategy. In order to fill this gap, in this paper we empirically study the above issue and verify that word-of-mouth recommendations are strongly associated with users' posterior evaluation. Through elaborately designed statistical hypothesis tests we prove the causality that word-of-mouth recommendations directly prompt the posterior evaluation of receivers. Finally, we propose a method for investigating users' social influence, namely, their ability to affect followers' posterior evaluation via word-of-mouth recommendations, by examining the number of their followers and their sensitivity of discovering good items. The experimental results on real datasets show that our method can successfully identify 78% influential friends with strong social influence.",Proceedings of the Fifth ACM International Conference on Web Search and Data Mining,2012,Research
A Word is Worth a Thousand Ratings: Augmenting Ratings using Reviews for Collaborative Filtering,,"['Oren Sar Shalom', 'Guy Uziel', 'Alexandros Karatzoglou', 'Amir Kantor']",https://doi.org/10.1145/3234944.3234953,"In order to provide personalized recommendations, collaborative filtering algorithms take into account several kinds of feedback from the user. A common kind of feedback, which was largely neglected by the Academic community until recently, is textual reviews that are written by the users. Reviews may reveal a great deal about both the users and the items, and indeed in recent years, several algorithms that make use of textual reviews were proposed. However, it is not entirely clear how this signal should be combined with traditional methods that address other kinds of feedback (such as an explicit numeric rating). In this paper, we introduce a novel algorithm, named Collaborative Filtering using Compatibility Vectors (CFCV), which builds upon recent advances in natural language understanding, and uses a neural network in order to provide a meaningful representation of the reviews. This allows to enhance collaborative filtering (particularly, factor methods ) with this new kind of information, in a way that is both natural and effective. We validate our algorithm by conducting experiments on several benchmark datasets, showing that it outperforms the existing methods. Moreover, underlying our solution there is a general architecture that may be further explored.",Proceedings of the 2018 ACM SIGIR International Conference on Theory of Information Retrieval,2018,Research
A Monte Carlo algorithm for cold start recommendation,,"['Yu Rong', 'Xiao Wen', 'Hong Cheng']",https://doi.org/10.1145/2566486.2567978,"Recommendation systems have been widely used in E-commerce sites, social networks, etc. One of the core tasks in recommendation systems is to predict the users' ratings on items. Although many models and algorithms have been proposed, how to make accurate prediction for new users with extremely few rating records still remains a big challenge, which is called the cold start problem. Many existing methods utilize additional information, such as social graphs, to cope with the cold start problem. However, the side information may not always be available. In contrast to such methods, we propose a more general solution to address the cold start problem based on the observed user rating records only. Specifically we define a random walk on a bipartite graph of users and items to simulate the preference propagation among users, in order to alleviate the data sparsity problem for cold start users. Then we propose a Monte Carlo algorithm to estimate the similarity between different users. This algorithm takes a precomputation approach, and thus can efficiently compute the user similarity given any new user for rating prediction. In addition, our algorithm can easily handle dynamic updates and can be parallelized naturally, which are crucial for large recommendation systems. Theoretical analysis is presented to demonstrate the efficiency and effectiveness of our algorithm, and extensive experiments also confirm our theoretical findings.",Proceedings of the 23rd International Conference on World Wide Web,2014,Research
Offline Retrieval Evaluation Without Evaluation Metrics,,"['Fernando Diaz', 'Andres Ferraro']",https://doi.org/10.1145/3477495.3532033,"Offline evaluation of information retrieval and recommendation has traditionally focused on distilling the quality of a ranking into a scalar metric such as average precision or normalized discounted cumulative gain. We can use this metric to compare the performance of multiple systems for the same request. Although evaluation metrics provide a convenient summary of system performance, they also collapse subtle differences across users into a single number and can carry assumptions about user behavior and utility not supported across retrieval scenarios. We propose recall-paired preference (RPP), a metric-free evaluation method based on directly computing a preference between ranked lists. RPP simulates multiple user subpopulations per query and compares systems across these pseudo-populations. Our results across multiple search and recommendation tasks demonstrate that RPP substantially improves discriminative power while correlating well with existing metrics and being equally robust to incomplete data.",Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval,2022,Research
Minimally-Supervised Structure-Rich Text Categorization via Learning on Text-Rich Networks,,"['Xinyang Zhang', 'Chenwei Zhang', 'Xin Dong', 'Jingbo Shang', 'Jiawei Han']",https://doi.org/10.1145/3442381.3450114,"Text categorization is an essential task in Web content analysis. Considering the ever-evolving Web data and new emerging categories, instead of the laborious supervised setting, in this paper, we focus on the minimally-supervised setting that aims to categorize documents effectively, with a couple of seed documents annotated per category. We recognize that texts collected from the Web are often structure-rich, i.e., accompanied by various metadata. One can easily organize the corpus into a text-rich network, joining raw text documents with document attributes, high-quality phrases, label surface names as nodes, and their associations as edges. Such a network provides a holistic view of the corpus’ heterogeneous data sources and enables a joint optimization for network-based analysis and deep textual model training. We therefore propose a novel framework for minimally supervised categorization by learning from the text-rich network. Specifically, we jointly train two modules with different inductive biases – a text analysis module for text understanding and a network learning module for class-discriminative, scalable network learning. Each module generates pseudo training labels from the unlabeled document set, and both modules mutually enhance each other by co-training using pooled pseudo labels. We test our model on two real-world datasets. On the challenging e-commerce product categorization dataset with 683 categories, our experiments show that given only three seed documents per category, our framework can achieve an accuracy of about 92%, significantly outperforming all compared methods; our accuracy is only less than 2% away from the supervised BERT model trained on about 50K labeled documents.",Proceedings of the Web Conference 2021,2021,Research
Something Just Like This: A Secret History of the Role of Analogues in Information Seeking,,"['Huiwen Zhang', 'Dana Mckay', 'Michael Twidale', 'George Buchanan']",https://doi.org/10.1145/3627508.3638317,"Information seekers often want 'something just like this', an information object (song, book, movie) like one they already know about. This approach is the premise of many modern recommender systems, which ask information seekers for examples of things they like in order to return similar things. This type of information seeking, though, is not particularly well supported by search engines, partly because the ways in which objects can be alike are multifaceted and difficult to articulate, partly because the analogue might emerge in the process of information seeking. This approach to information seeking has been touched on repeatedly in information science literature but not examined in detail. In this paper, we present a pair of studies that explore both how people seek information using analogues online and the ways in which information objects might be alike. Our results offer a novel understanding of a previously underexplored but common behaviour, addressing how analogues are identified, how they are used in information seeking, and the ways in which objects can be analogous from an information seeker's perspective. Our work can support the development of recommender systems, conversational search approaches, and digital interfaces that support this common but little-examined type of information seeking.",Proceedings of the 2024 Conference on Human Information Interaction and Retrieval,2024,Research
Spectral Relaxations and Fair Densest Subgraphs,,"['Aris Anagnostopoulos', 'Luca Becchetti', 'Adriano Fazzone', 'Cristina Menghini', 'Chris Schwiegelshohn']",https://doi.org/10.1145/3340531.3412036,"Reducing hidden bias in the data and ensuring fairness in algorithmic data analysis has recently received significant attention. In this paper, we address the problem of identifying a densest subgraph, while ensuring that none of one binary protected attribute is disparately impacted.Unfortunately, the underlying algorithmic problem is NP-hard, even in its approximation version: approximating the densest fair subgraph with a polynomial-time algorithm is at least as hard as the densest subgraph problem of at most k vertices, for which no constant approximation algorithms are known.Despite such negative premises, we are able to provide approximation results in two important cases. In particular, we are able to prove that a suitable spectral embedding allows recovery of an almost optimal, fair, dense subgraph hidden in the input data, whenever one is present, a result that is further supported by experimental evidence. We also show a polynomial-time, $2$-approximation algorithm, whenever the underlying graph is itself fair. We finally prove that, under the small set expansion hypothesis, this result is tight for fair graphs.The above theoretical findings drive the design of heuristics, which we experimentally evaluate on a scenario based on real data, in which our aim is to strike a good balance between diversity and highly correlated items from Amazon co-purchasing graphs.",Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,2020,Research
Deep Collaborative Filtering via Marginalized Denoising Auto-encoder,,"['Sheng Li', 'Jaya Kawale', 'Yun Fu']",https://doi.org/10.1145/2806416.2806527,"Collaborative filtering (CF) has been widely employed within recommender systems to solve many real-world problems. Learning effective latent factors plays the most important role in collaborative filtering. Traditional CF methods based upon matrix factorization techniques learn the latent factors from the user-item ratings and suffer from the cold start problem as well as the sparsity problem. Some improved CF methods enrich the priors on the latent factors by incorporating side information as regularization. However, the learned latent factors may not be very effective due to the sparse nature of the ratings and the side information. To tackle this problem, we learn effective latent representations via deep learning. Deep learning models have emerged as very appealing in learning effective representations in many applications. In particular, we propose a general deep architecture for CF by integrating matrix factorization with deep feature learning. We provide a natural instantiations of our architecture by combining probabilistic matrix factorization with marginalized denoising stacked auto-encoders. The combined framework leads to a parsimonious fit over the latent features as indicated by its improved performance in comparison to prior state-of-art models over four large datasets for the tasks of movie/book recommendation and response prediction.",Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,2015,Research
Closed-Loop Opinion Formation,,"['Larissa Spinelli', 'Mark Crovella']",https://doi.org/10.1145/3091478.3091483,"When information sources are moderated by recommender systems, so-called ""filter bubbles"" may restrict the diversity of content made available to users, potentially affecting their opinions. User opinions may in turn affect the output of recommender systems. In this work we ask how the dynamical system defined by user and recommender systems behaves, as each element evolves in time. In particular, we look at whether the use of recommender system can affect user experience and user opinions in a systematic way. We define and analyze three metrics to understand those effects - intensity, simplification, and divergence - and we explore both link-based and ratings-based recommender systems. Our results suggest that previous studies of this problem have been too simplistic, and that user opinions can evolve in complex ways under the influence of personalized information sources.",Proceedings of the 2017 ACM on Web Science Conference,2017,Research
The QWERTY Effect on the Web: How Typing Shapes the Meaning of Words in Online Human-Computer Interaction,,"['David Garcia', 'Markus Strohmaier']",https://doi.org/10.1145/2872427.2883019,"The QWERTY effect postulates that the keyboard layout influences word meanings by linking positivity to the use of the right hand and negativity to the use of the left hand. For example, previous research has established that words with more right hand letters are rated more positively than words with more left hand letters by human subjects in small scale experiments. In this paper, we perform large scale investigations of the QWERTY effect on the web. Using data from eleven web platforms related to products, movies, books, and videos, we conduct observational tests whether a hand-meaning relationship can be found in text interpretations by web users. Furthermore, we investigate whether writing text on the web exhibits the QWERTY effect as well, by analyzing the relationship between the text of online reviews and their star ratings in four additional datasets. Overall, we find robust evidence for the QWERTY effect both at the point of text interpretation (decoding) and at the point of text creation (encoding). We also find under which conditions the effect might not hold. Our findings have implications for any algorithmic method aiming to evaluate the meaning of words on the web, including for example semantic or sentiment analysis, and show the existence of ""dactilar onomatopoeias"" that shape the dynamics of word-meaning associations. To the best of our knowledge, this is the first work to reveal the extent to which the QWERTY effect exists in large scale human-computer interaction on the web.",Proceedings of the 25th International Conference on World Wide Web,2016,Research
On social networks and collaborative recommendation,,"['Ioannis Konstas', 'Vassilios Stathopoulos', 'Joemon Jose']",https://doi.org/10.1145/1571941.1571977,"Social network systems, like last.fm, play a significant role in Web 2.0, containing large amounts of multimedia-enriched data that are enhanced both by explicit user-provided annotations and implicit aggregated feedback describing the personal preferences of each user. It is also a common tendency for these systems to encourage the creation of virtual networks among their users by allowing them to establish bonds of friendship and thus provide a novel and direct medium for the exchange of data.We investigate the role of these additional relationships in developing a track recommendation system. Taking into account both the social annotation and friendships inherent in the social graph established among users, items and tags, we created a collaborative recommendation system that effectively adapts to the personal information needs of each user. We adopt the generic framework of Random Walk with Restarts in order to provide with a more natural and efficient way to represent social networks.In this work we collected a representative enough portion of the music social network last.fm, capturing explicitly expressed bonds of friendship of the user as well as social tags. We performed a series of comparison experiments between the Random Walk with Restarts model and a user-based collaborative filtering method using the Pearson Correlation similarity. The results show that the graph model system benefits from the additional information embedded in social knowledge. In addition, the graph model outperforms the standard collaborative filtering method.",Proceedings of the 32nd International ACM SIGIR Conference on Research and Development in Information Retrieval,2009,Research
Improving Content Retrievability in Search with Controllable Query Generation,,"['Gustavo Penha', 'Enrico Palumbo', 'Maryam Aziz', 'Alice Wang', 'Hugues Bouchard']",https://doi.org/10.1145/3543507.3583261,"An important goal of online platforms is to enable content discovery, i.e. allow users to find a catalog entity they were not familiar with. A pre-requisite to discover an entity, e.g. a book, with a search engine is that the entity is retrievable, i.e. there are queries for which the system will surface such entity in the top results. However, machine-learned search engines have a high retrievability bias, where the majority of the queries return the same entities. This happens partly due to the predominance of narrow intent queries, where users create queries using the title of an already known entity, e.g. in book search “harry potter”. The amount of broad queries where users want to discover new entities, e.g. in music search “chill lyrical electronica with an atmospheric feeling to it”, and have a higher tolerance to what they might find, is small in comparison. We focus here on two factors that have a negative impact on the retrievability of the entities (I) the training data used for dense retrieval models and (II) the distribution of narrow and broad intent queries issued in the system. We propose CtrlQGen, a method that generates queries for a chosen underlying intent—narrow or broad. We can use CtrlQGen to improve factor (I) by generating training data for dense retrieval models comprised of diverse synthetic queries. CtrlQGen can also be used to deal with factor (II) by suggesting queries with broader intents to users. Our results on datasets from the domains of music, podcasts, and books reveal that we can significantly decrease the retrievability bias of a dense retrieval model when using CtrlQGen. First, by using the generated queries as training data for dense models we make 9% of the entities retrievable—go from zero to non-zero retrievability. Second, by suggesting broader queries to users, we can make 12% of the entities retrievable in the best case.",Proceedings of the ACM Web Conference 2023,2023,Research
Measuring Fairness in Ranked Results: An Analytical and Empirical Comparison,,"['Amifa Raj', 'Michael Ekstrand']",https://doi.org/10.1145/3477495.3532018,"Information access systems, such as search and recommender systems, often use ranked lists to present results believed to be relevant to the user's information need. Evaluating these lists for their fairness along with other traditional metrics provides a more complete understanding of an information access system's behavior beyond accuracy or utility constructs. To measure the (un)fairness of rankings, particularly with respect to the protected group(s) of producers or providers, several metrics have been proposed in the last several years. However, an empirical and comparative analyses of these metrics showing the applicability to specific scenario or real data, conceptual similarities, and differences is still lacking. We aim to bridge the gap between theoretical and practical ap-plication of these metrics. In this paper we describe several fair ranking metrics from the existing literature in a common notation, enabling direct comparison of their approaches and assumptions, and empirically compare them on the same experimental setup and data sets in the context of three information access tasks. We also provide a sensitivity analysis to assess the impact of the design choices and parameter settings that go in to these metrics and point to additional work needed to improve fairness measurement.",Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval,2022,Research
MiNet: Mixed Interest Network for Cross-Domain Click-Through Rate Prediction,,"['Wentao Ouyang', 'Xiuwu Zhang', 'Lei Zhao', 'Jinmei Luo', 'Yu Zhang', 'Heng Zou', 'Zhaojie Liu', 'Yanlong Du']",https://doi.org/10.1145/3340531.3412728,"Click-through rate (CTR) prediction is a critical task in online advertising systems. Existing works mainly address the single-domain CTR prediction problem and model aspects such as feature interaction, user behavior history and contextual information. Nevertheless, ads are usually displayed with natural content, which offers an opportunity for cross-domain CTR prediction. In this paper, we address this problem and leverage auxiliary data from a source domain to improve the CTR prediction performance of a target domain. Our study is based on UC Toutiao (a news feed service integrated with the UC Browser App, serving hundreds of millions of users daily), where the source domain is the news and the target domain is the ad. In order to effectively leverage news data for predicting CTRs of ads, we propose the Mixed Interest Network (MiNet) which jointly models three types of user interest: 1) long-term interest across domains, 2) short-term interest from the source domain and 3) short-term interest in the target domain. MiNet contains two levels of attentions, where the item-level attention can adaptively distill useful information from clicked news / ads and the interest-level attention can adaptively fuse different interest representations. Offline experiments show that MiNet outperforms several state-of-the-art methods for CTR prediction. We have deployed MiNet in UC Toutiao and the A/B test results show that the online CTR is also improved substantially. MiNet now serves the main ad traffic in UC Toutiao.",Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,2020,Research
Nonparametric bayesian multitask collaborative filtering,,['Sotirios Chatzis'],https://doi.org/10.1145/2505515.2505517,"The dramatic rates new digital content becomes available has brought collaborative filtering systems to the epicenter of computer science research in the last decade. One of the greatest challenges collaborative filtering systems are confronted with is the data sparsity problem: users typically rate only very few items; thus, availability of historical data is not adequate to effectively perform prediction. To alleviate these issues, in this paper we propose a novel multitask collaborative filtering approach. Our approach is based on a coupled latent factor model of the users rating functions, which allows for coming up with an agile information sharing mechanism that extracts much richer task-correlation information compared to existing approaches. Formulation of our method is based on concepts from the field of Bayesian nonparametrics, specifically Indian Buffet Process priors, which allow for data-driven determination of the optimal number of underlying latent features (item characteristics and user traits) assumed in the context of the model. We experiment on several real-world datasets, demonstrating both the efficacy of our method, and its superiority over existing approaches.",Proceedings of the 22nd ACM International Conference on Information &amp; Knowledge Management,2013,Research
Clustered Monotone Transforms for Rating Factorization,,"['Gaurush Hiranandani', 'Raghav Somani', 'Oluwasanmi Koyejo', 'Sreangsu Acharyya']",https://doi.org/10.1145/3289600.3291005,"Exploiting low-rank structure of the user-item rating matrix has been the crux of many recommendation engines. However, existing recommendation engines force raters with heterogeneous behavior profiles to map their intrinsic rating scales to a common rating scale (e.g. 1-5). This non-linear transformation of the rating scale shatters the low-rank structure of the rating matrix, therefore resulting in a poor fit and consequentially, poor recommendations. In this paper, we propose Clustered Monotone Transforms for Rating Factorization (CMTRF), a novel approach to perform regression up to unknown monotonic transforms over unknown population segments. Essentially, for recommendation systems, the technique searches for monotonic transformations of the rating scales resulting in a better fit. This is combined with an underlying matrix factorization regression model that couples the user-wise ratings to exploit shared low dimensional structure. The rating scale transformations can be generated for each user, for a cluster of users, or for all the users at once, forming the basis of three simple and efficient algorithms proposed in this paper, all of which alternate between transformation of the rating scales and matrix factorization regression. Despite the non-convexity, CMTRF is theoretically shown to recover a unique solution under mild conditions. Experimental results on two synthetic and seven real-world datasets show that CMTRF outperforms other state-of-the-art baselines.",Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining,2019,Research
Web Structure Derived Clustering for Optimised Web Accessibility Evaluation,,"['Alexander Hambley', 'Yeliz Yesilada', 'Markel Vigo', 'Simon Harper']",https://doi.org/10.1145/3543507.3583508,"Web accessibility evaluation is a costly and complex process due to limited time, resources and ambiguity. To optimise the accessibility evaluation process, we aim to reduce the number of pages auditors must review by employing statistically representative pages, reducing a site of thousands of pages to a manageable review of archetypal pages. Our paper focuses on representativeness, one of six proposed metrics that form our methodology, to address the limitations we have identified with the W3C Website Accessibility Conformance Evaluation Methodology (WCAG-EM). These include the evaluative scope, the non-probabilistic sampling approach, and the potential for bias within the selected sample. Representativeness, in particular, is a metric to assess the quality and coverage of sampling. To measure this, we systematically evaluate five web page representations with a website of 388 pages, including tags, structure, the DOM tree, content, and a mixture of structure and content. Our findings highlight the importance of including structural components in representations. We validate our conclusions using the same methodology for three additional random sites of 500 pages. As an exclusive attribute, we find that features derived from web content are suboptimal and can lead to lower quality and more disparate clustering for optimised accessibility evaluation.",Proceedings of the ACM Web Conference 2023,2023,Research
Heimdall: A Privacy-Respecting Implicit Preference Collection Framework,,"['Amir Rahmati', 'Earlence Fernandes', 'Kevin Eykholt', 'Xinheng Chen', 'Atul Prakash']",https://doi.org/10.1145/3081333.3081334,"Many of the everyday decisions a user makes rely on the suggestions of online recommendation systems. These systems amass implicit (e.g.,location, purchase history, browsing history) and explicit (e.g.,reviews, ratings) feedback from multiple users, produce a general consensus, and provide suggestions based on that consensus. However, due to privacy concerns, users are uncomfortable with implicit data collection, thus requiring recommendation systems to be overly dependent on explicit feedback. Unfortunately, users do not frequently provide explicit feedback. This hampers the ability of recommendation systems to provide high-quality suggestions. We introduce Heimdall, the first privacy-respecting implicit preference collection framework that enables recommendation systems to extract user preferences from their activities in a privacy respecting manner. The key insight is to enable recommendation systems to run a collector on a user's device and precisely control the information a collector transmits to the recommendation system back-end. Heimdall introduces immutable blobs as a mechanism to guarantee this property. We implemented Heimdall on the Android platform and wrote three example collectors to enhance recommendation systems with implicit feedback. Our performance results suggest that the overhead of immutable blobs is minimal, and a user study of 166 participants indicates that privacy concerns are significantly less when collectors record only specific information--a property that Heimdall enables.","Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services",2017,Research
Enhancing Fairness in Meta-learned User Modeling via Adaptive Sampling,,"['Zheng Zhang', 'Qi Liu', 'Zirui Hu', 'Yi Zhan', 'Zhenya Huang', 'Weibo Gao', 'Qingyang Mao']",https://doi.org/10.1145/3589334.3645369,"Meta-learning has been widely employed to tackle the cold-start problem in user modeling. Similar to a guidebook for a new traveler, meta-learning significantly affects decision-making for new users in crucial scenarios, such as career recommendations. Consequently, the issue of fairness in meta-learning has gained paramount importance. Several methods have been proposed to mitigate unfairness in meta-learning and have shown promising results. However, a fundamental question remains unexplored: What is the critical factor leading to unfairness in meta-learned user modeling? Through the theoretical analysis that integrates the meta-learning paradigm with group fairness metrics, we identify group proportion imbalance as a critical factor. Subsequently, in order to mitigate the impact of this factor, we introduce a novel Fairness-aware Adaptive Sampling framework for meTa-learning, abbreviated as FAST. Its core concept involves adaptively adjusting the sampling distribution for different user groups during the interleaved training process of meta-learning. Furthermore, we provide theoretical guarantees demonstrating the convergence of FAST. Finally, empirical experiments conducted on three datasets reveal that FAST effectively enhances fairness while maintaining high accuracy. The code for FAST is available at https://github.com/zhengz99/FAST.",Proceedings of the ACM Web Conference 2024,2024,Research
AUC-oriented Graph Neural Network for Fraud Detection,,"['Mengda Huang', 'Yang Liu', 'Xiang Ao', 'Kuan Li', 'Jianfeng Chi', 'Jinghua Feng', 'Hao Yang', 'Qing He']",https://doi.org/10.1145/3485447.3512178,"Though Graph Neural Networks (GNNs) have been successful for fraud detection tasks, they suffer from imbalanced labels due to limited fraud compared to the overall userbase. This paper attempts to resolve this label-imbalance problem for GNNs by maximizing the AUC&nbsp;(Area Under ROC Curve) metric since it is unbiased with label distribution. However, maximizing AUC on GNN for fraud detection tasks is intractable due to the potential polluted topological structure caused by intentional noisy edges generated by fraudsters. To alleviate this problem, we propose to decouple the AUC maximization process on GNN into a classifier parameter searching and an edge pruning policy searching, respectively. We propose a model named AO-GNN&nbsp;(Short for AUC-oriented GNN), to achieve AUC maximization on GNN under the aforementioned framework. In the proposed model, an AUC-oriented stochastic gradient is applied for classifier parameter searching, and an AUC-oriented reinforcement learning module supervised by a surrogate reward of AUC is devised for edge pruning policy searching. Experiments on three real-world datasets demonstrate that the proposed AO-GNN patently outperforms state-of-the-art baselines in not only AUC but also other general metrics, e.g. F1-macro, G-means.",Proceedings of the ACM Web Conference 2022,2022,Research
Learning from Multi-View Multi-Way Data via Structural Factorization Machines,,"['Chun-Ta Lu', 'Lifang He', 'Hao Ding', 'Bokai Cao', 'Philip Yu']",https://doi.org/10.1145/3178876.3186071,"Real-world relations among entities can often be observed and determined by different perspectives/views. For example, the decision made by a user on whether to adopt an item relies on multiple aspects such as the contextual information of the decision, the item»s attributes, the user»s profile and the reviews given by other users. Different views may exhibit multi-way interactions among entities and provide complementary information. In this paper, we introduce a multi-tensor-based approach that can preserve the underlying structure of multi-view data in a generic predictive model. Specifically, we propose structural factorization machines (SFMs) that learn the common latent spaces shared by multi-view tensors and automatically adjust the importance of each view in the predictive model. Furthermore, the complexity of SFMs is linear in the number of parameters, which make SFMs suitable to large-scale problems. Extensive experiments on real-world datasets demonstrate that the proposed SFMs outperform several state-of-the-art methods in terms of prediction accuracy and computational cost.",Proceedings of the 2018 World Wide Web Conference,2018,Research
Social book search: comparing topical relevance judgements and book suggestions for evaluation,,"['Marijn Koolen', 'Jaap Kamps', 'Gabriella Kazai']",https://doi.org/10.1145/2396761.2396788,"The Web and social media give us access to a wealth of information, not only different in quantity but also in character---traditional descriptions from professionals are now supplemented with user generated content. This challenges modern search systems based on the classical model of topical relevance and ad hoc search: How does their effectiveness transfer to the changing nature of information and to the changing types of information needs and search tasks? We use the INEX 2011 Books and Social Search Track's collection of book descriptions from Amazon and social cataloguing site LibraryThing. We compare classical IR with social book search in the context of the LibraryThing discussion forums where members ask for book suggestions. Specifically, we compare book suggestions on the forum with Mechanical Turk judgements on topical relevance and recommendation, both the judgements directly and their resulting evaluation of retrieval systems. First, the book suggestions on the forum are a complete enough set of relevance judgements for system evaluation. Second, topical relevance judgements result in a different system ranking from evaluation based on the forum suggestions. Although it is an important aspect for social book search, topical relevance is not sufficient for evaluation. Third, professional metadata alone is often not enough to determine the topical relevance of a book. User reviews provide a better signal for topical relevance. Fourth, user-generated content is more effective for social book search than professional metadata. Based on our findings, we propose an experimental evaluation that better reflects the complexities of social book search.",Proceedings of the 21st ACM International Conference on Information and Knowledge Management,2012,Research
Notes toward a politics of personalization,,['Michael Murphy'],https://doi.org/10.1145/1940761.1940836,"A recommender system is an information organization tool which extracts knowledge of individual users of a specific (online) resource based on their activity within that domain, and uses this knowledge to generate for them individual recommendations. These recommendations are made based on the broad assumption that people who have agreed on some things in the past will likely agree on things in the future. [1] Because these systems classify content based on how it is engaged with by previous users, they have emerged as an effective (and profitable) way to organize content on the web, the web itself being resistant, almost by its very nature, to the imposition of top-down, ontological classificatory control. [2]This paper interrogates some of the assumptions and biases involved in the personalized organization and presentation of digital media content, in an effort to devise a more critical analysis of the economic, technical, and social forces that contribute to the growing popularity of the personalized recommender systems. It pays particular attention to how personalized content filtering finds expression in the recommendation engines of taste-coordinating websites like Amazon and Pandora, in the self-organization of information through social classification sites like LibraryThing and Delicious, in the adaptive capabilities of next generation search engines (what Michael Zimmer refers to as ""Search 2.0""), and finally within locational media software like FourSquare. Discussion of these recommender systems will refer to their mechanics as well as their accompanying rhetoric, which often associates the personalized delivery of content with a more empowered individual user.Promises of individual empowerment attached to emerging expressions of personalized media are generally made in opposition to the broadcast media model of the mass market. The concluding section of this paper will examine the rhetoric of these promises in a discussion that considers such novel adaptations of content production and delivery as a market response to current media configurations. These adaptations, it will be argued, serve in large part to define differences to be ""commercially exploited."" [3] The nurturing of differentiated markets represents a potential challenge to some of the very characteristics that have traditionally been associated with the internet's social and political potential.",Proceedings of the 2011 IConference,2011,Research
fLDA: matrix factorization through latent dirichlet allocation,,"['Deepak Agarwal', 'Bee-Chung Chen']",https://doi.org/10.1145/1718487.1718499,"We propose fLDA, a novel matrix factorization method to predict ratings in recommender system applications where a ""bag-of-words"" representation for item meta-data is natural. Such scenarios are commonplace in web applications like content recommendation, ad targeting and web search where items are articles, ads and web pages respectively. Because of data sparseness, regularization is key to good predictive accuracy. Our method works by regularizing both user and item factors simultaneously through user features and the bag of words associated with each item. Specifically, each word in an item is associated with a discrete latent factor often referred to as the topic of the word; item topics are obtained by averaging topics across all words in an item. Then, user rating on an item is modeled as user's affinity to the item's topics where user affinity to topics (user factors) and topic assignments to words in items (item factors) are learned jointly in a supervised fashion. To avoid overfitting, user and item factors are regularized through Gaussian linear regression and Latent Dirichlet Allocation (LDA) priors respectively. We show our model is accurate, interpretable and handles both cold-start and warm-start scenarios seamlessly through a single model. The efficacy of our method is illustrated on benchmark datasets and a new dataset from Yahoo! Buzz where fLDA provides superior predictive accuracy in cold-start scenarios and is comparable to state-of-the-art methods in warm-start scenarios. As a by-product, fLDA also identifies interesting topics that explains user-item interactions. Our method also generalizes a recently proposed technique called supervised LDA (sLDA) to collaborative filtering applications. While sLDA estimates item topic vectors in a supervised fashion for a single regression, fLDA incorporates multiple regressions (one for each user) in estimating the item factors.",Proceedings of the Third ACM International Conference on Web Search and Data Mining,2010,Research
Cross-media sentiment classification and application to box-office forecasting,,"[""\\'{E}lie Gu\\`{a}rdia-Sebaoun"", 'Abdelhalim Rafrafi', 'Vincent Guigue', 'Patrick Gallinari']",missing,"This article aims at demonstrating the interest of opinion mining on Twitter data for the box-office prediction. Whilst most approaches in box-office forecasting focus on expert knowledge (actor celebrity, film budget...), or more recently on Twitter volumetric features, we want to show that the tweet's content is also important to make an efficient decision. Firstly we focus on the cross-media sentiment classification task, by studying the impact different algorithms and data sources have on the accuracy of sentiment classification on Twitter. Secondly, models allow us to to build high level sentiment features for the box-office forecasting problem. We demonstrate the interest of opinion mining derived features for this second task.",Proceedings of the 10th Conference on Open Research Areas in Information Retrieval,2013,Research
Boosting Share Routing for Multi-task Learning,,"['Xiaokai Chen', 'Xiaoguang Gu', 'Libo Fu']",https://doi.org/10.1145/3442442.3452323,"Multi-task learning (MTL) aims to make full use of the knowledge contained in multi-task supervision signals to improve the overall performance. How to make the knowledge of multiple tasks shared appropriately is an open problem for MTL. Most existing deep MTL models are based on parameter sharing. However, suitable sharing mechanism is hard to design as the relationship among tasks is complicated. In this paper, we propose a general framework called Multi-Task Neural Architecture Search (MTNAS) to efficiently find a suitable sharing route for a given MTL problem. MTNAS modularizes the sharing part into multiple layers of sub-networks. It allows sparse connection among these sub-networks and soft sharing based on gating is enabled for a certain route. Benefiting from such setting, each candidate architecture in our search space defines a dynamic sparse sharing route which is more flexible compared with full-sharing in previous approaches. We show that existing typical sharing approaches are sub-graphs in our search space. Extensive experiments on three real-world recommendation datasets demonstrate MTANS achieves consistent improvement compared with single-task models and typical multi-task methods while maintaining high computation efficiency. Furthermore, in-depth experiments demonstrates that MTNAS can learn suitable sparse route to mitigate negative transfer.",Companion Proceedings of the Web Conference 2021,2021,Research
Instruction-based Hypergraph Pretraining,,"['Mingdai Yang', 'Zhiwei Liu', 'Liangwei Yang', 'Xiaolong Liu', 'Chen Wang', 'Hao Peng', 'Philip Yu']",https://doi.org/10.1145/3626772.3657715,"Pretraining has been widely explored to augment the adaptability of graph learning models to transfer knowledge from large datasets to a downstream task, such as link prediction or classification. However, the gap between training objectives and the discrepancy between data distributions in pretraining and downstream tasks hinders the transfer of the pre-trained knowledge. Inspired by instruction-based prompts widely used in pre-trained language models, we introduce instructions into graph pertaining. In this paper, we propose a novel pretraining framework named Instruction-based Hypergraph Pretraining. To overcome the discrepancy between pretraining and downstream tasks, text-based instructions provide explicit guidance on specific tasks for representation learning. Compared to learnable prompts, whose effectiveness depends on the quality and diversity of training data, text-based instructions intrinsically encapsulate task information and support the model's generalization beyond the structure seen during pretraining. To capture high-order relations with task information in a context-aware manner, a novel prompting hypergraph convolution layer is devised to integrate instructions into information propagation in hypergraphs. Extensive experiments conducted on three public datasets verify the superiority of IHP in various scenarios.",Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval,2024,Research
Leveraging Social Connections to Improve Personalized Ranking for Collaborative Filtering,,"['Tong Zhao', 'Julian McAuley', 'Irwin King']",https://doi.org/10.1145/2661829.2661998,"Recommending products to users means estimating their preferences for certain items over others. This can be cast either as a problem of estimating the rating that each user will give to each item, or as a problem of estimating users' relative preferences in the form of a ranking. Although collaborative-filtering approaches can be used to identify users who rate and rank products similarly, another source of data that informs us about users' preferences is their set of social connections. Both rating- and ranking-based paradigms are important in real-world recommendation settings, though rankings are especially important in settings where explicit feedback in the form of a numerical rating may not be available. Although many existing works have studied how social connections can be used to build better models for rating prediction, few have used social connections as a means to derive more accurate ranking-based models. Using social connections to better estimate users' rankings of products is the task we consider in this paper. We develop a model, SBPR (Social Bayesian Personalized Ranking), based on the simple observation that users tend to assign higher ranks to items that their friends prefer. We perform experiments on four real-world recommendation data sets, and show that SBPR outperforms alternatives in ranking prediction both in warm- and cold-start settings.",Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,2014,Research
MNC: Structure-Exploiting Sparsity Estimation for Matrix Expressions,,"['Johanna Sommer', 'Matthias Boehm', 'Alexandre Evfimievski', 'Berthold Reinwald', 'Peter Haas']",https://doi.org/10.1145/3299869.3319854,"Efficiently computing linear algebra expressions is central to machine learning (ML) systems. Most systems support sparse formats and operations because sparse matrices are ubiquitous and their dense representation can cause prohibitive overheads. Estimating the sparsity of intermediates, however, remains a key challenge when generating execution plans or performing sparse operations. These sparsity estimates are used for cost and memory estimates, format decisions, and result allocation. Existing estimators tend to focus on matrix products only, and struggle to attain good accuracy with low estimation overhead. However, a key observation is that real-world sparse matrices commonly exhibit structural properties such as a single non-zero per row, or columns with varying sparsity. In this paper, we introduce MNC (Matrix Non-zero Count), a remarkably simple, count-based matrix synopsis that exploits these structural properties for efficient, accurate, and general sparsity estimation. We describe estimators and sketch propagation for realistic linear algebra expressions. Our experiments - on a new estimation benchmark called SparsEst - show that the MNC estimator yields good accuracy with very low overhead. This behavior makes MNC practical and broadly applicable in ML systems.",Proceedings of the 2019 International Conference on Management of Data,2019,Research
Heterformer: Transformer-based Deep Node Representation Learning on Heterogeneous Text-Rich Networks,,"['Bowen Jin', 'Yu Zhang', 'Qi Zhu', 'Jiawei Han']",https://doi.org/10.1145/3580305.3599376,"Representation learning on networks aims to derive a meaningful vector representation for each node, thereby facilitating downstream tasks such as link prediction, node classification, and node clustering. In heterogeneous text-rich networks, this task is more challenging due to (1) presence or absence of text: Some nodes are associated with rich textual information, while others are not; (2) diversity of types: Nodes and edges of multiple types form a heterogeneous network structure. As pretrained language models (PLMs) have demonstrated their effectiveness in obtaining widely generalizable text representations, a substantial amount of effort has been made to incorporate PLMs into representation learning on text-rich networks. However, few of them can jointly consider heterogeneous structure (network) information as well as rich textual semantic information of each node effectively. In this paper, we propose Heterformer, a Heterogeneous Network-Empowered Transformer that performs contextualized text encoding and heterogeneous structure encoding in a unified model. Specifically, we inject heterogeneous structure information into each Transformer layer when encoding node texts. Meanwhile, Heterformer is capable of characterizing node/edge type heterogeneity and encoding nodes with or without texts. We conduct comprehensive experiments on three tasks (i.e., link prediction, node classification, and node clustering) on three large-scale datasets from different domains, where Heterformer outperforms competitive baselines significantly and consistently. The code can be found at https://github.com/PeterGriffinJin/Heterformer.",Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,2023,Research
Understanding book search behavior on the web,,"['Jin Kim', 'Henry Feild', 'Marc Cartright']",https://doi.org/10.1145/2396761.2396856,"With the increased availability of e-books and digitized book collections, more users are searching the web for information about books. There are many online digital libraries containing book, author and subject data, which are accessed via internal search services as well as external web sites, such as Google. Although this is a common yet complex information-seeking behavior involving multiple search systems with different characteristics, little is known about how users find information in this scenario.In this work, we analyze web-based book search behavior using three months of logs from the Open Library, a globally accessible digital library. Our study encompasses the user behavior on web search engines and the digital library, unlike previous work which focused on institution-level digital libraries. Among our findings are (1) query characteristics and session-level behaviors are drastically different between internal and external searchers; (2) the field usage is different based on the modes of interaction---keyword search, advanced search interface and faceted filtering; (3) users go through with more iterations of faceted filtering than query reformulation. To facilitate future research on book search, we also create a book search test collection based on the log data. We then perform an evaluation of several retrieval methods, finding that field-based retrieval models have advantages over document-based models.",Proceedings of the 21st ACM International Conference on Information and Knowledge Management,2012,Research
Social semantic query expansion,,"['Claudio Biancalana', 'Fabio Gasparetti', 'Alessandro Micarelli', 'Giuseppe Sansonetti']",https://doi.org/10.1145/2508037.2508041,"Weak semantic techniques rely on the integration of Semantic Web techniques with social annotations and aim to embrace the strengths of both. In this article, we propose a novel weak semantic technique for query expansion. Traditional query expansion techniques are based on the computation of two-dimensional co-occurrence matrices. Our approach proposes the use of three-dimensional matrices, where the added dimension is represented by semantic classes (i.e., categories comprising all the terms that share a semantic property) related to the folksonomy extracted from social bookmarking services, such as delicious and StumbleUpon. The results of an indepth experimental evaluation performed on both artificial datasets and real users show that our approach outperforms traditional techniques, such as relevance feedback and personalized PageRank, so confirming the validity and usefulness of the categorization of the user needs and preferences in semantic classes. We also present the results of a questionnaire aimed to know the users opinion regarding the system. As one drawback of several query expansion techniques is their high computational costs, we also provide a complexity analysis of our system, in order to show its capability of operating in real time.",missing,2013,Research
Personalised rating prediction for new users using latent factor models,,"['Yanir Seroussi', 'Fabian Bohnert', 'Ingrid Zukerman']",https://doi.org/10.1145/1995966.1995976,"In recent years, personalised recommendations have gained importance in helping users deal with the abundance of information available online. Personalised recommendations are often based on rating predictions, and thus accurate rating prediction is essential for the generation of useful recommendations. Recently, rating prediction algorithms that are based on matrix factorisation have become increasingly popular, due to their high accuracy and scalability. However, these algorithms still deliver inaccurate rating predictions for new users, who submitted only a few ratings.In this paper, we address the new user problem by introducing several extensions to the basic matrix factorisation algorithm, which take user attributes into account when generating rating predictions. We consider both demographic attributes, explicitly supplied by users, and attributes inferred from user-generated texts. Our results show that employing our text-based user attributes yields personalised rating predictions that are more accurate than our baselines, while not requiring users to explicitly supply any information about themselves and their preferences.",Proceedings of the 22nd ACM Conference on Hypertext and Hypermedia,2011,Research
Lady Chatterley's Library: Books and Reading as Public Performance and Private Act,,"['Dana Mckay', 'Michael Twidale', 'George Buchanan']",https://doi.org/10.1145/3406522.3446032,"If reading was simply ingesting information, it would not matter what format that information arrived in-whether it be digital, poor quality newsprint, or the most beautiful hardback book. We do make choices about our reading, though, based on other factors than informational content. Some of these have been discussed in the literature, including convenience, preferences between paper and screen, and acquisition preferences. In this paper, we discuss books and reading as a performance. We examine the visual and cultural elements of books that influence the decisions we make about privacy or performance. We use these reflections to suggest a new form of information interaction, and make suggestions for a future program of research to support this new interaction.",Proceedings of the 2021 Conference on Human Information Interaction and Retrieval,2021,Research
Envisioning Information Access Systems: What Makes for Good Tools and a Healthy Web?,,"['Chirag Shah', 'Emily Bender']",https://doi.org/10.1145/3649468,"We observe a recent trend toward applying large language models (LLMs) in search and positioning them as effective information access systems. While the interfaces may look appealing and the apparent breadth of applicability is exciting, we are concerned that the field is rushing ahead with a technology without sufficient study of the uses it is meant to serve, how it would be used, and what its use would mean. We argue that it is important to reassert the central research focus of the field of information retrieval, because information access is not merely an application to be solved by the so-called ‘AI’ techniques du jour. Rather, it is a key human activity, with impacts on both individuals and society. As information scientists, we should be asking what do people and society want and need from information access systems and how do we design and build systems to meet those needs? With that goal, in this conceptual article we investigate fundamental questions concerning information access from user and societal viewpoints. We revisit foundational work related to information behavior, information seeking, information retrieval, information filtering, and information access to resurface what we know about these fundamental questions and what may be missing. We then provide our conceptual framing about how we could fill this gap, focusing on methods as well as experimental and evaluation frameworks. We consider the Web as an information ecosystem and explore the ways in which synthetic media, produced by LLMs and otherwise, endangers that ecosystem. The primary goal of this conceptual article is to shed light on what we still do not know about the potential impacts of LLM-based information access systems, how to advance our understanding of user behaviors, and where the next generations of students, scholars, and developers could fruitfully invest their energies.",missing,2024,Research
Gender expression in a small world: social tagging of transgender-themed books,,['Melissa Adler'],missing,"Social tagging is evaluated as an information behavior in a small world, using Chatman, Burnett, and Besant's Theory of Normative Behavior. A survey was distributed to people who assign tags to transgender-themed books in LibraryThing, an social network site that allows members to catalog and tag their personal book collections. This study first establishes that there is an identifiable community of interest and then lays the groundwork for understanding the function of tagging in sharing information among a marginalized community for whom vocabulary and taxonomies are vital.",Proceedings of the 76th ASIS&amp;T Annual Meeting: Beyond the Cloud: Rethinking Information Boundaries,2013,Research
Web Content Classification Using Distributions of Subjective Quality Evaluations,,"['Maria Rafalak', 'Dominik Deja', 'Adam Wierzbicki', 'Rados\\l{}aw Nielek', 'Micha\\l{} K\\k{a}kol']",https://doi.org/10.1145/2994132,"Machine learning algorithms and recommender systems trained on human ratings are widely in use today. However, human ratings may be associated with a high level of uncertainty and are subjective, influenced by demographic or psychological factors. We propose a new approach to the design of object classes from human ratings: the use of entire distributions to construct classes. By avoiding aggregation for class definition, our approach loses no information and can deal with highly volatile or conflicting ratings. The approach is based the concept of the Earth Mover's Distance (EMD), a measure of distance for distributions. We evaluate the proposed approach based on four datasets obtained from diverse Web content or movie quality evaluation services or experiments. We show that clusters discovered in these datasets using the EMD measure are characterized by a consistent and simple interpretation. Quality classes defined using entire rating distributions can be fitted to clusters of distributions in the four datasets using two parameters, resulting in a good overall fit. We also consider the impact of the composition of small samples on the distributions that are the basis of our classification approach. We show that using distributions based on small samples of 10 evaluations is still robust to several demographic and psychological variables. This observation suggests that the proposed approach can be used in practice for quality evaluation, even for highly uncertain and subjective ratings.",missing,2016,Research
Transfer learning for collaborative filtering via a rating-matrix generative model,,"['Bin Li', 'Qiang Yang', 'Xiangyang Xue']",https://doi.org/10.1145/1553374.1553454,"Cross-domain collaborative filtering solves the sparsity problem by transferring rating knowledge across multiple domains. In this paper, we propose a rating-matrix generative model (RMGM) for effective cross-domain collaborative filtering. We first show that the relatedness across multiple rating matrices can be established by finding a shared implicit cluster-level rating matrix, which is next extended to a cluster-level rating model. Consequently, a rating matrix of any related task can be viewed as drawing a set of users and items from a user-item joint mixture model as well as drawing the corresponding ratings from the cluster-level rating model. The combination of these two models gives the RMGM, which can be used to fill the missing ratings for both existing and new users. A major advantage of RMGM is that it can share the knowledge by pooling the rating data from multiple tasks even when the users and items of these tasks do not overlap. We evaluate the RMGM empirically on three real-world collaborative filtering data sets to show that RMGM can outperform the individual models trained separately.",Proceedings of the 26th Annual International Conference on Machine Learning,2009,Research
Self-training through Classifier Disagreement for Cross-Domain Opinion Target Extraction,,"['Kai Sun', 'Richong Zhang', 'Mensah Samuel', 'Aletras Nikolaos', 'Yongyi Mao', 'Xudong Liu']",https://doi.org/10.1145/3543507.3583325,"Opinion target extraction (OTE) or aspect extraction (AE) is a fundamental task in opinion mining that aims to extract the targets (or aspects) on which opinions have been expressed. Recent work focus on cross-domain OTE, which is typically encountered in real-world scenarios, where the testing and training distributions differ. Most methods use domain adversarial neural networks that aim to reduce the domain gap between the labelled source and unlabelled target domains to improve target domain performance. However, this approach only aligns feature distributions and does not account for class-wise feature alignment, leading to suboptimal results. Semi-supervised learning (SSL) has been explored as a solution, but is limited by the quality of pseudo-labels generated by the model. Inspired by the theoretical foundations in domain adaptation&nbsp;[2], we propose a new SSL approach that opts for selecting target samples whose model output from a domain-specific teacher and student network disagree on the unlabelled target data, in an effort to boost the target domain performance. Extensive experiments on benchmark cross-domain OTE datasets show that this approach is effective and performs consistently well in settings with large domain shifts.",Proceedings of the ACM Web Conference 2023,2023,Research
Dead Angles of Personalization: Integrating Curation Algorithms in the Fabric of Design,,['Nolwenn Maudet'],https://doi.org/10.1145/3322276.3322322,"The amount of information available on the web is too vast for individuals to be able to process it all. To cope with this issue, digital platforms started relying on algorithms to curate, filter and recommend content to their users. This problem has generally been envisioned from a technical perspective, as an optimization issue and has been mostly untouched by design considerations. Through 16 interviews with daily users of platforms, we analyze how curation algorithms influence their daily experience and the strategies they use to try to adapt them to their own needs. Based on these empirical findings, we propose a set of four speculative design alternatives to explore how we can integrate curation algorithms as part of the larger fabric of design on the web. By exploring interactions to counter the binary nature of curation algorithms, their uniqueness, their anti-historicity and their implicit data collection, we provide tools to bridge the current divide between curation algorithms and people.",Proceedings of the 2019 on Designing Interactive Systems Conference,2019,Research
Emotional book classification from book blurbs,,"['Valentina Franzoni', 'Valentina Poggioni']",https://doi.org/10.1145/3106426.3109422,"Knowing and predicting opinions of people is considered a strategic added value, interpreting the qualia i.e., the subjective nature of emotional content. The aim of this work is to study the feasibility of an emotion recognition and automated classification of books according to emotional tags, by means of a lexical and semantic analysis of book blurbs. A supervised learning approach is used to determine if a correlation exists between the characteristics of a book blurb and emotional icons associated to the book by users. In this paper the underlying idea of the system is presented, the preprocessing and features extraction phases are described and experimental results on the social network Zazie and its mood tags are discussed.",Proceedings of the International Conference on Web Intelligence,2017,Research
Investigations into user rating information and predictive accuracy in a collaborative filtering domain,,"['Josephine Griffith', ""Colm O'Riordan"", 'Humphrey Sorensen']",https://doi.org/10.1145/2245276.2245458,"The work described in this paper extracts user rating information from collaborative filtering datasets, and for each dataset uses a supervised machine learning approach to identify if there is an underlying relationship between rating information in the dataset and the expected accuracy of recommendations returned by the system. The underlying relationship is represented by decision tree rules. The rules can be used to indicate the predictive accuracy of the system for users of the system. Thus a user can know in advance of recommendation the level of accuracy to expect from the collaborative filtering system and may have more (or less) confidence in the recommendations produced. The experiment outlined in this paper aims to test the accuracy of the rules produced using three different datasets. Results show good accuracy can be found for all three datasets.",Proceedings of the 27th Annual ACM Symposium on Applied Computing,2012,Research
To Join or Not to Join? Thinking Twice about Joins before Feature Selection,,"['Arun Kumar', 'Jeffrey Naughton', 'Jignesh Patel', 'Xiaojin Zhu']",https://doi.org/10.1145/2882903.2882952,"Closer integration of machine learning (ML) with data processing is a booming area in both the data management industry and academia. Almost all ML toolkits assume that the input is a single table, but many datasets are not stored as single tables due to normalization. Thus, analysts often perform key-foreign key joins to obtain features from all base tables and apply a feature selection method, either explicitly or implicitly, with the aim of improving accuracy. In this work, we show that the features brought in by such joins can often be ignored without affecting ML accuracy significantly, i.e., we can ""avoid joins safely."" We identify the core technical issue that could cause accuracy to decrease in some cases and analyze this issue theoretically. Using simulations, we validate our analysis and measure the effects of various properties of normalized data on accuracy. We apply our analysis to design easy-to-understand decision rules to predict when it is safe to avoid joins in order to help analysts exploit this runtime-accuracy trade-off. Experiments with multiple real normalized datasets show that our rules are able to accurately predict when joins can be avoided safely, and in some cases, this led to significant reductions in the runtime of some popular feature selection methods.",Proceedings of the 2016 International Conference on Management of Data,2016,Research
Estimation of Fair Ranking Metrics with Incomplete Judgments,,"['\\""{O}mer K\\i{}rnap', 'Fernando Diaz', 'Asia Biega', 'Michael Ekstrand', 'Ben Carterette', 'Emine Yilmaz']",https://doi.org/10.1145/3442381.3450080,"There is increasing attention to evaluating the fairness of search system ranking decisions. These metrics often consider the membership of items to particular groups, often identified using protected attributes such as gender or ethnicity. To date, these metrics typically assume the availability and completeness of protected attribute labels of items. However, the protected attributes of individuals are rarely present, limiting the application of fair ranking metrics in large scale systems. In order to address this problem, we propose a sampling strategy and estimation technique for four fair ranking metrics. We formulate a robust and unbiased estimator which can operate even with very limited number of labeled items. We evaluate our approach using both simulated and real world data. Our experimental results demonstrate that our method can estimate this family of fair ranking metrics and provides a robust, reliable alternative to exhaustive or random data annotation.",Proceedings of the Web Conference 2021,2021,Research
Open Knowledge Enrichment for Long-tail Entities,,"['Ermei Cao', 'Difeng Wang', 'Jiacheng Huang', 'Wei Hu']",https://doi.org/10.1145/3366423.3380123,"Knowledge bases (KBs) have gradually become a valuable asset for many AI applications. While many current KBs are quite large, they are widely acknowledged as incomplete, especially lacking facts of long-tail entities, e.g., less famous persons. Existing approaches enrich KBs mainly on completing missing links or filling missing values. However, they only tackle a part of the enrichment problem and lack specific considerations regarding long-tail entities. In this paper, we propose a full-fledged approach to knowledge enrichment, which predicts missing properties and infers true facts of long-tail entities from the open Web. Prior knowledge from popular entities is leveraged to improve every enrichment step. Our experiments on the synthetic and real-world datasets and comparison with related work demonstrate the feasibility and superiority of the approach.",Proceedings of The Web Conference 2020,2020,Research
A Robust Reputation-Based Group Ranking System and Its Resistance to Bribery,,"[""Jo\\~{a}o Sa\\'{u}de"", 'Guilherme Ramos', 'Ludovico Boratto', 'Carlos Caleiro']",https://doi.org/10.1145/3462210,"The spread of online reviews and opinions and its growing influence on people’s behavior and decisions boosted the interest to extract meaningful information from this data deluge. Hence, crowdsourced ratings of products and services gained a critical role in business and governments. Current state-of-the-art solutions rank the items with an average of the ratings expressed for an item, with a consequent lack of personalization for the users, and the exposure to attacks and spamming/spurious users. Using these ratings to group users with similar preferences might be useful to present users with items that reflect their preferences and overcome those vulnerabilities. In this article, we propose a new reputation-based ranking system, utilizing multipartite rating subnetworks, which clusters users by their similarities using three measures, two of them based on Kolmogorov complexity. We also study its resistance to bribery and how to design optimal bribing strategies. Our system is novel in that it reflects the diversity of preferences by (possibly) assigning distinct rankings to the same item, for different groups of users. We prove the convergence and efficiency of the system. By testing it on synthetic and real data, we see that it copes better with spamming/spurious users, being more robust to attacks than state-of-the-art approaches. Also, by clustering users, the effect of bribery in the proposed multipartite ranking system is dimmed, comparing to the bipartite case.",missing,2021,Research
Towards Understanding Complex Known-Item Requests on Reddit,,"['Florian Meier', 'Toine Bogers', 'Maria G\\""{a}de', 'Line Ebdrup Thomsen']",https://doi.org/10.1145/3465336.3475096,"Given the important role of search engines in our everyday lives, a better understanding of the information needs that guide our information seeking behavior is essential. Known-item needs form a particular type of information need and occur when a user has a limited but concrete description of an existing object and would like to (re-)find it. Most studies of know-item needs have focused on the short query representations of these needs as they occur in search engine logs. In this article, we focus on richer, more complex known-item need representations posted to six dedicated Reddit discussion forums in the casual leisure domain. An analysis of 462 known-item requests from these subreddits revealed 33 different relevance aspects of items in a variety of different domains. Some of these aspects are highly domain-specific, while others are broadly applicable across domains. The domain %of the item sought also has a strong influence on the length of the known-item requests. Our findings can be used to prioritize efforts to help existing search engines better support known-item needs, both by highlighting which aspects are easier to classify automatically and by determining which information sources should be added to a search engine's index.",Proceedings of the 32nd ACM Conference on Hypertext and Social Media,2021,Research
Measuring the Effects of Gender on Online Social Conformity,,"['Senuri Wijenayake', 'Niels Berkel', 'Vassilis Kostakos', 'Jorge Goncalves']",https://doi.org/10.1145/3359247,"Social conformity occurs when an individual changes their behaviour in line with the majority's expectations. Although social conformity has been investigated in small group settings, the effect of gender - of both the individual and the majority/minority - is not well understood in online settings. Here we systematically investigate the impact of groups' gender composition on social conformity in online settings. We use an online quiz in which participants submit their answers and confidence scores, both prior to and following the presentation of peer answers that are dynamically fabricated. Our results show an overall conformity rate of 39%, and a significant effect of gender that manifests in a number of ways: gender composition of the majority, the perceived nature of the question, participant gender, visual cues of the system, and final answer correctness. We conclude with a discussion on the implications of our findings in designing online group settings, accounting for the effects of gender on conformity.",missing,2019,Research
Revisiting Gendered Web Forms: An Evaluation of Gender Inputs with (Non-)Binary People,,"['Morgan Scheuerman', 'Aaron Jiang', 'Katta Spiel', 'Jed Brubaker']",https://doi.org/10.1145/3411764.3445742,"Gender input forms act as gates to accessing information, websites, and services online. Non-binary people regularly have to interact with them, though many do not offer non-binary gender options. This results in non-binary individuals having to either choose an incorrect gender category or refrain from using a site or service—which is occasionally infeasible (e.g., when accessing health services). We tested five different forms through a survey with binary and non-binary participants (n = 350) in three contexts—a digital health form, a social media website, and a dating app. Our results indicate that the majority of participants found binary “male or female” forms exclusive and uncomfortable to fill out across all contexts. We conclude with design considerations for improving gender input forms and consequently their underlying gender model in databases. Our work aims to sensitize designers of (online) gender web forms to the needs and desires of non-binary people.",Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems,2021,Research
Out of Site: Empowering a New Approach to Online Boycotts,,"['Hanlin Li', 'Bodhi Alarcon', 'Sara Milkes Espinosa', 'Brent Hecht']",https://doi.org/10.1145/3274375,"GrabYourWallet, #boycottNRA and other online boycott campaigns have attracted substantial public interest in recent months. However, a number of significant challenges are preventing online boycotts from reaching their potential. In particular, complex webs of brands and subsidiaries can make it difficult for participants to conform to the goals of a boycott. Similarly, participants and organizers have limited visibility into a boycott's progress. This affects their ability to use sociotechnical innovations from social computing to incentivize participation. To address these challenges, this paper makes a system contribution: a new boycott tool called Out of Site. Out of Site uses lightweight automation to remove obstacles to successful online boycotts. We describe the design challenges associated with Out of Site and report results from two phases of deployment with the GrabYourWallet and Stop Animal Testing boycott communities. Our findings highlight the potential of boycott-assisting technologies and inform the design of this new class of technologies. Finally, like is the case for many systems in social computing, while we designed Out of Site for pro-social uses, there are a number of easily predictable ways in which the system can be leveraged for anti-social purposes (e.g. exacerbating filter bubble issues, empowering boycotts of businesses owned by racial, ethnic, and religious minorities). As such, we developed for this project a new, very straightforward design approach that treats preventing these anti-social uses as a top-tier design concern. This approach stands in contrast to the status quo of ignoring potential anti-social uses and/or considering them to be a secondary design priority. We discuss how our simple approach may help other research projects reduce their potential negative impacts with minimal burden.",missing,2018,Research
Feral Concurrency Control: An Empirical Investigation of Modern Application Integrity,,"['Peter Bailis', 'Alan Fekete', 'Michael Franklin', 'Ali Ghodsi', 'Joseph Hellerstein', 'Ion Stoica']",https://doi.org/10.1145/2723372.2737784,"The rise of data-intensive ""Web 2.0"" Internet services has led to a range of popular new programming frameworks that collectively embody the latest incarnation of the vision of Object-Relational Mapping (ORM) systems, albeit at unprecedented scale. In this work, we empirically investigate modern ORM-backed applications' use and disuse of database concurrency control mechanisms. Specifically, we focus our study on the common use of feral, or application-level, mechanisms for maintaining database integrity, which, across a range of ORM systems, often take the form of declarative correctness criteria, or invariants. We quantitatively analyze the use of these mechanisms in a range of open source applications written using the Ruby on Rails ORM and find that feral invariants are the most popular means of ensuring integrity (and, by usage, are over 37 times more popular than transactions). We evaluate which of these feral invariants actually ensure integrity (by usage, up to 86.9%) and which---due to concurrency errors and lack of database support---may lead to data corruption (the remainder), which we experimentally quantify. In light of these findings, we present recommendations for database system designers for better supporting these modern ORM programming patterns, thus eliminating their adverse effects on application integrity.",Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,Research
Survey on social tagging techniques,,"['Manish Gupta', 'Rui Li', 'Zhijun Yin', 'Jiawei Han']",https://doi.org/10.1145/1882471.1882480,"Social tagging on online portals has become a trend now. It has emerged as one of the best ways of associating metadata with web objects. With the increase in the kinds of web objects becoming available, collaborative tagging of such objects is also developing along new dimensions. This popularity has led to a vast literature on social tagging. In this survey paper, we would like to summarize different techniques employed to study various aspects of tagging. Broadly, we would discuss about properties of tag streams, tagging models, tag semantics, generating recommendations using tags, visualizations of tags, applications of tags and problems associated with tagging usage. We would discuss topics like why people tag, what influences the choice of tags, how to model the tagging process, kinds of tags, different power laws observed in tagging domain, how tags are created, how to choose the right tags for recommendation, etc. We conclude with thoughts on future work in the area.",missing,2010,Research
Semantic stability in social tagging streams,,"['Claudia Wagner', 'Philipp Singer', 'Markus Strohmaier', 'Bernardo Huberman']",https://doi.org/10.1145/2566486.2567979,"One potential disadvantage of social tagging systems is that due to the lack of a centralized vocabulary, a crowd of users may never manage to reach a consensus on the description of resources (e.g., books, users or songs) on the Web. Yet, previous research has provided interesting evidence that the tag distributions of resources may become semantically stable over time as more and more users tag them. At the same time, previous work has raised an array of new questions such as: (i) How can we assess the semantic stability of social tagging systems in a robust and methodical way? (ii) Does semantic stabilization of tags vary across different social tagging systems and ultimately, (iii) what are the factors that can explain semantic stabilization in such systems? In this work we tackle these questions by (i) presenting a novel and robust method which overcomes a number of limitations in existing methods, (ii) empirically investigating semantic stabilization processes in a wide range of social tagging systems with distinct domains and properties and (iii) detecting potential causes for semantic stabilization, specifically imitation behavior, shared background knowledge and intrinsic properties of natural language. Our results show that tagging streams which are generated by a combination of imitation dynamics and shared background knowledge exhibit faster and higher semantic stability than tagging streams which are generated via imitation dynamics or natural language phenomena alone.",Proceedings of the 23rd International Conference on World Wide Web,2014,Research
Exploring Rated Datasets with Rating Maps,,"['Sihem Amer-Yahia', 'Sofia Kleisarchaki', 'Naresh Kolloju', 'Laks Lakshmanan', 'Ruben Zamar']",https://doi.org/10.1145/3038912.3052623,"Online rated datasets have become a source for large-scale population studies for analysts and a means for end-users to achieve routine tasks such as finding a book club. Existing systems however only provide limited insights into the opinions of different segments of the rater population. In this paper, we develop a framework for finding and exploring population segments and their opinions. We propose rating maps, a collection of (population segment, rating distribution) pairs, where a segment, e.g., {18-29 year old males in CA} has a rating distribution in the form of a histogram that aggregates its ratings for a set of items (e.g., movies starring Russel Crowe). We formalize the problem of building rating maps dynamically given desired input distributions. Our problem raises two challenges: (i) the choice of an appropriate measure for comparing rating distributions, and (ii) the design of efficient algorithms to find segments. We show that the Earth Mover's Distance (EMD) is well-adapted to comparing rating distributions and prove that finding segments whose rating distribution is close to input ones is NP-complete. We propose an efficient algorithm for building Partition Decision Trees and heuristics for combining the resulting partitions to further improve their quality. Our experiments on real and synthetic datasets validate the utility of rating maps for both analysts and end-users.",Proceedings of the 26th International Conference on World Wide Web,2017,Research
The User Experience in Zen and the Art of Motorcycle Maintenance,,['Simon Harper'],https://doi.org/10.1145/2851581.2892566,"How do we teach UX/HCI concepts to an audience who have not encountered the domain before? We thought the learning process may be best supported by using material which might be more compelling. Zen and the Art of Motorcycle Maintenance (ZAMM) is a classic and accessible work of American literature, often taught at college or as part of University degrees. Published in 1974 ZAMM is a first person account of a 17-day motorcycle journey from Minnesota to Northern California by the author and his son. Surprisingly, we encouraged reading ZAMM as a method of learning the over arching issues in HCI and UX. Even more surprisingly, students reported benefits in the comprehension of HCI/UX topics from reading it.",Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems,2016,Research
Fresh and Diverse Social Signals: Any Impacts on Search?,,"['Ismail Badache', 'Mohand Boughanem']",https://doi.org/10.1145/3020165.3020177,"In this paper, we extensively study the impact of social signals (users' actions) obtained from several social networks on search ranking task. Social signals associated with web resources (documents) can be considered as an additional information that can play a vital role to estimate a priori importance of these resources. Particularly, we are interested in the freshness of signals and their diversity. We hypothesize that the moment (the date) when the user actions occur and the diversity of actions may impact the search performance. We propose to model these heterogeneous social features as document prior. We evaluate the effectiveness of our approach by carrying out extensive experiments on two different INEX datasets, namely SBS and IMDb, enriched with several social signals collected from social networks. Our experimental results consistently demonstrate the interest of integrating fresh and diverse signals in the retrieval process.",Proceedings of the 2017 Conference on Conference Human Information Interaction and Retrieval,2017,Research
Using social media sentiment analysis for interaction design choices: an exploratory framework,,"['Mark McGuire', 'Constance Kampf']",https://doi.org/10.1145/2775441.2775472,"Social media analytics is an emerging skill for organizations. Currently, developers are exploring ways to create tools for simplifying social media analysis. These tools tend to focus on gathering data, and using systems to make it meaningful. However, we contend that making social media data meaningful is by nature a human-computer interaction problem. We examine this problem around the emerging field of sentiment analysis, exploring criteria for designing sentiment analysis systems based in Human Computer interaction, HCI. We contend that effective sentiment analysis affects audience analysis, and can serve as a basis for communication design choices that support strategic relationship goals for organizations",Proceedings of the 33rd Annual International Conference on the Design of Communication,2015,Research
Metadatapedia: a proposal for aggregating metadata on data archiving,,"['David Nichols', 'Michael Twidale', 'Sally Cunningham']",https://doi.org/10.1145/2132176.2132224,"The open access movement has highlighted the barriers that exist for users to gain access to significant portions of the research literature. The open data approach seeks to extend the principles of open access to the data and code that supports the published scholarly record. Current metadata is inadequate to allow information researchers to evaluate claims made about data archiving practices. Assessing current archiving practice and understanding the impact of archiving policies requires improved metadata. We propose that information researchers create an infrastructure for the collection of metadata about data use in the research literature, and that infrastructure should itself be open. The availability of metadata on data use would enable the calculation of archiving indices, just as citation data enables the calculation of the h-index.",Proceedings of the 2012 IConference,2012,Research
A language for end-user web augmentation: Caring for producers and consumers alike,,"[""Oscar D\\'{\\i}az"", ""Crist\\'{o}bal Arellano"", 'Maider Azanza']",https://doi.org/10.1145/2460383.2460388,"Web augmentation is to the Web what augmented reality is to the physical world: layering relevant content/layout/navigation over the existing Web to customize the user experience. This is achieved through JavaScript (JS) using browser weavers (e.g., Greasemonkey). To date, over 43 million of downloads of Greasemonkey scripts ground the vitality of this movement. However, Web augmentation is hindered by being programming intensive and prone to malware. This prevents end-users from participating as both producers and consumers of scripts: producers need to know JS, consumers need to trust JS. This article aims at promoting end-user participation in both roles. The vision is for end-users to prosume (the act of simultaneously caring for producing and consuming) scripts as easily as they currently prosume their pictures or videos. Encouraging production requires more “natural” and abstract constructs. Promoting consumption calls for augmentation scripts to be easier to understand, share, and trust upon. To this end, we explore the use of Domain-Specific Languages (DSLs) by introducing Sticklet. Sticklet is an internal DSL on JS, where JS generality is reduced for the sake of learnability and reliability. Specifically, Web augmentation is conceived as fixing in existing web sites (i.e., the wall) HTML fragments extracted from either other sites or Web services (i.e., the stickers). Sticklet targets hobby programmers as producers, and computer literates as consumers. From a producer perspective, benefits are threefold. As a restricted grammar on top of JS, Sticklet expressions are domain oriented and more declarative than their JS counterparts, hence speeding up development. As syntactically correct JS expressions, Sticklet scripts can be installed as traditional scripts and hence, programmers can continue using existing JS tools. As declarative expressions, they are easier to maintain, and amenable for optimization. From a consumer perspective, domain specificity brings understandability (due to declarativeness), reliability (due to built-in security), and “consumability” (i.e., installation/enactment/sharing of Sticklet expressions are tuned to the shortage of time and skills of the target audience). Preliminary evaluations indicate that 77% of the subjects were able to develop new Sticklet scripts in less than thirty minutes while 84% were able to consume these scripts in less than ten minutes. Sticklet is available to download as a Mozilla add-on.",missing,2013,Research
Entity-linking interfaces in user-contributed content: preference and performance,,"['Xiao Dong', 'F. Harper', 'Joseph Konstan']",https://doi.org/10.1145/1978942.1979261,"The ability to embed links to other resources in user generated content can help authors create more useful and usable content. A variety of interfaces have emerged for entity-linking at popular online sites; such interfaces vary in the way that entity linking is initiated (in-band or out-of-band with respect to the message creation), the timing of entity resolution (interrupting or deferred), and the method of resolving the entity (auto-completion or search). Four interfaces mimicking popular entity linking websites were developed and tested. Results showed that out-of-band initiation (e.g., a link button) was faster to learn, but that in-band initiation performance improved with familiarity. Deferred search was disliked and led to worse performance. And auto-completion was generally preferred to search interfaces.",Proceedings of the SIGCHI Conference on Human Factors in Computing Systems,2011,Research
"The Augmented Web: Rationales, Opportunities, and Challenges on Browser-Side Transcoding",,"[""Oscar D\\'{\\i}az"", ""Crist\\'{o}bal Arellano""]",https://doi.org/10.1145/2735633,"Today’s web personalization technologies use approaches like user categorization, configuration, and customization but do not fully support individualized requirements. As a significant portion of our social and working interactions are migrating to the web, we can expect an increase in these kinds of minority requirements. Browser-side transcoding holds the promise of facilitating this aim by opening personalization to third parties through web augmentation (WA), realized in terms of extensions and userscripts. WA is to the web what augmented reality is to the physical world: to layer relevant content/layout/navigation over the existing web to improve the user experience. From this perspective, WA is not as powerful as web personalization since its scope is limited to the surface of the web. However, it permits this surface to be tuned by developers other than the sites’ webmasters. This opens up the web to third parties who might come up with imaginative ways of adapting the web surface for their own purposes. Its success is backed up by millions of downloads. This work looks at this phenomenon, delving into the “what,” the “why,” and the “what for” of WA, and surveys the challenges ahead for WA to thrive. To this end, we appraise the most downloaded 45 WA extensions for Mozilla Firefox and Google Chrome as well as conduct a systematic literature review to identify what quality issues received the most attention in the literature. The aim is to raise awareness about WA as a key enabler of the personal web and point out research directions.",missing,2015,Research
NLP support for faceted navigation in scholarly collections,,"['Marti Hearst', 'Emilia Stoica']",missing,"Hierarchical faceted metadata is a proven and popular approach to organizing information for navigation of information collections. More recently, digital libraries have begun to adopt faceted navigation for collections of scholarly holdings. A key impediment to further adoption is the need for the creation of subject-oriented faceted metadata. The Castanet algorithm was developed for the purpose of (semi) automated creation of such structures. This paper describes the application of Castanet to journal title content, and presents an evaluation suggesting its efficacy. This is followed by a discussion of areas for future work.",Proceedings of the 2009 Workshop on Text and Citation Analysis for Scholarly Digital Libraries,2009,Research
