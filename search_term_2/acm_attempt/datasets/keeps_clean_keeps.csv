Title,Notes,Relevant,Authors,Link,Abstract,Venue,Year,Type
Towards Green Recommender Systems: Investigating the Impact of Data Reduction on Carbon Footprint and Algorithm Performances,"training recommender systems with less data makes the suggestions
more diverse and less biase",Keep,"['Giuseppe Spillo', 'Allegra De Filippo', 'Cataldo Musto', 'Michela Milano', 'Giovanni Semeraro']",https://doi.org/10.1145/3640457.3688160,"This work investigates the path toward green recommender systems by examining the impact of data reduction on both model performance and carbon footprint. In the pursuit of developing energy-efficient recommender systems, we investigated whether and how reducing the training data impacts the performances of several representative recommendation models. In order to obtain a fair comparison, all the models were run based on the implementations available in a popular recommendation library, i.e., RecBole, and used the same experimental settings. Results indicate that: (a) data reduction can be a promising strategy to make recommender systems more sustainable, at the cost of a lower accuracy; (b) training recommender systems with less data makes the suggestions more diverse and less biased. Overall, this study contributes to the ongoing discourse on the development of recommendation models that meet the principles of SDGs, laying the groundwork for the adoption of more sustainable practices in the field.",Proceedings of the 18th ACM Conference on Recommender Systems,2024,Short
Towards Sustainability-aware Recommender Systems: Analyzing the Trade-off Between Algorithms Performance and Carbon Footprint,"results show that more sophisticated approaches
tend to reduce popularity bias (i.e., lower average popularity) and
increase the diversity of the recommendations.",Keep,"['Giuseppe Spillo', 'Allegra De Filippo', 'Cataldo Musto', 'Michela Milano', 'Giovanni Semeraro']",https://doi.org/10.1145/3604915.3608840,"In this paper, we present a comparative analysis of the trade-off between the performance of state-of-the-art recommendation algorithms and their environmental impact. In particular, we compared 18 popular recommendation algorithms in terms of both performance metrics (i.e., accuracy and diversity of the recommendations) as well as in terms of energy consumption and carbon footprint on three different datasets. In order to obtain a fair comparison, all the algorithms were run based on the implementations available in a popular recommendation library, i.e., RecBole, and used the same experimental settings. The outcomes of the experiments showed that the choice of the optimal recommendation algorithm requires a thorough analysis, since more sophisticated algorithms often led to tiny improvements at the cost of an exponential increase of carbon emissions. Through this paper, we aim to shed light on the problem of carbon footprint and energy consumption of recommender systems, and we make the first step towards the development of sustainability-aware recommendation algorithms.",Proceedings of the 17th ACM Conference on Recommender Systems,2023,Short
The Effect of Feedback Granularity on Recommender Systems Performance,higher feedback granularity were often connected with increased Item Coverage and APLT.,Keep,"['Ladislav Peska', 'Stepan Balcar']",https://doi.org/10.1145/3523227.3551479,"The main source of knowledge utilized in recommender systems (RS) is users’ feedback. While the usage of implicit feedback (i.e. user’s behavior statistics) is gaining in prominence, the explicit feedback (i.e. user’s ratings) remain an important data source. This is true especially for domains, where evaluation of an object does not require an extensive usage and users are well motivated to do so (e.g., video-on-demand services or library archives). So far, numerous rating schemes for explicit feedback have been proposed, ranging both in granularity and presentation style. There are several works studying the effect of rating’s scale and presentation on user’s rating behavior, e.g. willingness to provide feedback or various biases in rating behavior. Nonetheless, the effect of ratings granularity on RS performance remain largely under-researched. In this paper, we studied the combined effect of ratings granularity and supposed probability of feedback existence on various performance statistics of recommender systems. Results indicate that decreasing feedback granularity may lead to changes in RS’s performance w.r.t. nDCG for some recommending algorithms. Nonetheless, in most cases the effect of feedback granularity is surpassed by even a small decrease in feedback’s quantity. Therefore, our results corroborate the policy of many major real-world applications, i.e. preference of simpler rating schemes with the higher chance of feedback reception instead of finer-grained rating scenarios.",Proceedings of the 16th ACM Conference on Recommender Systems,2022,Short
Improving Collaborative Metric Learning with Efficient Negative Sampling,"The motivation is that due to the popularity bias in interaction data, popular items tend to be close together. A challenge is thus to push non-matching popular items farther away in the latent space. Spreading popular items apart could then help to reduce the popularity bias often witnessed in recommendation.",Keep,"['Viet-Anh Tran', 'Romain Hennequin', 'Jimena Royo-Letelier', 'Manuel Moussallam']",https://doi.org/10.1145/3331184.3331337,"Distance metric learning based on triplet loss has been applied with success in a wide range of applications such as face recognition, image retrieval, speaker change detection and recently recommendation with the Collaborative Metric Learning (CML) model. However, as we show in this article, CML requires large batches to work reasonably well because of a too simplistic uniform negative sampling strategy for selecting triplets. Due to memory limitations, this makes it difficult to scale in high-dimensional scenarios. To alleviate this problem, we propose here a 2-stage negative sampling strategy which finds triplets that are highly informative for learning. Our strategy allows CML to work effectively in terms of accuracy and popularity bias, even when the batch size is an order of magnitude smaller than what would be needed with the default uniform sampling. We demonstrate the suitability of the proposed strategy for recommendation and exhibit consistent positive results across various datasets.",Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval,2019,Short
Modeling the uniqueness of the user preferences for recommendation systems,Using an experimental evaluation with two real datasets we have studied various recommendation strategies and demonstrated the effectiveness of a recommendation strategy that trades between personalization and popularity according to the user’s uniqueness level.,Keep,"['Haggai Roitman', 'David Carmel', 'Yosi Mass', 'Iris Eiron']",https://doi.org/10.1145/2484028.2484102,"In this paper we propose a novel framework for modeling the uniqueness of the user preferences for recommendation systems. User uniqueness is determined by learning to what extent the user's item preferences deviate from those of an ""average user"" in the system. Based on this framework, we suggest three different recommendation strategies that trade between uniqueness and conformity. Using two real item datasets, we demonstrate the effectiveness of our uniqueness based recommendation framework.",Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval,2013,Short
Navigating Serendipity - An Experimental User Study On The Interplay of Trust and Serendipity In Recommender Systems,"Our findings indicate that while interface enhancements did not yield significant increases in trust, they did notably elevate serendipity ratings for previously unknown books.",Keep,"['Irina Nalis', 'Tobias Sippl', 'Thomas Kolb', 'Julia Neidhardt']",https://doi.org/10.1145/3631700.3664901,"Recommender systems play a crucial role in our daily lives, constantly evolving to meet the diverse needs of users. As the pursuit of improved user experiences continues, metrics such as serendipity have emerged within the realm of beyond-accuracy paradigms. However, integrating serendipitous recommendations presents complex challenges, necessitating a delicate balance between novelty, relevance, and user engagement. In this interdisciplinary experimental user study, we address these challenges within the context of a book recommender system. By investigating the impact of interface design changes on user trust, a key determinant of satisfaction with serendipitous recommendations, we measured trust levels for both individual recommended items and the recommender system as a whole. Our findings indicate that while interface enhancements did not yield significant increases in trust, they did notably elevate serendipity ratings for previously unknown books. These results highlight the intricate interplay between technical and psychological factors in the design of recommender systems, emphasizing the importance of human-centered approaches in the creation of more responsible AI applications. This research contributes to ongoing discussions surrounding user-centric recommendation systems and aligns with broader themes of digital humanism and responsible AI.","Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization",2024,Research
On the Effectiveness of Sampled Softmax Loss for Item Recommendation,"In this work, we aim at offering a better understanding of SSM for item recommendation. Specifically, we first theoretically reveal three model-agnostic advantages: (1) mitigating popularity bias, which is beneficial to long-tail recommendation",Keep,"['Jiancan Wu', 'Xiang Wang', 'Xingyu Gao', 'Jiawei Chen', 'Hongcheng Fu', 'Tianyu Qiu']",https://doi.org/10.1145/3637061,"The learning objective plays a fundamental role to build a recommender system. Most methods routinely adopt either pointwise (e.g., binary cross-entropy) or pairwise (e.g., BPR) loss to train the model parameters, while rarely pay attention to softmax loss, which assumes the probabilities of all classes sum up to 1, due to its computational complexity when scaling up to large datasets or intractability for streaming data where the complete item space is not always available. The sampled softmax (SSM) loss emerges as an efficient substitute for softmax loss. Its special case, InfoNCE loss, has been widely used in self-supervised learning and exhibited remarkable performance for contrastive learning. Nonetheless, limited recommendation work uses the SSM loss as the learning objective. Worse still, none of them explores its properties thoroughly and answers “Does SSM loss suit for item recommendation?” and “What are the conceptual advantages of SSM loss, as compared with the prevalent losses?”, to the best of our knowledge.In this work, we aim at offering a better understanding of SSM for item recommendation. Specifically, we first theoretically reveal three model-agnostic advantages: (1) mitigating popularity bias, which is beneficial to long-tail recommendation; (2) mining hard negative samples, which offers informative gradients to optimize model parameters; and (3) maximizing the ranking metric, which facilitates top-K performance. However, based on our empirical studies, we recognize that the default choice of cosine similarity function in SSM limits its ability in learning the magnitudes of representation vectors. As such, the combinations of SSM with the models that also fall short in adjusting magnitudes (e.g., matrix factorization) may result in poor representations. One step further, we provide mathematical proof that message passing schemes in graph convolution networks can adjust representation magnitude according to node degree, which naturally compensates for the shortcoming of SSM. Extensive experiments on four benchmark datasets justify our analyses, demonstrating the superiority of SSM for item recommendation. Our implementations are available in both TensorFlow1 and PyTorch.2",missing,2024,Research
Modeling User Repeat Consumption Behavior for Online Novel Recommendation,"That is, these models has the popularity bias problem [ 6 ]. Consequently, new novels have slight chances to be recommended, resulting in small new part of MRR@1 scores.",Keep,"['Yuncong Li', 'Cunxiang Yin', 'yancheng he', 'Guoqiang Xu', 'Jing Cai', 'leeven luo', 'Sheng-hua Zhong']",https://doi.org/10.1145/3523227.3546762,"Given a user’s historical interaction sequence, online novel recommendation suggests the next novel the user may be interested in. Online novel recommendation is important but underexplored. In this paper, we concentrate on recommending online novels to new users of an online novel reading platform, whose first visits to the platform occurred in the last seven days. We have two observations about online novel recommendation for new users. First, repeat novel consumption of new users is a common phenomenon. Second, interactions between users and novels are informative. To accurately predict whether a user will reconsume a novel, it is crucial to characterize each interaction at a fine-grained level. Based on these two observations, we propose a neural network for online novel recommendation, called NovelNet. NovelNet can recommend the next novel from both the user’s consumed novels and new novels simultaneously. Specifically, an interaction encoder is used to obtain accurate interaction representation considering fine-grained attributes of interaction, and a pointer network with a pointwise loss is incorporated into NovelNet to recommend previously-consumed novels. Moreover, an online novel recommendation dataset is built from a well-known online novel reading platform and is released for public use as a benchmark. Experimental results on the dataset demonstrate the effectiveness of NovelNet 1.",Proceedings of the 16th ACM Conference on Recommender Systems,2022,Research
Graph Masked Autoencoder for Sequential Recommendation,Hmmm,Keep,"['Yaowen Ye', 'Lianghao Xia', 'Chao Huang']",https://doi.org/10.1145/3539618.3591692,"While some powerful neural network architectures (e.g., Transformer, Graph Neural Networks) have achieved improved performance in sequential recommendation with high-order item dependency modeling, they may suffer from poor representation capability in label scarcity scenarios. To address the issue of insufficient labels, Contrastive Learning (CL) has attracted much attention in recent methods to perform data augmentation through embedding contrasting for self-supervision. However, due to the hand-crafted property of their contrastive view generation strategies, existing CL-enhanced models i) can hardly yield consistent performance on diverse sequential recommendation tasks; ii) may not be immune to user behavior data noise. In light of this, we propose a simple yet effective Graph Masked AutoEncoder-enhanced sequential Recommender system (MAERec) that adaptively and dynamically distills global item transitional information for self-supervised augmentation. It naturally avoids the above issue of heavy reliance on constructing high-quality embedding contrastive views. Instead, an adaptive data reconstruction paradigm is designed to be integrated with the long-range item dependency modeling, for informative augmentation in sequential recommendation. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baseline models and can learn more accurate representations against data noise and sparsity. Our implemented model code is available at https://github.com/HKUDS/MAERec.",Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval,2023,Research
ReuseKNN: Neighborhood Reuse for Differentially Private KNN-Based Recommendations,"Additionally, the nature of neighborhood reuse may raise concerns that the generated recommendations are biased towards items consumed by many users, i.e., popular items. Thus, we investigate whether the proposed approach is more or less prone to item popularity bias than the baselines.",Keep,"['Peter M\\""{u}llner', 'Elisabeth Lex', 'Markus Schedl', 'Dominik Kowald']",https://doi.org/10.1145/3608481,"User-based KNN recommender systems (UserKNN) utilize the rating data of a target user’s k nearest neighbors in the recommendation process. This, however, increases the privacy risk of the neighbors, since the recommendations could expose the neighbors’ rating data to other users or malicious parties. To reduce this risk, existing work applies differential privacy by adding randomness to the neighbors’ ratings, which unfortunately reduces the accuracy of UserKNN. In this work, we introduce ReuseKNN, a novel differentially private KNN-based recommender system. The main idea is to identify small but highly reusable neighborhoods so that (i) only a minimal set of users requires protection with differential privacy and (ii) most users do not need to be protected with differential privacy since they are only rarely exploited as neighbors. In our experiments on five diverse datasets, we make two key observations. Firstly, ReuseKNN requires significantly smaller neighborhoods and, thus, fewer neighbors need to be protected with differential privacy compared with traditional UserKNN. Secondly, despite the small neighborhoods, ReuseKNN outperforms UserKNN and a fully differentially private approach in terms of accuracy. Overall, ReuseKNN leads to significantly less privacy risk for users than in the case of UserKNN.",missing,2023,Research
Causality-driven User Modeling for Sequential Recommendations over Time,"In conclusion, our causality-driven user modeling approach for sequential recommendation notably improves prediction accuracy and reduces bias.",Keep,"['Xingming Chen', 'Qing Li']",https://doi.org/10.1145/3589335.3651896,"Contemporary sequential recommendation systems predominantly leverage statistical correlations derived from user interaction histories to predict future preferences. However, these correlations often mask implicit challenges. On the one hand, user data is frequently plagued by implicit, noisy feedback, misdirecting users towards items that fail to align with their actual interests, which is magnified in sequential recommendation contexts. On the other hand, prevalent methods tend to over-rely on similarity-based attention mechanisms across item pairs, which are prone to utilizing heuristic shortcuts, thereby leading to suboptimal recommendation.To tackle these issues, we put forward a causality-driven user modeling approach for sequential recommendation, which pivots towards a causal perspective. Specifically, we involves the application of a causal graph to identify confounding factors that give rise to spurious correlations and to isolate conceptual variables that causally encapsulate user preferences. By learning the representation of these disentangled causal variables at the conceptual level, we can distinguish between causal and non-causal associations while preserving the inherent sequential nature of user behaviors. This enables us to ascertain which elements are critical and which may induce unintended biases. The framework of our method can be compatible with various mainstream sequential models, which offers a robust foundation for reconstructing more accurate and meaningful user and item representations driven by causality.",Companion Proceedings of the ACM Web Conference 2024,2024,Research
Batch-Mix Negative Sampling for Learning Recommendation Retrievers,"We integrate the popularity into the mixing coefficient for adapting to the sampled softmax loss, with the aim of reducing the sample selection bias, after which a loss function containing inbatch samples and generated samples is utilized for optimization.",Keep,"['Yongfu Fan', 'Jin Chen', 'Yongquan Jiang', 'Defu Lian', 'Fangda Guo', 'Kai Zheng']",https://doi.org/10.1145/3583780.3614789,"Recommendation retrievers commonly retrieve user potentially preferred items from numerous items, where the query and item representation are learned according to the dual encoders with the log-softmax loss. Under real scenarios, the number of items becomes considerably large, making it exceedingly difficult to calculate the partition function with the whole item corpus. Negative sampling, which samples a subset from the item corpus, is widely used to accelerate the model training. Among different samplers, the in-batch sampling is commonly adopted for online recommendation retrievers, which regards the other items within the mini-batch as the negative samples for the given query, owing to its time and memory efficiency. However, the sample selection bias occurs due to the skewed feedback, harming the retrieval quality. In this paper, we propose a negative sampling approach named Batch-Mix Negative Sampling (BMNS), which adopts batch mixing operation to generate additional negatives for model training. Concretely, BMNS first generates new negative items with the sampled mix coefficient from the Beta distribution, after which a tailored correct strategy guided by frequency is designed to match the sampled softmax loss. In this way, the effort of re-encoding items out of the mini-batch is reduced while also improving the representation space of the negative set. The empirical experiments on four real-world datasets demonstrate BMNS is superior to the competitive negative inbatch sampling method.",Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,2023,Research
User Cold-start Problem in Multi-armed Bandits: When the First Recommendations Guide the User’s Experience,"hus, current parametric bandit algorithms are making first recommendations based on a random sampling of the items (i.e., a pure-exploration) or a biased selection of the most popular ones (i.e., a pureexploitation).",Keep,"['Nicollas Silva', 'Thiago Silva', 'Heitor Werneck', 'Leonardo Rocha', 'Adriano Pereira']",https://doi.org/10.1145/3554819,"Nowadays, Recommender Systems have played a crucial role in several entertainment scenarios by making personalised recommendations and guiding the entire users’ journey from their first interaction. Recent works have addressed it as a Contextual Bandit by providing a sequential decision model to explore items not tried yet (or not tried enough) or exploit the best options learned so far. However, this work noticed these current algorithms are limited to naive non-personalised approaches in the first interactions of a new user, offering random or most popular items. Through experiments in three domains, we identify a negative impact of these first choices. Our study indicates that the bandit performance is directly related to the choices made in the first trials. Then, we propose a new approach to balance exploration and exploitation in the first interactions and handle these drawbacks. This approach is based on the Active Learning theory to catch more information about the new users and improve their long-term experience. Our idea is to explore the potential information gain of items that can also please the user’s taste. This method is named Warm-Starting Contextual Bandits, and it statistically outperforms 10 benchmarks in the literature in the long run.",missing,2023,Research
Inductive Modeling for Realtime Cold Start Recommendations,Experiments on both public datasets and industry applications demonstrate that IHM can significantly outperform baselines in recommending fresh and long-tail contents.,Keep,"['Chandler Zuo', 'Jonathan Castaldo', 'Hanqing Zhu', 'Haoyu Zhang', 'Ji Liu', 'Yangpeng Ou', 'Xiao Kong']",https://doi.org/10.1145/3637528.3671588,"In recommendation systems, the timely delivery of new content to their relevant audiences is critical for generating a growing and high quality collection of content for all users. The nature of this problem requires retrieval models to be able to make inferences in real time and with high relevance. There are two specific challenges for cold start contents. First, the information loss problem in a standard Two Tower model, due to the limited feature interactions between the user and item towers, is exacerbated for cold start items due to training data sparsity. Second, the huge volume of user-generated content in industry applications today poses a big bottleneck in the end-to-end latency of recommending new content. To overcome the two challenges, we propose a novel architecture, the Item History Model (IHM). IHM directly injects user-interaction information into the item tower to overcome information loss. In addition, IHM incorporates an inductive structure using attention-based pooling to eliminate the need for recurring training, a key bottleneck for the real-timeness. On both public and industry datasets, we demonstrate that IHM can not only outperform baselines in recommending cold start contents, but also achieves SoTA real-timeness in industry applications.",Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,2024,Research
Post-hoc Selection of Pareto-Optimal Solutions in Search and Recommendation,"we proposed PDU, a novel, theoretically-justified posthoc technique to select one—best—Pareto-optimal solution among the ones lying in the Pareto frontier in search and recommendation scenarios (Savvina: APLT)",Keep,"['Vincenzo Paparella', 'Vito Anelli', 'Franco Nardini', 'Raffaele Perego', 'Tommaso Di Noia']",https://doi.org/10.1145/3583780.3615010,"Information Retrieval (IR) and Recommender Systems (RSs) tasks are moving from computing a ranking of final results based on a single metric to multi-objective problems. Solving these problems leads to a set of Pareto-optimal solutions, known as Pareto frontier, in which no objective can be further improved without hurting the others. In principle, all the points on the Pareto frontier are potential candidates to represent the best model selected with respect to the combination of two, or more, metrics. To our knowledge, there are no well-recognized strategies to decide which point should be selected on the frontier in IR and RSs. In this paper, we propose a novel, post-hoc, theoretically-justified technique, named ""Population Distance from Utopia"" (PDU), to identify and select the one-best Pareto-optimal solution. PDU considers fine-grained utopia points, and measures how far each point is from its utopia point, allowing to select solutions tailored to user preferences, a novel feature we call ""calibration"". We compare PDU against state-of-the-art strategies through extensive experiments on tasks from both IR and RS, showing that PDU combined with calibration notably impacts the solution selection.",Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,2023,Research
Challenging the Myth of Graph Collaborative Filtering: a Reasoned and Reproducibility-driven Analysis,"Thus, the study introduces and analyzes the information flow in the graph and discovers that 2-hop information (combining user activeness and item popularity) is a valid indicator of CF behavior and could motivate the recommendation performance.",Keep,"['Vito Anelli', 'Daniele Malitesta', 'Claudio Pomo', 'Alejandro Bellogin', 'Eugenio Di Sciascio', 'Tommaso Di Noia']",https://doi.org/10.1145/3604915.3609489,"The success of graph neural network-based models (GNNs) has significantly advanced recommender systems by effectively modeling users and items as a bipartite, undirected graph. However, many original graph-based works often adopt results from baseline papers without verifying their validity for the specific configuration under analysis. Our work addresses this issue by focusing on the replicability of results. We present a code that successfully replicates results from six popular and recent graph recommendation models (NGCF, DGCF, LightGCN, SGL, UltraGCN, and GFCF) on three common benchmark datasets (Gowalla, Yelp 2018, and Amazon Book). Additionally, we compare these graph models with traditional collaborative filtering models that historically performed well in offline evaluations. Furthermore, we extend our study to two new datasets (Allrecipes and BookCrossing) that lack established setups in existing literature. As the performance on these datasets differs from the previous benchmarks, we analyze the impact of specific dataset characteristics on recommendation accuracy. By investigating the information flow from users’ neighborhoods, we aim to identify which models are influenced by intrinsic features in the dataset structure. The code to reproduce our experiments is available at:&nbsp;https://github.com/sisinflab/Graph-RSs-Reproducibility.",Proceedings of the 17th ACM Conference on Recommender Systems,2023,Research
Revisiting Neural Retrieval on Accelerators,"This new formulation is expressive, capable of modeling high rank (user, item) interactions, and further generalizes to the long tai",Keep,"['Jiaqi Zhai', 'Zhaojie Gong', 'Yueming Wang', 'Xiao Sun', 'Zheng Yan', 'Fu Li', 'Xing Liu']",https://doi.org/10.1145/3580305.3599897,"Retrieval finds a small number of relevant candidates from a large corpus for information retrieval and recommendation applications. A key component of retrieval is to model (user, item) similarity, which is commonly represented as the dot product of two learned embeddings. This formulation permits efficient inference, commonly known as Maximum Inner Product Search (MIPS). Despite its popularity, dot products cannot capture complex user-item interactions, which are multifaceted and likely high rank. We hence examine non-dot-product retrieval settings on accelerators, and propose mixture of logits (MoL), which models (user, item) similarity as an adaptive composition of elementary similarity functions. This new formulation is expressive, capable of modeling high rank (user, item) interactions, and further generalizes to the long tail. When combined with a hierarchical retrieval strategy, h-indexer, we are able to scale up MoL to 100M corpus on a single GPU with latency comparable to MIPS baselines. On public datasets, our approach leads to uplifts of up to 77.3% in hit rate (HR). Experiments on a large recommendation surface at Meta showed strong metric gains and reduced popularity bias, validating the proposed approach's performance and improved generalization.",Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,2023,Research
Unifying Explicit and Implicit Feedback for Rating Prediction and Ranking Recommendation Tasks,The key aspects of the proposed model is that (1) it is applied at the level of data pre-processing and (2) it increases the representation of less popular items in recommendations while maintaining reasonable recommendation performance.,Keep,"['Amir Jadidinejad', 'Craig Macdonald', 'Iadh Ounis']",https://doi.org/10.1145/3341981.3344225,"The two main tasks addressed by collaborative filtering approaches are rating prediction and ranking. Rating prediction models leverage explicit feedback (e.g. ratings), and aim to estimate the rating a user would assign to an unseen item. In contrast, ranking models leverage implicit feedback (e.g. clicks) in order to provide the user with a personalized ranked list of recommended items. Several previous approaches have been proposed that learn from both explicit and implicit feedback to optimize the task of ranking or rating prediction at the level of recommendation algorithm. Yet we argue that these two tasks are not completely separate, but are part of a unified process: a user first interacts with a set of items and then might decide to provide explicit feedback on a subset of items. We propose to bridge the gap between the tasks of rating prediction and ranking through the use of a novel weak supervision approach that unifies both explicit and implicit feedback datasets. The key aspects of the proposed model is that (1) it is applied at the level of data pre-processing and (2) it increases the representation of less popular items in recommendations while maintaining reasonable recommendation performance. Our experimental results - on six datasets covering different types of heterogeneous user's interactions and using a wide range of evaluation metrics - show that, our proposed approach can effectively combine explicit and implicit feedback and improve the effectiveness of the baseline explicit model on the ranking task by covering a broader range of long-tail items.",Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval,2019,Research
"Updatable, Accurate, Diverse, and Scalable Recommendations for Interactive Applications",e show empirically that RP 3 β provides accurate recommendations with high long-tail item frequency at the top of the recommendation list.,Keep,"['Bibek Paudel', 'Fabian Christoffel', 'Chris Newell', 'Abraham Bernstein']",https://doi.org/10.1145/2955101,"Recommender systems form the backbone of many interactive systems. They incorporate user feedback to personalize the user experience typically via personalized recommendation lists. As users interact with a system, an increasing amount of data about a user’s preferences becomes available, which can be leveraged for improving the systems’ performance. Incorporating these new data into the underlying recommendation model is, however, not always straightforward. Many models used by recommender systems are computationally expensive and, therefore, have to perform offline computations to compile the recommendation lists. For interactive applications, it is desirable to be able to update the computed values as soon as new user interaction data is available: updating recommendations in interactive time using new feedback data leads to better accuracy and increases the attraction of the system to the users. Additionally, there is a growing consensus that accuracy alone is not enough and user satisfaction is also dependent on diverse recommendations.In this work, we tackle this problem of updating personalized recommendation lists for interactive applications in order to provide both accurate and diverse recommendations. To that end, we explore algorithms that exploit random walks as a sampling technique to obtain diverse recommendations without compromising on efficiency and accuracy. Specifically, we present a novel graph vertex ranking recommendation algorithm called RP3β that reranks items based on three-hop random walk transition probabilities. We show empirically that RP3β provides accurate recommendations with high long-tail item frequency at the top of the recommendation list. We also present approximate versions of RP3β and the two most accurate previously published vertex ranking algorithms based on random walk transition probabilities and show that these approximations converge with an increasing number of samples.To obtain interactively updatable recommendations, we additionally show how our algorithm can be extended for online updates at interactive speeds. The underlying random walk sampling technique makes it possible to perform the updates without having to recompute the values for the entire dataset.In an empirical evaluation with three real-world datasets, we show that RP3β provides highly accurate and diverse recommendations that can easily be updated with newly gathered information at interactive speeds (≪ 100ms).",missing,2016,Research
Improving Graph Collaborative Filtering with Directional Behavior Enhanced Contrastive Learning, Does the proposed BDCL model perform better for long-tail data? Why?,Keep,"['Penghang Yu', 'Bing-Kun Bao', 'Zhiyi Tan', 'Guanming Lu']",https://doi.org/10.1145/3663574,"Graph Collaborative Filtering is a widely adopted approach for recommendation, which captures similar behavior features through Graph Neural Network (GNN). Recently, Contrastive Learning (CL) has been demonstrated as an effective method to enhance the performance of graph collaborative filtering. Typically, CL-based methods first perturb users’ history behavior data (e.g., drop clicked items), then construct a self-discriminating task for behavior representations under different random perturbations. However, for widely existing inactive users, random perturbation makes their sparse behavior information more incomplete, thereby harming the behavior feature extraction. To tackle the above issue, we design a novel directional perturbation-based CL method to improve the graph collaborative filtering performance. The idea is to perturb node representations through directionally enhancing behavior features. To do so, we propose a simple yet effective feedback mechanism, which fuses the representations of nodes based on behavior similarity. Then, to avoid irrelevant behavior preferences introduced by the feedback mechanism, we construct a behavior self-contrast task before and after feedback, to align the node representations between the final output and the first layer of GNN. Different from the widely adopted self-discriminating task, the behavior self-contrast task avoids complex message propagation on different perturbed graphs, which is more efficient than previous methods. Extensive experiments on three public datasets demonstrate that the proposed method has distinct advantages over other CL methods on recommendation accuracy.",missing,2024,Research
Triangle Graph Interest Network for Click-through Rate Prediction,"Besides, those works are more biased towards popular or similar commodities.",Keep,"['Wensen Jiang', 'Yizhu Jiao', 'Qingqin Wang', 'Chuanming Liang', 'Lijie Guo', 'Yao Zhang', 'Zhijun Sun', 'Yun Xiong', 'Yangyong Zhu']",https://doi.org/10.1145/3488560.3498458,"Click-through rate prediction is a critical task in online advertising. Currently, many existing methods attempt to extract user potential interests from historical click behavior sequences. However, it is difficult to handle sparse user behaviors or broaden interest exploration. Recently, some researchers incorporate the item-item co-occurrence graph as an auxiliary. Due to the elusiveness of user interests, those works still fail to determine the real motivation of user click behaviors. Besides, those works are more biased towards popular or similar commodities. They lack an effective mechanism to break the diversity restrictions. In this paper, we point out two special properties of triangles in the item-item graphs for recommendation systems: Intra-triangle homophily and Inter-triangle heterophiy. Based on this, we propose a novel and effective framework named Triangle Graph Interest Network (TGIN). For each clicked item in user behavior sequences, we introduce the triangles in its neighborhood of the item-item graphs as a supplement. TGIN regards these triangles as the basic units of user interests, which provide the clues to capture the real motivation for a user clicking an item. We characterize every click behavior by aggregating the information of several interest units to alleviate the elusive motivation problem. The attention mechanism determines users' preference for different interest units. By selecting diverse and relative triangles, short brings in novel and serendipitous items to expand exploration opportunities of user interests. Then, we aggregate the multi-level interests of historical behavior sequences to improve CTR prediction. Extensive experiments on both of public and industrial datasets clearly verify the effectiveness of our framework.",Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining,2022,Research
"Complexities associated with user-generated book reviews in digital libraries: temporal, cultural, and political case studies","All these books are subject to selection bias and historical biases in literary history (e.g., classism, sexism, racism, colonialism), which poses questions about the inclusiveness and representativeness of prior DH studies on book reviews.",Keep,"['Yuerong Hu', 'Zoe LeBlanc', 'Jana Diesner', 'Ted Underwood', 'Glen Layne-Worthey', 'J. Downie']",https://doi.org/10.1145/3529372.3530930,"While digital libraries (DL) have made large-scale collections of digitized books increasingly available to researchers [31, 67], there remains a dearth of similar data provisions or infrastructure for computational studies of the consumption and reception of books. In the last two decades, user-generated book reviews on social media have opened up unprecedented research possibilities for humanities and social sciences (HSS) scholars who are interested in book reception. However, limitations and gaps have emerged from existing DH research which utilize social media data for answering HSS questions. To shed light on the under-investigated features of user-generated book reviews and the challenges they might pose to scholarly research, we conducted three exemplar cases studies: (1) a longitudinal analysis for profiling the temporal changes of ratings and popularity of 552 books across ten years; (2) a cross-cultural comparison of book ratings of the same 538 books across two platforms; and, (3) a classification experiment on 20,000 sponsored and non-sponsored books reviews. Correspondingly, our research reveals the real-world complexities and under-investigated features of user-generated book reviews in three dimensions: the transience of book ratings and popularity (temporal dimension), the cross-cultural differences in reading interests and book reception (cultural dimension), and the user power dynamics behind the publicly accessible reviews (""political"" dimension). Our case studies also demonstrate the challenges posed by user-generated book reviews' real-world complexities to their scholarly usage and propose solutions to these challenges. We conclude that DL stakeholders and scholars working with user-generated book reviews should look into these under-investigated features and real-world challenges to evaluate and improve the scholarly usability and interpretability of their data.",Proceedings of the 22nd ACM/IEEE Joint Conference on Digital Libraries,2022,Research
HybridSVD: when collaborative information is not enough,"ur results suggest that, in the standard scenario, debiasing data is often more important than adding side information.",Keep,"['Evgeny Frolov', 'Ivan Oseledets']",https://doi.org/10.1145/3298689.3347055,"We propose a new hybrid algorithm that allows incorporating both user and item side information within the standard collaborative filtering technique. One of its key features is that it naturally extends a simple PureSVD approach and inherits its unique advantages, such as highly efficient Lanczos-based optimization procedure, simplified hyper-parameter tuning and a quick folding-in computation for generating recommendations instantly even in highly dynamic online environments. The algorithm utilizes a generalized formulation of the singular value decomposition, which adds flexibility to the solution and allows imposing the desired structure on its latent space. Conveniently, the resulting model also admits an efficient and straightforward solution for the cold start scenario. We evaluate our approach on a diverse set of datasets and show its superiority over similar classes of hybrid models.",Proceedings of the 13th ACM Conference on Recommender Systems,2019,Research
Offline Retrieval Evaluation Without Evaluation Metrics,"Moreover, they demonstrate the ability to adapt RPP to different scenarios (e.g. position bias, novelty).",Keep,"['Fernando Diaz', 'Andres Ferraro']",https://doi.org/10.1145/3477495.3532033,"Offline evaluation of information retrieval and recommendation has traditionally focused on distilling the quality of a ranking into a scalar metric such as average precision or normalized discounted cumulative gain. We can use this metric to compare the performance of multiple systems for the same request. Although evaluation metrics provide a convenient summary of system performance, they also collapse subtle differences across users into a single number and can carry assumptions about user behavior and utility not supported across retrieval scenarios. We propose recall-paired preference (RPP), a metric-free evaluation method based on directly computing a preference between ranked lists. RPP simulates multiple user subpopulations per query and compares systems across these pseudo-populations. Our results across multiple search and recommendation tasks demonstrate that RPP substantially improves discriminative power while correlating well with existing metrics and being equally robust to incomplete data.",Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval,2022,Research
Spectral Relaxations and Fair Densest Subgraphs,"Reducing hidden bias in the data and ensuring fairness in algorithmic data analysis has recently received significant attention. In this paper, we address the problem of identifying a densest subgraph, while ensuring that none of one binary protected attribute is disparately impacted.",Keep,"['Aris Anagnostopoulos', 'Luca Becchetti', 'Adriano Fazzone', 'Cristina Menghini', 'Chris Schwiegelshohn']",https://doi.org/10.1145/3340531.3412036,"Reducing hidden bias in the data and ensuring fairness in algorithmic data analysis has recently received significant attention. In this paper, we address the problem of identifying a densest subgraph, while ensuring that none of one binary protected attribute is disparately impacted.Unfortunately, the underlying algorithmic problem is NP-hard, even in its approximation version: approximating the densest fair subgraph with a polynomial-time algorithm is at least as hard as the densest subgraph problem of at most k vertices, for which no constant approximation algorithms are known.Despite such negative premises, we are able to provide approximation results in two important cases. In particular, we are able to prove that a suitable spectral embedding allows recovery of an almost optimal, fair, dense subgraph hidden in the input data, whenever one is present, a result that is further supported by experimental evidence. We also show a polynomial-time, $2$-approximation algorithm, whenever the underlying graph is itself fair. We finally prove that, under the small set expansion hypothesis, this result is tight for fair graphs.The above theoretical findings drive the design of heuristics, which we experimentally evaluate on a scenario based on real data, in which our aim is to strike a good balance between diversity and highly correlated items from Amazon co-purchasing graphs.",Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,2020,Research
Understanding book search behavior on the web,"In this work, we analyze web-based book search behavior
using three months of logs from the Open Library, a globally
accessible digital library.",Keep,"['Jin Kim', 'Henry Feild', 'Marc Cartright']",https://doi.org/10.1145/2396761.2396856,"With the increased availability of e-books and digitized book collections, more users are searching the web for information about books. There are many online digital libraries containing book, author and subject data, which are accessed via internal search services as well as external web sites, such as Google. Although this is a common yet complex information-seeking behavior involving multiple search systems with different characteristics, little is known about how users find information in this scenario.In this work, we analyze web-based book search behavior using three months of logs from the Open Library, a globally accessible digital library. Our study encompasses the user behavior on web search engines and the digital library, unlike previous work which focused on institution-level digital libraries. Among our findings are (1) query characteristics and session-level behaviors are drastically different between internal and external searchers; (2) the field usage is different based on the modes of interaction---keyword search, advanced search interface and faceted filtering; (3) users go through with more iterations of faceted filtering than query reformulation. To facilitate future research on book search, we also create a book search test collection based on the log data. We then perform an evaluation of several retrieval methods, finding that field-based retrieval models have advantages over document-based models.",Proceedings of the 21st ACM International Conference on Information and Knowledge Management,2012,Research
