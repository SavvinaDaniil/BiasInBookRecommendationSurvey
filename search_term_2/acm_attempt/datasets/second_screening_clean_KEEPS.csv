Title,Notes,Relevant,Authors,Link,Abstract,Venue,Year,Type
User Perceptions of Diversity in Recommender Systems,"We investigate user responses to recommendation lists generated using varied diversity metrics but identical diversification thresholds, and lists created with the same metrics but differing thresholds. goodbooks.",Keep,"['Patrik Dokoupil', 'Ludovico Boratto', 'Ladislav Peska']",https://doi.org/10.1145/3627043.3659555,"In the context of recommender systems (RS), the concept of diversity is probably the most studied perspective beyond mere accuracy. Despite the extensive development of diversity measures and enhancement methods, the understanding of how users perceive diversity in recommendations remains limited. This gap hinders progress in multi-objective RS, as it challenges the alignment of algorithmic advancements with genuine user needs. Addressing this, our study delves into two key aspects of diversity perception in RS. We investigate user responses to recommendation lists generated using varied diversity metrics but identical diversification thresholds, and lists created with the same metrics but differing thresholds. Our findings reveal a user preference for metadata and content-based diversity metrics over collaborative ones. Interestingly, while users typically recognize more diversified lists as being more diverse in scenarios with significant diversification differences, this perception is not consistently linear and quickly diminishes when the diversification variance between lists is less pronounced. This study sheds light on the nuanced user perceptions of diversity in RS, providing valuable insights for the development of more user-centric recommendation algorithms. Study data and analysis scripts are available from https://osf.io/9y8gx/.","Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization",2024,Research
Reconciling the Accuracy-Diversity Trade-off in Recommendations,"We study the accuracy-diversity trade-off by bringing in a third
concept: user utility. We argue that accuracy is misaligned with
user utility. Goodbooks. Nothing about bias :/",Keep,"['Kenny Peng', 'Manish Raghavan', 'Emma Pierson', 'Jon Kleinberg', 'Nikhil Garg']",https://doi.org/10.1145/3589334.3645625,"When making recommendations, there is an apparent trade-off between the goals of accuracy (to recommend items a user is most likely to want) and diversity (to recommend items representing a range of categories). As such, real-world recommender systems often explicitly incorporate diversity into recommendations, at the cost of accuracy.We study the accuracy-diversity trade-off by bringing in a third concept: user utility. We argue that accuracy is misaligned with user utility because it fails to incorporate a user's consumption constraints: at any given time, users can typically only use at most a few recommended items (e.g., dine at one restaurant, or watch a couple of movies). In a theoretical model, we show that utility-maximizing recommendations---when accounting for consumption constraints---are naturally diverse due to diminishing returns of recommending similar items. Therefore, while increasing diversity may come at the cost of accuracy, it can also help align accuracy-based recommendations toward the more fundamental objective of user utility. Our theoretical results yield practical guidance into how recommendations should incorporate diversity to serve user ends.",Proceedings of the ACM Web Conference 2024,2024,Research
Exploring Scenarios of Uncertainty about the Users' Preferences in Interactive Recommendation Systems,mitigate the impact of such scenarios. We modify three traditional bandits to recommend items with a higher potential to get more user information without decreasing the modelâ€™s accuracy when an uncertain scenario is observed. goodbooks,Keep,"[""N\\'{\\i}collas Silva"", 'Thiago Silva', 'Henrique Hott', 'Yan Ribeiro', 'Adriano Pereira', 'Leonardo Rocha']",https://dl.acm.org/doi/10.1145/3539618.3591684,"Interactive Recommender Systems have played a crucial role in distinct entertainment domains through a Contextual Bandit model. Despite the current advances, their personalisation level is still directly related to the information previously available about the users. However, there are at least two scenarios of uncertainty about the users' preferences over their journey: (1) when the user joins for the first time and (2) when the system continually makes wrong recommendations because of prior misleading assumptions. In this work, we introduce concepts from the Active Learning theory to mitigate the impact of such scenarios. We modify three traditional bandits to recommend items with a higher potential to get more user information without decreasing the model's accuracy when an uncertain scenario is observed. Our experiments show that the modified models outperform all baselines by increasing the cumulative reward in the long run. Moreover, a counterfactual evaluation validates that such improvements were not simply achieved due to the bias of offline datasets.",Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval,2023,Research
The Datasets Dilemma: How Much Do We Really Know About Recommendation Datasets?,"we adopt a systematic and comprehensive approach to understand the datasets used for implicit feedback based top-K recommendation. amazon books, goodreads etc.",Keep,"['Jin Chin', 'Yile Chen', 'Gao Cong']",https://doi.org/10.1145/3488560.3498519,"There has been sustained interest from both academia and industry throughout the years due to the importance and practicability of recommendation systems. However, several recent papers have pointed out critical issues with the evaluation process in recommender systems. Likewise, this paper takes an in-depth look at a fundamental but often neglected aspect of the evaluation procedure, i.e. the datasets themselves. To do so, we adopt a systematic and comprehensive approach to understand the datasets used for implicit feedback based top-K recommendation. We start by examining recent papers from top-tier conferences to find out how different datasets have been utilised thus far. Next, we look at the characteristics of these datasets to understand their similarities and differences. Finally, we conduct an empirical study to determine whether the choice of datasets used for evaluation can influence the observations and/or conclusions obtained. Our findings suggest that greater attention needs to be paid to the selection process of datasets used for evaluating recommender systems in order to improve the robustness of the obtained results.",Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining,2022,Research
On Sampling Collaborative Filtering Datasets,We study the practical consequences of dataset sampling strategies on the ranking performance of recommendation algorithms. goodreads comics,Keep,"['Noveen Sachdeva', 'Carole-Jean Wu', 'Julian McAuley']",https://doi.org/10.1145/3488560.3498439,"We study the practical consequences of dataset sampling strategies on the ranking performance of recommendation algorithms. Recommender systems are generally trained and evaluated on samples of larger datasets. Samples are often taken in a naive or ad-hoc fashion: e.g. by sampling a dataset randomly or by selecting users or items with many interactions. As we demonstrate, commonly-used data sampling schemes can have significant consequences on algorithm performance. Following this observation, this paper makes three main contributions: (1) characterizing the effect of sampling on algorithm performance, in terms of algorithm and dataset characteristics (e.g. sparsity characteristics, sequential dynamics, etc.); (2) designing SVP-CF, which is a data-specific sampling strategy, that aims to preserve the relative performance of models after sampling, and is especially suited to long-tailed interaction data; and (3) developing an oracle, DATA-GENIE, which can suggest the sampling scheme that is most likely to preserve model performance for a given dataset. The main benefit of DATA-GENIE is that it will allow recommender system practitioners to quickly prototype and compare various approaches, while remaining confident that algorithm performance will be preserved, once the algorithm is retrained and deployed on the complete data. Detailed experiments show that using DATA-GENIE, we can discard upto 5x more data than any sampling strategy with the same level of performance.",Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining,2022,Research
Closed-Loop Opinion Formation,we look at whether the use of recommender system can affect user experience and user opinions in a systematic way. bookcrossing,Keep,"['Larissa Spinelli', 'Mark Crovella']",https://doi.org/10.1145/3091478.3091483,"When information sources are moderated by recommender systems, so-called ""filter bubbles"" may restrict the diversity of content made available to users, potentially affecting their opinions. User opinions may in turn affect the output of recommender systems. In this work we ask how the dynamical system defined by user and recommender systems behaves, as each element evolves in time. In particular, we look at whether the use of recommender system can affect user experience and user opinions in a systematic way. We define and analyze three metrics to understand those effects - intensity, simplification, and divergence - and we explore both link-based and ratings-based recommender systems. Our results suggest that previous studies of this problem have been too simplistic, and that user opinions can evolve in complex ways under the influence of personalized information sources.",Proceedings of the 2017 ACM on Web Science Conference,2017,Research
Social book search: comparing topical relevance judgements and book suggestions for evaluation,"About forums vs mechanical turk suggestions of books, not automated rs. librarything",Keep,"['Marijn Koolen', 'Jaap Kamps', 'Gabriella Kazai']",https://doi.org/10.1145/2396761.2396788,"The Web and social media give us access to a wealth of information, not only different in quantity but also in character---traditional descriptions from professionals are now supplemented with user generated content. This challenges modern search systems based on the classical model of topical relevance and ad hoc search: How does their effectiveness transfer to the changing nature of information and to the changing types of information needs and search tasks? We use the INEX 2011 Books and Social Search Track's collection of book descriptions from Amazon and social cataloguing site LibraryThing. We compare classical IR with social book search in the context of the LibraryThing discussion forums where members ask for book suggestions. Specifically, we compare book suggestions on the forum with Mechanical Turk judgements on topical relevance and recommendation, both the judgements directly and their resulting evaluation of retrieval systems. First, the book suggestions on the forum are a complete enough set of relevance judgements for system evaluation. Second, topical relevance judgements result in a different system ranking from evaluation based on the forum suggestions. Although it is an important aspect for social book search, topical relevance is not sufficient for evaluation. Third, professional metadata alone is often not enough to determine the topical relevance of a book. User reviews provide a better signal for topical relevance. Fourth, user-generated content is more effective for social book search than professional metadata. Based on our findings, we propose an experimental evaluation that better reflects the complexities of social book search.",Proceedings of the 21st ACM International Conference on Information and Knowledge Management,2012,Research
Envisioning Information Access Systems: What Makes for Good Tools and a Healthy Web?,in this conceptual article we investigate fundamental questions concerning information access from user and societal viewpoints. ,Keep,"['Chirag Shah', 'Emily Bender']",https://doi.org/10.1145/3649468,"We observe a recent trend toward applying large language models (LLMs) in search and positioning them as effective information access systems. While the interfaces may look appealing and the apparent breadth of applicability is exciting, we are concerned that the field is rushing ahead with a technology without sufficient study of the uses it is meant to serve, how it would be used, and what its use would mean. We argue that it is important to reassert the central research focus of the field of information retrieval, because information access is not merely an application to be solved by the so-called â€˜AIâ€™ techniques du jour. Rather, it is a key human activity, with impacts on both individuals and society. As information scientists, we should be asking what do people and society want and need from information access systems and how do we design and build systems to meet those needs? With that goal, in this conceptual article we investigate fundamental questions concerning information access from user and societal viewpoints. We revisit foundational work related to information behavior, information seeking, information retrieval, information filtering, and information access to resurface what we know about these fundamental questions and what may be missing. We then provide our conceptual framing about how we could fill this gap, focusing on methods as well as experimental and evaluation frameworks. We consider the Web as an information ecosystem and explore the ways in which synthetic media, produced by LLMs and otherwise, endangers that ecosystem. The primary goal of this conceptual article is to shed light on what we still do not know about the potential impacts of LLM-based information access systems, how to advance our understanding of user behaviors, and where the next generations of students, scholars, and developers could fruitfully invest their energies.",missing,2024,Research
Open Knowledge Enrichment for Long-tail Entities,"we propose a full-fledged approach to knowledge enrichment, which predicts missing properties and infers true facts of long-tail entities from the open Web. goodreads(google?)",Keep,"['Ermei Cao', 'Difeng Wang', 'Jiacheng Huang', 'Wei Hu']",https://doi.org/10.1145/3366423.3380123,"Knowledge bases (KBs) have gradually become a valuable asset for many AI applications. While many current KBs are quite large, they are widely acknowledged as incomplete, especially lacking facts of long-tail entities, e.g., less famous persons. Existing approaches enrich KBs mainly on completing missing links or filling missing values. However, they only tackle a part of the enrichment problem and lack specific considerations regarding long-tail entities. In this paper, we propose a full-fledged approach to knowledge enrichment, which predicts missing properties and infers true facts of long-tail entities from the open Web. Prior knowledge from popular entities is leveraged to improve every enrichment step. Our experiments on the synthetic and real-world datasets and comparison with related work demonstrate the feasibility and superiority of the approach.",Proceedings of The Web Conference 2020,2020,Research
