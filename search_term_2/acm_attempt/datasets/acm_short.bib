@inproceedings{10.1145/3640457.3688160,
author = {Spillo, Giuseppe and De Filippo, Allegra and Musto, Cataldo and Milano, Michela and Semeraro, Giovanni},
title = {Towards Green Recommender Systems: Investigating the Impact of Data Reduction on Carbon Footprint and Algorithm Performances},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3688160},
doi = {10.1145/3640457.3688160},
abstract = {This work investigates the path toward green recommender systems by examining the impact of data reduction on both model performance and carbon footprint. In the pursuit of developing energy-efficient recommender systems, we investigated whether and how reducing the training data impacts the performances of several representative recommendation models. In order to obtain a fair comparison, all the models were run based on the implementations available in a popular recommendation library, i.e., RecBole, and used the same experimental settings. Results indicate that: (a) data reduction can be a promising strategy to make recommender systems more sustainable, at the cost of a lower accuracy; (b) training recommender systems with less data makes the suggestions more diverse and less biased. Overall, this study contributes to the ongoing discourse on the development of recommendation models that meet the principles of SDGs, laying the groundwork for the adoption of more sustainable practices in the field.},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {866–871},
numpages = {6},
keywords = {Carbon Footprint, Data Reduction, GreenAI, Recommender Systems},
location = {Bari, Italy},
series = {RecSys '24}
}

@inproceedings{10.1145/3604915.3608840,
author = {Spillo, Giuseppe and De Filippo, Allegra and Musto, Cataldo and Milano, Michela and Semeraro, Giovanni},
title = {Towards Sustainability-aware Recommender Systems: Analyzing the Trade-off Between Algorithms Performance and Carbon Footprint},
year = {2023},
isbn = {9798400702419},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604915.3608840},
doi = {10.1145/3604915.3608840},
abstract = {In this paper, we present a comparative analysis of the trade-off between the performance of state-of-the-art recommendation algorithms and their environmental impact. In particular, we compared 18 popular recommendation algorithms in terms of both performance metrics (i.e., accuracy and diversity of the recommendations) as well as in terms of energy consumption and carbon footprint on three different datasets. In order to obtain a fair comparison, all the algorithms were run based on the implementations available in a popular recommendation library, i.e., RecBole, and used the same experimental settings. The outcomes of the experiments showed that the choice of the optimal recommendation algorithm requires a thorough analysis, since more sophisticated algorithms often led to tiny improvements at the cost of an exponential increase of carbon emissions. Through this paper, we aim to shed light on the problem of carbon footprint and energy consumption of recommender systems, and we make the first step towards the development of sustainability-aware recommendation algorithms.},
booktitle = {Proceedings of the 17th ACM Conference on Recommender Systems},
pages = {856–862},
numpages = {7},
keywords = {carbon footprint, evaluation, non-accuracy metrics, recommender systems, sustainability},
location = {Singapore, Singapore},
series = {RecSys '23}
}

@inproceedings{10.1145/3640457.3688169,
author = {Xu, Lanling and Lin, Zihan and Wang, Jinpeng and Chen, Sheng and Zhao, Wayne Xin and Wen, Ji-Rong},
title = {Promoting Two-sided Fairness with Adaptive Weights for Providers and Customers in Recommendation},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3688169},
doi = {10.1145/3640457.3688169},
abstract = {At present, most recommender systems involve two stakeholders, providers and customers. Apart from maximizing the recommendation accuracy, the fairness issue for both sides should also be considered. Most of previous studies try to improve two-sided fairness with post-processing algorithms or fairness-aware loss constraints, which are highly dependent on the heuristic adjustments without respect to the optimization goal of accuracy. In contrast, we propose a novel training framework, adaptive weighting towards two-sided fairness-aware recommendation&nbsp;(named Ada2Fair), which lies in the extension of the accuracy-focused objective to a controllable preference learning loss over the interaction data. Specifically, we adjust the optimization scale of an interaction sample with an adaptive weight generator, and estimate the two-sided fairness-aware weights within model training. During the training process, the recommender is trained with two-sided fairness-aware weights to boost the utility of niche providers and inactive customers in a unified way. Extensive experiments on three public datasets verify the effectiveness of&nbsp;Ada2Fair, which can achieve Pareto efficiency in two-sided fairness-aware recommendation.},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {918–923},
numpages = {6},
keywords = {Fairness-aware Recommendation, Recommender Systems},
location = {Bari, Italy},
series = {RecSys '24}
}

@inproceedings{10.1145/3604915.3608851,
author = {Hasan, Tonmoy and Bunescu, Razvan},
title = {Topic-Level Bayesian Surprise and Serendipity for Recommender Systems},
year = {2023},
isbn = {9798400702419},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604915.3608851},
doi = {10.1145/3604915.3608851},
abstract = {A recommender system that optimizes its recommendations solely to fit a user’s history of ratings for consumed items can create a filter bubble, wherein the user does not get to experience items from novel, unseen categories. One approach to mitigate this undesired behavior is to recommend items with high potential for serendipity, namely surprising items that are likely to be highly rated. In this paper, we propose a content-based formulation of serendipity that is rooted in Bayesian surprise and use it to measure the serendipity of items after they are consumed and rated by the user. When coupled with a collaborative-filtering component that identifies similar users, this enables recommending items with high potential for serendipity. To facilitate the evaluation of topic-level models for surprise and serendipity, we introduce a dataset of book reading histories extracted from Goodreads, containing over 26 thousand users and close to 1.3 million books, where we manually annotate 449 books read by 4 users in terms of their time-dependent, topic-level surprise. Experimental evaluations show that models that use Bayesian surprise correlate much better with the manual annotations of topic-level surprise than distance-based heuristics, and also obtain better serendipitous item recommendation performance.},
booktitle = {Proceedings of the 17th ACM Conference on Recommender Systems},
pages = {933–939},
numpages = {7},
keywords = {non-stationary time series, surprise and serendipity, topic distributions.},
location = {Singapore, Singapore},
series = {RecSys '23}
}

@inproceedings{10.1145/3583780.3615181,
author = {Verma, Sahil and Singh, Ashudeep and Boonsanong, Varich and Dickerson, John P. and Shah, Chirag},
title = {RecRec: Algorithmic Recourse for Recommender Systems},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615181},
doi = {10.1145/3583780.3615181},
abstract = {Recommender systems play an essential role in the choices people make in domains such as entertainment, shopping, food, news, employment, and education. The machine learning models underlying these recommender systems are often enormously large and black-box in nature for users, content providers, and system developers alike. It is often crucial for all stakeholders to understand the model's rationale behind making certain predictions and recommendations. This is especially true for the content providers whose livelihoods depend on the recommender system. Drawing motivation from the practitioners' need, in this work, we propose a recourse framework for recommender systems, targeted towards the content providers. Algorithmic recourse in the recommendation setting is a set of actions that, if executed, would modify the recommendations (or ranking) of an item in the desired manner. A recourse suggests actions of the form: ''if a feature changes X to Y, then the ranking of that item for a set of users will change to X.'' Furthermore, we demonstrate that RecRec is highly effective in generating valid, sparse, and actionable recourses through an empirical evaluation of recommender systems trained on three real-world datasets. To the best of our knowledge, this work is the first to conceptualize and empirically test a generalized framework for generating recourses for recommender systems.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {4325–4329},
numpages = {5},
keywords = {algorithmic recourse, explainable recommender systems, recommender systems},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3523227.3551479,
author = {Peska, Ladislav and Balcar, Stepan},
title = {The Effect of Feedback Granularity on Recommender Systems Performance},
year = {2022},
isbn = {9781450392785},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3523227.3551479},
doi = {10.1145/3523227.3551479},
abstract = {The main source of knowledge utilized in recommender systems (RS) is users’ feedback. While the usage of implicit feedback (i.e. user’s behavior statistics) is gaining in prominence, the explicit feedback (i.e. user’s ratings) remain an important data source. This is true especially for domains, where evaluation of an object does not require an extensive usage and users are well motivated to do so (e.g., video-on-demand services or library archives). So far, numerous rating schemes for explicit feedback have been proposed, ranging both in granularity and presentation style. There are several works studying the effect of rating’s scale and presentation on user’s rating behavior, e.g. willingness to provide feedback or various biases in rating behavior. Nonetheless, the effect of ratings granularity on RS performance remain largely under-researched. In this paper, we studied the combined effect of ratings granularity and supposed probability of feedback existence on various performance statistics of recommender systems. Results indicate that decreasing feedback granularity may lead to changes in RS’s performance w.r.t. nDCG for some recommending algorithms. Nonetheless, in most cases the effect of feedback granularity is surpassed by even a small decrease in feedback’s quantity. Therefore, our results corroborate the policy of many major real-world applications, i.e. preference of simpler rating schemes with the higher chance of feedback reception instead of finer-grained rating scenarios.},
booktitle = {Proceedings of the 16th ACM Conference on Recommender Systems},
pages = {586–591},
numpages = {6},
keywords = {Explicit feedback granularity, Performance evaluation, Recommender systems},
location = {Seattle, WA, USA},
series = {RecSys '22}
}

@inproceedings{10.1145/3640457.3688181,
author = {Jamet, Henri and Manderlier, Maxime and Shrestha, Yash Raj and Vlachos, Michalis},
title = {Evaluation and simplification of text difficulty using LLMs in the context of recommending texts in French to facilitate language learning},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3688181},
doi = {10.1145/3640457.3688181},
abstract = {Learning a new language can be challenging. To help learners, we built a recommendation system that suggests texts and videos based on the learners’ skill level of the language and topic interests. Our system analyzes content to determine its difficulty and topic, and, if needed, can simplify complex texts while maintaining semantics. Our work explores the holistic use of Large Language Models (LLMs) for the various sub-tasks involved for accurate recommendations: difficulty estimation and simplification, graph recommender engine, topic estimation. We present a comprehensive evaluation comparing zero-shot and fine-tuned LLMs, demonstrating significant improvements in French content difficulty prediction (18-56%), topic prediction accuracy (27%), and recommendation relevance (up to 18% NDCG increase).},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {987–992},
numpages = {6},
keywords = {digital education, extensive reading, large language models, machine learning},
location = {Bari, Italy},
series = {RecSys '24}
}

@inproceedings{10.1145/3335783.3335809,
author = {Otunba, Rasaq and Rufai, Raimi A. and Lin, Jessica},
title = {Deep Stacked Ensemble Recommender},
year = {2019},
isbn = {9781450362160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3335783.3335809},
doi = {10.1145/3335783.3335809},
abstract = {Collaborative filtering techniques remain a staple in recommender systems research and applications. With the plethora of research done in recommender systems, some more recent works applied deep learning with great success. We stack a deep neural network recommender onto a shallow one for item recommendations in this work. Our experiments with popular datasets indicate that the proposed technique outperforms other state-of-the art techniques and baselines in key performance metrics.},
booktitle = {Proceedings of the 31st International Conference on Scientific and Statistical Database Management},
pages = {197–201},
numpages = {5},
keywords = {Deep neural networks, personalization, ranking, recommendations},
location = {Santa Cruz, CA, USA},
series = {SSDBM '19}
}

@inproceedings{10.1145/3604915.3608827,
author = {Spi\v{s}\'{a}k, Martin and Bartyzal, Radek and Hoskovec, Anton\'{\i}n and Peska, Ladislav and T\r{u}ma, Miroslav},
title = {Scalable Approximate NonSymmetric Autoencoder for Collaborative Filtering},
year = {2023},
isbn = {9798400702419},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604915.3608827},
doi = {10.1145/3604915.3608827},
abstract = {In the&nbsp;field of recommender systems, shallow autoencoders have recently gained significant attention. One of the&nbsp;most highly acclaimed shallow autoencoders is easer, favored for its competitive recommendation accuracy and simultaneous simplicity. However, the&nbsp;poor scalability of easer (both in time and especially in memory) severely restricts its use in production environments with vast item sets. In this paper, we propose a&nbsp;hyperefficient factorization technique for sparse approximate inversion of the&nbsp;data-Gram matrix used in easer. The&nbsp;resulting autoencoder, sansa, is an&nbsp;end-to-end sparse solution with prescribable density and almost arbitrarily low memory requirements — even for training. As such, sansa allows us to effortlessly scale the&nbsp;concept of easer to millions of items and beyond.},
booktitle = {Proceedings of the 17th ACM Conference on Recommender Systems},
pages = {763–770},
numpages = {8},
keywords = {Algorithm scalability, Numerical approximation, Sparse approximate inverse, Sparse autoencoders},
location = {Singapore, Singapore},
series = {RecSys '23}
}

@inproceedings{10.1145/3604915.3608829,
author = {Mysore, Sheshera and Mccallum, Andrew and Zamani, Hamed},
title = {Large Language Model Augmented Narrative Driven Recommendations},
year = {2023},
isbn = {9798400702419},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604915.3608829},
doi = {10.1145/3604915.3608829},
abstract = {Narrative-driven recommendation (NDR) presents an information access problem where users solicit recommendations with verbose descriptions of their preferences and context, for example, travelers soliciting recommendations for points of interest while describing their likes/dislikes and travel circumstances. These requests are increasingly important with the rise of natural language-based conversational interfaces for search and recommendation systems. However, NDR lacks abundant training data for models, and current platforms commonly do not support these requests. Fortunately, classical user-item interaction datasets contain rich textual data, e.g., reviews, which often describe user preferences and context – this may be used to bootstrap training for NDR models. In this work, we explore using large language models (LLMs) for data augmentation to train NDR models. We use LLMs for authoring synthetic narrative queries from user-item interactions with few-shot prompting and train retrieval models for NDR on synthetic queries and user-item interaction data. Our experiments demonstrate that this is an effective strategy for training small-parameter retrieval models that outperform other retrieval and LLM baselines for narrative-driven recommendation.},
booktitle = {Proceedings of the 17th ACM Conference on Recommender Systems},
pages = {777–783},
numpages = {7},
location = {Singapore, Singapore},
series = {RecSys '23}
}

@inproceedings{10.1145/3404835.3463032,
author = {Wang, Jinpeng and Zhu, Jieming and He, Xiuqiang},
title = {Cross-Batch Negative Sampling for Training Two-Tower Recommenders},
year = {2021},
isbn = {9781450380379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3404835.3463032},
doi = {10.1145/3404835.3463032},
abstract = {The two-tower architecture has been widely applied for learning item and user representations, which is important for large-scale recommender systems. Many two-tower models are trained using various in-batch negative sampling strategies, where the effects of such strategies inherently rely on the size of mini-batches. However, training two-tower models with a large batch size is inefficient, as it demands a large volume of memory for item and user contents and consumes a lot of time for feature encoding. Interestingly, we find that neural encoders can output relatively stable features for the same input after warming up in the training process. Based on such facts, we propose a simple yet effective sampling strategy called Cross-Batch Negative Sampling (CBNS), which takes advantage of the encoded item embeddings from recent mini-batches to boost the model training. Both theoretical analysis and empirical evaluations demonstrate the effectiveness and the efficiency of CBNS.},
booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1632–1636},
numpages = {5},
keywords = {information retrieval, neural networks, recommender systems},
location = {Virtual Event, Canada},
series = {SIGIR '21}
}

@inproceedings{10.1145/3486622.3493998,
author = {Yamanaka, Yuki and Sugiyama, Kazunari},
title = {Generalized Negative Sampling for Implicit Feedback in Recommendation},
year = {2022},
isbn = {9781450391153},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3486622.3493998},
doi = {10.1145/3486622.3493998},
abstract = {In a typical model-based collaborative filtering with implicit feedback, negative sampling is getting more and more popular to obtain negative labeled inputs from massive unobserved data. However, this approach wrongly samples false negatives, resulting in unacceptable recommender model. In this work, we first identify a situation where false negatives are problematic and estimate their impact on a model accuracy. Then, we take our negative sampling as a classification task and demonstrate that a recommender model and a negative sampling method actually share the same goal: identification of false negatives from other unobserved data. We also estimate the actual upper bound of the accuracy improvements with a feasible negative sampling. Lastly, we propose a generalized negative sampling that can alleviate the impact of false negatives by introducing two robustness against false negatives: self-sampling and dynamic sub-sampling. In user-item interaction matrix, experimental results on publicly available datasets show that our approach outperforms some state-of-the-arts with statistical significance.},
booktitle = {IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology},
pages = {544–549},
numpages = {6},
keywords = {Collaborative filtering, False negative, Implicit feedback, Matrix factorization, Negative sampling},
location = {Melbourne, VIC, Australia},
series = {WI-IAT '21}
}

@inproceedings{10.1145/2792838.2799677,
author = {Valcarce, Daniel and Parapar, Javier and Barreiro, Alvaro},
title = {A Study of Priors for Relevance-Based Language Modelling of Recommender Systems},
year = {2015},
isbn = {9781450336925},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2792838.2799677},
doi = {10.1145/2792838.2799677},
abstract = {Probabilistic modelling of recommender systems naturally introduces the concept of prior probability into the recommendation task. Relevance-Based Language Models, a principled probabilistic query expansion technique in Information Retrieval, has been recently adapted to the item recommendation task with success. In this paper, we study the effect of the item and user prior probabilities under that framework. We adapt two priors from the document retrieval field and then we propose other two new probabilistic priors. Evidence gathered from experimentation indicates that a linear prior for the neighbour and a probabilistic prior based on Dirichlet smoothing for the items improve the quality of the item recommendation ranking.},
booktitle = {Proceedings of the 9th ACM Conference on Recommender Systems},
pages = {237–240},
numpages = {4},
keywords = {collaborative filtering, prior probability, recommender systems, relevance-based language models},
location = {Vienna, Austria},
series = {RecSys '15}
}

@inproceedings{10.1145/3459637.3482092,
author = {Wang, Yu and Liu, Zhiwei and Fan, Ziwei and Sun, Lichao and Yu, Philip S.},
title = {DSKReG: Differentiable Sampling on Knowledge Graph for Recommendation with Relational GNN},
year = {2021},
isbn = {9781450384469},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3459637.3482092},
doi = {10.1145/3459637.3482092},
abstract = {In the information explosion era, recommender systems (RSs) are widely studied and applied to discover user-preferred information. A RS performs poorly when suffering from the cold-start issue, which can be alleviated if incorporating Knowledge Graphs (KGs) as side information. However, most existing works neglect the facts that node degrees in KGs are skewed and massive amount of interactions in KGs are recommendation-irrelevant. To address these problems, in this paper, we propose Differentiable Sampling on Knowledge Graph for Recommendation with Relational GNN (DSKReG) that learns the relevance distribution of connected items from KGs and samples suitable items for recommendation following this distribution. We devise a differentiable sampling strategy, which enables the selection of relevant items to be jointly optimized with the model training procedure. The experimental results demonstrate that our model outperforms state-of-the-art KG-based recommender systems. The code is available online at https://github.com/YuWang-1024/DSKReG.},
booktitle = {Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management},
pages = {3513–3517},
numpages = {5},
keywords = {graph neural network, knowledge graph, recommender systems},
location = {Virtual Event, Queensland, Australia},
series = {CIKM '21}
}

@inproceedings{10.1145/3213586.3226223,
author = {Kallumadi, Surya and Necoechea, Gabriel},
title = {Injecting Semantic Diversity in Top-N Recommender Systems Using Determinantal Point Processes and Curated Lists},
year = {2018},
isbn = {9781450357845},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3213586.3226223},
doi = {10.1145/3213586.3226223},
abstract = {Top-N Recommender Systems usually suffer from intra-list diversity as they are tailored for relevance and predicted rating accuracy. This problem is magnified in the case of cold start setting - resulting in users being restricted to popular set of items and can result in a "rich getting richer eco-system". As a result, in recent years, more attention is being paid to improving the diversity of recommender system results. List creation has become a popular way for users to express preferences over items on online platforms such as imdb.com and goodreads.com. These user curated lists tend to contain a coherent semantic representation of the domain the list of items belong to. List curation can be seen as a way to capture fine grained topic-specific item-lists by users. Understanding and modeling user preferences expressed in these curated lists can help with diverse set of applications such as recommendations, user modeling, session understanding etc. In this paper, we propose an approach to improve the diversity of results generated by Top-N recommender systems, by using Determinantal Point Processes (DPPs) over user curated lists in the movie domain and incorporating them to rerank the Top-N recommender systems. For this work, we use the user curated lists in the imdb.com domain. We evaluate our approach over the Movielens 1-Million dataset and compare the results with other baseline approaches. Our early results show that incorporating semantic similarity expressed in user lists as a diversity proxy results in a more diverse set of recommendations.},
booktitle = {Adjunct Publication of the 26th Conference on User Modeling, Adaptation and Personalization},
pages = {127–130},
numpages = {4},
keywords = {diversity, diversity metrics, recommender systems, user curated lists},
location = {Singapore, Singapore},
series = {UMAP '18}
}

@inproceedings{10.1145/3404835.3463089,
author = {Wang, Jianling and Ding, Kaize and Caverlee, James},
title = {Sequential Recommendation for Cold-start Users with Meta Transitional Learning},
year = {2021},
isbn = {9781450380379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3404835.3463089},
doi = {10.1145/3404835.3463089},
abstract = {A fundamental challenge for sequential recommenders is to capture the sequential patterns of users toward modeling how users transit among items. In many practical scenarios, however, there are a great number of cold-start users with only minimal logged interactions. As a result, existing sequential recommendation models will lose their predictive power due to the difficulties in learning sequential patterns over users with only limited interactions. In this work, we aim to improve sequential recommendation for cold-start users with a novel framework named MetaTL, which learns to model the transition patterns of users through meta-learning. Specifically, the proposed MetaTL: (i) formulates sequential recommendation for cold-start users as a few-shot learning problem; (ii) extracts the dynamic transition patterns among users with a translation-based architecture; and (iii) adopts meta transitional learning to enable fast learning for cold-start users with only limited interactions, leading to accurate inference of sequential interactions.},
booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1783–1787},
numpages = {5},
keywords = {cold-start, meta-learning, recommendation systems},
location = {Virtual Event, Canada},
series = {SIGIR '21}
}

@inproceedings{10.1145/2507157.2508071,
author = {Guo, Guibing},
title = {Integrating trust and similarity to ameliorate the data sparsity and cold start for recommender systems},
year = {2013},
isbn = {9781450324090},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2507157.2508071},
doi = {10.1145/2507157.2508071},
abstract = {Our research aims to tackle the problems of data sparsity and cold start of traditional recommender systems. Insufficient ratings often result in poor quality of recommendations in terms of accuracy and coverage. To address these issues, we propose three different approaches from the perspective of preference modelling. Firstly, we propose to merge the ratings of trusted neighbors and thus form a new rating profile for the active users, based on which better recommendations can be generated. Secondly, we aim to make better use of user ratings and introduce a novel Bayesian similarity measure by taking into account both the direction and length of rating vectors. Thirdly, we propose a new information source called prior ratings based on virtual product experience in virtual reality environments, in order to inherently resolve the concerned problems.},
booktitle = {Proceedings of the 7th ACM Conference on Recommender Systems},
pages = {451–454},
numpages = {4},
keywords = {prior ratings, similarity, similarity measure, trust},
location = {Hong Kong, China},
series = {RecSys '13}
}

@inproceedings{10.1145/3331184.3331295,
author = {Kalloori, Saikishore and Li, Tianyu and Ricci, Francesco},
title = {Item Recommendation by Combining Relative and Absolute Feedback Data},
year = {2019},
isbn = {9781450361729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3331184.3331295},
doi = {10.1145/3331184.3331295},
abstract = {User preferences in the form of absolute feedback, s.a., ratings, are widely exploited in Recommender Systems (RSs). Recent research has explored the usage of preferences expressed with pairwise comparisons, which signal relative feedback. It has been shown that pairwise comparisons can be effectively combined with ratings, but, it is important to fine tune the technique that leverages both types of feedback. Previous approaches train a single model by converting ratings into pairwise comparisons, and then use only that type of data. However, we claim that these two types of preferences reveal different information about users interests and should be exploited differently. Hence, in this work, we develop a ranking technique that separately exploits absolute and relative preferences in a hybrid model. In particular, we propose a joint loss function which is computed on both absolute and relative preferences of users. Our proposed ranking model uses pairwise comparisons data to predict the user's preference order between pairs of items and uses ratings to push high rated (relevant) items to the top of the ranking. Experimental results on three different data sets demonstrate that the proposed technique outperforms competitive baseline algorithms on popular ranking-oriented evaluation metrics.},
booktitle = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {933–936},
numpages = {4},
keywords = {absolute feedback, pairwise preferences, ratings, recommender system, relative feedback},
location = {Paris, France},
series = {SIGIR'19}
}

@inproceedings{10.1145/3331184.3331337,
author = {Tran, Viet-Anh and Hennequin, Romain and Royo-Letelier, Jimena and Moussallam, Manuel},
title = {Improving Collaborative Metric Learning with Efficient Negative Sampling},
year = {2019},
isbn = {9781450361729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3331184.3331337},
doi = {10.1145/3331184.3331337},
abstract = {Distance metric learning based on triplet loss has been applied with success in a wide range of applications such as face recognition, image retrieval, speaker change detection and recently recommendation with the Collaborative Metric Learning (CML) model. However, as we show in this article, CML requires large batches to work reasonably well because of a too simplistic uniform negative sampling strategy for selecting triplets. Due to memory limitations, this makes it difficult to scale in high-dimensional scenarios. To alleviate this problem, we propose here a 2-stage negative sampling strategy which finds triplets that are highly informative for learning. Our strategy allows CML to work effectively in terms of accuracy and popularity bias, even when the batch size is an order of magnitude smaller than what would be needed with the default uniform sampling. We demonstrate the suitability of the proposed strategy for recommendation and exhibit consistent positive results across various datasets.},
booktitle = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1201–1204},
numpages = {4},
keywords = {collaborative filtering, metric learning, recommender systems, triplet loss},
location = {Paris, France},
series = {SIGIR'19}
}

@inproceedings{10.1145/3459637.3482070,
author = {Zhang, Jingsen and Chen, Xu and Zhao, Wayne Xin},
title = {Causally Attentive Collaborative Filtering},
year = {2021},
isbn = {9781450384469},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3459637.3482070},
doi = {10.1145/3459637.3482070},
abstract = {Attention-based recommender models hold the promise of improving performance by learning to discriminate different user/item feature importances. However, due to the existence of the latent confounders, the correlations captured by attention mechanisms may fail to reflect the true influence of the features on the targets (i.e., spurious correlation). In this paper, we propose to empower attention mechanism by the causal inference, which is a powerful tool to identify the real causal effects. Our model is based on the potential outcome framework, where the item features are regarded as the treatment and the outcome is the predicted user preference. In specific, the causal relation of each feature on the outcome is measured by the individual treatment effect (ITE). In order to distill the causal information into the attention learning process, we minimize the distance between the traditional attention weights and the normalized ITE. With such causal regularization, the learned attention weights can capture the real causal effects, which are expected to correct the feature importances for improving performance. We conduct extensive experiments based on three real-world datasets to demonstrate the effectiveness.},
booktitle = {Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management},
pages = {3622–3626},
numpages = {5},
keywords = {causal inference, collaborative filtering, recommendation system},
location = {Virtual Event, Queensland, Australia},
series = {CIKM '21}
}

@inproceedings{10.1145/3240323.3240378,
author = {Cunha, Tiago and Soares, Carlos and de Carvalho, Andr\'{e} C. P. L. F.},
title = {CF4CF: recommending collaborative filtering algorithms using collaborative filtering},
year = {2018},
isbn = {9781450359016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3240323.3240378},
doi = {10.1145/3240323.3240378},
abstract = {As Collaborative Filtering becomes increasingly important in both academia and industry recommendation solutions, it also becomes imperative to study the algorithm selection task in this domain. This problem aims at finding automatic solutions which enable the selection of the best algorithms for a new problem, without performing full-fledged training and validation procedures. Existing work in this area includes several approaches using Metalearning, which relate the characteristics of the problem domain with the performance of the algorithms. This study explores an alternative approach to deal with this problem. Since, in essence, the algorithm selection problem is a recommendation problem, we investigate the use of Collaborative Filtering algorithms to select Collaborative Filtering algorithms. The proposed approach integrates subsampling landmarkers, a data characterization approach commonly used in Metalearning, with a Collaborative Filtering methodology, named CF4CF. The predictive performance obtained by CF4CF using benchmark recommendation datasets was similar or superior to that obtained with Metalearning.},
booktitle = {Proceedings of the 12th ACM Conference on Recommender Systems},
pages = {357–361},
numpages = {5},
keywords = {collaborative filtering, label ranking, metalearning},
location = {Vancouver, British Columbia, Canada},
series = {RecSys '18}
}

@inproceedings{10.1145/2645710.2645770,
author = {Aiolli, Fabio},
title = {Convex AUC optimization for top-N recommendation with implicit feedback},
year = {2014},
isbn = {9781450326681},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2645710.2645770},
doi = {10.1145/2645710.2645770},
abstract = {In this paper, an effective collaborative filtering algorithm for top-N item recommendation with implicit feedback is proposed. The task of top-N item recommendation is to predict a ranking of items (movies, books, songs, or products in general) that can be of interest for a user based on earlier preferences of the user. We focus on implicit feedback where preferences are given in the form of binary events/ratings. Differently from state-of-the-art methods, the method proposed is designed to optimize the AUC directly within a margin maximization paradigm. Specifically, this turns out in a simple constrained quadratic optimization problem, one for each user. Experiments performed on several benchmarks show that our method significantly outperforms state-of-the-art matrix factorization methods in terms of AUC of the obtained predictions.},
booktitle = {Proceedings of the 8th ACM Conference on Recommender Systems},
pages = {293–296},
numpages = {4},
keywords = {auc optimization, collaborative filtering, implicit feedback, top-n recommendation},
location = {Foster City, Silicon Valley, California, USA},
series = {RecSys '14}
}

@inproceedings{10.1145/3511808.3557531,
author = {Li, Hai and Dong, Xin and Cheng, Lei and Mo, Linjian},
title = {A Hierarchical User Behavior Modeling Framework for Cross-Domain Click-Through Rate Prediction},
year = {2022},
isbn = {9781450392365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511808.3557531},
doi = {10.1145/3511808.3557531},
abstract = {Click-through rate (CTR) prediction is a long-standing problem in advertising systems. Existing single-domain CTR prediction methods suffer from the data sparsity problem since few users can click advertisements on many items. Recently, cross-domain CTR prediction leverages the relatively richer information from a source domain to improve the performance on a target domain with sparser information, but it cannot explicitly capture users' diverse interests in different domains. In this paper, we propose a novel hierarchical user behavior modeling framework for cross-domain CTR prediction, named HBMNet. HBMNet contains two main components: an element-wise behavior transfer(EWBT) layer and a user representation layer. EWBT layer transfers the information collected from one domain by element-level masks to dynamically highlight the informative elements in another domain. The user representation layer performs behavior-level attention between these behavior representations and the ranking item representation. Extensive experimental results on two cross-domain datasets show that the proposed HBMNet outperforms SOTA models.},
booktitle = {Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management},
pages = {4163–4167},
numpages = {5},
keywords = {click-through rate, cross domain, representation learning},
location = {Atlanta, GA, USA},
series = {CIKM '22}
}

@inproceedings{10.1145/2645710.2645771,
author = {Loni, Babak and Said, Alan and Larson, Martha and Hanjalic, Alan},
title = { 'Free lunch' enhancement for collaborative filtering with factorization machines},
year = {2014},
isbn = {9781450326681},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2645710.2645771},
doi = {10.1145/2645710.2645771},
abstract = {The advantage of Factorization Machines over other factorization models is their ability to easily integrate and efficiently exploit auxiliary information to improve Collaborative Filtering. Until now, this auxiliary information has been drawn from external knowledge sources beyond the user-item matrix. In this paper, we demonstrate that Factorization Machines can exploit additional representations of information inherent in the user-item matrix to improve recommendation performance. We refer to our approach as 'Free Lunch' enhancement since it leverages clusters that are based on information that is present in the user-item matrix, but not otherwise directly exploited during matrix factorization. Borrowing clustering concepts from codebook sharing, our approach can also make use of 'Free Lunch' information inherent in a user-item matrix from a auxiliary domain that is different from the target domain of the recommender. Our approach improves performance both in the joint case, in which the auxiliary and target domains share users, and in the disjoint case, in which they do not. Although 'Free Lunch' enhancement does not apply equally well to any given domain or domain combination, our overall conclusion is that Factorization Machines present an opportunity to exploit information that is ubiquitously present, but commonly under-appreciated by Collaborative Filtering algorithms.},
booktitle = {Proceedings of the 8th ACM Conference on Recommender Systems},
pages = {281–284},
numpages = {4},
keywords = {cluster encoding, collaborative filtering, cross-domain collaborative filtering, factorization machines},
location = {Foster City, Silicon Valley, California, USA},
series = {RecSys '14}
}

@inproceedings{10.1145/3511808.3557652,
author = {Zhou, Huachi and Fan, Jiaqi and Huang, Xiao and Li, Ka Ho and Tang, Zhenyu and Yu, Dahai},
title = {Multi-Interest Refinement by Collaborative Attributes Modeling for Click-Through Rate Prediction},
year = {2022},
isbn = {9781450392365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511808.3557652},
doi = {10.1145/3511808.3557652},
abstract = {Learning interest representation plays a core role in click-through rate prediction task. Existing Transformer-based approaches learn multi-interests from a sequence of interacted items with rich attributes. The attention weights explain how relevant an item's specific attribute sequence is to the user's interest. However, it implicitly assumes the independence of attributes regarding the same item, which may not always hold in practice. Empirically, the user places varied emphasis on different attributes to consider whether interacting with one item, which is unobserved. Independently modeling each attribute may allow attention to assign probability mass to some unimportant attributes. Collaborative attributes of varied emphasis can be incorporated to help the model more reasonably approximate attributes' relevance to others and generate refined interest representations.To this end, we novelly propose to integrate a dynamic collaborative attribute routing module into Transformer. The module assigns collaborative scores to each attribute of clicked items and induces the extended Transformer to prioritize the influential attributes. To learn collaborative scores without labels, we design a diversity loss to facilitate score differentiation. The comparison with baselines on two real-world benchmark datasets and one industrial dataset validates the effectiveness of the framework.},
booktitle = {Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management},
pages = {4732–4736},
numpages = {5},
keywords = {attention-smoothing, click-through rate prediction, multi-interest},
location = {Atlanta, GA, USA},
series = {CIKM '22}
}

@inproceedings{10.1145/3409256.3409847,
author = {Htait, Amal and Fournier, S\'{e}bastien and Bellot, Patrice and Azzopardi, Leif and Pasi, Gabriella},
title = {Using Sentiment Analysis for Pseudo-Relevance Feedback in Social Book Search},
year = {2020},
isbn = {9781450380676},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3409256.3409847},
doi = {10.1145/3409256.3409847},
abstract = {Book search is a challenging task due to discrepancies between the content and description of books, on one side, and the ways in which people query for books, on the other. However, online reviewers provide an opinionated description of the book, with alternative features that describe the emotional and experiential aspects of the book. Therefore, locating emotional sentences within reviews, could provide a rich alternative source of evidence to help improve book recommendations. Specifically, sentiment analysis (SA) could be employed to identify salient emotional terms, which could then be used for query expansion? This paper explores the employment ofSA based query expansion, in the book search domain. We introduce a sentiment-oriented method for the selection of sentences from the reviews of top rated book. From these sentences, we extract the terms to be employed in the query formulation. The sentence selection process is based on a semi-supervised SA method, which makes use of adapted word embeddings and lexicon seed-words.Using the CLEF 2016 Social Book Search (SBS) Suggestion TrackCollection, an exploratory comparison between standard pseudo-relevance feedback and the proposed sentiment-based approach is performed. The experiments show that the proposed approach obtains 24%-57% improvement over the baselines, whilst the classic technique actually degrades the performance by 14%-51%.},
booktitle = {Proceedings of the 2020 ACM SIGIR on International Conference on Theory of Information Retrieval},
pages = {29–32},
numpages = {4},
keywords = {pseudo-relevance feedback, query expansion, sentiment analysis},
location = {Virtual Event, Norway},
series = {ICTIR '20}
}

@inproceedings{10.1145/3583780.3615241,
author = {Heist, Nicolas and Hertling, Sven and Paulheim, Heiko},
title = {KGrEaT: A Framework to Evaluate Knowledge Graphs via Downstream Tasks},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615241},
doi = {10.1145/3583780.3615241},
abstract = {In recent years, countless research papers have addressed the topics of knowledge graph creation, extension, or completion in order to create knowledge graphs that are larger, more correct, or more diverse. This research is typically motivated by the argumentation that using such enhanced knowledge graphs to solve downstream tasks will improve performance. Nonetheless, this is hardly ever evaluated. Instead, the predominant evaluation metrics - aiming at correctness and completeness - are undoubtedly valuable but fail to capture the complete picture, i.e., how useful the created or enhanced knowledge graph actually is. Further, the accessibility of such a knowledge graph is rarely considered (e.g., whether it contains expressive labels, descriptions, and sufficient context information to link textual mentions to the entities of the knowledge graph). To better judge how well knowledge graphs perform on actual tasks, we present KGrEaT - a framework to estimate the quality of knowledge graphs via actual downstream tasks like classification, clustering, or recommendation. Instead of comparing different methods of processing knowledge graphs with respect to a single task, the purpose of KGrEaT is to compare various knowledge graphs as such by evaluating them on a fixed task setup. The framework takes a knowledge graph as input, automatically maps it to the datasets to be evaluated on, and computes performance metrics for the defined tasks. It is built in a modular way to be easily extendable with additional tasks and datasets.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {3938–3942},
numpages = {5},
keywords = {data mining, entity mapping, evaluation framework, knowledge graph, semantic recommendation},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/2567948.2579232,
author = {Dooms, Simon and De Pessemier, Toon and Martens, Luc},
title = {Mining cross-domain rating datasets from structured data on twitter},
year = {2014},
isbn = {9781450327459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2567948.2579232},
doi = {10.1145/2567948.2579232},
abstract = {While rating data is essential for all recommender systems research, there are only a few public rating datasets available, most of them years old and limited to the movie domain. With this work, we aim to end the lack of rating data by illustrating how vast amounts of ratings can be unambiguously collected from Twitter. We validate our approach by mining ratings from four major online websites focusing on movies, books, music and video clips. In a short mining period of 2 weeks, close to 3 million ratings were collected. Since some users turned up in more than one dataset, we believe this work to be amongst the first to provide a true cross-domain rating dataset.},
booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
pages = {621–624},
numpages = {4},
keywords = {IMDB, YouTube, dataset, goodreads, mining, pandora, twitter},
location = {Seoul, Korea},
series = {WWW '14 Companion}
}

@inproceedings{10.1145/2484028.2484102,
author = {Roitman, Haggai and Carmel, David and Mass, Yosi and Eiron, Iris},
title = {Modeling the uniqueness of the user preferences for recommendation systems},
year = {2013},
isbn = {9781450320344},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2484028.2484102},
doi = {10.1145/2484028.2484102},
abstract = {In this paper we propose a novel framework for modeling the uniqueness of the user preferences for recommendation systems. User uniqueness is determined by learning to what extent the user's item preferences deviate from those of an "average user" in the system. Based on this framework, we suggest three different recommendation strategies that trade between uniqueness and conformity. Using two real item datasets, we demonstrate the effectiveness of our uniqueness based recommendation framework.},
booktitle = {Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {777–780},
numpages = {4},
keywords = {popularity, recommender systems, user uniqueness},
location = {Dublin, Ireland},
series = {SIGIR '13}
}

@inproceedings{10.1145/2911451.2914669,
author = {Cao, Xuezhi and Huang, Weiyue and Yu, Yong},
title = {A Complete &amp; Comprehensive Movie Review Dataset (CCMR)},
year = {2016},
isbn = {9781450340694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2911451.2914669},
doi = {10.1145/2911451.2914669},
abstract = {Online review sites are widely used for various domains including movies and restaurants. These sites now have strong influences towards users during purchasing processes. There exist plenty of research works for review sites on various aspects, including item recommendation, user behavior analysis, etc. However, due to the lack of complete and comprehensive dataset, there are still problems that remain to be solved. Therefore, in this paper we assemble and publish such dataset (CCMR) for the community. CCMR outruns existing datasets in terms of completeness, comprehensiveness and scale. Besides describing the dataset and its collecting methodology, we also propose several potential research topics that are made possible by having this dataset. Such topics include: (i) a statistical approach to reduce the impacts from fake reviews and (ii) analyzing and modeling the influences of public opinions towards users during rating actions. We further conduct preliminary analysis and experiments for both directions to show that they are promising.},
booktitle = {Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {661–664},
numpages = {4},
keywords = {review sites, test collection, user behavior},
location = {Pisa, Italy},
series = {SIGIR '16}
}

@inproceedings{10.1145/2766462.2767785,
author = {Zamani, Hamed and Moradi, Pooya and Shakery, Azadeh},
title = {Adaptive User Engagement Evaluation via Multi-task Learning},
year = {2015},
isbn = {9781450336215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2766462.2767785},
doi = {10.1145/2766462.2767785},
abstract = {User engagement evaluation task in social networks has recently attracted considerable attention due to its applications in recommender systems. In this task, the posts containing users' opinions about items, e.g., the tweets containing the users' ratings about movies in the IMDb website, are studied. In this paper, we try to make use of tweets from different web applications to improve the user engagement evaluation performance. To this aim, we propose an adaptive method based on multi-task learning. Since in this paper we study the problem of detecting tweets with positive engagement which is a highly imbalanced classification problem, we modify the loss function of multi-task learning algorithms to cope with the imbalanced data. Our evaluations over a dataset including the tweets of four diverse and popular data sources, i.e., IMDb, YouTube, Goodreads, and Pandora, demonstrate the effectiveness of the proposed method. Our findings suggest that transferring knowledge between data sources can improve the user engagement evaluation performance.},
booktitle = {Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1011–1014},
numpages = {4},
keywords = {adaptive model, multi-task learning, transfer learning, user engagement},
location = {Santiago, Chile},
series = {SIGIR '15}
}

@inproceedings{10.1145/3342220.3343647,
author = {Rettberg, Jill Walker and Gunderson, Marianne and Kronman, Linda and Solberg, Ragnhild and Stokkedal, Linn Heidi},
title = {Mapping Cultural Representations of Machine Vision: Developing Methods to Analyse Games, Art and Narratives},
year = {2019},
isbn = {9781450368858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342220.3343647},
doi = {10.1145/3342220.3343647},
abstract = {Machine vision technologies are increasingly ubiquitous in society and have become part of everyday life. However, the rapid adoption has led to ethical concerns relating to privacy, agency, bias and accuracy. This paper presents the methodology and preliminary results from a digital humanities project that maps and categorises references to and uses of machine vision in digital art, narratives and games in order to find patterns to help us analyse broader cultural understandings of machine vision in society. Understanding the cultural significance and valence of machine vision is crucial for developers of machine vision technologies, so that new technologies are designed to meet general needs and ethical concerns, and ultimately contribute to a better, more just society.},
booktitle = {Proceedings of the 30th ACM Conference on Hypertext and Social Media},
pages = {97–101},
numpages = {5},
keywords = {computer games, computer vision, digital art, digital humanities, machine vision, methodology, narratives, network analysis, science fiction},
location = {Hof, Germany},
series = {HT '19}
}

@inproceedings{10.1145/3343413.3378011,
author = {Torbati, Ghazaleh H. and Yates, Andrew and Weikum, Gerhard},
title = {Personalized Entity Search by Sparse and Scrutable User Profiles},
year = {2020},
isbn = {9781450368926},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3343413.3378011},
doi = {10.1145/3343413.3378011},
abstract = {Prior work on personalizing web search results has focused on considering query-and-click logs to capture users' individual interests. For product search, extensive user histories about purchases and ratings have been exploited. However, for general entity search, such as for books on specific topics or travel destinations with certain features, personalization is largely underexplored. In this paper, we address personalization of book search, as an exemplary case of entity search, by exploiting sparse user profiles obtained through online questionnaires. We devise and compare a variety of re-ranking methods based on language models or neural learning. Our experiments show that even very sparse information about individuals can enhance the effectiveness of the search results.},
booktitle = {Proceedings of the 2020 Conference on Human Information Interaction and Retrieval},
pages = {427–431},
numpages = {5},
keywords = {knowledge graph, personalized entity search, sparse user profile},
location = {Vancouver BC, Canada},
series = {CHIIR '20}
}

@inproceedings{10.1145/3486622.3494006,
author = {Kohlmeyer, Lasse and Repke, Tim and Krestel, Ralf},
title = {Novel Views on Novels:Embedding Multiple Facets of Long Texts},
year = {2022},
isbn = {9781450391153},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3486622.3494006},
doi = {10.1145/3486622.3494006},
abstract = {Novels are one of the longest document types and thus one of the most complex types of texts. Many NLP tasks utilize document embeddings as machine-understandable semantic representations of documents. However, such document embeddings are optimized for short texts, such as sentences or paragraphs. When faced with longer texts, these models either truncate the long text or split it sequentially into smaller chunks. We show that when applied to a fictional novel, these traditional document embeddings fail to capture all its facets. Complex information, such as time, place, atmosphere, style, and plot is typically not represented adequately. To this end, we propose lib2vec which computes and combines multiple embedding vectors based on various facets. Instead of splitting the text sequentially, lib2vec splits the text semantically based on domain-specific facets. We evaluate the semantic expressiveness using human-assessed book comparisons as well as content-based information retrieval tasks. The results show that our approach outperforms state-of-the-art document embeddings for long texts.},
booktitle = {IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology},
pages = {670–675},
numpages = {6},
location = {Melbourne, VIC, Australia},
series = {WI-IAT '21}
}

