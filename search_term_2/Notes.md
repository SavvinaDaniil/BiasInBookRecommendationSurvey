# Search term 2

We look for incidental studies.
("book-crossing" OR "bookcrossing" OR "Librarything" OR "Amazon books" OR "Goodreads" OR "Goodbooks" )("bias") ("recommender") 
## Thursday, 26 September 2024

### Start
Let’s start with searches.

Google scholar

1610 results. Download issue, work on it!


## Thursday, 03 October 2024

### Processing
Now we start processing

Google scholar

Managed to download 899 results.

Scopus

60 results. Downloaded into table

Let’s process them.

Merged table. 959 TOTAL. 37 duplicates. 940 left.


Remove duplicates with the previous search term: 9 of them we already have, so 931 left.
### Screening
Screening starts! First screen only Title and Abstract.

What is relevant:  Bias means BIAS, not bias parameter in algorithms. Not theses. Studying these actual datasets. Not surveys.


OMG it's such a terrible thing to be doing. Ill try something different:
- Take the bias and debias paper, look for the book datasets in the paper they cite.
    - 227 papers, exported by scopus.
- Do the search term 2 only from 2022 onwards.



<span style="color:blue">Tomorrow</span>
-

## Wednesday, 09 October 2024
Continue with the initial screening...

No! New idea. Search only in top conferences and journals related to RS. List:
- [ ] WWW ACM
- [ ] WSDM ACM
- [ ] SIGIR ACM
- [ ] RecSys ACM 
- [ ] TOIS ACM


- [ ] UMAP ACM
- [ ] (ECIR)
- [ ] TORS ACM
- [ ] Frontiers in Big Data|Recommender Systems

Searched term from this file in ACM. 366 results. 259 research articles. 34 short papers. -> 293.\
Includes the following: RecSys, CIKM, WWW, SIGIR, KDD, WSDM, UMAP, CHI, etc.



## Tuesday, 29 October 2024
Screen these 293 papers. Idea discussed with Laura: Yes for papers that specifically are looking into bias, No for irrelevant, Keep for some incidental so we might include them!
Let's fucking do it.


## Monday, 4 November 2024
Actually do the fucking thing mentioned above.\
Goals for this week:
- [] Screen these ACM papers
- [] Check citations of the relevant papers
- [] Find other relevant venues: ECIR,...
- [] Look for LIS venues \
I put everything in Notion\
I am 'keeping' some surveys. How do I search generally: click the link, search the word bias, see if it's relevant, then scheme through the abstract.

Look at information retrieval journal, see: Alejandro Bellogín, Pablo Castells, and Iván Cantador. 2017. Statistical biases in information retrieval metrics for
recommender systems

Maybe generally springer nature?

## Tuesday, 5 November 2024
Continue the previous task.

Unrelated: bias as in user/item bias in RS, bias in they way they decided some study, inductive bias, some algorithms are called 'biased something', not about RS, not using the datasets (but only referencing them in related work)\
Keep: not targeted work on uncovering or mitigating bias but incidental results, something interesting about book search/recommendation,


*Result*: 293 screened, 45 Yes, 202 no, 46 keep.\
No duplicates.

All of them are retrievable (they are from ACM library).
So I'll check eligibility.

To do that I'll make notes on each Yes paper.

Before doing the above: Make list of venues to look for papers.

LIS:\
From Emil's email!
1. ​Library Quarterly (JSTOR)
2. Journal of Documentation (Emerald insight)
3. Cataloging & Classification Quarterly (tandfonline)
4. Library Trends (John hopkins)
5. Collection Management (tandfonline)
6. Journal of the Association for Information Science & Technology (JASIST) (wiley)

Other:
1. ECIR (Springer nature) NOT UNIFIED!
2. Frontiers in Big Data|Recommender Systems (nothing I think)
4. Advances in Bias and Fairness in Information Retrieval (Springer nature)
5. Transforming digital worlds (Springer nature)
6. Information Processing & Management (elsevier) !!
7. User Modeling and User-Adapted Interaction (Sprigner nature)
8. Transactions on Knowledge and data engineering (IEEE)
9. Data mining and knowledge discovery (springer)



## Wednesday, 6 November 2024
To-do: 
- Finish notes on every 'yes' in eligibility checked.
- Look at citations of every yes.
- Do notes on every 'keep'.

What am I doing: Going through every paper, note what they're doing, look at citations and see if they're citing non-acm papers. (See other above.)

Clear criterion: Papers that either measure or attempt to mitigate some form of bias in recommender systems, and try their method (of measurement or mitigation) on a book dataset.

Result!! Out of 45 yes's, now I have 33 yes's + 9 keeps + 3 no's\
I made notes and looked at citations. My conclusion: include springer nature, elsevier, ieee. repeat with the same term.

To-do:
- Repeat everything for springer nature, elsevier, ieee.
- Look at keeps! (maybe that later).

Idea: look only at springer nature places where youve found relevant work.

Other:
1. ECIR (Springer nature)
2. Frontiers in Big Data|Recommender Systems (nothing I think)
3. PeerJ computer science?
4. Advances in Bias and Fairness in Information Retrieval (Springer nature)
5. Transforming digital worlds (Springer nature)
6. Information Processing & Management (elsevier) !! *17*
7. User Modeling and User-Adapted Interaction (Sprigner nature)
8. Transactions on Knowledge and data engineering (IEEE)
9. Data mining and knowledge discovery (springer)



springer: 86 confernece papers, 89 articles


Let's start with the 17 from elsevier's info processing and management! 5 yes, 1 Keep, 11 no

Let's do ieee tkde! 



## Wednesday, 25 September 2024

### Eligibility
We check for eligibility

We have 24 retrievable results.

15 not eligible, 9 eligible.

