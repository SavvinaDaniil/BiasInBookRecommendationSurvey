Title,Notes,Link,Venue,Year,Authors,Type,Abstract
Cross-view hypergraph contrastive learning for attribute-aware recommendation,"However, user interactions are often sparse and noisy. Moreover, existing works
have constraints in modeling high-order interactions flexibly and sufficiently. We propose
a novel Cross-view Hypergraph Contrastive Learning for Attribute-aware Recommendation
(CHCLA) to deal with such issues. bookcrossing",https://www.sciencedirect.com/science/article/pii/S030645732400061X,Information Processing & Management,2024,"['Ang Ma', 'Yanhua Yu', 'Chuan Shi', 'Zirui Guo', 'Tat-Seng Chua']",missing,"Recommender systems typically model user–item interaction data to learn user interests and preferences. However, user interactions are often sparse and noisy. Moreover, existing works have constraints in modeling high-order interactions flexibly and sufficiently. We propose a novel Cross-view Hypergraph Contrastive Learning for Attribute-aware Recommendation (CHCLA) to deal with such issues. For considering the high-order interactions, CHCLA models user–item interaction through a graph convolutional network and user/item attribute information through hypergraph convolutional networks, learning user and item representations in two distinct ways. Furthermore, for the problem of sparse and noisy supervised signals, CHCLA uses self-supervised cross-view contrastive learning by generating self-augmented contrastive views between user–item interaction graph and user/item attribute interaction hypergraph to improve the robustness of graph representations learning. CHCLA not only captures user behavior representations but also accommodates inherent user and item attribute preferences. Extensive experiments illustrate that CHCLA performs better than advanced approaches, the NDCG@10 of CHCLA on MovieLens, Book-crossing and Taobao datasets is improved by 1.29%, 2.11% and 8.09% respectively, offering a promising avenue for further research and advancement in recommender systems."
Enhancing Recommender Systems With a Stimulus-Evoked Curiosity Mechanism,"proposes a Curiosity-drive Recommendation Framework (CdRF) which incorporates a highly innovative Stimulus evoked Curiosity mechanism (SeCM) together with a basic accuracy-oriented algorithm via Borda count. amazon books, librarything",10.1109/TKDE.2019.2957770,IEEE Transactions on Knowledge and Data Engineering,2021,"['Ke Xu', 'Junwen Mo', 'Yi Cai', 'Huaqing Min']",missing,"Classical algorithms in recommender systems (RS) mainly emphasis on achieving high accuracy and thus recommend items precisely matching a user's past choices. However, the user may gradually lose interest and crave something more inspiring. In psychology, curiosity is a critical human nature and can be efficient bootstrap exploratory behaviors, thus this phenomenon can be explained as insufficient stimulation to induce curiosity regard to recommended items. Inspired from the above, this work proposes a Curiosity-drive Recommendation Framework (CdRF) which incorporates a highly innovative Stimulus-evoked Curiosity mechanism (SeCM) together with a basic accuracy-oriented algorithm via Borda count. In SeCM, we first estimate the stimulus intensity appearing on each item for each user and then model personalized curiosity among the calculated intensities using Wundt curve. For the target user, the output of CdRF is a ranked list of N N items which are both relevant and highly curiousness. We conduct extensive experiments using four public datasets to evaluate the performance of each specification of SeCM as well as the whole framework CdRF. The results reveal that SeCM can flexibly generate diversified items and CdRF can increase diversity in terms of ILS, Newness and AD while compromising very little Precision. This kind of research also offers a way to understand both individual differences in curiosity and how curiosity contributes to item exploration at the level of RS."
GS-RS: A Generative Approach for Alleviating Cold Start and Filter Bubbles in Recommender Systems,hm ,10.1109/TKDE.2023.3290140,IEEE Transactions on Knowledge and Data Engineering,2024,"['Yuanbo Xu', 'En Wang', 'Yongjian Yang', 'Hui Xiong']",missing,"Recommender Systems (RSs) typically face the cold-start problem and the filter-bubble problem when users suffer the familiar, repeated, and even predictable recommendations, making them bored and unsatisfied. The key to solving these issues is learning users’ fine-grained preferences and recommending appealing and unexplored items deviating from users’ historical items. However, existing models consider cold-start or filter bubble problems separately and ignore that they can reinforce mutually and damage the models’ performance accuracy. To this end, we devise a novel serendipity-oriented recommender system (Generative Self-constrained Serendipitous Recommender System, GS$^{2}$2-RS) that generates users’ fine-grained preferences to enhance the recommendation performance. Specifically, GS$^{2}$2-RS extracts users’ interest and satisfaction preferences and generates virtual but convincible neighbors’ preferences from themselves with a twin Conditional Generative Adversarial Nets (not from real neighbors). Then we introduce the serendipity item, which is low-interest but high-satisfaction among candidate items. We use the serendipity item to improve the diversity of recommended items, which relieves the filter-bubble problem. Along with this line, a gated mechanism is applied to their fine-grained preferences (interests, satisfactions) to obtain their serendipity items. Finally, these serendipity items are inversely injected into the original user-item rating matrix and build a relatively dense matrix as the input for backbone RS models. Note that GS$^{2}$2-RS tackles cold-start and filter-bubble problems in a unified framework without any additional side information and enriches the interpretability of recommendation models. We comprehensively validate GS$^{2}$2-RS for solving cold-start and filter bubble problems on four real-world benchmark datasets. Extensive experiments illustrate GS$^{2}$2-RS's superiority in accuracy, serendipity, and interpretability over state-of-the-art models. Also, we can plug our model into existing recommender systems as a preprocessing procedure to enhance their performance."
Novel and Diverse Recommendations by Leveraging Linear Models with User and Item Embeddings,"we present EER, a linear model for the top-N recommendation task, which takes advantage of user and item embeddings for improving novelty and diversity without harming accuracy. Librarything",http://link.springer.com/chapter/10.1007/978-3-030-45442-5_27,Advances in Information Retrieval,2020,Alfonso LandinJavier ParaparÁlvaro Barreiro,Chapter,missing
Towards Green Recommender Systems: Investigating the Impact of Data Reduction on Carbon Footprint and Algorithm Performances,"training recommender systems with less data makes the suggestions
more diverse and less biase",https://doi.org/10.1145/3640457.3688160,Proceedings of the 18th ACM Conference on Recommender Systems,2024,"['Giuseppe Spillo', 'Allegra De Filippo', 'Cataldo Musto', 'Michela Milano', 'Giovanni Semeraro']",Short,"This work investigates the path toward green recommender systems by examining the impact of data reduction on both model performance and carbon footprint. In the pursuit of developing energy-efficient recommender systems, we investigated whether and how reducing the training data impacts the performances of several representative recommendation models. In order to obtain a fair comparison, all the models were run based on the implementations available in a popular recommendation library, i.e., RecBole, and used the same experimental settings. Results indicate that: (a) data reduction can be a promising strategy to make recommender systems more sustainable, at the cost of a lower accuracy; (b) training recommender systems with less data makes the suggestions more diverse and less biased. Overall, this study contributes to the ongoing discourse on the development of recommendation models that meet the principles of SDGs, laying the groundwork for the adoption of more sustainable practices in the field."
Towards Sustainability-aware Recommender Systems: Analyzing the Trade-off Between Algorithms Performance and Carbon Footprint,"results show that more sophisticated approaches
tend to reduce popularity bias (i.e., lower average popularity) and
increase the diversity of the recommendations.",https://doi.org/10.1145/3604915.3608840,Proceedings of the 17th ACM Conference on Recommender Systems,2023,"['Giuseppe Spillo', 'Allegra De Filippo', 'Cataldo Musto', 'Michela Milano', 'Giovanni Semeraro']",Short,"In this paper, we present a comparative analysis of the trade-off between the performance of state-of-the-art recommendation algorithms and their environmental impact. In particular, we compared 18 popular recommendation algorithms in terms of both performance metrics (i.e., accuracy and diversity of the recommendations) as well as in terms of energy consumption and carbon footprint on three different datasets. In order to obtain a fair comparison, all the algorithms were run based on the implementations available in a popular recommendation library, i.e., RecBole, and used the same experimental settings. The outcomes of the experiments showed that the choice of the optimal recommendation algorithm requires a thorough analysis, since more sophisticated algorithms often led to tiny improvements at the cost of an exponential increase of carbon emissions. Through this paper, we aim to shed light on the problem of carbon footprint and energy consumption of recommender systems, and we make the first step towards the development of sustainability-aware recommendation algorithms."
The Effect of Feedback Granularity on Recommender Systems Performance,higher feedback granularity were often connected with increased Item Coverage and APLT.,https://doi.org/10.1145/3523227.3551479,Proceedings of the 16th ACM Conference on Recommender Systems,2022,"['Ladislav Peska', 'Stepan Balcar']",Short,"The main source of knowledge utilized in recommender systems (RS) is users’ feedback. While the usage of implicit feedback (i.e. user’s behavior statistics) is gaining in prominence, the explicit feedback (i.e. user’s ratings) remain an important data source. This is true especially for domains, where evaluation of an object does not require an extensive usage and users are well motivated to do so (e.g., video-on-demand services or library archives). So far, numerous rating schemes for explicit feedback have been proposed, ranging both in granularity and presentation style. There are several works studying the effect of rating’s scale and presentation on user’s rating behavior, e.g. willingness to provide feedback or various biases in rating behavior. Nonetheless, the effect of ratings granularity on RS performance remain largely under-researched. In this paper, we studied the combined effect of ratings granularity and supposed probability of feedback existence on various performance statistics of recommender systems. Results indicate that decreasing feedback granularity may lead to changes in RS’s performance w.r.t. nDCG for some recommending algorithms. Nonetheless, in most cases the effect of feedback granularity is surpassed by even a small decrease in feedback’s quantity. Therefore, our results corroborate the policy of many major real-world applications, i.e. preference of simpler rating schemes with the higher chance of feedback reception instead of finer-grained rating scenarios."
Improving Collaborative Metric Learning with Efficient Negative Sampling,"The motivation is that due to the popularity bias in interaction data, popular items tend to be close together. A challenge is thus to push non-matching popular items farther away in the latent space. Spreading popular items apart could then help to reduce the popularity bias often witnessed in recommendation.",https://doi.org/10.1145/3331184.3331337,Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval,2019,"['Viet-Anh Tran', 'Romain Hennequin', 'Jimena Royo-Letelier', 'Manuel Moussallam']",Short,"Distance metric learning based on triplet loss has been applied with success in a wide range of applications such as face recognition, image retrieval, speaker change detection and recently recommendation with the Collaborative Metric Learning (CML) model. However, as we show in this article, CML requires large batches to work reasonably well because of a too simplistic uniform negative sampling strategy for selecting triplets. Due to memory limitations, this makes it difficult to scale in high-dimensional scenarios. To alleviate this problem, we propose here a 2-stage negative sampling strategy which finds triplets that are highly informative for learning. Our strategy allows CML to work effectively in terms of accuracy and popularity bias, even when the batch size is an order of magnitude smaller than what would be needed with the default uniform sampling. We demonstrate the suitability of the proposed strategy for recommendation and exhibit consistent positive results across various datasets."
Modeling the uniqueness of the user preferences for recommendation systems,Using an experimental evaluation with two real datasets we have studied various recommendation strategies and demonstrated the effectiveness of a recommendation strategy that trades between personalization and popularity according to the user’s uniqueness level.,https://doi.org/10.1145/2484028.2484102,Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval,2013,"['Haggai Roitman', 'David Carmel', 'Yosi Mass', 'Iris Eiron']",Short,"In this paper we propose a novel framework for modeling the uniqueness of the user preferences for recommendation systems. User uniqueness is determined by learning to what extent the user's item preferences deviate from those of an ""average user"" in the system. Based on this framework, we suggest three different recommendation strategies that trade between uniqueness and conformity. Using two real item datasets, we demonstrate the effectiveness of our uniqueness based recommendation framework."
Navigating Serendipity - An Experimental User Study On The Interplay of Trust and Serendipity In Recommender Systems,"Our findings indicate that while interface enhancements did not yield significant increases in trust, they did notably elevate serendipity ratings for previously unknown books.",https://doi.org/10.1145/3631700.3664901,"Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization",2024,"['Irina Nalis', 'Tobias Sippl', 'Thomas Kolb', 'Julia Neidhardt']",Research,"Recommender systems play a crucial role in our daily lives, constantly evolving to meet the diverse needs of users. As the pursuit of improved user experiences continues, metrics such as serendipity have emerged within the realm of beyond-accuracy paradigms. However, integrating serendipitous recommendations presents complex challenges, necessitating a delicate balance between novelty, relevance, and user engagement. In this interdisciplinary experimental user study, we address these challenges within the context of a book recommender system. By investigating the impact of interface design changes on user trust, a key determinant of satisfaction with serendipitous recommendations, we measured trust levels for both individual recommended items and the recommender system as a whole. Our findings indicate that while interface enhancements did not yield significant increases in trust, they did notably elevate serendipity ratings for previously unknown books. These results highlight the intricate interplay between technical and psychological factors in the design of recommender systems, emphasizing the importance of human-centered approaches in the creation of more responsible AI applications. This research contributes to ongoing discussions surrounding user-centric recommendation systems and aligns with broader themes of digital humanism and responsible AI."
On the Effectiveness of Sampled Softmax Loss for Item Recommendation,"In this work, we aim at offering a better understanding of SSM for item recommendation. Specifically, we first theoretically reveal three model-agnostic advantages: (1) mitigating popularity bias, which is beneficial to long-tail recommendation",https://doi.org/10.1145/3637061,missing,2024,"['Jiancan Wu', 'Xiang Wang', 'Xingyu Gao', 'Jiawei Chen', 'Hongcheng Fu', 'Tianyu Qiu']",Research,"The learning objective plays a fundamental role to build a recommender system. Most methods routinely adopt either pointwise (e.g., binary cross-entropy) or pairwise (e.g., BPR) loss to train the model parameters, while rarely pay attention to softmax loss, which assumes the probabilities of all classes sum up to 1, due to its computational complexity when scaling up to large datasets or intractability for streaming data where the complete item space is not always available. The sampled softmax (SSM) loss emerges as an efficient substitute for softmax loss. Its special case, InfoNCE loss, has been widely used in self-supervised learning and exhibited remarkable performance for contrastive learning. Nonetheless, limited recommendation work uses the SSM loss as the learning objective. Worse still, none of them explores its properties thoroughly and answers “Does SSM loss suit for item recommendation?” and “What are the conceptual advantages of SSM loss, as compared with the prevalent losses?”, to the best of our knowledge.In this work, we aim at offering a better understanding of SSM for item recommendation. Specifically, we first theoretically reveal three model-agnostic advantages: (1) mitigating popularity bias, which is beneficial to long-tail recommendation; (2) mining hard negative samples, which offers informative gradients to optimize model parameters; and (3) maximizing the ranking metric, which facilitates top-K performance. However, based on our empirical studies, we recognize that the default choice of cosine similarity function in SSM limits its ability in learning the magnitudes of representation vectors. As such, the combinations of SSM with the models that also fall short in adjusting magnitudes (e.g., matrix factorization) may result in poor representations. One step further, we provide mathematical proof that message passing schemes in graph convolution networks can adjust representation magnitude according to node degree, which naturally compensates for the shortcoming of SSM. Extensive experiments on four benchmark datasets justify our analyses, demonstrating the superiority of SSM for item recommendation. Our implementations are available in both TensorFlow1 and PyTorch.2"
Modeling User Repeat Consumption Behavior for Online Novel Recommendation,"That is, these models has the popularity bias problem [ 6 ]. Consequently, new novels have slight chances to be recommended, resulting in small new part of MRR@1 scores.",https://doi.org/10.1145/3523227.3546762,Proceedings of the 16th ACM Conference on Recommender Systems,2022,"['Yuncong Li', 'Cunxiang Yin', 'yancheng he', 'Guoqiang Xu', 'Jing Cai', 'leeven luo', 'Sheng-hua Zhong']",Research,"Given a user’s historical interaction sequence, online novel recommendation suggests the next novel the user may be interested in. Online novel recommendation is important but underexplored. In this paper, we concentrate on recommending online novels to new users of an online novel reading platform, whose first visits to the platform occurred in the last seven days. We have two observations about online novel recommendation for new users. First, repeat novel consumption of new users is a common phenomenon. Second, interactions between users and novels are informative. To accurately predict whether a user will reconsume a novel, it is crucial to characterize each interaction at a fine-grained level. Based on these two observations, we propose a neural network for online novel recommendation, called NovelNet. NovelNet can recommend the next novel from both the user’s consumed novels and new novels simultaneously. Specifically, an interaction encoder is used to obtain accurate interaction representation considering fine-grained attributes of interaction, and a pointer network with a pointwise loss is incorporated into NovelNet to recommend previously-consumed novels. Moreover, an online novel recommendation dataset is built from a well-known online novel reading platform and is released for public use as a benchmark. Experimental results on the dataset demonstrate the effectiveness of NovelNet 1."
Graph Masked Autoencoder for Sequential Recommendation,Hmmm,https://doi.org/10.1145/3539618.3591692,Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval,2023,"['Yaowen Ye', 'Lianghao Xia', 'Chao Huang']",Research,"While some powerful neural network architectures (e.g., Transformer, Graph Neural Networks) have achieved improved performance in sequential recommendation with high-order item dependency modeling, they may suffer from poor representation capability in label scarcity scenarios. To address the issue of insufficient labels, Contrastive Learning (CL) has attracted much attention in recent methods to perform data augmentation through embedding contrasting for self-supervision. However, due to the hand-crafted property of their contrastive view generation strategies, existing CL-enhanced models i) can hardly yield consistent performance on diverse sequential recommendation tasks; ii) may not be immune to user behavior data noise. In light of this, we propose a simple yet effective Graph Masked AutoEncoder-enhanced sequential Recommender system (MAERec) that adaptively and dynamically distills global item transitional information for self-supervised augmentation. It naturally avoids the above issue of heavy reliance on constructing high-quality embedding contrastive views. Instead, an adaptive data reconstruction paradigm is designed to be integrated with the long-range item dependency modeling, for informative augmentation in sequential recommendation. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baseline models and can learn more accurate representations against data noise and sparsity. Our implemented model code is available at https://github.com/HKUDS/MAERec."
ReuseKNN: Neighborhood Reuse for Differentially Private KNN-Based Recommendations,"Additionally, the nature of neighborhood reuse may raise concerns that the generated recommendations are biased towards items consumed by many users, i.e., popular items. Thus, we investigate whether the proposed approach is more or less prone to item popularity bias than the baselines.",https://doi.org/10.1145/3608481,missing,2023,"['Peter M\\""{u}llner', 'Elisabeth Lex', 'Markus Schedl', 'Dominik Kowald']",Research,"User-based KNN recommender systems (UserKNN) utilize the rating data of a target user’s k nearest neighbors in the recommendation process. This, however, increases the privacy risk of the neighbors, since the recommendations could expose the neighbors’ rating data to other users or malicious parties. To reduce this risk, existing work applies differential privacy by adding randomness to the neighbors’ ratings, which unfortunately reduces the accuracy of UserKNN. In this work, we introduce ReuseKNN, a novel differentially private KNN-based recommender system. The main idea is to identify small but highly reusable neighborhoods so that (i) only a minimal set of users requires protection with differential privacy and (ii) most users do not need to be protected with differential privacy since they are only rarely exploited as neighbors. In our experiments on five diverse datasets, we make two key observations. Firstly, ReuseKNN requires significantly smaller neighborhoods and, thus, fewer neighbors need to be protected with differential privacy compared with traditional UserKNN. Secondly, despite the small neighborhoods, ReuseKNN outperforms UserKNN and a fully differentially private approach in terms of accuracy. Overall, ReuseKNN leads to significantly less privacy risk for users than in the case of UserKNN."
Causality-driven User Modeling for Sequential Recommendations over Time,"In conclusion, our causality-driven user modeling approach for sequential recommendation notably improves prediction accuracy and reduces bias.",https://doi.org/10.1145/3589335.3651896,Companion Proceedings of the ACM Web Conference 2024,2024,"['Xingming Chen', 'Qing Li']",Research,"Contemporary sequential recommendation systems predominantly leverage statistical correlations derived from user interaction histories to predict future preferences. However, these correlations often mask implicit challenges. On the one hand, user data is frequently plagued by implicit, noisy feedback, misdirecting users towards items that fail to align with their actual interests, which is magnified in sequential recommendation contexts. On the other hand, prevalent methods tend to over-rely on similarity-based attention mechanisms across item pairs, which are prone to utilizing heuristic shortcuts, thereby leading to suboptimal recommendation.To tackle these issues, we put forward a causality-driven user modeling approach for sequential recommendation, which pivots towards a causal perspective. Specifically, we involves the application of a causal graph to identify confounding factors that give rise to spurious correlations and to isolate conceptual variables that causally encapsulate user preferences. By learning the representation of these disentangled causal variables at the conceptual level, we can distinguish between causal and non-causal associations while preserving the inherent sequential nature of user behaviors. This enables us to ascertain which elements are critical and which may induce unintended biases. The framework of our method can be compatible with various mainstream sequential models, which offers a robust foundation for reconstructing more accurate and meaningful user and item representations driven by causality."
Batch-Mix Negative Sampling for Learning Recommendation Retrievers,"We integrate the popularity into the mixing coefficient for adapting to the sampled softmax loss, with the aim of reducing the sample selection bias, after which a loss function containing inbatch samples and generated samples is utilized for optimization.",https://doi.org/10.1145/3583780.3614789,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,2023,"['Yongfu Fan', 'Jin Chen', 'Yongquan Jiang', 'Defu Lian', 'Fangda Guo', 'Kai Zheng']",Research,"Recommendation retrievers commonly retrieve user potentially preferred items from numerous items, where the query and item representation are learned according to the dual encoders with the log-softmax loss. Under real scenarios, the number of items becomes considerably large, making it exceedingly difficult to calculate the partition function with the whole item corpus. Negative sampling, which samples a subset from the item corpus, is widely used to accelerate the model training. Among different samplers, the in-batch sampling is commonly adopted for online recommendation retrievers, which regards the other items within the mini-batch as the negative samples for the given query, owing to its time and memory efficiency. However, the sample selection bias occurs due to the skewed feedback, harming the retrieval quality. In this paper, we propose a negative sampling approach named Batch-Mix Negative Sampling (BMNS), which adopts batch mixing operation to generate additional negatives for model training. Concretely, BMNS first generates new negative items with the sampled mix coefficient from the Beta distribution, after which a tailored correct strategy guided by frequency is designed to match the sampled softmax loss. In this way, the effort of re-encoding items out of the mini-batch is reduced while also improving the representation space of the negative set. The empirical experiments on four real-world datasets demonstrate BMNS is superior to the competitive negative inbatch sampling method."
User Cold-start Problem in Multi-armed Bandits: When the First Recommendations Guide the User’s Experience,"hus, current parametric bandit algorithms are making first recommendations based on a random sampling of the items (i.e., a pure-exploration) or a biased selection of the most popular ones (i.e., a pureexploitation).",https://doi.org/10.1145/3554819,missing,2023,"['Nicollas Silva', 'Thiago Silva', 'Heitor Werneck', 'Leonardo Rocha', 'Adriano Pereira']",Research,"Nowadays, Recommender Systems have played a crucial role in several entertainment scenarios by making personalised recommendations and guiding the entire users’ journey from their first interaction. Recent works have addressed it as a Contextual Bandit by providing a sequential decision model to explore items not tried yet (or not tried enough) or exploit the best options learned so far. However, this work noticed these current algorithms are limited to naive non-personalised approaches in the first interactions of a new user, offering random or most popular items. Through experiments in three domains, we identify a negative impact of these first choices. Our study indicates that the bandit performance is directly related to the choices made in the first trials. Then, we propose a new approach to balance exploration and exploitation in the first interactions and handle these drawbacks. This approach is based on the Active Learning theory to catch more information about the new users and improve their long-term experience. Our idea is to explore the potential information gain of items that can also please the user’s taste. This method is named Warm-Starting Contextual Bandits, and it statistically outperforms 10 benchmarks in the literature in the long run."
Inductive Modeling for Realtime Cold Start Recommendations,Experiments on both public datasets and industry applications demonstrate that IHM can significantly outperform baselines in recommending fresh and long-tail contents.,https://doi.org/10.1145/3637528.3671588,Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,2024,"['Chandler Zuo', 'Jonathan Castaldo', 'Hanqing Zhu', 'Haoyu Zhang', 'Ji Liu', 'Yangpeng Ou', 'Xiao Kong']",Research,"In recommendation systems, the timely delivery of new content to their relevant audiences is critical for generating a growing and high quality collection of content for all users. The nature of this problem requires retrieval models to be able to make inferences in real time and with high relevance. There are two specific challenges for cold start contents. First, the information loss problem in a standard Two Tower model, due to the limited feature interactions between the user and item towers, is exacerbated for cold start items due to training data sparsity. Second, the huge volume of user-generated content in industry applications today poses a big bottleneck in the end-to-end latency of recommending new content. To overcome the two challenges, we propose a novel architecture, the Item History Model (IHM). IHM directly injects user-interaction information into the item tower to overcome information loss. In addition, IHM incorporates an inductive structure using attention-based pooling to eliminate the need for recurring training, a key bottleneck for the real-timeness. On both public and industry datasets, we demonstrate that IHM can not only outperform baselines in recommending cold start contents, but also achieves SoTA real-timeness in industry applications."
Post-hoc Selection of Pareto-Optimal Solutions in Search and Recommendation,"we proposed PDU, a novel, theoretically-justified posthoc technique to select one—best—Pareto-optimal solution among the ones lying in the Pareto frontier in search and recommendation scenarios (Savvina: APLT)",https://doi.org/10.1145/3583780.3615010,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,2023,"['Vincenzo Paparella', 'Vito Anelli', 'Franco Nardini', 'Raffaele Perego', 'Tommaso Di Noia']",Research,"Information Retrieval (IR) and Recommender Systems (RSs) tasks are moving from computing a ranking of final results based on a single metric to multi-objective problems. Solving these problems leads to a set of Pareto-optimal solutions, known as Pareto frontier, in which no objective can be further improved without hurting the others. In principle, all the points on the Pareto frontier are potential candidates to represent the best model selected with respect to the combination of two, or more, metrics. To our knowledge, there are no well-recognized strategies to decide which point should be selected on the frontier in IR and RSs. In this paper, we propose a novel, post-hoc, theoretically-justified technique, named ""Population Distance from Utopia"" (PDU), to identify and select the one-best Pareto-optimal solution. PDU considers fine-grained utopia points, and measures how far each point is from its utopia point, allowing to select solutions tailored to user preferences, a novel feature we call ""calibration"". We compare PDU against state-of-the-art strategies through extensive experiments on tasks from both IR and RS, showing that PDU combined with calibration notably impacts the solution selection."
Challenging the Myth of Graph Collaborative Filtering: a Reasoned and Reproducibility-driven Analysis,"Thus, the study introduces and analyzes the information flow in the graph and discovers that 2-hop information (combining user activeness and item popularity) is a valid indicator of CF behavior and could motivate the recommendation performance.",https://doi.org/10.1145/3604915.3609489,Proceedings of the 17th ACM Conference on Recommender Systems,2023,"['Vito Anelli', 'Daniele Malitesta', 'Claudio Pomo', 'Alejandro Bellogin', 'Eugenio Di Sciascio', 'Tommaso Di Noia']",Research,"The success of graph neural network-based models (GNNs) has significantly advanced recommender systems by effectively modeling users and items as a bipartite, undirected graph. However, many original graph-based works often adopt results from baseline papers without verifying their validity for the specific configuration under analysis. Our work addresses this issue by focusing on the replicability of results. We present a code that successfully replicates results from six popular and recent graph recommendation models (NGCF, DGCF, LightGCN, SGL, UltraGCN, and GFCF) on three common benchmark datasets (Gowalla, Yelp 2018, and Amazon Book). Additionally, we compare these graph models with traditional collaborative filtering models that historically performed well in offline evaluations. Furthermore, we extend our study to two new datasets (Allrecipes and BookCrossing) that lack established setups in existing literature. As the performance on these datasets differs from the previous benchmarks, we analyze the impact of specific dataset characteristics on recommendation accuracy. By investigating the information flow from users’ neighborhoods, we aim to identify which models are influenced by intrinsic features in the dataset structure. The code to reproduce our experiments is available at:&nbsp;https://github.com/sisinflab/Graph-RSs-Reproducibility."
Revisiting Neural Retrieval on Accelerators,"This new formulation is expressive, capable of modeling high rank (user, item) interactions, and further generalizes to the long tai",https://doi.org/10.1145/3580305.3599897,Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,2023,"['Jiaqi Zhai', 'Zhaojie Gong', 'Yueming Wang', 'Xiao Sun', 'Zheng Yan', 'Fu Li', 'Xing Liu']",Research,"Retrieval finds a small number of relevant candidates from a large corpus for information retrieval and recommendation applications. A key component of retrieval is to model (user, item) similarity, which is commonly represented as the dot product of two learned embeddings. This formulation permits efficient inference, commonly known as Maximum Inner Product Search (MIPS). Despite its popularity, dot products cannot capture complex user-item interactions, which are multifaceted and likely high rank. We hence examine non-dot-product retrieval settings on accelerators, and propose mixture of logits (MoL), which models (user, item) similarity as an adaptive composition of elementary similarity functions. This new formulation is expressive, capable of modeling high rank (user, item) interactions, and further generalizes to the long tail. When combined with a hierarchical retrieval strategy, h-indexer, we are able to scale up MoL to 100M corpus on a single GPU with latency comparable to MIPS baselines. On public datasets, our approach leads to uplifts of up to 77.3% in hit rate (HR). Experiments on a large recommendation surface at Meta showed strong metric gains and reduced popularity bias, validating the proposed approach's performance and improved generalization."
Unifying Explicit and Implicit Feedback for Rating Prediction and Ranking Recommendation Tasks,The key aspects of the proposed model is that (1) it is applied at the level of data pre-processing and (2) it increases the representation of less popular items in recommendations while maintaining reasonable recommendation performance.,https://doi.org/10.1145/3341981.3344225,Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval,2019,"['Amir Jadidinejad', 'Craig Macdonald', 'Iadh Ounis']",Research,"The two main tasks addressed by collaborative filtering approaches are rating prediction and ranking. Rating prediction models leverage explicit feedback (e.g. ratings), and aim to estimate the rating a user would assign to an unseen item. In contrast, ranking models leverage implicit feedback (e.g. clicks) in order to provide the user with a personalized ranked list of recommended items. Several previous approaches have been proposed that learn from both explicit and implicit feedback to optimize the task of ranking or rating prediction at the level of recommendation algorithm. Yet we argue that these two tasks are not completely separate, but are part of a unified process: a user first interacts with a set of items and then might decide to provide explicit feedback on a subset of items. We propose to bridge the gap between the tasks of rating prediction and ranking through the use of a novel weak supervision approach that unifies both explicit and implicit feedback datasets. The key aspects of the proposed model is that (1) it is applied at the level of data pre-processing and (2) it increases the representation of less popular items in recommendations while maintaining reasonable recommendation performance. Our experimental results - on six datasets covering different types of heterogeneous user's interactions and using a wide range of evaluation metrics - show that, our proposed approach can effectively combine explicit and implicit feedback and improve the effectiveness of the baseline explicit model on the ranking task by covering a broader range of long-tail items."
"Updatable, Accurate, Diverse, and Scalable Recommendations for Interactive Applications",e show empirically that RP 3 β provides accurate recommendations with high long-tail item frequency at the top of the recommendation list.,https://doi.org/10.1145/2955101,missing,2016,"['Bibek Paudel', 'Fabian Christoffel', 'Chris Newell', 'Abraham Bernstein']",Research,"Recommender systems form the backbone of many interactive systems. They incorporate user feedback to personalize the user experience typically via personalized recommendation lists. As users interact with a system, an increasing amount of data about a user’s preferences becomes available, which can be leveraged for improving the systems’ performance. Incorporating these new data into the underlying recommendation model is, however, not always straightforward. Many models used by recommender systems are computationally expensive and, therefore, have to perform offline computations to compile the recommendation lists. For interactive applications, it is desirable to be able to update the computed values as soon as new user interaction data is available: updating recommendations in interactive time using new feedback data leads to better accuracy and increases the attraction of the system to the users. Additionally, there is a growing consensus that accuracy alone is not enough and user satisfaction is also dependent on diverse recommendations.In this work, we tackle this problem of updating personalized recommendation lists for interactive applications in order to provide both accurate and diverse recommendations. To that end, we explore algorithms that exploit random walks as a sampling technique to obtain diverse recommendations without compromising on efficiency and accuracy. Specifically, we present a novel graph vertex ranking recommendation algorithm called RP3β that reranks items based on three-hop random walk transition probabilities. We show empirically that RP3β provides accurate recommendations with high long-tail item frequency at the top of the recommendation list. We also present approximate versions of RP3β and the two most accurate previously published vertex ranking algorithms based on random walk transition probabilities and show that these approximations converge with an increasing number of samples.To obtain interactively updatable recommendations, we additionally show how our algorithm can be extended for online updates at interactive speeds. The underlying random walk sampling technique makes it possible to perform the updates without having to recompute the values for the entire dataset.In an empirical evaluation with three real-world datasets, we show that RP3β provides highly accurate and diverse recommendations that can easily be updated with newly gathered information at interactive speeds (≪ 100ms)."
Improving Graph Collaborative Filtering with Directional Behavior Enhanced Contrastive Learning, Does the proposed BDCL model perform better for long-tail data? Why?,https://doi.org/10.1145/3663574,missing,2024,"['Penghang Yu', 'Bing-Kun Bao', 'Zhiyi Tan', 'Guanming Lu']",Research,"Graph Collaborative Filtering is a widely adopted approach for recommendation, which captures similar behavior features through Graph Neural Network (GNN). Recently, Contrastive Learning (CL) has been demonstrated as an effective method to enhance the performance of graph collaborative filtering. Typically, CL-based methods first perturb users’ history behavior data (e.g., drop clicked items), then construct a self-discriminating task for behavior representations under different random perturbations. However, for widely existing inactive users, random perturbation makes their sparse behavior information more incomplete, thereby harming the behavior feature extraction. To tackle the above issue, we design a novel directional perturbation-based CL method to improve the graph collaborative filtering performance. The idea is to perturb node representations through directionally enhancing behavior features. To do so, we propose a simple yet effective feedback mechanism, which fuses the representations of nodes based on behavior similarity. Then, to avoid irrelevant behavior preferences introduced by the feedback mechanism, we construct a behavior self-contrast task before and after feedback, to align the node representations between the final output and the first layer of GNN. Different from the widely adopted self-discriminating task, the behavior self-contrast task avoids complex message propagation on different perturbed graphs, which is more efficient than previous methods. Extensive experiments on three public datasets demonstrate that the proposed method has distinct advantages over other CL methods on recommendation accuracy."
Triangle Graph Interest Network for Click-through Rate Prediction,"Besides, those works are more biased towards popular or similar commodities.",https://doi.org/10.1145/3488560.3498458,Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining,2022,"['Wensen Jiang', 'Yizhu Jiao', 'Qingqin Wang', 'Chuanming Liang', 'Lijie Guo', 'Yao Zhang', 'Zhijun Sun', 'Yun Xiong', 'Yangyong Zhu']",Research,"Click-through rate prediction is a critical task in online advertising. Currently, many existing methods attempt to extract user potential interests from historical click behavior sequences. However, it is difficult to handle sparse user behaviors or broaden interest exploration. Recently, some researchers incorporate the item-item co-occurrence graph as an auxiliary. Due to the elusiveness of user interests, those works still fail to determine the real motivation of user click behaviors. Besides, those works are more biased towards popular or similar commodities. They lack an effective mechanism to break the diversity restrictions. In this paper, we point out two special properties of triangles in the item-item graphs for recommendation systems: Intra-triangle homophily and Inter-triangle heterophiy. Based on this, we propose a novel and effective framework named Triangle Graph Interest Network (TGIN). For each clicked item in user behavior sequences, we introduce the triangles in its neighborhood of the item-item graphs as a supplement. TGIN regards these triangles as the basic units of user interests, which provide the clues to capture the real motivation for a user clicking an item. We characterize every click behavior by aggregating the information of several interest units to alleviate the elusive motivation problem. The attention mechanism determines users' preference for different interest units. By selecting diverse and relative triangles, short brings in novel and serendipitous items to expand exploration opportunities of user interests. Then, we aggregate the multi-level interests of historical behavior sequences to improve CTR prediction. Extensive experiments on both of public and industrial datasets clearly verify the effectiveness of our framework."
"Complexities associated with user-generated book reviews in digital libraries: temporal, cultural, and political case studies","All these books are subject to selection bias and historical biases in literary history (e.g., classism, sexism, racism, colonialism), which poses questions about the inclusiveness and representativeness of prior DH studies on book reviews.",https://doi.org/10.1145/3529372.3530930,Proceedings of the 22nd ACM/IEEE Joint Conference on Digital Libraries,2022,"['Yuerong Hu', 'Zoe LeBlanc', 'Jana Diesner', 'Ted Underwood', 'Glen Layne-Worthey', 'J. Downie']",Research,"While digital libraries (DL) have made large-scale collections of digitized books increasingly available to researchers [31, 67], there remains a dearth of similar data provisions or infrastructure for computational studies of the consumption and reception of books. In the last two decades, user-generated book reviews on social media have opened up unprecedented research possibilities for humanities and social sciences (HSS) scholars who are interested in book reception. However, limitations and gaps have emerged from existing DH research which utilize social media data for answering HSS questions. To shed light on the under-investigated features of user-generated book reviews and the challenges they might pose to scholarly research, we conducted three exemplar cases studies: (1) a longitudinal analysis for profiling the temporal changes of ratings and popularity of 552 books across ten years; (2) a cross-cultural comparison of book ratings of the same 538 books across two platforms; and, (3) a classification experiment on 20,000 sponsored and non-sponsored books reviews. Correspondingly, our research reveals the real-world complexities and under-investigated features of user-generated book reviews in three dimensions: the transience of book ratings and popularity (temporal dimension), the cross-cultural differences in reading interests and book reception (cultural dimension), and the user power dynamics behind the publicly accessible reviews (""political"" dimension). Our case studies also demonstrate the challenges posed by user-generated book reviews' real-world complexities to their scholarly usage and propose solutions to these challenges. We conclude that DL stakeholders and scholars working with user-generated book reviews should look into these under-investigated features and real-world challenges to evaluate and improve the scholarly usability and interpretability of their data."
HybridSVD: when collaborative information is not enough,"ur results suggest that, in the standard scenario, debiasing data is often more important than adding side information.",https://doi.org/10.1145/3298689.3347055,Proceedings of the 13th ACM Conference on Recommender Systems,2019,"['Evgeny Frolov', 'Ivan Oseledets']",Research,"We propose a new hybrid algorithm that allows incorporating both user and item side information within the standard collaborative filtering technique. One of its key features is that it naturally extends a simple PureSVD approach and inherits its unique advantages, such as highly efficient Lanczos-based optimization procedure, simplified hyper-parameter tuning and a quick folding-in computation for generating recommendations instantly even in highly dynamic online environments. The algorithm utilizes a generalized formulation of the singular value decomposition, which adds flexibility to the solution and allows imposing the desired structure on its latent space. Conveniently, the resulting model also admits an efficient and straightforward solution for the cold start scenario. We evaluate our approach on a diverse set of datasets and show its superiority over similar classes of hybrid models."
Offline Retrieval Evaluation Without Evaluation Metrics,"Moreover, they demonstrate the ability to adapt RPP to different scenarios (e.g. position bias, novelty).",https://doi.org/10.1145/3477495.3532033,Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval,2022,"['Fernando Diaz', 'Andres Ferraro']",Research,"Offline evaluation of information retrieval and recommendation has traditionally focused on distilling the quality of a ranking into a scalar metric such as average precision or normalized discounted cumulative gain. We can use this metric to compare the performance of multiple systems for the same request. Although evaluation metrics provide a convenient summary of system performance, they also collapse subtle differences across users into a single number and can carry assumptions about user behavior and utility not supported across retrieval scenarios. We propose recall-paired preference (RPP), a metric-free evaluation method based on directly computing a preference between ranked lists. RPP simulates multiple user subpopulations per query and compares systems across these pseudo-populations. Our results across multiple search and recommendation tasks demonstrate that RPP substantially improves discriminative power while correlating well with existing metrics and being equally robust to incomplete data."
Spectral Relaxations and Fair Densest Subgraphs,"Reducing hidden bias in the data and ensuring fairness in algorithmic data analysis has recently received significant attention. In this paper, we address the problem of identifying a densest subgraph, while ensuring that none of one binary protected attribute is disparately impacted.",https://doi.org/10.1145/3340531.3412036,Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management,2020,"['Aris Anagnostopoulos', 'Luca Becchetti', 'Adriano Fazzone', 'Cristina Menghini', 'Chris Schwiegelshohn']",Research,"Reducing hidden bias in the data and ensuring fairness in algorithmic data analysis has recently received significant attention. In this paper, we address the problem of identifying a densest subgraph, while ensuring that none of one binary protected attribute is disparately impacted.Unfortunately, the underlying algorithmic problem is NP-hard, even in its approximation version: approximating the densest fair subgraph with a polynomial-time algorithm is at least as hard as the densest subgraph problem of at most k vertices, for which no constant approximation algorithms are known.Despite such negative premises, we are able to provide approximation results in two important cases. In particular, we are able to prove that a suitable spectral embedding allows recovery of an almost optimal, fair, dense subgraph hidden in the input data, whenever one is present, a result that is further supported by experimental evidence. We also show a polynomial-time, $2$-approximation algorithm, whenever the underlying graph is itself fair. We finally prove that, under the small set expansion hypothesis, this result is tight for fair graphs.The above theoretical findings drive the design of heuristics, which we experimentally evaluate on a scenario based on real data, in which our aim is to strike a good balance between diversity and highly correlated items from Amazon co-purchasing graphs."
Understanding book search behavior on the web,"In this work, we analyze web-based book search behavior
using three months of logs from the Open Library, a globally
accessible digital library.",https://doi.org/10.1145/2396761.2396856,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,2012,"['Jin Kim', 'Henry Feild', 'Marc Cartright']",Research,"With the increased availability of e-books and digitized book collections, more users are searching the web for information about books. There are many online digital libraries containing book, author and subject data, which are accessed via internal search services as well as external web sites, such as Google. Although this is a common yet complex information-seeking behavior involving multiple search systems with different characteristics, little is known about how users find information in this scenario.In this work, we analyze web-based book search behavior using three months of logs from the Open Library, a globally accessible digital library. Our study encompasses the user behavior on web search engines and the digital library, unlike previous work which focused on institution-level digital libraries. Among our findings are (1) query characteristics and session-level behaviors are drastically different between internal and external searchers; (2) the field usage is different based on the modes of interaction---keyword search, advanced search interface and faceted filtering; (3) users go through with more iterations of faceted filtering than query reformulation. To facilitate future research on book search, we also create a book search test collection based on the log data. We then perform an evaluation of several retrieval methods, finding that field-based retrieval models have advantages over document-based models."
User Perceptions of Diversity in Recommender Systems,"We investigate user responses to recommendation lists generated using varied diversity metrics but identical diversification thresholds, and lists created with the same metrics but differing thresholds. goodbooks.",https://doi.org/10.1145/3627043.3659555,"Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization",2024,"['Patrik Dokoupil', 'Ludovico Boratto', 'Ladislav Peska']",Research,"In the context of recommender systems (RS), the concept of diversity is probably the most studied perspective beyond mere accuracy. Despite the extensive development of diversity measures and enhancement methods, the understanding of how users perceive diversity in recommendations remains limited. This gap hinders progress in multi-objective RS, as it challenges the alignment of algorithmic advancements with genuine user needs. Addressing this, our study delves into two key aspects of diversity perception in RS. We investigate user responses to recommendation lists generated using varied diversity metrics but identical diversification thresholds, and lists created with the same metrics but differing thresholds. Our findings reveal a user preference for metadata and content-based diversity metrics over collaborative ones. Interestingly, while users typically recognize more diversified lists as being more diverse in scenarios with significant diversification differences, this perception is not consistently linear and quickly diminishes when the diversification variance between lists is less pronounced. This study sheds light on the nuanced user perceptions of diversity in RS, providing valuable insights for the development of more user-centric recommendation algorithms. Study data and analysis scripts are available from https://osf.io/9y8gx/."
Reconciling the Accuracy-Diversity Trade-off in Recommendations,"We study the accuracy-diversity trade-off by bringing in a third
concept: user utility. We argue that accuracy is misaligned with
user utility. Goodbooks. Nothing about bias :/",https://doi.org/10.1145/3589334.3645625,Proceedings of the ACM Web Conference 2024,2024,"['Kenny Peng', 'Manish Raghavan', 'Emma Pierson', 'Jon Kleinberg', 'Nikhil Garg']",Research,"When making recommendations, there is an apparent trade-off between the goals of accuracy (to recommend items a user is most likely to want) and diversity (to recommend items representing a range of categories). As such, real-world recommender systems often explicitly incorporate diversity into recommendations, at the cost of accuracy.We study the accuracy-diversity trade-off by bringing in a third concept: user utility. We argue that accuracy is misaligned with user utility because it fails to incorporate a user's consumption constraints: at any given time, users can typically only use at most a few recommended items (e.g., dine at one restaurant, or watch a couple of movies). In a theoretical model, we show that utility-maximizing recommendations---when accounting for consumption constraints---are naturally diverse due to diminishing returns of recommending similar items. Therefore, while increasing diversity may come at the cost of accuracy, it can also help align accuracy-based recommendations toward the more fundamental objective of user utility. Our theoretical results yield practical guidance into how recommendations should incorporate diversity to serve user ends."
Exploring Scenarios of Uncertainty about the Users' Preferences in Interactive Recommendation Systems,mitigate the impact of such scenarios. We modify three traditional bandits to recommend items with a higher potential to get more user information without decreasing the model’s accuracy when an uncertain scenario is observed. goodbooks,https://dl.acm.org/doi/10.1145/3539618.3591684,Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval,2023,"[""N\\'{\\i}collas Silva"", 'Thiago Silva', 'Henrique Hott', 'Yan Ribeiro', 'Adriano Pereira', 'Leonardo Rocha']",Research,"Interactive Recommender Systems have played a crucial role in distinct entertainment domains through a Contextual Bandit model. Despite the current advances, their personalisation level is still directly related to the information previously available about the users. However, there are at least two scenarios of uncertainty about the users' preferences over their journey: (1) when the user joins for the first time and (2) when the system continually makes wrong recommendations because of prior misleading assumptions. In this work, we introduce concepts from the Active Learning theory to mitigate the impact of such scenarios. We modify three traditional bandits to recommend items with a higher potential to get more user information without decreasing the model's accuracy when an uncertain scenario is observed. Our experiments show that the modified models outperform all baselines by increasing the cumulative reward in the long run. Moreover, a counterfactual evaluation validates that such improvements were not simply achieved due to the bias of offline datasets."
The Datasets Dilemma: How Much Do We Really Know About Recommendation Datasets?,"we adopt a systematic and comprehensive approach to understand the datasets used for implicit feedback based top-K recommendation. amazon books, goodreads etc.",https://doi.org/10.1145/3488560.3498519,Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining,2022,"['Jin Chin', 'Yile Chen', 'Gao Cong']",Research,"There has been sustained interest from both academia and industry throughout the years due to the importance and practicability of recommendation systems. However, several recent papers have pointed out critical issues with the evaluation process in recommender systems. Likewise, this paper takes an in-depth look at a fundamental but often neglected aspect of the evaluation procedure, i.e. the datasets themselves. To do so, we adopt a systematic and comprehensive approach to understand the datasets used for implicit feedback based top-K recommendation. We start by examining recent papers from top-tier conferences to find out how different datasets have been utilised thus far. Next, we look at the characteristics of these datasets to understand their similarities and differences. Finally, we conduct an empirical study to determine whether the choice of datasets used for evaluation can influence the observations and/or conclusions obtained. Our findings suggest that greater attention needs to be paid to the selection process of datasets used for evaluating recommender systems in order to improve the robustness of the obtained results."
On Sampling Collaborative Filtering Datasets,We study the practical consequences of dataset sampling strategies on the ranking performance of recommendation algorithms. goodreads comics,https://doi.org/10.1145/3488560.3498439,Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining,2022,"['Noveen Sachdeva', 'Carole-Jean Wu', 'Julian McAuley']",Research,"We study the practical consequences of dataset sampling strategies on the ranking performance of recommendation algorithms. Recommender systems are generally trained and evaluated on samples of larger datasets. Samples are often taken in a naive or ad-hoc fashion: e.g. by sampling a dataset randomly or by selecting users or items with many interactions. As we demonstrate, commonly-used data sampling schemes can have significant consequences on algorithm performance. Following this observation, this paper makes three main contributions: (1) characterizing the effect of sampling on algorithm performance, in terms of algorithm and dataset characteristics (e.g. sparsity characteristics, sequential dynamics, etc.); (2) designing SVP-CF, which is a data-specific sampling strategy, that aims to preserve the relative performance of models after sampling, and is especially suited to long-tailed interaction data; and (3) developing an oracle, DATA-GENIE, which can suggest the sampling scheme that is most likely to preserve model performance for a given dataset. The main benefit of DATA-GENIE is that it will allow recommender system practitioners to quickly prototype and compare various approaches, while remaining confident that algorithm performance will be preserved, once the algorithm is retrained and deployed on the complete data. Detailed experiments show that using DATA-GENIE, we can discard upto 5x more data than any sampling strategy with the same level of performance."
Closed-Loop Opinion Formation,we look at whether the use of recommender system can affect user experience and user opinions in a systematic way. bookcrossing,https://doi.org/10.1145/3091478.3091483,Proceedings of the 2017 ACM on Web Science Conference,2017,"['Larissa Spinelli', 'Mark Crovella']",Research,"When information sources are moderated by recommender systems, so-called ""filter bubbles"" may restrict the diversity of content made available to users, potentially affecting their opinions. User opinions may in turn affect the output of recommender systems. In this work we ask how the dynamical system defined by user and recommender systems behaves, as each element evolves in time. In particular, we look at whether the use of recommender system can affect user experience and user opinions in a systematic way. We define and analyze three metrics to understand those effects - intensity, simplification, and divergence - and we explore both link-based and ratings-based recommender systems. Our results suggest that previous studies of this problem have been too simplistic, and that user opinions can evolve in complex ways under the influence of personalized information sources."
Social book search: comparing topical relevance judgements and book suggestions for evaluation,"About forums vs mechanical turk suggestions of books, not automated rs. librarything",https://doi.org/10.1145/2396761.2396788,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,2012,"['Marijn Koolen', 'Jaap Kamps', 'Gabriella Kazai']",Research,"The Web and social media give us access to a wealth of information, not only different in quantity but also in character---traditional descriptions from professionals are now supplemented with user generated content. This challenges modern search systems based on the classical model of topical relevance and ad hoc search: How does their effectiveness transfer to the changing nature of information and to the changing types of information needs and search tasks? We use the INEX 2011 Books and Social Search Track's collection of book descriptions from Amazon and social cataloguing site LibraryThing. We compare classical IR with social book search in the context of the LibraryThing discussion forums where members ask for book suggestions. Specifically, we compare book suggestions on the forum with Mechanical Turk judgements on topical relevance and recommendation, both the judgements directly and their resulting evaluation of retrieval systems. First, the book suggestions on the forum are a complete enough set of relevance judgements for system evaluation. Second, topical relevance judgements result in a different system ranking from evaluation based on the forum suggestions. Although it is an important aspect for social book search, topical relevance is not sufficient for evaluation. Third, professional metadata alone is often not enough to determine the topical relevance of a book. User reviews provide a better signal for topical relevance. Fourth, user-generated content is more effective for social book search than professional metadata. Based on our findings, we propose an experimental evaluation that better reflects the complexities of social book search."
Envisioning Information Access Systems: What Makes for Good Tools and a Healthy Web?,in this conceptual article we investigate fundamental questions concerning information access from user and societal viewpoints. ,https://doi.org/10.1145/3649468,missing,2024,"['Chirag Shah', 'Emily Bender']",Research,"We observe a recent trend toward applying large language models (LLMs) in search and positioning them as effective information access systems. While the interfaces may look appealing and the apparent breadth of applicability is exciting, we are concerned that the field is rushing ahead with a technology without sufficient study of the uses it is meant to serve, how it would be used, and what its use would mean. We argue that it is important to reassert the central research focus of the field of information retrieval, because information access is not merely an application to be solved by the so-called ‘AI’ techniques du jour. Rather, it is a key human activity, with impacts on both individuals and society. As information scientists, we should be asking what do people and society want and need from information access systems and how do we design and build systems to meet those needs? With that goal, in this conceptual article we investigate fundamental questions concerning information access from user and societal viewpoints. We revisit foundational work related to information behavior, information seeking, information retrieval, information filtering, and information access to resurface what we know about these fundamental questions and what may be missing. We then provide our conceptual framing about how we could fill this gap, focusing on methods as well as experimental and evaluation frameworks. We consider the Web as an information ecosystem and explore the ways in which synthetic media, produced by LLMs and otherwise, endangers that ecosystem. The primary goal of this conceptual article is to shed light on what we still do not know about the potential impacts of LLM-based information access systems, how to advance our understanding of user behaviors, and where the next generations of students, scholars, and developers could fruitfully invest their energies."
Open Knowledge Enrichment for Long-tail Entities,"we propose a full-fledged approach to knowledge enrichment, which predicts missing properties and infers true facts of long-tail entities from the open Web. goodreads(google?)",https://doi.org/10.1145/3366423.3380123,Proceedings of The Web Conference 2020,2020,"['Ermei Cao', 'Difeng Wang', 'Jiacheng Huang', 'Wei Hu']",Research,"Knowledge bases (KBs) have gradually become a valuable asset for many AI applications. While many current KBs are quite large, they are widely acknowledged as incomplete, especially lacking facts of long-tail entities, e.g., less famous persons. Existing approaches enrich KBs mainly on completing missing links or filling missing values. However, they only tackle a part of the enrichment problem and lack specific considerations regarding long-tail entities. In this paper, we propose a full-fledged approach to knowledge enrichment, which predicts missing properties and infers true facts of long-tail entities from the open Web. Prior knowledge from popular entities is leveraged to improve every enrichment step. Our experiments on the synthetic and real-world datasets and comparison with related work demonstrate the feasibility and superiority of the approach."
